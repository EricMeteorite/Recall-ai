"""Recall æ ¸å¿ƒå¼•æ“ - ç»Ÿä¸€çš„è®°å¿†ç®¡ç†å…¥å£"""

import os
import time
import uuid
from typing import List, Dict, Any, Optional, Union
from dataclasses import dataclass, field

from .version import __version__
# æ³¨æ„ï¼šRecallInit å’Œ LightweightConfig ä¿ç•™ç”¨äºæœªæ¥æ‰©å±•
from .init import RecallInit  # noqa: F401 - ä¿ç•™ç”¨äº CLI ç­‰åœºæ™¯
from .config import LightweightConfig  # noqa: F401 - ä¿ç•™ç”¨äºé…ç½®è¿ç§»
from .models import Entity, EntityType
from .storage import (
    VolumeManager, ConsolidatedMemory, ConsolidatedEntity,
    MultiTenantStorage, MemoryScope, CoreSettings
)
from .index import EntityIndex, InvertedIndex, VectorIndex, OptimizedNgramIndex
from .graph import KnowledgeGraph, RelationExtractor
from .processor import (
    EntityExtractor, ForeshadowingTracker,
    ConsistencyChecker, MemorySummarizer, ScenarioDetector,
    ForeshadowingAnalyzer, ForeshadowingAnalyzerConfig, AnalysisResult,
    ContextTracker, ContextType
)

# v4.0 Phase 1/2 å¯é€‰æ¨¡å—ï¼ˆå»¶è¿Ÿå¯¼å…¥ä»¥ä¿æŒå‘åå…¼å®¹ï¼‰
# è¿™äº›æ¨¡å—ä»…åœ¨é…ç½®å¯ç”¨æ—¶æ‰ä¼šåŠ è½½
from .processor.foreshadowing import Foreshadowing
from .retrieval import EightLayerRetriever, ContextBuilder
from .utils import (
    LLMClient, WarmupManager, PerformanceMonitor,
    EnvironmentManager
)
from .utils.perf_monitor import MetricType
from .embedding import EmbeddingConfig
from .embedding.base import EmbeddingBackendType


@dataclass
class AddResult:
    """æ·»åŠ è®°å¿†ç»“æœ"""
    id: str
    success: bool
    entities: List[str] = field(default_factory=list)
    message: str = ""
    consistency_warnings: List[str] = field(default_factory=list)  # ä¸€è‡´æ€§è­¦å‘Š


@dataclass
class SearchResult:
    """æœç´¢ç»“æœ"""
    id: str
    content: str
    score: float
    metadata: Dict[str, Any] = field(default_factory=dict)
    entities: List[str] = field(default_factory=list)


class RecallEngine:
    """Recall æ ¸å¿ƒå¼•æ“
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. è®°å¿†å­˜å‚¨å’Œæ£€ç´¢
    2. å®ä½“å’Œå…³ç³»ç®¡ç†
    3. ä¼ç¬”è¿½è¸ª
    4. ä¸€è‡´æ€§æ£€æŸ¥
    5. ä¸Šä¸‹æ–‡æ„å»º
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
    ```python
    from recall import RecallEngine
    
    # åˆå§‹åŒ–
    engine = RecallEngine()
    
    # æ·»åŠ è®°å¿†
    result = engine.add("ç”¨æˆ·å–œæ¬¢å–å’–å•¡", user_id="user1")
    
    # æœç´¢è®°å¿†
    memories = engine.search("å’–å•¡", user_id="user1")
    
    # æ„å»ºä¸Šä¸‹æ–‡
    context = engine.build_context(
        query="æ¨èä¸€äº›é¥®å“",
        user_id="user1"
    )
    ```
    """
    
    def __init__(
        self,
        data_root: Optional[str] = None,
        llm_model: Optional[str] = None,
        llm_api_key: Optional[str] = None,
        lightweight: bool = False,
        embedding_config: Optional[EmbeddingConfig] = None,
        auto_warmup: bool = True,
        foreshadowing_config: Optional[ForeshadowingAnalyzerConfig] = None
    ):
        """åˆå§‹åŒ– Recall å¼•æ“
        
        Args:
            data_root: æ•°æ®å­˜å‚¨æ ¹ç›®å½•ï¼Œé»˜è®¤ä¸º ./recall_data
            llm_model: LLM æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º gpt-3.5-turbo
            llm_api_key: LLM API Key
            lightweight: æ˜¯å¦ä½¿ç”¨è½»é‡æ¨¡å¼ï¼ˆçº¦80MBå†…å­˜ï¼Œæ— è¯­ä¹‰æœç´¢ï¼‰
            embedding_config: Embedding é…ç½®ï¼Œæ”¯æŒä¸‰ç§æ¨¡å¼ï¼š
                - None/è‡ªåŠ¨: æ ¹æ®ç¯å¢ƒè‡ªåŠ¨é€‰æ‹©
                - EmbeddingConfig.lightweight(): è½»é‡æ¨¡å¼ï¼Œ~100MBå†…å­˜
                - EmbeddingConfig.hybrid_openai(key): Hybridæ¨¡å¼ï¼Œ~150MBå†…å­˜
                - EmbeddingConfig.hybrid_siliconflow(key): Hybridæ¨¡å¼ï¼ˆå›½å†…ï¼‰
                - EmbeddingConfig.full(): å®Œæ•´æ¨¡å¼ï¼Œ~1.5GBå†…å­˜
            auto_warmup: æ˜¯å¦è‡ªåŠ¨é¢„çƒ­æ¨¡å‹
            foreshadowing_config: ä¼ç¬”åˆ†æå™¨é…ç½®ï¼ˆå¯é€‰ï¼‰
                - None/é»˜è®¤: æ‰‹åŠ¨æ¨¡å¼ï¼Œä¸å¯ç”¨è‡ªåŠ¨åˆ†æ
                - ForeshadowingAnalyzerConfig.llm_based(...): LLM è¾…åŠ©æ¨¡å¼
        """
        # 1. åˆå§‹åŒ–ç¯å¢ƒ
        self.env_manager = EnvironmentManager(data_root)
        self.env_manager.setup()
        self.data_root = str(self.env_manager.data_root)
        
        # 2. åŠ è½½é…ç½®
        self.config = self.env_manager.load_config()
        
        # ä¿å­˜ä¼ç¬”åˆ†æå™¨é…ç½®ï¼ˆç¨ååœ¨ _init_components ä¸­ä½¿ç”¨ï¼‰
        self._foreshadowing_config = foreshadowing_config
        
        # 3. ç¡®å®š Embedding é…ç½®
        if lightweight:
            self.embedding_config = EmbeddingConfig.lightweight()
        elif embedding_config:
            self.embedding_config = embedding_config
        else:
            # è‡ªåŠ¨é€‰æ‹©
            from .embedding.factory import auto_select_backend
            self.embedding_config = auto_select_backend()
        
        # æ ¹æ®æœ€ç»ˆçš„ embedding_config ç¡®å®šæ˜¯å¦ä¸ºè½»é‡æ¨¡å¼
        self.lightweight = (self.embedding_config.backend == EmbeddingBackendType.NONE)
        
        # 4. åˆå§‹åŒ–ç»„ä»¶
        self._init_components(llm_model, llm_api_key)
        
        # 5. é¢„çƒ­
        if auto_warmup and not lightweight and self.embedding_config.backend == EmbeddingBackendType.LOCAL:
            self._warmup()
        
        # 6. æ¢å¤å†…å®¹ç¼“å­˜ï¼ˆç¡®ä¿é‡å¯åæ£€ç´¢èƒ½æ‰¾åˆ°å†…å®¹ï¼‰
        self._rebuild_content_cache()
        
        # æ‰“å°æ¨¡å¼ä¿¡æ¯
        mode = self._get_mode_name()
        print(f"[Recall v{__version__}] å¼•æ“åˆå§‹åŒ–å®Œæˆ ({mode})")
    
    def _get_mode_name(self) -> str:
        """è·å–å½“å‰æ¨¡å¼åç§°"""
        backend = self.embedding_config.backend
        if backend == EmbeddingBackendType.NONE:
            return "è½»é‡æ¨¡å¼"
        elif backend == EmbeddingBackendType.LOCAL:
            return "å®Œæ•´æ¨¡å¼"
        elif backend == EmbeddingBackendType.OPENAI:
            return "Hybridæ¨¡å¼-OpenAI"
        elif backend == EmbeddingBackendType.SILICONFLOW:
            return "Hybridæ¨¡å¼-ç¡…åŸºæµåŠ¨"
        elif backend == EmbeddingBackendType.CUSTOM:
            return "Hybridæ¨¡å¼-è‡ªå®šä¹‰API"
        return "æœªçŸ¥æ¨¡å¼"
    
    def _init_components(
        self,
        llm_model: Optional[str],
        llm_api_key: Optional[str]
    ):
        """åˆå§‹åŒ–å„ç»„ä»¶"""
        # LLMå®¢æˆ·ç«¯ï¼ˆä¼˜å…ˆä½¿ç”¨ LLM_API_KEYï¼Œå…¼å®¹æ—§çš„ OPENAI_API_KEYï¼‰
        model = llm_model or os.environ.get('LLM_MODEL') or self.config.get('llm', {}).get('model', 'gpt-4o-mini')
        api_key = llm_api_key or os.environ.get('LLM_API_KEY') or os.environ.get('OPENAI_API_KEY')
        api_base = os.environ.get('LLM_API_BASE')
        self.llm_client = LLMClient(model=model, api_key=api_key, api_base=api_base) if api_key else None
        
        if self.llm_client:
            print(f"[Recall] LLM å®¢æˆ·ç«¯å·²åˆå§‹åŒ– (æ¨¡å‹: {model})")
        else:
            print("[Recall] LLM å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼ˆæœªé…ç½® LLM_API_KEYï¼‰")
        
        # å­˜å‚¨å±‚
        self.storage = MultiTenantStorage(
            base_path=os.path.join(self.data_root, 'data')
        )
        
        # åˆ†å·å­˜å‚¨ï¼ˆArchiveåŸæ–‡ä¿å­˜ - ç¡®ä¿100%ä¸é—å¿˜ï¼‰
        self.volume_manager = VolumeManager(
            data_path=os.path.join(self.data_root, 'data')
        )
        
        # ç´¢å¼•å±‚ï¼ˆè½»é‡æ¨¡å¼å»¶è¿ŸåŠ è½½ï¼‰
        self._entity_index: Optional[EntityIndex] = None
        self._inverted_index: Optional[InvertedIndex] = None
        self._vector_index: Optional[VectorIndex] = None
        self._ngram_index: Optional[OptimizedNgramIndex] = None
        
        if not self.lightweight:
            self._init_indexes()
        
        # å¤„ç†å™¨å±‚ï¼ˆéœ€è¦å…ˆåˆå§‹åŒ–ï¼Œå› ä¸ºå›¾è°±å±‚ä¾èµ–ï¼‰
        self.entity_extractor = EntityExtractor()
        
        # è·å–Embeddingåç«¯ï¼ˆç”¨äºè¯­ä¹‰å»é‡ï¼‰
        embedding_backend_for_trackers = None
        if self._vector_index and self._vector_index.enabled:
            embedding_backend_for_trackers = self._vector_index.embedding_backend
        
        # ä¼ç¬”è¿½è¸ªå™¨ï¼ˆæ”¯æŒè¯­ä¹‰å»é‡ï¼‰
        # ä½¿ç”¨æ–°çš„ {user_id}/{character_id}/ å­˜å‚¨ç»“æ„
        self.foreshadowing_tracker = ForeshadowingTracker(
            base_path=os.path.join(self.data_root, 'data'),
            embedding_backend=embedding_backend_for_trackers
        )
        
        # ä¼ç¬”åˆ†æå™¨ï¼ˆå¯é€‰åŠŸèƒ½ï¼Œé»˜è®¤æ‰‹åŠ¨æ¨¡å¼ï¼‰
        # ä¼ å…¥ memory_provider ç”¨äºä»å·²ä¿å­˜è®°å¿†è·å–å¯¹è¯ï¼Œæé«˜å¯é æ€§
        # ä¼ å…¥ storage_dir ç”¨äºæŒä¹…åŒ–åˆ†æçŠ¶æ€ï¼ŒæœåŠ¡å™¨é‡å¯ä¸ä¸¢å¤±
        self.foreshadowing_analyzer = ForeshadowingAnalyzer(
            tracker=self.foreshadowing_tracker,
            config=self._foreshadowing_config,  # å¯èƒ½æ˜¯ Noneï¼Œä¼šä½¿ç”¨é»˜è®¤æ‰‹åŠ¨æ¨¡å¼
            storage_dir=os.path.join(self.data_root, 'data', 'foreshadowing_analyzer'),
            memory_provider=self._get_recent_memories_for_analysis
        )
        
        # L0 æ ¸å¿ƒè®¾å®šï¼ˆè§’è‰²å¡ã€ä¸–ç•Œè§‚ã€è§„åˆ™ç­‰ï¼‰
        # æå‰åŠ è½½ï¼Œå› ä¸º ConsistencyChecker éœ€è¦ absolute_rules
        self.core_settings = CoreSettings.load(
            data_path=os.path.join(self.data_root, 'data')
        )
        
        # ä¸€è‡´æ€§æ£€æŸ¥å™¨ï¼ˆä¼ å…¥ç”¨æˆ·å®šä¹‰çš„ç»å¯¹è§„åˆ™ + LLMå®¢æˆ·ç«¯ç”¨äºè¯­ä¹‰æ£€æµ‹ï¼‰
        self.consistency_checker = ConsistencyChecker(
            absolute_rules=self.core_settings.absolute_rules,
            llm_client=self.llm_client  # å¯ç”¨LLMè¯­ä¹‰è§„åˆ™æ£€æµ‹
        )
        self.memory_summarizer = MemorySummarizer(llm_client=self.llm_client)
        self.scenario_detector = ScenarioDetector()
        
        # æŒä¹…ä¸Šä¸‹æ–‡è¿½è¸ªå™¨ï¼ˆè¿½è¸ªæŒä¹…æ€§å‰ææ¡ä»¶ï¼‰
        # ä½¿ç”¨åŒä¸€ä¸ªembedding_backendç”¨äºè¯­ä¹‰å»é‡
        # ä½¿ç”¨æ–°çš„ {user_id}/{character_id}/ å­˜å‚¨ç»“æ„
        # ä¼ å…¥ memory_provider ç”¨äºä»å·²ä¿å­˜è®°å¿†è·å–å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œå¸®åŠ© LLM æ›´å¥½æå–æ¡ä»¶
        self.context_tracker = ContextTracker(
            base_path=os.path.join(self.data_root, 'data'),
            llm_client=self.llm_client,
            embedding_backend=embedding_backend_for_trackers,
            memory_provider=self._get_recent_memories_for_analysis
        )
        
        # é•¿æœŸè®°å¿†å±‚ï¼ˆL1 ConsolidatedMemoryï¼‰
        self.consolidated_memory = ConsolidatedMemory(
            data_path=os.path.join(self.data_root, 'data')
        )
        
        # å›¾è°±å±‚
        self.knowledge_graph = KnowledgeGraph(
            data_path=os.path.join(self.data_root, 'data')
        )
        self.relation_extractor = RelationExtractor(
            entity_extractor=self.entity_extractor
        )
        
        # æ£€ç´¢å±‚ - æä¾›å†…å®¹å›è°ƒ
        self.retriever = EightLayerRetriever(
            bloom_filter=self._ngram_index.bloom_filter if self._ngram_index else None,
            inverted_index=self._inverted_index,
            entity_index=self._entity_index,
            ngram_index=self._ngram_index,
            vector_index=self._vector_index,
            llm_client=self.llm_client,
            content_store=self._get_memory_content_by_id
        )
        self.context_builder = ContextBuilder()
        
        # ç›‘æ§
        self.monitor = PerformanceMonitor(auto_collect=False)
        
        # é¢„åŠ è½½æœ€è¿‘çš„å·ï¼ˆç¡®ä¿çƒ­æ•°æ®åœ¨å†…å­˜ä¸­ï¼Œæ”¯æŒä¸Šä¸‡è½®RPï¼‰
        self.volume_manager.preload_recent()
        
        # æ£€æŸ¥å¹¶ä¸ºå·²æœ‰çš„ä¼ç¬”/æ¡ä»¶è¡¥å»º VectorIndex ç´¢å¼•ï¼ˆé¦–æ¬¡å‡çº§æ—¶æ‰§è¡Œï¼‰
        self._check_and_rebuild_index()
        
        # v4.0 Phase 1 å¯é€‰æ¨¡å—åˆå§‹åŒ–ï¼ˆåŸºäºé…ç½®å¼€å…³ï¼‰
        self._init_v4_modules()
    
    def _init_v4_modules(self):
        """åˆå§‹åŒ– v4.0 Phase 1/2 å¯é€‰æ¨¡å—
        
        è¿™äº›æ¨¡å—åŸºäºé…ç½®æ–‡ä»¶ä¸­çš„å¼€å…³å†³å®šæ˜¯å¦å¯ç”¨ï¼š
        - TEMPORAL_GRAPH_ENABLED: æ—¶æ€çŸ¥è¯†å›¾è°±
        - CONTRADICTION_DETECTION_ENABLED: çŸ›ç›¾æ£€æµ‹
        - FULLTEXT_ENABLED: å…¨æ–‡æ£€ç´¢ (BM25)
        
        è®¾è®¡åŸåˆ™ï¼š
        1. é»˜è®¤å…³é—­ï¼Œä¸å½±å“ç°æœ‰åŠŸèƒ½
        2. å³ä½¿å¯ç”¨å¤±è´¥ä¹Ÿä¸å½±å“å¼•æ“è¿è¡Œ
        3. æ‰€æœ‰ Phase 1 æ¨¡å—éƒ½æ˜¯å¯é€‰çš„å¢å¼ºåŠŸèƒ½
        """
        # åˆå§‹åŒ–ä¸º Noneï¼Œè¡¨ç¤ºæœªå¯ç”¨
        self.temporal_graph = None
        self.contradiction_manager = None
        self.fulltext_index = None
        
        # è¯»å–é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡ï¼‰
        temporal_enabled = os.environ.get('TEMPORAL_GRAPH_ENABLED', 'false').lower() == 'true'
        contradiction_enabled = os.environ.get('CONTRADICTION_DETECTION_ENABLED', 'false').lower() == 'true'
        fulltext_enabled = os.environ.get('FULLTEXT_ENABLED', 'false').lower() == 'true'
        
        # 1. æ—¶æ€çŸ¥è¯†å›¾è°±
        if temporal_enabled:
            try:
                from .graph import TemporalKnowledgeGraph
                self.temporal_graph = TemporalKnowledgeGraph(
                    data_path=os.path.join(self.data_root, 'data')
                )
                print("[Recall v4.0] æ—¶æ€çŸ¥è¯†å›¾è°±å·²å¯ç”¨")
            except Exception as e:
                print(f"[Recall v4.0] æ—¶æ€çŸ¥è¯†å›¾è°±åˆå§‹åŒ–å¤±è´¥ï¼ˆä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼‰: {e}")
        
        # 2. çŸ›ç›¾æ£€æµ‹ç®¡ç†å™¨
        if contradiction_enabled:
            try:
                from .graph import ContradictionManager, DetectionStrategy
                # ç­–ç•¥æ˜ å°„ï¼šEMBEDDING->HYBRID, LLM->LLM_ONLY, é»˜è®¤ HYBRID
                strategy_str = os.environ.get('CONTRADICTION_DETECTION_STRATEGY', 'HYBRID').upper()
                strategy_map = {
                    'EMBEDDING': DetectionStrategy.HYBRID,  # å…¼å®¹æ—§é…ç½®
                    'LLM': DetectionStrategy.LLM_ONLY,
                    'HYBRID': DetectionStrategy.HYBRID,
                    'RULE': DetectionStrategy.RULE_ONLY,
                    'AUTO': DetectionStrategy.AUTO,
                }
                strategy = strategy_map.get(strategy_str, DetectionStrategy.HYBRID)
                
                self.contradiction_manager = ContradictionManager(
                    data_path=os.path.join(self.data_root, 'data'),
                    strategy=strategy,
                    llm_client=self.llm_client
                )
                print(f"[Recall v4.0] çŸ›ç›¾æ£€æµ‹å·²å¯ç”¨ (ç­–ç•¥: {strategy.value})")
            except Exception as e:
                print(f"[Recall v4.0] çŸ›ç›¾æ£€æµ‹åˆå§‹åŒ–å¤±è´¥ï¼ˆä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼‰: {e}")
        
        # 3. å…¨æ–‡æ£€ç´¢ç´¢å¼• (BM25)
        if fulltext_enabled:
            try:
                from .index import FullTextIndex, BM25Config
                k1 = float(os.environ.get('FULLTEXT_K1', '1.5'))
                b = float(os.environ.get('FULLTEXT_B', '0.75'))
                
                self.fulltext_index = FullTextIndex(
                    data_path=os.path.join(self.data_root, 'index', 'fulltext'),
                    config=BM25Config(k1=k1, b=b)
                )
                print(f"[Recall v4.0] å…¨æ–‡æ£€ç´¢å·²å¯ç”¨ (BM25 k1={k1}, b={b})")
            except Exception as e:
                print(f"[Recall v4.0] å…¨æ–‡æ£€ç´¢åˆå§‹åŒ–å¤±è´¥ï¼ˆä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼‰: {e}")
    
    def _check_and_rebuild_index(self):
        """æ£€æŸ¥å¹¶ä¸ºå·²æœ‰ä¼ç¬”/æ¡ä»¶è¡¥å»º VectorIndex ç´¢å¼•
        
        ä½¿ç”¨æ ‡è®°æ–‡ä»¶ .index_rebuilt_v3 æ¥åˆ¤æ–­æ˜¯å¦å·²ç»è¿ç§»è¿‡ã€‚
        v3 ç‰ˆæœ¬æ”¯æŒç´¢å¼•å½’æ¡£æ–‡ä»¶ (archive/*.jsonl)ã€‚
        å¦‚æœæ²¡æœ‰ VectorIndex æˆ–å·²ç¦ç”¨ï¼Œåˆ™è·³è¿‡ã€‚
        """
        if not self._vector_index or not self._vector_index.enabled:
            return
        
        marker_file = os.path.join(self.data_root, 'data', '.index_rebuilt_v3')
        if os.path.exists(marker_file):
            return  # å·²ç»è¿ç§»è¿‡
        
        import logging
        import glob
        logger = logging.getLogger(__name__)
        logger.info("[Recall] æ£€æµ‹åˆ°é¦–æ¬¡å‡çº§æˆ–ç‰ˆæœ¬æ›´æ–°ï¼Œå¼€å§‹ä¸ºå·²æœ‰ä¼ç¬”/æ¡ä»¶è¡¥å»º VectorIndex ç´¢å¼•...")
        
        indexed_count = 0
        archived_count = 0
        
        # 1. ç´¢å¼•æ‰€æœ‰ä¼ç¬”å’Œæ¡ä»¶ï¼ˆåŒ…æ‹¬æ´»è·ƒçš„å’Œå½’æ¡£çš„ï¼‰
        data_path = os.path.join(self.data_root, 'data')
        if os.path.exists(data_path):
            for user_id in os.listdir(data_path):
                user_path = os.path.join(data_path, user_id)
                if not os.path.isdir(user_path) or user_id.startswith('.'):
                    continue
                for character_id in os.listdir(user_path):
                    char_path = os.path.join(user_path, character_id)
                    if not os.path.isdir(char_path):
                        continue
                    
                    # 1.1 ç´¢å¼•æ´»è·ƒä¼ç¬” (foreshadowings.json)
                    fsh_file = os.path.join(char_path, 'foreshadowings.json')
                    if os.path.exists(fsh_file):
                        try:
                            import json
                            with open(fsh_file, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                            foreshadowings = data.get('foreshadowings', {})
                            for fsh_id, fsh in foreshadowings.items():
                                content = fsh.get('content', '')
                                if content:
                                    # æ³¨æ„ï¼šfsh_id å·²ç»æ˜¯ fsh_{counter}_{timestamp} æ ¼å¼
                                    # ä¸éœ€è¦å†åŠ  fsh_ å‰ç¼€ï¼Œä¸ plant_foreshadowing ä¿æŒä¸€è‡´
                                    doc_id = f"{user_id}_{character_id}_{fsh_id}"
                                    self._vector_index.add_text(doc_id, content)
                                    indexed_count += 1
                        except Exception as e:
                            logger.warning(f"[Recall] ç´¢å¼•ä¼ç¬”å¤±è´¥ ({user_id}/{character_id}): {e}")
                    
                    # 1.2 ç´¢å¼•æ´»è·ƒæ¡ä»¶ (contexts.json)
                    ctx_file = os.path.join(char_path, 'contexts.json')
                    if os.path.exists(ctx_file):
                        try:
                            import json
                            with open(ctx_file, 'r', encoding='utf-8') as f:
                                contexts = json.load(f)
                            for ctx in contexts:
                                if ctx.get('is_active', True):
                                    content = ctx.get('content', '')
                                    ctx_id = ctx.get('id', '')
                                    if content and ctx_id:
                                        doc_id = f"ctx_{user_id}_{character_id}_{ctx_id}"
                                        self._vector_index.add_text(doc_id, content)
                                        indexed_count += 1
                        except Exception as e:
                            logger.warning(f"[Recall] ç´¢å¼•æ¡ä»¶å¤±è´¥ ({user_id}/{character_id}): {e}")
                    
                    # 1.3 ç´¢å¼•å½’æ¡£ä¼ç¬” (archive/foreshadowings*.jsonl)
                    archive_dir = os.path.join(char_path, 'archive')
                    if os.path.isdir(archive_dir):
                        # åŒ¹é… foreshadowings.jsonl å’Œ foreshadowings_001.jsonl ç­‰
                        fsh_archive_files = glob.glob(os.path.join(archive_dir, 'foreshadowings*.jsonl'))
                        for archive_file in fsh_archive_files:
                            try:
                                with open(archive_file, 'r', encoding='utf-8') as f:
                                    for line in f:
                                        line = line.strip()
                                        if not line:
                                            continue
                                        fsh = json.loads(line)
                                        fsh_id = fsh.get('id', '')
                                        content = fsh.get('content', '')
                                        if content and fsh_id:
                                            doc_id = f"{user_id}_{character_id}_{fsh_id}"
                                            self._vector_index.add_text(doc_id, content)
                                            archived_count += 1
                            except Exception as e:
                                logger.warning(f"[Recall] ç´¢å¼•å½’æ¡£ä¼ç¬”å¤±è´¥ ({archive_file}): {e}")
                        
                        # 1.4 ç´¢å¼•å½’æ¡£æ¡ä»¶ (archive/contexts*.jsonl)
                        ctx_archive_files = glob.glob(os.path.join(archive_dir, 'contexts*.jsonl'))
                        for archive_file in ctx_archive_files:
                            try:
                                with open(archive_file, 'r', encoding='utf-8') as f:
                                    for line in f:
                                        line = line.strip()
                                        if not line:
                                            continue
                                        ctx = json.loads(line)
                                        ctx_id = ctx.get('id', '')
                                        content = ctx.get('content', '')
                                        if content and ctx_id:
                                            doc_id = f"ctx_{user_id}_{character_id}_{ctx_id}"
                                            self._vector_index.add_text(doc_id, content)
                                            archived_count += 1
                            except Exception as e:
                                logger.warning(f"[Recall] ç´¢å¼•å½’æ¡£æ¡ä»¶å¤±è´¥ ({archive_file}): {e}")
        
        # åˆ›å»ºæ ‡è®°æ–‡ä»¶
        os.makedirs(os.path.dirname(marker_file), exist_ok=True)
        total_count = indexed_count + archived_count
        with open(marker_file, 'w') as f:
            f.write(f"indexed_at: {time.time()}\n")
            f.write(f"active_count: {indexed_count}\n")
            f.write(f"archived_count: {archived_count}\n")
            f.write(f"total_count: {total_count}\n")
        
        logger.info(f"[Recall] VectorIndex ç´¢å¼•è¡¥å»ºå®Œæˆï¼Œå…±ç´¢å¼• {total_count} æ¡è®°å½• (æ´»è·ƒ: {indexed_count}, å½’æ¡£: {archived_count})")
        
        return total_count

    def rebuild_vector_index(self, force: bool = False) -> int:
        """æ‰‹åŠ¨é‡å»º VectorIndex ç´¢å¼•
        
        ä¸ºæ‰€æœ‰ä¼ç¬”å’Œæ¡ä»¶é‡å»ºè¯­ä¹‰ç´¢å¼•ã€‚é€šå¸¸ä¸éœ€è¦æ‰‹åŠ¨è°ƒç”¨ï¼Œ
        ç³»ç»Ÿä¼šåœ¨é¦–æ¬¡å‡çº§æ—¶è‡ªåŠ¨é‡å»ºã€‚
        
        ä½¿ç”¨åœºæ™¯ï¼š
        - ç´¢å¼•æ•°æ®æŸåéœ€è¦é‡å»º
        - æ‰‹åŠ¨å¯¼å…¥äº†æ•°æ®æ–‡ä»¶
        - ä»å¤‡ä»½æ¢å¤åéœ€è¦é‡å»ºç´¢å¼•
        
        Args:
            force: æ˜¯å¦å¼ºåˆ¶é‡å»ºï¼ˆåˆ é™¤æ ‡è®°æ–‡ä»¶åé‡å»ºï¼‰
            
        Returns:
            int: ç´¢å¼•çš„è®°å½•æ•°é‡
        """
        if force:
            # åˆ é™¤ v3 æ ‡è®°æ–‡ä»¶ï¼ˆå½“å‰ç‰ˆæœ¬ï¼‰
            marker_file_v3 = os.path.join(self.data_root, 'data', '.index_rebuilt_v3')
            if os.path.exists(marker_file_v3):
                os.remove(marker_file_v3)
            # å…¼å®¹ï¼šä¹Ÿåˆ é™¤æ—§ç‰ˆæœ¬æ ‡è®°æ–‡ä»¶
            marker_file_v2 = os.path.join(self.data_root, 'data', '.index_rebuilt_v2')
            if os.path.exists(marker_file_v2):
                os.remove(marker_file_v2)
        
        return self._check_and_rebuild_index() or 0

    def _get_recent_memories_for_analysis(self, user_id: str, limit: int) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„è®°å¿†ç”¨äºä¼ç¬”åˆ†æ
        
        è¿™æ˜¯ ForeshadowingAnalyzer çš„ memory_provider å›è°ƒå‡½æ•°ã€‚
        ä»å·²ä¿å­˜çš„è®°å¿†ä¸­è·å–å¯¹è¯ï¼Œç¡®ä¿åˆ†æåŸºäºå·²æŒä¹…åŒ–çš„æ•°æ®ã€‚
        
        Args:
            user_id: ç”¨æˆ·/è§’è‰²ID
            limit: æœ€å¤§è¿”å›æ•°é‡
            
        Returns:
            List[Dict]: è®°å¿†åˆ—è¡¨ï¼ŒæŒ‰æ—¶é—´æ’åº
        """
        try:
            scope = self.storage.get_scope(user_id)
            memories = scope.get_all(limit=limit)
            
            # æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆæ—§ -> æ–°ï¼‰
            memories.sort(key=lambda m: m.get('metadata', {}).get('timestamp', 0))
            
            return memories
        except Exception as e:
            print(f"[Recall] è·å–è®°å¿†å¤±è´¥: {e}")
            return []
    
    def _get_memory_content_by_id(self, memory_id: str) -> Optional[str]:
        """é€šè¿‡ ID è·å–è®°å¿†å†…å®¹ï¼ˆä¾›æ£€ç´¢å™¨å›è°ƒï¼‰
        
        æŸ¥æ‰¾é¡ºåºï¼š
        1. MultiTenantStorage å†…å­˜ç¼“å­˜ï¼ˆæœ€å¿«ï¼‰
        2. VolumeManager å­˜æ¡£ï¼ˆç¡®ä¿100%ä¸é—å¿˜ï¼‰
        3. N-gram ç´¢å¼•çš„åŸæ–‡ç¼“å­˜ï¼ˆå…œåº•ï¼‰
        """
        # 1. å…ˆä» MultiTenantStorage å†…å­˜ä¸­æŸ¥æ‰¾ï¼ˆæœ€å¿«ï¼‰
        for scope_key, scope in self.storage._scopes.items():
            for memory in scope._memories:
                if memory.get('metadata', {}).get('id') == memory_id:
                    return memory.get('content', '')
        
        # 2. ä» VolumeManager å­˜æ¡£ä¸­æŸ¥æ‰¾ï¼ˆç¡®ä¿100%ä¸é—å¿˜ï¼‰
        if hasattr(self, 'volume_manager') and self.volume_manager:
            turn_data = self.volume_manager.get_turn_by_memory_id(memory_id)
            if turn_data:
                return turn_data.get('content', '')
        
        # 3. ä» N-gram ç´¢å¼•çš„åŸæ–‡ç¼“å­˜ä¸­æŸ¥æ‰¾ï¼ˆå…œåº•ï¼‰
        if self._ngram_index and hasattr(self._ngram_index, 'get_raw_content'):
            content = self._ngram_index.get_raw_content(memory_id)
            if content:
                return content
        
        return None
    
    def _init_indexes(self):
        """åˆå§‹åŒ–ç´¢å¼•"""
        index_path = os.path.join(self.data_root, 'index')
        os.makedirs(index_path, exist_ok=True)
        
        self._entity_index = EntityIndex(data_path=self.data_root)
        self._inverted_index = InvertedIndex(data_path=self.data_root)
        self._vector_index = VectorIndex(
            data_path=self.data_root,
            embedding_config=self.embedding_config
        )
        # N-gram ç´¢å¼•ï¼ˆæ”¯æŒæŒä¹…åŒ–ï¼‰
        ngram_data_path = os.path.join(self.data_root, 'index', 'ngram')
        self._ngram_index = OptimizedNgramIndex(data_path=ngram_data_path)
    
    def _rebuild_content_cache(self):
        """é‡å»ºå†…å®¹ç¼“å­˜ï¼ˆä»æŒä¹…åŒ–å­˜å‚¨æ¢å¤ï¼‰"""
        # æ‰«ææ‰€æœ‰ç”¨æˆ·ç›®å½•
        data_path = os.path.join(self.data_root, 'data')
        if not os.path.exists(data_path):
            return
        
        count = 0
        for user_dir in os.listdir(data_path):
            user_path = os.path.join(data_path, user_dir)
            if not os.path.isdir(user_path):
                continue
            
            # æ‰«æè¯¥ç”¨æˆ·ä¸‹çš„æ‰€æœ‰è§’è‰²/ä¼šè¯
            for root, dirs, files in os.walk(user_path):
                if 'memories.json' in files:
                    memories_file = os.path.join(root, 'memories.json')
                    try:
                        with open(memories_file, 'r', encoding='utf-8') as f:
                            memories = __import__('json').load(f)
                            for mem in memories:
                                mem_id = mem.get('metadata', {}).get('id')
                                content = mem.get('content', '')
                                if mem_id and content:
                                    self.retriever.cache_content(mem_id, content)
                                    count += 1
                    except Exception as e:
                        print(f"[Recall] åŠ è½½ {memories_file} å¤±è´¥: {e}")
        
        if count > 0:
            print(f"[Recall] å·²æ¢å¤ {count} æ¡è®°å¿†å†…å®¹åˆ°ç¼“å­˜")
    
    def _warmup(self):
        """é¢„çƒ­æ¨¡å‹ï¼ˆä»…å®Œæ•´æ¨¡å¼ï¼‰"""
        warmup_manager = WarmupManager()
        
        # æ³¨å†Œé¢„çƒ­ä»»åŠ¡
        warmup_manager.register(
            'entity_extractor',
            lambda: self.entity_extractor.nlp,
            priority=10
        )
        
        # åªæœ‰æœ¬åœ°æ¨¡å¼æ‰é¢„çƒ­å‘é‡æ¨¡å‹
        if self._vector_index and self._vector_index.enabled:
            if self.embedding_config.backend == EmbeddingBackendType.LOCAL:
                warmup_manager.register(
                    'vector_model',
                    lambda: self._vector_index.embedding_backend.model,
                    priority=5
                )
        
        # åå°é¢„çƒ­
        warmup_manager.warmup_async()
    
    # ==================== æ ¸å¿ƒ API ====================
    
    def add(
        self,
        content: str,
        user_id: str = "default",
        metadata: Optional[Dict[str, Any]] = None,
        check_consistency: bool = True
    ) -> AddResult:
        """æ·»åŠ è®°å¿†
        
        Args:
            content: è®°å¿†å†…å®¹
            user_id: ç”¨æˆ·ID
            metadata: å…ƒæ•°æ®
            check_consistency: æ˜¯å¦æ£€æŸ¥ä¸€è‡´æ€§
        
        Returns:
            AddResult: æ·»åŠ ç»“æœ
        """
        start_time = time.time()
        consistency_warnings = []  # æ”¶é›†ä¸€è‡´æ€§è­¦å‘Š
        
        try:
            # ã€æ–°å¢ã€‘å»é‡æ£€æŸ¥ï¼šæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨å®Œå…¨ç›¸åŒå†…å®¹çš„è®°å¿†
            scope = self.storage.get_scope(user_id)
            existing_memories = scope.get_all(limit=100)  # æ£€æŸ¥æœ€è¿‘100æ¡
            content_normalized = content.strip()
            for mem in existing_memories:
                existing_content = mem.get('content', '').strip()
                if existing_content == content_normalized:
                    print(f"[Recall] è·³è¿‡é‡å¤è®°å¿†: content_len={len(content)}, user={user_id}")
                    return AddResult(
                        id=mem.get('metadata', {}).get('id', 'unknown'),
                        success=False,
                        entities=[],
                        message="è®°å¿†å†…å®¹å·²å­˜åœ¨ï¼Œè·³è¿‡é‡å¤ä¿å­˜"
                    )
            
            # 1. æå–å®ä½“
            entities = self.entity_extractor.extract(content)
            entity_names = [e.name for e in entities]
            
            # 2. æå–å…³é”®è¯
            keywords = self.entity_extractor.extract_keywords(content)
            
            # 3. ä¸€è‡´æ€§æ£€æŸ¥
            if check_consistency:
                existing_memories = self.search(content, user_id=user_id, top_k=5)
                consistency = self.consistency_checker.check(
                    content,
                    [{'content': m.content} for m in existing_memories]
                )
                if not consistency.is_consistent:
                    # æ”¶é›†è­¦å‘Šå¹¶è®°å½•
                    for v in consistency.violations:
                        warning_msg = v.description
                        consistency_warnings.append(warning_msg)
                        print(f"[Recall] ä¸€è‡´æ€§è­¦å‘Š: {warning_msg}")
            
            # 4. ç”ŸæˆIDå¹¶å­˜å‚¨
            memory_id = f"mem_{uuid.uuid4().hex[:12]}"
            
            memory_data = {
                'id': memory_id,
                'content': content,
                'user_id': user_id,
                'entities': entity_names,
                'keywords': keywords,
                'metadata': metadata or {},
                'created_at': time.time()
            }
            
            # å­˜å‚¨åˆ°ä½œç”¨åŸŸï¼ˆæ ¸å¿ƒå­˜å‚¨ï¼‰
            scope = self.storage.get_scope(user_id)
            scope.add(content, metadata={
                'id': memory_id,
                'entities': entity_names,
                'keywords': keywords,
                **(metadata or {})
            })
            
            # === ä»¥ä¸‹æ“ä½œå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ ===
            try:
                # 4.5 ArchiveåŸæ–‡ä¿å­˜ï¼ˆç¡®ä¿100%ä¸é—å¿˜ï¼‰
                # å°†å®Œæ•´å¯¹è¯å­˜å…¥åˆ†å·å­˜å‚¨ï¼Œæ”¯æŒä»»æ„è½®æ¬¡çš„O(1)å®šä½
                turn_number = self.volume_manager.append_turn({
                    'memory_id': memory_id,
                    'user_id': user_id,
                    'content': content,
                    'entities': entity_names,
                    'keywords': keywords,
                    'metadata': metadata or {},
                    'created_at': time.time()
                })
            except Exception as e:
                print(f"[Recall] Archiveä¿å­˜å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
            
            # 5. æ›´æ–°ç´¢å¼•ï¼ˆå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼‰
            try:
                if self._entity_index:
                    for entity in entities:
                        self._entity_index.add_entity_occurrence(
                            entity_name=entity.name,
                            turn_id=memory_id,
                            context=content[:200]
                        )
                
                if self._inverted_index:
                    self._inverted_index.add_batch(keywords, memory_id)
                
                if self._ngram_index:
                    # NgamIndex.add æ¥å— (turn_id, content)
                    self._ngram_index.add(memory_id, content)
                
                if self._vector_index:
                    # VectorIndex.add_text æ¥å— (turn_id, text)
                    self._vector_index.add_text(memory_id, content)
            except Exception as e:
                # æ‰“å°æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                import traceback
                print(f"[Recall] ç´¢å¼•æ›´æ–°å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {type(e).__name__}: {e}")
                traceback.print_exc()
            
            # 5.5 ç¼“å­˜å†…å®¹åˆ°æ£€ç´¢å™¨ï¼ˆç¡®ä¿æ£€ç´¢æ—¶èƒ½è·å–å†…å®¹ï¼‰
            try:
                self.retriever.cache_content(memory_id, content)
            except Exception as e:
                print(f"[Recall] ç¼“å­˜æ›´æ–°å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {type(e).__name__}: {e}")
            
            # 5.6 æ›´æ–°é•¿æœŸè®°å¿†ï¼ˆL1 ConsolidatedMemoryï¼‰
            # æ¯ä¸ªå®ä½“éƒ½ä¼šè¢«è‡ªåŠ¨æ•´åˆå’ŒéªŒè¯
            try:
                for entity in entities:
                    consolidated_entity = ConsolidatedEntity(
                        id=f"entity_{entity.name.lower().replace(' ', '_')}",
                    name=entity.name,
                    entity_type=entity.entity_type if hasattr(entity, 'entity_type') else "UNKNOWN",
                    source_turns=[memory_id],
                    last_verified=time.strftime('%Y-%m-%dT%H:%M:%S')
                )
                self.consolidated_memory.add_or_update(consolidated_entity)
            except Exception as e:
                print(f"[Recall] é•¿æœŸè®°å¿†æ›´æ–°å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
            
            # 6. æ›´æ–°çŸ¥è¯†å›¾è°±ï¼ˆå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼‰
            try:
                relations = self.relation_extractor.extract(content, 0)  # ä¼ å…¥turn=0
                for rel in relations:
                    source_id, relation_type, target_id, source_text = rel
                    self.knowledge_graph.add_relation(
                        source_id=source_id,
                        target_id=target_id,
                        relation_type=relation_type,
                        source_text=source_text
                    )
            except Exception as e:
                print(f"[Recall] çŸ¥è¯†å›¾è°±æ›´æ–°å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
            
            # 7. è‡ªåŠ¨æå–æŒä¹…æ¡ä»¶ï¼ˆå·²ç§»è‡³ server.py ä¸­å¤„ç†ï¼Œé¿å… character_id ä¼ é€’é—®é¢˜ï¼‰
            # æ³¨æ„ï¼šä¹‹å‰è¿™é‡Œè°ƒç”¨ extract_from_text æ—¶æ²¡æœ‰ä¼ é€’ character_idï¼Œ
            # å¯¼è‡´æ‰€æœ‰æ¡ä»¶éƒ½å­˜å‚¨åˆ° "default" è§’è‰²ä¸‹ï¼Œä¸å…¶ä»–è§’è‰²æ•°æ®æ··æ·†ã€‚
            # ç°åœ¨ç”± server.py åœ¨æ·»åŠ è®°å¿†åæ­£ç¡®ä¼ é€’ character_id æ¥æå–æ¡ä»¶ã€‚
            
            # è®°å½•æ€§èƒ½
            try:
                self.monitor.record(
                    MetricType.LATENCY,
                    (time.time() - start_time) * 1000
                )
            except Exception:
                pass  # å¿½ç•¥æ€§èƒ½ç›‘æ§é”™è¯¯
            
            return AddResult(
                id=memory_id,
                success=True,
                entities=entity_names,
                message="è®°å¿†æ·»åŠ æˆåŠŸ",
                consistency_warnings=consistency_warnings
            )
        
        except Exception as e:
            print(f"[Recall] æ·»åŠ è®°å¿†å¼‚å¸¸: {type(e).__name__}: {e}")
            import traceback
            traceback.print_exc()
            return AddResult(
                id="",
                success=False,
                message=f"æ·»åŠ å¤±è´¥: {str(e)}"
            )
    
    def search(
        self,
        query: str,
        user_id: str = "default",
        top_k: int = 10,
        filters: Optional[Dict[str, Any]] = None
    ) -> List[SearchResult]:
        """æœç´¢è®°å¿†
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            user_id: ç”¨æˆ·ID
            top_k: è¿”å›æ•°é‡
            filters: è¿‡æ»¤æ¡ä»¶
        
        Returns:
            List[SearchResult]: æœç´¢ç»“æœ
        """
        # 1. æå–æŸ¥è¯¢å®ä½“å’Œå…³é”®è¯
        entities = [e.name for e in self.entity_extractor.extract(query)]
        keywords = self.entity_extractor.extract_keywords(query)
        
        # 2. æ£€æµ‹åœºæ™¯
        scenario = self.scenario_detector.detect(query)
        
        # 3. æ‰§è¡Œæ£€ç´¢
        retrieval_results = self.retriever.retrieve(
            query=query,
            entities=entities,
            keywords=keywords,
            top_k=top_k,
            filters=filters
        )
        
        # 4. è¡¥å……ä»å­˜å‚¨è·å–
        scope = self.storage.get_scope(user_id)
        stored_memories = scope.search(query, limit=top_k)
        
        # 5. åˆå¹¶ç»“æœ
        results = []
        seen_ids = set()
        
        for r in retrieval_results:
            if r.id not in seen_ids:
                results.append(SearchResult(
                    id=r.id,
                    content=r.content,
                    score=r.score,
                    metadata=r.metadata,
                    entities=r.entities
                ))
                seen_ids.add(r.id)
        
        for m in stored_memories:
            mem_id = m.get('metadata', {}).get('id', '') or m.get('id', '')
            if mem_id and mem_id not in seen_ids:
                results.append(SearchResult(
                    id=mem_id,
                    content=m.get('content', m.get('memory', '')),
                    score=m.get('score', 0.5),
                    metadata=m.get('metadata', {}),
                    entities=m.get('entities', [])
                ))
                seen_ids.add(mem_id)
        
        return results[:top_k]
    
    def get_all(
        self,
        user_id: str = "default",
        limit: int = None
    ) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰è®°å¿†
        
        Args:
            user_id: ç”¨æˆ·ID
            limit: é™åˆ¶æ•°é‡ï¼ŒNoneè¡¨ç¤ºè¿”å›å…¨éƒ¨
        
        Returns:
            List[Dict]: è®°å¿†åˆ—è¡¨
        """
        scope = self.storage.get_scope(user_id)
        return scope.get_all(limit=limit)
    
    def get_paginated(
        self,
        user_id: str = "default",
        offset: int = 0,
        limit: int = 20
    ) -> tuple:
        """åˆ†é¡µè·å–è®°å¿†ï¼ˆé«˜æ•ˆç‰ˆæœ¬ï¼‰
        
        Args:
            user_id: ç”¨æˆ·ID
            offset: åç§»é‡
            limit: æ¯é¡µæ•°é‡
        
        Returns:
            tuple: (memories, total_count)
        """
        scope = self.storage.get_scope(user_id)
        total = scope.count()
        memories = scope.get_paginated(offset=offset, limit=limit)
        return memories, total
    
    def count_memories(self, user_id: str = "default") -> int:
        """è·å–è®°å¿†æ€»æ•°ï¼ˆO(1)æ“ä½œï¼‰
        
        Args:
            user_id: ç”¨æˆ·ID
        
        Returns:
            int: è®°å¿†æ€»æ•°
        """
        scope = self.storage.get_scope(user_id)
        return scope.count()
    
    def get(
        self,
        memory_id: str,
        user_id: str = "default"
    ) -> Optional[Dict[str, Any]]:
        """è·å–å•æ¡è®°å¿†
        
        Args:
            memory_id: è®°å¿†ID
            user_id: ç”¨æˆ·ID
        
        Returns:
            Dict: è®°å¿†æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
        """
        scope = self.storage.get_scope(user_id)
        all_memories = scope.get_all()
        for memory in all_memories:
            if memory.get('metadata', {}).get('id') == memory_id:
                return memory
        return None
    
    def clear(
        self,
        user_id: str = "default"
    ) -> bool:
        """æ¸…ç©ºç”¨æˆ·çš„æ‰€æœ‰è®°å¿†
        
        Args:
            user_id: ç”¨æˆ·ID
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        scope = self.storage.get_scope(user_id)
        scope.clear()
        return True
    
    def stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯ï¼ˆget_stats çš„åˆ«åï¼‰"""
        return self.get_stats()
    
    def delete(
        self,
        memory_id: str,
        user_id: str = "default"
    ) -> bool:
        """åˆ é™¤è®°å¿†
        
        Args:
            memory_id: è®°å¿†ID
            user_id: ç”¨æˆ·ID
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        scope = self.storage.get_scope(user_id)
        return scope.delete(memory_id)
    
    def update(
        self,
        memory_id: str,
        content: str,
        user_id: str = "default",
        metadata: Optional[Dict[str, Any]] = None
    ) -> bool:
        """æ›´æ–°è®°å¿†
        
        Args:
            memory_id: è®°å¿†ID
            content: æ–°å†…å®¹
            user_id: ç”¨æˆ·ID
            metadata: æ–°å…ƒæ•°æ®
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        scope = self.storage.get_scope(user_id)
        return scope.update(memory_id, content, metadata)
    
    def build_context(
        self,
        query: str,
        user_id: str = "default",
        character_id: str = "default",
        max_tokens: int = 2000,
        include_recent: int = None,  # ä»é…ç½®è¯»å–é»˜è®¤å€¼
        include_core_facts: bool = True,
        auto_extract_context: bool = False  # é»˜è®¤å…³é—­ï¼Œé¿å…æ¯æ¬¡ç”Ÿæˆéƒ½æå–æ¡ä»¶
    ) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡ - å…¨æ–¹ä½è®°å¿†ç­–ç•¥ï¼Œç¡®ä¿100%ä¸é—æ¼ä»»ä½•ç»†èŠ‚
        
        ä¸ƒå±‚ä¸Šä¸‹æ–‡ç­–ç•¥ï¼ˆ100%ä¸é—å¿˜ä¿è¯ï¼‰ï¼š
        1. æŒä¹…æ¡ä»¶å±‚ - å·²ç¡®ç«‹çš„èƒŒæ™¯è®¾å®šï¼ˆå¦‚ç”¨æˆ·èº«ä»½ã€ç¯å¢ƒã€ç›®æ ‡ï¼‰
        2. æ ¸å¿ƒäº‹å®å±‚ - å‹ç¼©çš„å®ä½“çŸ¥è¯† + å…³ç³»å›¾è°±
        3. ç›¸å…³è®°å¿†å±‚ - ä¸æŸ¥è¯¢ç›¸å…³çš„è¯¦ç»†è®°å¿†
        4. å…³é”®å®ä½“è¡¥å……å±‚ - ä»æŒä¹…æ¡ä»¶å’Œä¼ç¬”ä¸­æå–å…³é”®è¯ï¼Œè¡¥å……æ£€ç´¢ï¼ˆæ–°å¢ï¼‰
        5. æœ€è¿‘å¯¹è¯å±‚ - ä¿æŒå¯¹è¯è¿è´¯æ€§
        6. ä¼ç¬”å±‚ - æ‰€æœ‰æ´»è·ƒä¼ç¬” + ä¸»åŠ¨æé†’
        7. åœºæ™¯ä¼˜åŒ–å±‚ - æ ¹æ®åœºæ™¯è°ƒæ•´æ£€ç´¢ç­–ç•¥
        
        Args:
            query: å½“å‰æŸ¥è¯¢
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            max_tokens: æœ€å¤§tokenæ•°ï¼ˆè¶Šå¤§èƒ½æ³¨å…¥è¶Šå¤šç»†èŠ‚ï¼‰
            include_recent: åŒ…å«çš„æœ€è¿‘å¯¹è¯æ•°ï¼ˆNone æ—¶ä»é…ç½®è¯»å– BUILD_CONTEXT_INCLUDE_RECENTï¼‰
            include_core_facts: æ˜¯å¦åŒ…å«æ ¸å¿ƒäº‹å®æ‘˜è¦
            auto_extract_context: æ˜¯å¦è‡ªåŠ¨ä»æŸ¥è¯¢ä¸­æå–æŒä¹…æ¡ä»¶ï¼ˆé»˜è®¤Falseï¼Œæ¡ä»¶æå–åœ¨ä¿å­˜è®°å¿†æ—¶è¿›è¡Œï¼‰
        
        Returns:
            str: æ„å»ºçš„ä¸Šä¸‹æ–‡
        """
        import time as _time
        import os as _os
        start_time = _time.time()
        
        # ä»é…ç½®è¯»å–é»˜è®¤å€¼
        if include_recent is None:
            include_recent = int(_os.environ.get('BUILD_CONTEXT_INCLUDE_RECENT', '10'))
        proactive_enabled = _os.environ.get('PROACTIVE_REMINDER_ENABLED', 'true').lower() in ('true', '1', 'yes')
        proactive_turns = int(_os.environ.get('PROACTIVE_REMINDER_TURNS', '50'))
        
        query_preview = query[:50].replace('\n', ' ') if len(query) > 50 else query.replace('\n', ' ')
        print(f"[Recall][Engine] ğŸ“¦ æ„å»ºä¸Šä¸‹æ–‡: user={user_id}, char={character_id}")
        print(f"[Recall][Engine]    æŸ¥è¯¢: {query_preview}{'...' if len(query) > 50 else ''}")
        print(f"[Recall][Engine]    å‚æ•°: max_tokens={max_tokens}, recent={include_recent}, proactive={proactive_enabled}")
        parts = []
        
        # ========== 0. åœºæ™¯æ£€æµ‹ï¼ˆå†³å®šæ£€ç´¢ç­–ç•¥ï¼‰==========
        scenario = self.scenario_detector.detect(query)
        retrieval_strategy = scenario.suggested_retrieval_strategy
        
        # ========== 0.5 L0 æ ¸å¿ƒè®¾å®šæ³¨å…¥ï¼ˆè§’è‰²å¡/ä¸–ç•Œè§‚/è§„åˆ™ - æœ€é«˜ä¼˜å…ˆçº§ï¼‰==========
        if hasattr(self, 'core_settings') and self.core_settings:
            # æ ¹æ®åœºæ™¯ç±»å‹è·å–å¯¹åº”çš„æ ¸å¿ƒè®¾å®š
            scenario_type = 'roleplay' if scenario.type.value in ['roleplay', 'novel_writing', 'worldbuilding'] else 'coding' if scenario.type.value == 'coding' else 'general'
            injection_text = self.core_settings.get_injection_text(scenario_type)
            if injection_text:
                parts.append(f"ã€æ ¸å¿ƒè®¾å®šã€‘\n{injection_text}")
        
        # ========== 1. æŒä¹…æ¡ä»¶å±‚ï¼ˆå·²ç¡®ç«‹çš„èƒŒæ™¯è®¾å®šï¼‰==========
        # è¿™æ˜¯æœ€é‡è¦çš„å±‚ - ç”¨æˆ·è¯´"æˆ‘æ˜¯å¤§å­¦ç”Ÿæƒ³åˆ›ä¸š"ï¼Œåç»­æ‰€æœ‰å¯¹è¯éƒ½åº”åŸºäºæ­¤
        active_contexts = self.context_tracker.get_active(user_id, character_id)
        if active_contexts:
            # æ‰¹é‡æ ‡è®°æ‰€æœ‰è¢«ä½¿ç”¨çš„æ¡ä»¶ï¼ˆæ›´æ–° last_used å’Œ use_countï¼Œåªå†™ä¸€æ¬¡æ–‡ä»¶ï¼‰
            context_ids = [ctx.id for ctx in active_contexts]
            self.context_tracker.mark_used_batch(context_ids, user_id, character_id)
            
            persistent_context = self.context_tracker.format_for_prompt(user_id, character_id)
            if persistent_context:
                parts.append(persistent_context)
        
        # è‡ªåŠ¨ä»å½“å‰æŸ¥è¯¢ä¸­æå–æ–°çš„æŒä¹…æ¡ä»¶
        if auto_extract_context and query:
            self.context_tracker.extract_from_text(query, user_id, character_id)
        
        # ========== 2. æ ¸å¿ƒäº‹å®å±‚ + å…³ç³»å›¾è°± ==========
        if include_core_facts:
            core_facts = self._build_core_facts_section(user_id, max_tokens // 5)
            if core_facts:
                parts.append(core_facts)
            
            # åˆ©ç”¨çŸ¥è¯†å›¾è°±æ‰©å±•ç›¸å…³å®ä½“
            graph_context = self._build_graph_context(query, user_id, max_tokens // 10)
            if graph_context:
                parts.append(graph_context)
        
        # ========== 3. ç›¸å…³è®°å¿†å±‚ï¼ˆè¯¦ç»†è®°å¿†ï¼‰==========
        # æ ¹æ®åœºæ™¯å’Œ token é¢„ç®—åŠ¨æ€è°ƒæ•´æ£€ç´¢æ•°é‡
        top_k = self._calculate_top_k(max_tokens, retrieval_strategy)
        memories = self.search(query, user_id=user_id, top_k=top_k)
        
        if memories:
            memory_section = self._build_memory_section(memories, max_tokens // 3)
            if memory_section:
                parts.append(memory_section)
        
        # ========== 3.5 å…³é”®å®ä½“è¡¥å……æ£€ç´¢å±‚ï¼ˆ100%ä¸é—å¿˜ä¿è¯ï¼‰==========
        # ä»æŒä¹…æ¡ä»¶å’Œä¼ç¬”ä¸­æå–å…³é”®è¯ï¼Œè¿›è¡Œè¡¥å……æ£€ç´¢
        # ç¡®ä¿å³ä½¿ query ä¸­æ²¡æœ‰ç›´æ¥æåŠï¼Œé‡è¦ä¿¡æ¯ä¹Ÿèƒ½è¢«å¬å›
        supplementary_keywords = self._extract_supplementary_keywords(user_id, character_id, active_contexts)
        if supplementary_keywords:
            supplementary_memories = self._search_by_keywords(supplementary_keywords, user_id, top_k=5)
            if supplementary_memories:
                # è¿‡æ»¤æ‰å·²ç»åœ¨ memories ä¸­çš„è®°å¿†
                existing_ids = {m.id for m in memories} if memories else set()
                new_supplementary = [m for m in supplementary_memories if m.id not in existing_ids]
                if new_supplementary:
                    supplementary_section = self._build_supplementary_section(new_supplementary)
                    if supplementary_section:
                        parts.append(supplementary_section)
        
        # ========== 4. æœ€è¿‘å¯¹è¯å±‚ ==========
        scope = self.storage.get_scope(user_id)
        recent = scope.get_recent(include_recent)
        
        if recent:
            recent_section = self._build_recent_section(recent)
            if recent_section:
                parts.append(recent_section)
        
        # ========== 5. ä¼ç¬”å±‚ï¼ˆæ‰€æœ‰æ´»è·ƒä¼ç¬” + ä¸»åŠ¨æé†’ï¼‰==========
        # ä½¿ç”¨ tracker çš„ä¸“ç”¨æ–¹æ³•ï¼ŒåŒ…å«ä¸»åŠ¨æé†’é€»è¾‘ï¼ˆé‡è¦ä¼ç¬”é•¿æœŸæœªæ¨è¿›ä¼šæé†’ AIï¼‰
        foreshadowing_context = self.foreshadowing_tracker.get_context_for_prompt(
            user_id=user_id,
            character_id=character_id,
            max_count=5,
            current_turn=self.volume_manager.get_total_turns() if self.volume_manager else None
        )
        if foreshadowing_context:
            parts.append(foreshadowing_context)
        
        # ========== 5.5 ä¸»åŠ¨æé†’å±‚ï¼ˆ100%ä¸é—å¿˜ä¿è¯ï¼‰==========
        # å¯¹é•¿æœŸæœªæåŠçš„é‡è¦æŒä¹…æ¡ä»¶è¿›è¡Œä¸»åŠ¨æé†’
        if proactive_enabled and active_contexts:
            proactive_reminders = self._build_proactive_reminders(
                active_contexts, proactive_turns, user_id
            )
            if proactive_reminders:
                parts.append(proactive_reminders)
        
        elapsed = _time.time() - start_time
        total_len = sum(len(p) for p in parts)
        print(f"[Recall][Engine] âœ… æ„å»ºå®Œæˆ: è€—æ—¶={elapsed:.3f}s")
        print(f"[Recall][Engine]    å±‚æ•°={len(parts)}, æ€»é•¿åº¦={total_len}å­—ç¬¦")
        if parts:
            print(f"[Recall][Engine]    åŒ…å«: {[p[:20] + '...' for p in parts]}")
        
        return "\n".join(parts)
    
    def _calculate_top_k(self, max_tokens: int, strategy: str) -> int:
        """æ ¹æ®ç­–ç•¥å’Œtokené¢„ç®—è®¡ç®—æ£€ç´¢æ•°é‡"""
        base_k = max(10, min(50, max_tokens // 100))
        
        # æ ¹æ®åœºæ™¯è°ƒæ•´
        strategy_multipliers = {
            'entity_focused': 1.5,      # è§’è‰²æ‰®æ¼”éœ€è¦æ›´å¤šå®ä½“ä¿¡æ¯
            'keyword_exact': 0.8,       # ä»£ç åœºæ™¯ç²¾ç¡®åŒ¹é…ï¼Œä¸éœ€è¦å¤ªå¤š
            'semantic_broad': 1.2,      # çŸ¥è¯†é—®ç­”éœ€è¦å¹¿æ³›æ£€ç´¢
            'creative_blend': 1.3,      # åˆ›æ„å†™ä½œéœ€è¦å¤šæ ·æ€§
            'task_relevant': 0.7,       # ä»»åŠ¡æ‰§è¡Œèšç„¦ç›¸å…³
            'recent_context': 0.5,      # é—²èŠä¸»è¦é æœ€è¿‘ä¸Šä¸‹æ–‡
            'hybrid_balanced': 1.0,     # é»˜è®¤å¹³è¡¡
        }
        
        multiplier = strategy_multipliers.get(strategy, 1.0)
        return int(base_k * multiplier)
    
    def _build_graph_context(self, query: str, user_id: str, budget: int) -> str:
        """åˆ©ç”¨çŸ¥è¯†å›¾è°±æ„å»ºå…³ç³»ä¸Šä¸‹æ–‡"""
        # ä»æŸ¥è¯¢ä¸­æå–å®ä½“
        entities = [e.name for e in self.entity_extractor.extract(query)]
        if not entities:
            return ""
        
        lines = []
        current_length = 0
        
        for entity_name in entities[:5]:  # æœ€å¤šå¤„ç†5ä¸ªå®ä½“
            # è·å–è¯¥å®ä½“çš„å…³ç³»
            neighbors = self.knowledge_graph.get_neighbors(entity_name, direction='both')
            if neighbors:
                for neighbor_id, relation in neighbors[:3]:  # æ¯ä¸ªå®ä½“æœ€å¤š3ä¸ªå…³ç³»
                    rel_text = f"â€¢ {entity_name} --[{relation.relation_type}]--> {neighbor_id}"
                    if current_length + len(rel_text) > budget:
                        break
                    lines.append(rel_text)
                    current_length += len(rel_text)
        
        if lines:
            return "<relationships>\nã€å…³ç³»å›¾è°±ã€‘\n" + "\n".join(lines) + "\n</relationships>"
        return ""
    
    def _build_core_facts_section(self, user_id: str, budget: int) -> str:
        """æ„å»ºæ ¸å¿ƒäº‹å®éƒ¨åˆ† - ä» L1 ConsolidatedMemory è·å–å‹ç¼©çŸ¥è¯†"""
        # è·å–æ‰€æœ‰å·²éªŒè¯çš„å®ä½“å’Œæ ¸å¿ƒäº‹å®
        all_entities = list(self.consolidated_memory.entities.values()) if hasattr(self, 'consolidated_memory') else []
        
        if not all_entities:
            # å¦‚æœæ²¡æœ‰æ•´åˆçš„è®°å¿†ï¼Œå°è¯•ç”Ÿæˆæ‘˜è¦
            return self._generate_memory_summary(user_id, budget)
        
        lines = ["<core_facts>", "ã€æ ¸å¿ƒçŸ¥è¯†åº“ã€‘ä»¥ä¸‹æ˜¯å·²ç¡®è®¤çš„å…³é”®ä¿¡æ¯ï¼š"]
        current_length = 0
        
        # æŒ‰ç½®ä¿¡åº¦æ’åºï¼Œä¼˜å…ˆé«˜ç½®ä¿¡åº¦çš„
        sorted_entities = sorted(all_entities, key=lambda e: -e.confidence)
        
        for entity in sorted_entities:
            fact_line = f"â€¢ {entity.name}"
            if entity.entity_type != "UNKNOWN":
                fact_line += f" ({entity.entity_type})"
            if entity.current_state:
                states = [f"{k}:{v}" for k, v in list(entity.current_state.items())[:3]]
                fact_line += f": {', '.join(states)}"
            
            if current_length + len(fact_line) > budget:
                break
            lines.append(fact_line)
            current_length += len(fact_line)
        
        lines.append("</core_facts>")
        return "\n".join(lines) if len(lines) > 3 else ""
    
    def _generate_memory_summary(self, user_id: str, budget: int) -> str:
        """ç”Ÿæˆè®°å¿†æ‘˜è¦ - å½“æ²¡æœ‰æ•´åˆè®°å¿†æ—¶ä½¿ç”¨"""
        scope = self.storage.get_scope(user_id)
        all_memories = scope.get_all(limit=100)  # è·å–æœ€å¤š100æ¡
        
        if not all_memories or len(all_memories) < 5:
            return ""
        
        # å¦‚æœæœ‰ LLMï¼Œä½¿ç”¨ LLM ç”Ÿæˆæ‘˜è¦
        if self.llm_client and self.memory_summarizer:
            try:
                from .processor.memory_summarizer import MemoryItem
                memory_items = []
                for m in all_memories:
                    memory_items.append(MemoryItem(
                        id=m.get('metadata', {}).get('id', ''),
                        content=m.get('content', ''),
                        user_id=user_id
                    ))
                summary = self.memory_summarizer.summarize_memories(memory_items, max_length=budget)
                if summary:
                    return f"<memory_summary>\nã€å†å²æ‘˜è¦ã€‘\n{summary}\n</memory_summary>"
            except Exception as e:
                pass  # é™é»˜å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
        
        # å¤‡ç”¨æ–¹æ¡ˆï¼šç®€å•æå–å…³é”®è¯å’Œå®ä½“
        entities_set = set()
        for m in all_memories:
            entities = m.get('metadata', {}).get('entities', [])
            entities_set.update(entities)
        
        if entities_set:
            return f"<memory_summary>\nã€æ¶‰åŠçš„è§’è‰²/äº‹ç‰©ã€‘{', '.join(list(entities_set)[:20])}\n</memory_summary>"
        
        return ""
    
    def _build_memory_section(self, memories, budget: int) -> str:
        """æ„å»ºè¯¦ç»†è®°å¿†éƒ¨åˆ†ï¼ˆè‡ªåŠ¨å»é‡ï¼‰"""
        if not memories:
            return ""
        
        lines = ["<memories>", "ã€ç›¸å…³è®°å¿†ã€‘"]
        current_length = 0
        seen_contents = set()  # ç”¨äºå»é‡
        
        for m in memories:
            content = m.content if hasattr(m, 'content') else m.get('content', '')
            
            # å»é‡ï¼šè·³è¿‡å·²ç»æ·»åŠ è¿‡çš„ç›¸åŒå†…å®¹
            content_key = content.strip().lower()
            if content_key in seen_contents:
                continue
            seen_contents.add(content_key)
            
            entities = m.entities if hasattr(m, 'entities') else m.get('entities', [])
            
            line = f"â€¢ {content}"
            if entities:
                line = f"â€¢ [æ¶‰åŠ: {', '.join(entities[:3])}] {content}"
            
            if current_length + len(line) > budget:
                lines.append("...")
                break
            lines.append(line)
            current_length += len(line)
        
        lines.append("</memories>")
        return "\n".join(lines) if len(lines) > 3 else ""
    
    def _build_recent_section(self, recent) -> str:
        """æ„å»ºæœ€è¿‘å¯¹è¯éƒ¨åˆ†"""
        if not recent:
            return ""
        
        lines = ["<recent_conversation>"]
        for turn in recent:
            role = turn.get('metadata', {}).get('role', 'user')
            content = turn.get('content', '')
            lines.append(f"{role}: {content}")
        lines.append("</recent_conversation>")
        return "\n".join(lines)
    
    def _extract_supplementary_keywords(
        self,
        user_id: str,
        character_id: str,
        active_contexts: List
    ) -> List[str]:
        """ä»æŒä¹…æ¡ä»¶å’Œä¼ç¬”ä¸­æå–å…³é”®è¯ç”¨äºè¡¥å……æ£€ç´¢
        
        ç¡®ä¿é‡è¦ä¿¡æ¯å³ä½¿åœ¨å½“å‰ query ä¸­æœªæåŠä¹Ÿèƒ½è¢«å¬å›
        
        Args:
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            active_contexts: æ´»è·ƒçš„æŒä¹…æ¡ä»¶åˆ—è¡¨
            
        Returns:
            List[str]: å…³é”®è¯åˆ—è¡¨
        """
        keywords = set()
        
        # ä»æŒä¹…æ¡ä»¶ä¸­æå–å…³é”®è¯
        if active_contexts:
            for ctx in active_contexts:
                # è·å–å…³é”®è¯
                ctx_keywords = ctx.keywords if hasattr(ctx, 'keywords') else ctx.get('keywords', [])
                if ctx_keywords:
                    keywords.update(ctx_keywords[:3])  # æ¯ä¸ªæ¡ä»¶æœ€å¤šå–3ä¸ªå…³é”®è¯
        
        # ä»æ´»è·ƒä¼ç¬”ä¸­æå–å…³é”®å®ä½“
        try:
            foreshadowings = self.foreshadowing_tracker.get_active(user_id, character_id)
            for fsh in foreshadowings[:5]:  # æœ€å¤š5ä¸ªä¼ç¬”
                entities = fsh.related_entities if hasattr(fsh, 'related_entities') else []
                if entities:
                    keywords.update(entities[:2])  # æ¯ä¸ªä¼ç¬”æœ€å¤šå–2ä¸ªå®ä½“
        except Exception:
            pass
        
        return list(keywords)[:10]  # æ€»å…±æœ€å¤š10ä¸ªå…³é”®è¯
    
    def _search_by_keywords(
        self,
        keywords: List[str],
        user_id: str,
        top_k: int = 5
    ) -> List:
        """æ ¹æ®å…³é”®è¯åˆ—è¡¨è¿›è¡Œè¡¥å……æ£€ç´¢
        
        Args:
            keywords: å…³é”®è¯åˆ—è¡¨
            user_id: ç”¨æˆ·ID
            top_k: è¿”å›çš„æœ€å¤§è®°å¿†æ•°
            
        Returns:
            List: ç›¸å…³è®°å¿†åˆ—è¡¨
        """
        if not keywords:
            return []
        
        all_memories = []
        seen_ids = set()
        
        for keyword in keywords[:5]:  # æœ€å¤šä½¿ç”¨5ä¸ªå…³é”®è¯
            try:
                memories = self.search(keyword, user_id=user_id, top_k=2)
                for m in memories:
                    mem_id = m.id if hasattr(m, 'id') else m.get('id', '')
                    if mem_id and mem_id not in seen_ids:
                        seen_ids.add(mem_id)
                        all_memories.append(m)
                        if len(all_memories) >= top_k:
                            return all_memories
            except Exception:
                continue
        
        return all_memories
    
    def _build_supplementary_section(self, memories) -> str:
        """æ„å»ºè¡¥å……æ£€ç´¢è®°å¿†éƒ¨åˆ†
        
        Args:
            memories: è¡¥å……æ£€ç´¢åˆ°çš„è®°å¿†åˆ—è¡¨
            
        Returns:
            str: æ ¼å¼åŒ–çš„è¡¥å……è®°å¿†æ–‡æœ¬
        """
        if not memories:
            return ""
        
        lines = ["<supplementary_memories>", "ã€ç›¸å…³èƒŒæ™¯ï¼ˆè¡¥å……å¬å›ï¼‰ã€‘"]
        
        for m in memories[:5]:  # æœ€å¤š5æ¡
            content = m.content if hasattr(m, 'content') else m.get('content', '')
            entities = m.entities if hasattr(m, 'entities') else m.get('entities', [])
            
            line = f"â€¢ {content}"
            if entities:
                line = f"â€¢ [æ¶‰åŠ: {', '.join(entities[:3])}] {content}"
            lines.append(line)
        
        lines.append("</supplementary_memories>")
        return "\n".join(lines) if len(lines) > 3 else ""
    
    def _build_proactive_reminders(
        self,
        active_contexts: List,
        threshold_turns: int,
        user_id: str
    ) -> str:
        """æ„å»ºä¸»åŠ¨æé†’æ–‡æœ¬ï¼ˆå¯¹é•¿æœŸæœªæåŠçš„é‡è¦æŒä¹…æ¡ä»¶ï¼‰
        
        ç±»ä¼¼äºä¼ç¬”çš„ä¸»åŠ¨æé†’æœºåˆ¶ï¼Œç¡®ä¿é‡è¦èƒŒæ™¯ä¿¡æ¯ä¸ä¼šè¢«é—å¿˜
        
        Args:
            active_contexts: æ´»è·ƒçš„æŒä¹…æ¡ä»¶åˆ—è¡¨
            threshold_turns: è§¦å‘æé†’çš„è½®æ¬¡é˜ˆå€¼
            user_id: ç”¨æˆ·ID
            
        Returns:
            str: ä¸»åŠ¨æé†’æ–‡æœ¬ï¼Œå¦‚æœæ²¡æœ‰éœ€è¦æé†’çš„å†…å®¹åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        if not active_contexts:
            return ""
        
        # è·å–å½“å‰æ€»è½®æ¬¡
        current_turn = 0
        if self.volume_manager:
            current_turn = self.volume_manager.get_total_turns()
        
        reminders = []
        
        for ctx in active_contexts:
            # è·å–æœ€åæåŠè½®æ¬¡ - PersistentContext æ˜¯ dataclassï¼Œä½¿ç”¨ getattr
            last_mentioned = getattr(ctx, 'last_mentioned_turn', None) or getattr(ctx, 'use_count', 0)
            importance = getattr(ctx, 'importance', None) or getattr(ctx, 'confidence', 0.5)
            content = getattr(ctx, 'content', '')
            
            # è®¡ç®—æœªæåŠçš„è½®æ¬¡æ•°
            turns_since_mention = current_turn - last_mentioned if last_mentioned else current_turn
            
            # é«˜é‡è¦æ€§æ¡ä»¶é˜ˆå€¼å‡åŠ
            effective_threshold = threshold_turns // 2 if importance > 0.7 else threshold_turns
            
            if turns_since_mention >= effective_threshold and importance >= 0.5:
                reminders.append({
                    'content': content,
                    'importance': importance,
                    'turns_since': turns_since_mention
                })
        
        if not reminders:
            return ""
        
        # æŒ‰é‡è¦æ€§å’ŒæœªæåŠæ—¶é•¿æ’åº
        reminders.sort(key=lambda x: (x['importance'], x['turns_since']), reverse=True)
        
        lines = [
            "<proactive_reminders>",
            "ã€é‡è¦èƒŒæ™¯æé†’ã€‘ä»¥ä¸‹æ˜¯ä½ å¯èƒ½éœ€è¦æ³¨æ„çš„é‡è¦èƒŒæ™¯ä¿¡æ¯ï¼ˆé•¿æœŸæœªåœ¨å¯¹è¯ä¸­æ¶‰åŠï¼‰ï¼š"
        ]
        
        for r in reminders[:3]:  # æœ€å¤šæé†’3æ¡
            importance_label = "é«˜" if r['importance'] > 0.7 else "ä¸­"
            lines.append(f"â€¢ [{importance_label}é‡è¦æ€§ï¼Œ{r['turns_since']}è½®æœªæåŠ] {r['content']}")
        
        lines.append("</proactive_reminders>")
        return "\n".join(lines)
    
    def _format_foreshadowings(self, foreshadowings) -> str:
        """æ ¼å¼åŒ–ä¼ç¬”ä¸ºæç¤ºæ–‡æœ¬"""
        if not foreshadowings:
            return ""
        
        lines = ["\n<foreshadowings>", "ä»¥ä¸‹æ˜¯å°šæœªè§£å†³çš„ä¼ç¬”ï¼Œè¯·åœ¨åˆé€‚æ—¶æœºè‡ªç„¶åœ°æ¨è¿›æˆ–å›æ”¶ï¼š"]
        for f in foreshadowings:
            importance_label = "é«˜" if f.importance > 0.7 else "ä¸­" if f.importance > 0.4 else "ä½"
            lines.append(f"â€¢ [{importance_label}] {f.content}")
            if f.related_entities:
                lines.append(f"  ç›¸å…³è§’è‰²/äº‹ç‰©: {', '.join(f.related_entities)}")
        lines.append("</foreshadowings>")
        return "\n".join(lines)
    
    # ==================== ä¼ç¬” API ====================
    
    def plant_foreshadowing(
        self,
        content: str,
        user_id: str = "default",
        character_id: str = "default",
        related_entities: Optional[List[str]] = None,
        importance: float = 0.5
    ) -> Foreshadowing:
        """åŸ‹ä¸‹ä¼ç¬”
        
        åŒæ—¶å°†ä¼ç¬”ç´¢å¼•åˆ° VectorIndex ä»¥æ”¯æŒè¯­ä¹‰æ£€ç´¢ï¼ˆå³ä½¿å½’æ¡£åä¹Ÿèƒ½æœç´¢ï¼‰
        """
        foreshadowing = self.foreshadowing_tracker.plant(
            content=content,
            user_id=user_id,
            character_id=character_id,
            related_entities=related_entities,
            importance=importance
        )
        
        # ç´¢å¼•åˆ° VectorIndexï¼ˆç¡®ä¿å½’æ¡£åä»å¯è¯­ä¹‰æ£€ç´¢ï¼‰
        # æ³¨æ„ï¼šforeshadowing.id å·²ç»æ˜¯ fsh_{counter}_{timestamp} æ ¼å¼ï¼Œä¸éœ€è¦å†åŠ  fsh_ å‰ç¼€
        if self._vector_index and self._vector_index.enabled:
            doc_id = f"{user_id}_{character_id}_{foreshadowing.id}"
            self._vector_index.add_text(doc_id, content)
        
        return foreshadowing
    
    def resolve_foreshadowing(
        self,
        foreshadowing_id: str,
        resolution: str,
        user_id: str = "default",
        character_id: str = "default"
    ) -> bool:
        """è§£å†³ä¼ç¬”"""
        return self.foreshadowing_tracker.resolve(foreshadowing_id, resolution, user_id, character_id)
    
    def add_foreshadowing_hint(
        self,
        foreshadowing_id: str,
        hint: str,
        user_id: str = "default",
        character_id: str = "default"
    ) -> bool:
        """æ·»åŠ ä¼ç¬”æç¤º
        
        ä¸ºä¼ç¬”æ·»åŠ è¿›å±•æç¤ºï¼Œä¼šå°†çŠ¶æ€ä» PLANTED æ›´æ–°ä¸º DEVELOPING
        
        Args:
            foreshadowing_id: ä¼ç¬”ID
            hint: æç¤ºå†…å®¹
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        return self.foreshadowing_tracker.add_hint(foreshadowing_id, hint, user_id, character_id)
    
    def abandon_foreshadowing(
        self,
        foreshadowing_id: str,
        user_id: str = "default",
        character_id: str = "default"
    ) -> bool:
        """æ”¾å¼ƒ/åˆ é™¤ä¼ç¬”
        
        å°†ä¼ç¬”æ ‡è®°ä¸ºå·²æ”¾å¼ƒçŠ¶æ€ï¼ˆä¸ä¼šç‰©ç†åˆ é™¤ï¼Œä¿ç•™å†å²è®°å½•ï¼‰
        
        Args:
            foreshadowing_id: ä¼ç¬”ID
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        return self.foreshadowing_tracker.abandon(foreshadowing_id, user_id, character_id)
    
    def get_active_foreshadowings(self, user_id: str = "default", character_id: str = "default") -> List[Foreshadowing]:
        """è·å–æ´»è·ƒä¼ç¬”"""
        return self.foreshadowing_tracker.get_active(user_id, character_id)
    
    def get_foreshadowing_by_id(
        self,
        foreshadowing_id: str,
        user_id: str = "default",
        character_id: str = "default"
    ) -> Optional[Foreshadowing]:
        """æ ¹æ®IDè·å–ä¼ç¬”ï¼ˆåŒ…æ‹¬å·²å½’æ¡£çš„ï¼‰
        
        ç”¨äºä» VectorIndex æœç´¢ç»“æœä¸­è·å–ä¼ç¬”è¯¦æƒ…ã€‚
        æœç´¢å‘½ä¸­å½’æ¡£ä¼ç¬”æ—¶ï¼Œé€šè¿‡æ­¤æ–¹æ³•ä»å½’æ¡£æ–‡ä»¶è¯»å–å®Œæ•´ä¿¡æ¯ã€‚
        
        Args:
            foreshadowing_id: ä¼ç¬”ID
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            
        Returns:
            Optional[Foreshadowing]: ä¼ç¬”å¯¹è±¡ï¼Œæœªæ‰¾åˆ°è¿”å› None
        """
        return self.foreshadowing_tracker.get_by_id(foreshadowing_id, user_id, character_id)
    
    def on_foreshadowing_turn(
        self, 
        content: str, 
        role: str = "user", 
        user_id: str = "default",
        character_id: str = "default"
    ) -> AnalysisResult:
        """å¤„ç†æ–°çš„ä¸€è½®å¯¹è¯ï¼ˆç”¨äºä¼ç¬”åˆ†æï¼‰
        
        åœ¨æ¯è½®å¯¹è¯åè°ƒç”¨æ­¤æ–¹æ³•ï¼Œåˆ†æå™¨ä¼šï¼š
        - æ‰‹åŠ¨æ¨¡å¼ï¼šä¸åšä»»ä½•æ“ä½œï¼Œè¿”å›ç©ºç»“æœ
        - LLMæ¨¡å¼ï¼šç´¯ç§¯å¯¹è¯ï¼Œè¾¾åˆ°è§¦å‘æ¡ä»¶æ—¶è‡ªåŠ¨åˆ†æ
        
        Args:
            content: å¯¹è¯å†…å®¹
            role: è§’è‰²ï¼ˆuser/assistantï¼‰
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            
        Returns:
            AnalysisResult: åˆ†æç»“æœ
        """
        return self.foreshadowing_analyzer.on_new_turn(
            content=content,
            role=role,
            user_id=user_id,
            character_id=character_id
        )
    
    def trigger_foreshadowing_analysis(self, user_id: str = "default", character_id: str = "default") -> AnalysisResult:
        """æ‰‹åŠ¨è§¦å‘ä¼ç¬”åˆ†æ
        
        å¯ä»¥åœ¨ä»»ä½•æ—¶å€™è°ƒç”¨ï¼Œå¼ºåˆ¶è§¦å‘ LLM åˆ†æï¼ˆå¦‚æœå·²é…ç½®ï¼‰ã€‚
        
        Args:
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            
        Returns:
            AnalysisResult: åˆ†æç»“æœ
        """
        return self.foreshadowing_analyzer.trigger_analysis(user_id, character_id)
    
    def get_foreshadowing_analyzer_config(self) -> Dict[str, Any]:
        """è·å–ä¼ç¬”åˆ†æå™¨é…ç½®"""
        return self.foreshadowing_analyzer.config.to_dict()
    
    def update_foreshadowing_analyzer_config(
        self,
        trigger_interval: Optional[int] = None,
        auto_plant: Optional[bool] = None,
        auto_resolve: Optional[bool] = None
    ):
        """æ›´æ–°ä¼ç¬”åˆ†æå™¨é…ç½®"""
        self.foreshadowing_analyzer.update_config(
            trigger_interval=trigger_interval,
            auto_plant=auto_plant,
            auto_resolve=auto_resolve
        )
    
    def enable_foreshadowing_llm_mode(
        self,
        api_key: str,
        model: str = "gpt-4o-mini",
        base_url: Optional[str] = None
    ):
        """å¯ç”¨ä¼ç¬”åˆ†æå™¨çš„ LLM æ¨¡å¼ï¼ˆåŠ¨æ€åˆ‡æ¢ï¼Œæ— éœ€é‡å¯ï¼‰"""
        self.foreshadowing_analyzer.enable_llm_mode(
            api_key=api_key,
            model=model,
            base_url=base_url
        )
    
    def disable_foreshadowing_llm_mode(self):
        """ç¦ç”¨ä¼ç¬”åˆ†æå™¨çš„ LLM æ¨¡å¼ï¼Œåˆ‡æ¢å›æ‰‹åŠ¨æ¨¡å¼"""
        self.foreshadowing_analyzer.disable_llm_mode()
    
    # ==================== æŒä¹…æ¡ä»¶ API ====================
    
    def add_persistent_context(
        self,
        content: str,
        context_type = "custom",
        user_id: str = "default",
        character_id: str = "default",
        keywords: List[str] = None
    ):
        """æ·»åŠ æŒä¹…æ¡ä»¶
        
        æŒä¹…æ¡ä»¶æ˜¯ä¸€æ—¦ç¡®ç«‹å°±åº”è¯¥åœ¨åç»­æ‰€æœ‰å¯¹è¯ä¸­é»˜è®¤æˆç«‹çš„èƒŒæ™¯ä¿¡æ¯ã€‚
        
        Args:
            content: æ¡ä»¶å†…å®¹ï¼Œå¦‚"ç”¨æˆ·æ˜¯å¤§å­¦æ¯•ä¸šç”Ÿæƒ³åˆ›ä¸š"
            context_type: ç±»å‹ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ– ContextType æšä¸¾ï¼Œå¯é€‰å€¼ï¼š
                - user_identity: ç”¨æˆ·èº«ä»½
                - user_goal: ç”¨æˆ·ç›®æ ‡
                - user_preference: ç”¨æˆ·åå¥½
                - environment: æŠ€æœ¯ç¯å¢ƒ
                - project: é¡¹ç›®ä¿¡æ¯
                - character_trait: è§’è‰²ç‰¹å¾
                - world_setting: ä¸–ç•Œè§‚
                - relationship: å…³ç³»è®¾å®š
                - assumption: å‡è®¾å‰æ
                - constraint: çº¦æŸæ¡ä»¶
                - custom: è‡ªå®šä¹‰
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            keywords: å…³é”®è¯åˆ—è¡¨
            
        Returns:
            PersistentContext: åˆ›å»ºçš„æ¡ä»¶å¯¹è±¡
        """
        from .processor.context_tracker import ContextType
        
        # æ”¯æŒå­—ç¬¦ä¸²å’Œæšä¸¾ä¸¤ç§è¾“å…¥
        if isinstance(context_type, ContextType):
            ctx_type = context_type
        else:
            try:
                ctx_type = ContextType(context_type)
            except ValueError:
                ctx_type = ContextType.CUSTOM
        
        context = self.context_tracker.add(
            content=content,
            context_type=ctx_type,
            user_id=user_id,
            character_id=character_id,
            keywords=keywords
        )
        
        # ç´¢å¼•åˆ° VectorIndexï¼ˆæ— è®ºæ˜¯å¦æ´»è·ƒï¼Œç¡®ä¿å³ä½¿è¢«æ·˜æ±°ä¹Ÿå¯è¯­ä¹‰æ£€ç´¢ï¼‰
        # è¢« _enforce_limits() æ·˜æ±°çš„æ¡ä»¶ä»éœ€å¯è¢«æœç´¢æ‰¾å›
        if self._vector_index and self._vector_index.enabled:
            doc_id = f"ctx_{user_id}_{character_id}_{context.id}"
            self._vector_index.add_text(doc_id, content)
        
        return context
    
    def get_persistent_contexts(self, user_id: str = "default", character_id: str = "default") -> List[Dict]:
        """è·å–æ‰€æœ‰æ´»è·ƒçš„æŒä¹…æ¡ä»¶"""
        contexts = self.context_tracker.get_active(user_id, character_id)
        return [c.to_dict() for c in contexts]
    
    def get_persistent_context_by_id(
        self,
        context_id: str,
        user_id: str = "default",
        character_id: str = "default"
    ) -> Optional[Dict]:
        """æ ¹æ®IDè·å–æŒä¹…æ¡ä»¶ï¼ˆåŒ…æ‹¬å·²å½’æ¡£çš„ï¼‰
        
        ç”¨äºä» VectorIndex æœç´¢ç»“æœä¸­è·å–æ¡ä»¶è¯¦æƒ…ã€‚
        æœç´¢å‘½ä¸­å½’æ¡£æ¡ä»¶æ—¶ï¼Œé€šè¿‡æ­¤æ–¹æ³•ä»å½’æ¡£æ–‡ä»¶è¯»å–å®Œæ•´ä¿¡æ¯ã€‚
        
        Args:
            context_id: æ¡ä»¶ID
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            
        Returns:
            Optional[Dict]: æ¡ä»¶æ•°æ®å­—å…¸ï¼Œæœªæ‰¾åˆ°è¿”å› None
        """
        ctx = self.context_tracker.get_context_by_id(context_id, user_id, character_id)
        return ctx.to_dict() if ctx else None
    
    def remove_persistent_context(self, context_id: str, user_id: str = "default", character_id: str = "default") -> bool:
        """ç§»é™¤ï¼ˆåœç”¨ï¼‰æŸä¸ªæŒä¹…æ¡ä»¶"""
        return self.context_tracker.deactivate(context_id, user_id, character_id)
    
    def extract_contexts_from_text(self, text: str, user_id: str = "default", character_id: str = "default") -> List[Dict]:
        """ä»æ–‡æœ¬ä¸­è‡ªåŠ¨æå–æŒä¹…æ¡ä»¶
        
        ä½¿ç”¨ LLMï¼ˆå¦‚æœå¯ç”¨ï¼‰æˆ–è§„åˆ™ä»æ–‡æœ¬ä¸­æå–åº”è¯¥æŒä¹…åŒ–çš„æ¡ä»¶ã€‚
        åŒæ—¶å°†æ–°æå–çš„æ¡ä»¶ç´¢å¼•åˆ° VectorIndex ä»¥æ”¯æŒè¯­ä¹‰æ£€ç´¢ã€‚
        
        Args:
            text: è¦åˆ†æçš„æ–‡æœ¬
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            
        Returns:
            List[Dict]: æå–å‡ºçš„æ¡ä»¶åˆ—è¡¨
        """
        contexts = self.context_tracker.extract_from_text(text, user_id, character_id)
        
        # ç´¢å¼•æ–°æå–çš„æ¡ä»¶åˆ° VectorIndexï¼ˆæ— è®ºæ´»è·ƒçŠ¶æ€ï¼‰
        if self._vector_index and self._vector_index.enabled:
            for ctx in contexts:
                doc_id = f"ctx_{user_id}_{character_id}_{ctx.id}"
                self._vector_index.add_text(doc_id, ctx.content)
        
        return [c.to_dict() for c in contexts]
    
    def consolidate_persistent_contexts(self, user_id: str = "default", character_id: str = "default", force: bool = False) -> Dict:
        """å‹ç¼©åˆå¹¶æŒä¹…æ¡ä»¶
        
        å½“æŒä¹…æ¡ä»¶æ•°é‡è¿‡å¤šæ—¶ï¼Œæ™ºèƒ½åˆå¹¶ç›¸ä¼¼çš„æ¡ä»¶ä»¥æ§åˆ¶å¢é•¿ã€‚
        å¦‚æœé…ç½®äº†LLMï¼Œä¼šä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½å‹ç¼©ï¼›å¦åˆ™åªä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„æ¡ä»¶ã€‚
        
        Args:
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            force: æ˜¯å¦å¼ºåˆ¶æ‰§è¡Œï¼ˆé»˜è®¤åªåœ¨è¶…è¿‡é˜ˆå€¼æ—¶æ‰§è¡Œï¼‰
            
        Returns:
            Dict: å‹ç¼©ç»“æœï¼ŒåŒ…å«ï¼š
                - reduced: å‡å°‘çš„æ¡ä»¶æ•°é‡
                - before: å‹ç¼©å‰çš„ç»Ÿè®¡
                - after: å‹ç¼©åçš„ç»Ÿè®¡
        """
        before_stats = self.context_tracker.get_stats(user_id=user_id, character_id=character_id)
        reduced = self.context_tracker.consolidate_contexts(user_id=user_id, character_id=character_id, force=force)
        after_stats = self.context_tracker.get_stats(user_id=user_id, character_id=character_id)
        
        return {
            'reduced': reduced,
            'before': before_stats,
            'after': after_stats
        }
    
    # ==================== å®ä½“ API ====================
    
    def get_entity(self, name: str) -> Optional[Dict[str, Any]]:
        """è·å–å®ä½“ä¿¡æ¯"""
        if self._entity_index:
            indexed = self._entity_index.get_entity(name)
            if indexed:
                return {
                    'name': indexed.name,
                    'type': indexed.entity_type,
                    'aliases': indexed.aliases,
                    'mention_count': len(indexed.turn_references),
                    'related_turns': indexed.turn_references[:10]
                }
        return None
    
    def get_related_entities(self, name: str) -> List[str]:
        """è·å–ç›¸å…³å®ä½“"""
        neighbors = self.knowledge_graph.get_neighbors(name)
        return [neighbor_id for neighbor_id, _ in neighbors]
    
    # ==================== ç®¡ç† API ====================
    
    def rebuild_vector_index(self, user_id: Optional[str] = None) -> Dict[str, Any]:
        """é‡å»ºå‘é‡ç´¢å¼•
        
        ä»ç°æœ‰è®°å¿†æ•°æ®é‡æ–°ç”Ÿæˆå‘é‡ç´¢å¼•ï¼Œç”¨äºä¿®å¤ç»´åº¦ä¸åŒ¹é…ç­‰é—®é¢˜ã€‚
        
        Args:
            user_id: å¯é€‰ï¼ŒæŒ‡å®šåªé‡å»ºæŸä¸ªç”¨æˆ·çš„ç´¢å¼•ã€‚ä¸º None æ—¶é‡å»ºæ‰€æœ‰ç”¨æˆ·ã€‚
            
        Returns:
            Dict: åŒ…å« success, message, indexed_count ç­‰ä¿¡æ¯
        """
        if self._vector_index is None:
            return {
                'success': False,
                'message': 'å‘é‡ç´¢å¼•æœªå¯ç”¨',
                'indexed_count': 0
            }
        
        # æ”¶é›†éœ€è¦ç´¢å¼•çš„è®°å¿†
        memories_to_index = []
        
        if user_id:
            # åªé‡å»ºæŒ‡å®šç”¨æˆ·
            scope = self.storage.get_scope(user_id)
            for m in scope.get_all():
                memory_id = m.get('id', '')
                content = m.get('content', m.get('memory', ''))
                if memory_id and content:
                    memories_to_index.append((memory_id, content))
            print(f"[Recall] é‡å»ºå‘é‡ç´¢å¼•: user={user_id}, è®°å¿†æ•°={len(memories_to_index)}")
        else:
            # é‡å»ºæ‰€æœ‰ç”¨æˆ·
            for scope_key, scope in self.storage._scopes.items():
                for m in scope.get_all():
                    memory_id = m.get('id', '')
                    content = m.get('content', m.get('memory', ''))
                    if memory_id and content:
                        memories_to_index.append((memory_id, content))
            print(f"[Recall] é‡å»ºå‘é‡ç´¢å¼•: å…¨éƒ¨ç”¨æˆ·, è®°å¿†æ•°={len(memories_to_index)}")
        
        if not memories_to_index:
            return {
                'success': True,
                'message': 'æ²¡æœ‰éœ€è¦ç´¢å¼•çš„è®°å¿†',
                'indexed_count': 0
            }
        
        # è°ƒç”¨å‘é‡ç´¢å¼•çš„é‡å»ºæ–¹æ³•
        try:
            indexed_count = self._vector_index.rebuild_from_memories(memories_to_index)
            return {
                'success': True,
                'message': f'å‘é‡ç´¢å¼•é‡å»ºå®Œæˆ',
                'indexed_count': indexed_count,
                'total_memories': len(memories_to_index)
            }
        except Exception as e:
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'message': f'é‡å»ºå¤±è´¥: {e}',
                'indexed_count': 0
            }
    
    def get_stats(self, user_id: Optional[str] = None) -> Dict[str, Any]:
        """è·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            user_id: å¯é€‰çš„ç”¨æˆ·IDï¼ŒæŒ‡å®šåè¿”å›è¯¥ç”¨æˆ·çš„è¯¦ç»†ç»Ÿè®¡
        
        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…å«ï¼š
                - total_memories: æ€»è®°å¿†æ•°
                - total_entities: æ€»å®ä½“æ•°
                - total_foreshadowings: ä¼ç¬”æ•°
                - å¦‚æœæŒ‡å®š user_idï¼Œè¿˜åŒ…å«è¯¥ç”¨æˆ·çš„è¯¦ç»†ç»Ÿè®¡
        """
        stats = {
            'version': __version__,
            'data_root': self.data_root,
            'mode': self._get_mode_name(),
            'lightweight': self.lightweight,
        }
        
        # å…¨å±€ç»Ÿè®¡
        total_memories = 0
        total_entities_in_memories = 0
        
        for scope_key, scope in self.storage._scopes.items():
            memories = scope.get_all()
            total_memories += len(memories)
            for m in memories:
                entities = m.get('metadata', {}).get('entities', [])
                total_entities_in_memories += len(entities)
        
        stats['global'] = {
            'total_memories': total_memories,
            'total_scopes': len(self.storage._scopes),
            'consolidated_entities': len(self.consolidated_memory.entities) if hasattr(self, 'consolidated_memory') else 0,
            'active_foreshadowings': len(self.foreshadowing_tracker.get_active()),
        }
        
        # ç´¢å¼•ç»Ÿè®¡
        stats['indexes'] = {
            'entity_index': self._entity_index is not None,
            'inverted_index': self._inverted_index is not None,
            'vector_index': self._vector_index is not None,
            'ngram_index': self._ngram_index is not None,
            'cached_contents': len(self.retriever._content_cache) if hasattr(self.retriever, '_content_cache') else 0,
        }
        
        # ç”¨æˆ·ç‰¹å®šç»Ÿè®¡
        if user_id:
            scope = self.storage.get_scope(user_id)
            user_memories = scope.get_all()
            
            # ç»Ÿè®¡å®ä½“åˆ†å¸ƒ
            entity_counts = {}
            for m in user_memories:
                for e in m.get('metadata', {}).get('entities', []):
                    entity_counts[e] = entity_counts.get(e, 0) + 1
            
            # æŒ‰å‡ºç°æ¬¡æ•°æ’åº
            top_entities = sorted(entity_counts.items(), key=lambda x: -x[1])[:20]
            
            stats['user'] = {
                'user_id': user_id,
                'total_memories': len(user_memories),
                'unique_entities': len(entity_counts),
                'top_entities': dict(top_entities),
                'active_foreshadowings': len([f for f in self.foreshadowing_tracker.get_active() 
                                              if hasattr(f, 'user_id') and f.user_id == user_id]),
                'persistent_contexts': self.context_tracker.get_stats(user_id),
            }
        
        # æ€§èƒ½ç»Ÿè®¡
        try:
            stats['performance'] = self.monitor.get_all_stats() if hasattr(self.monitor, 'get_all_stats') else {}
        except:
            stats['performance'] = {}
        
        return stats
    
    def consolidate(self, user_id: str = "default"):
        """æ‰§è¡Œè®°å¿†æ•´åˆ"""
        scope = self.storage.get_scope(user_id)
        
        # è·å–å·¥ä½œè®°å¿†
        working = scope.get_all()
        
        # ä½¿ç”¨æ‘˜è¦å™¨å‹ç¼©
        from .processor.memory_summarizer import MemoryItem, MemoryPriority
        items = [
            MemoryItem(
                id=m.get('id', ''),
                content=m.get('content', m.get('memory', '')),
                user_id=user_id,
                priority=MemoryPriority.NORMAL
            )
            for m in working
        ]
        
        # åˆå¹¶ç›¸ä¼¼è®°å¿†
        merged = self.memory_summarizer.merge_similar(items)
        
        # ç§»åŠ¨åˆ°æ•´åˆå±‚
        # TODO: å®ç°å®é™…çš„æ•´åˆé€»è¾‘
        
        print(f"[Recall] æ•´åˆå®Œæˆ: {len(working)} -> {len(merged)}")
    
    def reset(self, user_id: Optional[str] = None):
        """é‡ç½®ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰"""
        if user_id:
            scope = self.storage.get_scope(user_id)
            scope.clear()
        else:
            # é‡ç½®æ‰€æœ‰
            self.storage = MultiTenantStorage(
                base_path=os.path.join(self.data_root, 'data')
            )
            if not self.lightweight:
                self._init_indexes()
        
        print(f"[Recall] é‡ç½®å®Œæˆ")
    
    def close(self):
        """å…³é—­å¼•æ“"""
        # 1. æŒä¹…åŒ– VolumeManagerï¼ˆç¡®ä¿æ‰€æœ‰æ•°æ®ä¿å­˜ï¼‰
        if self.volume_manager:
            self.volume_manager.flush()
        
        # 2. ä¿å­˜ N-gram ç´¢å¼•ï¼ˆåŸæ–‡å­˜å‚¨ï¼‰
        if self._ngram_index:
            self._ngram_index.save()
        
        # 3. ä¿å­˜å¹¶å…³é—­å‘é‡ç´¢å¼•
        if self._vector_index:
            self._vector_index.close()
        
        print("[Recall] å¼•æ“å·²å…³é—­")


# ä¾¿æ·å‡½æ•°
def create_engine(**kwargs) -> RecallEngine:
    """åˆ›å»ºå¼•æ“çš„ä¾¿æ·å‡½æ•°"""
    return RecallEngine(**kwargs)

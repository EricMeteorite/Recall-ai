"""Recall æ ¸å¿ƒå¼•æ“ - ç»Ÿä¸€çš„è®°å¿†ç®¡ç†å…¥å£"""

import os
import time
import uuid
from typing import List, Dict, Any, Optional, Union
from dataclasses import dataclass, field

from .version import __version__
# æ³¨æ„ï¼šRecallInit å’Œ LightweightConfig ä¿ç•™ç”¨äºæœªæ¥æ‰©å±•
from .init import RecallInit  # noqa: F401 - ä¿ç•™ç”¨äº CLI ç­‰åœºæ™¯
from .config import LightweightConfig, TripleRecallConfig  # noqa: F401 - ä¿ç•™ç”¨äºé…ç½®è¿ç§»
from .models import Entity, EntityType
from .storage import (
    VolumeManager, ConsolidatedMemory, ConsolidatedEntity,
    MultiTenantStorage, MemoryScope, CoreSettings
)
from .index import EntityIndex, InvertedIndex, VectorIndex, OptimizedNgramIndex
from .graph import KnowledgeGraph, RelationExtractor
from .processor import (
    EntityExtractor, ForeshadowingTracker,
    ConsistencyChecker, MemorySummarizer, ScenarioDetector,
    ForeshadowingAnalyzer, ForeshadowingAnalyzerConfig, AnalysisResult,
    ContextTracker, ContextType
)

# v4.0 Phase 1/2 å¯é€‰æ¨¡å—ï¼ˆå»¶è¿Ÿå¯¼å…¥ä»¥ä¿æŒå‘åå…¼å®¹ï¼‰
# è¿™äº›æ¨¡å—ä»…åœ¨é…ç½®å¯ç”¨æ—¶æ‰ä¼šåŠ è½½
from .processor.foreshadowing import Foreshadowing
from .retrieval import EightLayerRetriever, ContextBuilder
# Phase 3: å¯é€‰å¯¼å…¥ ElevenLayerRetrieverï¼ˆä»…åœ¨å¯ç”¨æ—¶ä½¿ç”¨ï¼‰
from .retrieval import (
    ElevenLayerRetriever, RetrievalConfig, 
    TemporalContext, LayerWeights
)
from .utils import (
    LLMClient, WarmupManager, PerformanceMonitor,
    EnvironmentManager
)
from .utils.perf_monitor import MetricType
from .embedding import EmbeddingConfig
from .embedding.base import EmbeddingBackendType


# Windows GBK ç¼–ç å…¼å®¹çš„å®‰å…¨æ‰“å°å‡½æ•°
def _safe_print(msg: str) -> None:
    """å®‰å…¨æ‰“å°å‡½æ•°ï¼Œæ›¿æ¢ emoji ä¸º ASCII ç­‰ä»·ç‰©ä»¥é¿å… Windows GBK ç¼–ç é”™è¯¯"""
    emoji_map = {
        'ğŸ“¥': '[IN]', 'ğŸ“¤': '[OUT]', 'ğŸ”': '[SEARCH]', 'âœ…': '[OK]', 'âŒ': '[FAIL]',
        'âš ï¸': '[WARN]', 'ğŸ’¾': '[SAVE]', 'ğŸ—ƒï¸': '[DB]', 'ğŸ§¹': '[CLEAN]', 'ğŸ“Š': '[STATS]',
        'ğŸ”„': '[SYNC]', 'ğŸ“¦': '[PKG]', 'ğŸš€': '[START]', 'ğŸ¯': '[TARGET]', 'ğŸ’¡': '[HINT]',
        'ğŸ”§': '[FIX]', 'ğŸ“': '[NOTE]', 'ğŸ‰': '[DONE]', 'â±ï¸': '[TIME]', 'ğŸŒ': '[NET]',
        'ğŸ§ ': '[BRAIN]', 'ğŸ’¬': '[CHAT]', 'ğŸ·ï¸': '[TAG]', 'ğŸ“': '[DIR]', 'ğŸ”’': '[LOCK]',
        'ğŸŒ±': '[PLANT]', 'ğŸ—‘ï¸': '[DEL]', 'ğŸ’«': '[MAGIC]', 'ğŸ­': '[MASK]', 'ğŸ“–': '[BOOK]',
        'âš¡': '[FAST]', 'ğŸ”¥': '[HOT]', 'ğŸ’': '[GEM]', 'ğŸŒŸ': '[STAR]', 'ğŸ¨': '[ART]'
    }
    for emoji, ascii_equiv in emoji_map.items():
        msg = msg.replace(emoji, ascii_equiv)
    try:
        print(msg)
    except UnicodeEncodeError:
        print(msg.encode('ascii', errors='replace').decode('ascii'))


@dataclass
class AddResult:
    """æ·»åŠ è®°å¿†ç»“æœ"""
    id: str
    success: bool
    entities: List[str] = field(default_factory=list)
    message: str = ""
    consistency_warnings: List[str] = field(default_factory=list)  # ä¸€è‡´æ€§è­¦å‘Š


@dataclass
class SearchResult:
    """æœç´¢ç»“æœ"""
    id: str
    content: str
    score: float
    metadata: Dict[str, Any] = field(default_factory=dict)
    entities: List[str] = field(default_factory=list)


class RecallEngine:
    """Recall æ ¸å¿ƒå¼•æ“
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. è®°å¿†å­˜å‚¨å’Œæ£€ç´¢
    2. å®ä½“å’Œå…³ç³»ç®¡ç†
    3. ä¼ç¬”è¿½è¸ª
    4. ä¸€è‡´æ€§æ£€æŸ¥
    5. ä¸Šä¸‹æ–‡æ„å»º
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
    ```python
    from recall import RecallEngine
    
    # åˆå§‹åŒ–
    engine = RecallEngine()
    
    # æ·»åŠ è®°å¿†
    result = engine.add("ç”¨æˆ·å–œæ¬¢å–å’–å•¡", user_id="user1")
    
    # æœç´¢è®°å¿†
    memories = engine.search("å’–å•¡", user_id="user1")
    
    # æ„å»ºä¸Šä¸‹æ–‡
    context = engine.build_context(
        query="æ¨èä¸€äº›é¥®å“",
        user_id="user1"
    )
    ```
    """
    
    def __init__(
        self,
        data_root: Optional[str] = None,
        llm_model: Optional[str] = None,
        llm_api_key: Optional[str] = None,
        lightweight: bool = False,
        lite: bool = None,  # æ–°åç§°ï¼Œä¸ lightweight ç­‰æ•ˆ
        embedding_config: Optional[EmbeddingConfig] = None,
        auto_warmup: bool = True,
        foreshadowing_config: Optional[ForeshadowingAnalyzerConfig] = None
    ):
        """åˆå§‹åŒ– Recall å¼•æ“
        
        Args:
            data_root: æ•°æ®å­˜å‚¨æ ¹ç›®å½•ï¼Œé»˜è®¤ä¸º ./recall_data
            llm_model: LLM æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º gpt-3.5-turbo
            llm_api_key: LLM API Key
            lite: æ˜¯å¦ä½¿ç”¨ Lite æ¨¡å¼ï¼ˆçº¦80MBå†…å­˜ï¼Œæ— è¯­ä¹‰æœç´¢ï¼‰
            lightweight: lite çš„åˆ«åï¼ˆå‘åå…¼å®¹ï¼‰
            embedding_config: Embedding é…ç½®ï¼Œæ”¯æŒä¸‰ç§æ¨¡å¼ï¼š
                - None/è‡ªåŠ¨: æ ¹æ®ç¯å¢ƒè‡ªåŠ¨é€‰æ‹©
                - EmbeddingConfig.lite(): Lite æ¨¡å¼ï¼Œ~100MBå†…å­˜
                - EmbeddingConfig.cloud_openai(key): Cloud æ¨¡å¼ï¼Œ~150MBå†…å­˜
                - EmbeddingConfig.cloud_siliconflow(key): Cloud æ¨¡å¼ï¼ˆå›½å†…ï¼‰
                - EmbeddingConfig.local(): Local æ¨¡å¼ï¼Œ~1.5GBå†…å­˜
            auto_warmup: æ˜¯å¦è‡ªåŠ¨é¢„çƒ­æ¨¡å‹
            foreshadowing_config: ä¼ç¬”åˆ†æå™¨é…ç½®ï¼ˆå¯é€‰ï¼‰
                - None/é»˜è®¤: æ‰‹åŠ¨æ¨¡å¼ï¼Œä¸å¯ç”¨è‡ªåŠ¨åˆ†æ
                - ForeshadowingAnalyzerConfig.llm_based(...): LLM è¾…åŠ©æ¨¡å¼
        """
        # å¤„ç† lite/lightweight åˆ«å
        if lite is not None:
            lightweight = lite
        
        # 1. åˆå§‹åŒ–ç¯å¢ƒ
        self.env_manager = EnvironmentManager(data_root)
        self.env_manager.setup()
        self.data_root = str(self.env_manager.data_root)
        
        # 2. åŠ è½½é…ç½®
        self.config = self.env_manager.load_config()
        
        # ä¿å­˜ä¼ç¬”åˆ†æå™¨é…ç½®ï¼ˆç¨ååœ¨ _init_components ä¸­ä½¿ç”¨ï¼‰
        self._foreshadowing_config = foreshadowing_config
        
        # 3. ç¡®å®š Embedding é…ç½®
        if lightweight:
            self.embedding_config = EmbeddingConfig.lite()
        elif embedding_config:
            self.embedding_config = embedding_config
        else:
            # è‡ªåŠ¨é€‰æ‹©
            from .embedding.factory import auto_select_backend
            self.embedding_config = auto_select_backend()
        
        # æ ¹æ®æœ€ç»ˆçš„ embedding_config ç¡®å®šæ˜¯å¦ä¸º Lite æ¨¡å¼
        self.lightweight = (self.embedding_config.backend == EmbeddingBackendType.NONE)
        
        # 4. åˆå§‹åŒ–ç»„ä»¶
        self._init_components(llm_model, llm_api_key)
        
        # 5. é¢„çƒ­
        if auto_warmup and not lightweight and self.embedding_config.backend == EmbeddingBackendType.LOCAL:
            self._warmup()
        
        # 6. æ¢å¤å†…å®¹ç¼“å­˜ï¼ˆç¡®ä¿é‡å¯åæ£€ç´¢èƒ½æ‰¾åˆ°å†…å®¹ï¼‰
        self._rebuild_content_cache()
        
        # æ‰“å°æ¨¡å¼ä¿¡æ¯
        mode = self._get_mode_name()
        _safe_print(f"[Recall v{__version__}] å¼•æ“åˆå§‹åŒ–å®Œæˆ ({mode})")
    
    def _get_mode_name(self) -> str:
        """è·å–å½“å‰æ¨¡å¼åç§°"""
        backend = self.embedding_config.backend
        
        # æ£€æµ‹æ˜¯å¦å®‰è£…äº†ä¼ä¸šçº§ä¾èµ–
        enterprise_features = []
        try:
            import kuzu
            enterprise_features.append("Kuzu")
        except ImportError:
            pass
        try:
            import networkx
            enterprise_features.append("NetworkX")
        except ImportError:
            pass
        
        # åŸºç¡€æ¨¡å¼åç§°
        if backend == EmbeddingBackendType.NONE:
            base_mode = "Lite æ¨¡å¼"
        elif backend == EmbeddingBackendType.LOCAL:
            base_mode = "Local æ¨¡å¼"
        elif backend == EmbeddingBackendType.OPENAI:
            base_mode = "Cloud æ¨¡å¼-OpenAI"
        elif backend == EmbeddingBackendType.SILICONFLOW:
            base_mode = "Cloud æ¨¡å¼-ç¡…åŸºæµåŠ¨"
        elif backend == EmbeddingBackendType.CUSTOM:
            base_mode = "Cloud æ¨¡å¼-è‡ªå®šä¹‰API"
        else:
            base_mode = "æœªçŸ¥æ¨¡å¼"
        
        # å¦‚æœæœ‰ä¼ä¸šçº§åŠŸèƒ½ï¼Œæ·»åŠ æ ‡è¯†
        if enterprise_features:
            return f"{base_mode} + Enterprise ({', '.join(enterprise_features)})"
        return base_mode
    
    def _init_components(
        self,
        llm_model: Optional[str],
        llm_api_key: Optional[str]
    ):
        """åˆå§‹åŒ–å„ç»„ä»¶"""
        # LLMå®¢æˆ·ç«¯ï¼ˆä¼˜å…ˆä½¿ç”¨ LLM_API_KEYï¼Œå…¼å®¹æ—§çš„ OPENAI_API_KEYï¼‰
        model = llm_model or os.environ.get('LLM_MODEL') or self.config.get('llm', {}).get('model', 'gpt-4o-mini')
        api_key = llm_api_key or os.environ.get('LLM_API_KEY') or os.environ.get('OPENAI_API_KEY')
        api_base = os.environ.get('LLM_API_BASE')
        self.llm_client = LLMClient(model=model, api_key=api_key, api_base=api_base) if api_key else None
        
        if self.llm_client:
            _safe_print(f"[Recall] LLM å®¢æˆ·ç«¯å·²åˆå§‹åŒ– (æ¨¡å‹: {model})")
        else:
            _safe_print("[Recall] LLM å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼ˆæœªé…ç½® LLM_API_KEYï¼‰")
        
        # å­˜å‚¨å±‚
        self.storage = MultiTenantStorage(
            base_path=os.path.join(self.data_root, 'data')
        )
        
        # åˆ†å·å­˜å‚¨ï¼ˆArchiveåŸæ–‡ä¿å­˜ - ç¡®ä¿100%ä¸é—å¿˜ï¼‰
        self.volume_manager = VolumeManager(
            data_path=os.path.join(self.data_root, 'data')
        )
        
        # ç´¢å¼•å±‚ï¼ˆLite æ¨¡å¼å»¶è¿ŸåŠ è½½ï¼‰
        self._entity_index: Optional[EntityIndex] = None
        self._inverted_index: Optional[InvertedIndex] = None
        self._vector_index: Optional[VectorIndex] = None
        self._ngram_index: Optional[OptimizedNgramIndex] = None
        
        if not self.lightweight:
            self._init_indexes()
        
        # å¤„ç†å™¨å±‚ï¼ˆéœ€è¦å…ˆåˆå§‹åŒ–ï¼Œå› ä¸ºå›¾è°±å±‚ä¾èµ–ï¼‰
        self.entity_extractor = EntityExtractor()
        
        # è·å–Embeddingåç«¯ï¼ˆç”¨äºè¯­ä¹‰å»é‡ï¼‰
        embedding_backend_for_trackers = None
        if self._vector_index and self._vector_index.enabled:
            embedding_backend_for_trackers = self._vector_index.embedding_backend
        
        # ä¼ç¬”è¿½è¸ªå™¨ï¼ˆæ”¯æŒè¯­ä¹‰å»é‡ï¼‰
        # ä½¿ç”¨æ–°çš„ {user_id}/{character_id}/ å­˜å‚¨ç»“æ„
        self.foreshadowing_tracker = ForeshadowingTracker(
            base_path=os.path.join(self.data_root, 'data'),
            embedding_backend=embedding_backend_for_trackers
        )
        
        # ä¼ç¬”åˆ†æå™¨ï¼ˆå¯é€‰åŠŸèƒ½ï¼Œé»˜è®¤æ‰‹åŠ¨æ¨¡å¼ï¼‰
        # ä¼ å…¥ memory_provider ç”¨äºä»å·²ä¿å­˜è®°å¿†è·å–å¯¹è¯ï¼Œæé«˜å¯é æ€§
        # ä¼ å…¥ storage_dir ç”¨äºæŒä¹…åŒ–åˆ†æçŠ¶æ€ï¼ŒæœåŠ¡å™¨é‡å¯ä¸ä¸¢å¤±
        self.foreshadowing_analyzer = ForeshadowingAnalyzer(
            tracker=self.foreshadowing_tracker,
            config=self._foreshadowing_config,  # å¯èƒ½æ˜¯ Noneï¼Œä¼šä½¿ç”¨é»˜è®¤æ‰‹åŠ¨æ¨¡å¼
            storage_dir=os.path.join(self.data_root, 'data', 'foreshadowing_analyzer'),
            memory_provider=self._get_recent_memories_for_analysis
        )
        
        # L0 æ ¸å¿ƒè®¾å®šï¼ˆè§’è‰²å¡ã€ä¸–ç•Œè§‚ã€è§„åˆ™ç­‰ï¼‰
        # æå‰åŠ è½½ï¼Œå› ä¸º ConsistencyChecker éœ€è¦ absolute_rules
        self.core_settings = CoreSettings.load(
            data_path=os.path.join(self.data_root, 'data')
        )
        
        # ä¸€è‡´æ€§æ£€æŸ¥å™¨ï¼ˆä¼ å…¥ç”¨æˆ·å®šä¹‰çš„ç»å¯¹è§„åˆ™ + LLMå®¢æˆ·ç«¯ç”¨äºè¯­ä¹‰æ£€æµ‹ï¼‰
        self.consistency_checker = ConsistencyChecker(
            absolute_rules=self.core_settings.absolute_rules,
            llm_client=self.llm_client  # å¯ç”¨LLMè¯­ä¹‰è§„åˆ™æ£€æµ‹
        )
        self.memory_summarizer = MemorySummarizer(llm_client=self.llm_client)
        self.scenario_detector = ScenarioDetector()
        
        # æŒä¹…ä¸Šä¸‹æ–‡è¿½è¸ªå™¨ï¼ˆè¿½è¸ªæŒä¹…æ€§å‰ææ¡ä»¶ï¼‰
        # ä½¿ç”¨åŒä¸€ä¸ªembedding_backendç”¨äºè¯­ä¹‰å»é‡
        # ä½¿ç”¨æ–°çš„ {user_id}/{character_id}/ å­˜å‚¨ç»“æ„
        # ä¼ å…¥ memory_provider ç”¨äºä»å·²ä¿å­˜è®°å¿†è·å–å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œå¸®åŠ© LLM æ›´å¥½æå–æ¡ä»¶
        self.context_tracker = ContextTracker(
            base_path=os.path.join(self.data_root, 'data'),
            llm_client=self.llm_client,
            embedding_backend=embedding_backend_for_trackers,
            memory_provider=self._get_recent_memories_for_analysis
        )
        
        # é•¿æœŸè®°å¿†å±‚ï¼ˆL1 ConsolidatedMemoryï¼‰
        self.consolidated_memory = ConsolidatedMemory(
            data_path=os.path.join(self.data_root, 'data')
        )
        
        # å›¾è°±å±‚
        self.knowledge_graph = KnowledgeGraph(
            data_path=os.path.join(self.data_root, 'data')
        )
        self.relation_extractor = RelationExtractor(
            entity_extractor=self.entity_extractor
        )
        
        # æ£€ç´¢å±‚ - æä¾›å†…å®¹å›è°ƒ
        # Phase 3.6: åŠ è½½ä¸‰è·¯å¬å›é…ç½®
        self.triple_recall_config = TripleRecallConfig.from_env()
        
        self.retriever = EightLayerRetriever(
            bloom_filter=self._ngram_index.bloom_filter if self._ngram_index else None,
            inverted_index=self._inverted_index,
            entity_index=self._entity_index,
            ngram_index=self._ngram_index,
            vector_index=self._vector_index,
            llm_client=self.llm_client,
            content_store=self._get_memory_content_by_id,
            # Phase 3.6: ä¼ å…¥ embedding_backendï¼ˆç”¨äº VectorIndexIVFï¼‰
            embedding_backend=self.embedding_backend if hasattr(self, 'embedding_backend') else None,
        )
        
        # Phase 3.6: æ³¨å…¥å¹¶è¡Œå¬å›é…ç½®
        if self.triple_recall_config.enabled:
            self.retriever.config.update({
                'parallel_recall_enabled': True,
                'rrf_k': self.triple_recall_config.rrf_k,
                'vector_weight': self.triple_recall_config.vector_weight,
                'keyword_weight': self.triple_recall_config.keyword_weight,
                'entity_weight': self.triple_recall_config.entity_weight,
                'fallback_enabled': self.triple_recall_config.fallback_enabled,
                'fallback_parallel': self.triple_recall_config.fallback_parallel,
                'fallback_workers': self.triple_recall_config.fallback_workers,
            })
        
        self.context_builder = ContextBuilder()
        
        # ç›‘æ§
        self.monitor = PerformanceMonitor(auto_collect=False)
        
        # é¢„åŠ è½½æœ€è¿‘çš„å·ï¼ˆç¡®ä¿çƒ­æ•°æ®åœ¨å†…å­˜ä¸­ï¼Œæ”¯æŒä¸Šä¸‡è½®RPï¼‰
        self.volume_manager.preload_recent()
        
        # æ£€æŸ¥å¹¶ä¸ºå·²æœ‰çš„ä¼ç¬”/æ¡ä»¶è¡¥å»º VectorIndex ç´¢å¼•ï¼ˆé¦–æ¬¡å‡çº§æ—¶æ‰§è¡Œï¼‰
        self._check_and_rebuild_index()
        
        # v4.0 Phase 1 å¯é€‰æ¨¡å—åˆå§‹åŒ–ï¼ˆåŸºäºé…ç½®å¼€å…³ï¼‰
        self._init_v4_modules()
    
    def _init_v4_modules(self):
        """åˆå§‹åŒ– v4.0 Phase 1/2 å¯é€‰æ¨¡å—
        
        è¿™äº›æ¨¡å—åŸºäºé…ç½®æ–‡ä»¶ä¸­çš„å¼€å…³å†³å®šæ˜¯å¦å¯ç”¨ï¼š
        - TEMPORAL_GRAPH_ENABLED: æ—¶æ€çŸ¥è¯†å›¾è°±
        - CONTRADICTION_DETECTION_ENABLED: çŸ›ç›¾æ£€æµ‹
        - FULLTEXT_ENABLED: å…¨æ–‡æ£€ç´¢ (BM25)
        
        è®¾è®¡åŸåˆ™ï¼š
        1. é»˜è®¤å…³é—­ï¼Œä¸å½±å“ç°æœ‰åŠŸèƒ½
        2. å³ä½¿å¯ç”¨å¤±è´¥ä¹Ÿä¸å½±å“å¼•æ“è¿è¡Œ
        3. æ‰€æœ‰ Phase 1 æ¨¡å—éƒ½æ˜¯å¯é€‰çš„å¢å¼ºåŠŸèƒ½
        """
        # åˆå§‹åŒ–ä¸º Noneï¼Œè¡¨ç¤ºæœªå¯ç”¨
        self.temporal_graph = None
        self.contradiction_manager = None
        self.fulltext_index = None
        
        # è¯»å–é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡ï¼‰
        temporal_enabled = os.environ.get('TEMPORAL_GRAPH_ENABLED', 'false').lower() == 'true'
        contradiction_enabled = os.environ.get('CONTRADICTION_DETECTION_ENABLED', 'false').lower() == 'true'
        fulltext_enabled = os.environ.get('FULLTEXT_ENABLED', 'false').lower() == 'true'
        
        # 1. æ—¶æ€çŸ¥è¯†å›¾è°±
        if temporal_enabled:
            try:
                from .graph import TemporalKnowledgeGraph
                # è¯»å–å›¾è°±åç«¯é…ç½®
                graph_backend = os.environ.get('TEMPORAL_GRAPH_BACKEND', 'file').lower()
                # è¯»å–è¡°å‡ç‡å’Œå†å²è®°å½•é™åˆ¶é…ç½®
                decay_rate = float(os.environ.get('TEMPORAL_DECAY_RATE', '0.1'))
                max_history = int(os.environ.get('TEMPORAL_MAX_HISTORY', '1000'))
                self.temporal_graph = TemporalKnowledgeGraph(
                    data_path=os.path.join(self.data_root, 'data'),
                    backend=graph_backend
                )
                # è®¾ç½®é¢å¤–é…ç½®ï¼ˆå¦‚æœç±»æ”¯æŒï¼‰
                if hasattr(self.temporal_graph, 'decay_rate'):
                    self.temporal_graph.decay_rate = decay_rate
                if hasattr(self.temporal_graph, 'max_history'):
                    self.temporal_graph.max_history = max_history
                _safe_print(f"[Recall v4.0] æ—¶æ€çŸ¥è¯†å›¾è°±å·²å¯ç”¨ (backend={graph_backend})")
            except Exception as e:
                _safe_print(f"[Recall v4.0] æ—¶æ€çŸ¥è¯†å›¾è°±åˆå§‹åŒ–å¤±è´¥ï¼ˆä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼‰: {e}")
        
        # 2. çŸ›ç›¾æ£€æµ‹ç®¡ç†å™¨
        if contradiction_enabled:
            try:
                from .graph import ContradictionManager, DetectionStrategy
                # ç­–ç•¥æ˜ å°„ï¼šæ”¯æŒæ–°æ—§åç§°ï¼Œé»˜è®¤ MIXED
                strategy_str = os.environ.get('CONTRADICTION_DETECTION_STRATEGY', 'MIXED').upper()
                strategy_map = {
                    # æ–°åç§°ï¼ˆæ¨èï¼‰
                    'RULE': DetectionStrategy.RULE,
                    'LLM': DetectionStrategy.LLM,
                    'MIXED': DetectionStrategy.MIXED,
                    'AUTO': DetectionStrategy.AUTO,
                    # æ—§åç§°ï¼ˆå‘åå…¼å®¹ï¼‰
                    'EMBEDDING': DetectionStrategy.MIXED,  # å…¼å®¹æ—§é…ç½®
                    'LLM_ONLY': DetectionStrategy.LLM,
                    'RULE_ONLY': DetectionStrategy.RULE,
                    'HYBRID': DetectionStrategy.MIXED,
                }
                strategy = strategy_map.get(strategy_str, DetectionStrategy.MIXED)
                
                # è¯»å–é¢å¤–é…ç½®
                auto_resolve = os.environ.get('CONTRADICTION_AUTO_RESOLVE', 'false').lower() == 'true'
                similarity_threshold = float(os.environ.get('CONTRADICTION_SIMILARITY_THRESHOLD', '0.8'))
                
                self.contradiction_manager = ContradictionManager(
                    data_path=os.path.join(self.data_root, 'data'),
                    strategy=strategy,
                    llm_client=self.llm_client,
                    auto_resolve=auto_resolve
                )
                # è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆå¦‚æœç±»æ”¯æŒï¼‰
                if hasattr(self.contradiction_manager, 'similarity_threshold'):
                    self.contradiction_manager.similarity_threshold = similarity_threshold
                _safe_print(f"[Recall v4.0] çŸ›ç›¾æ£€æµ‹å·²å¯ç”¨ (ç­–ç•¥: {strategy.value}, è‡ªåŠ¨è§£å†³: {auto_resolve})")
            except Exception as e:
                _safe_print(f"[Recall v4.0] çŸ›ç›¾æ£€æµ‹åˆå§‹åŒ–å¤±è´¥ï¼ˆä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼‰: {e}")
        
        # 3. å…¨æ–‡æ£€ç´¢ç´¢å¼• (BM25)
        if fulltext_enabled:
            try:
                from .index import FullTextIndex, BM25Config
                k1 = float(os.environ.get('FULLTEXT_K1', '1.5'))
                b = float(os.environ.get('FULLTEXT_B', '0.75'))
                weight = float(os.environ.get('FULLTEXT_WEIGHT', '0.3'))
                
                self.fulltext_index = FullTextIndex(
                    data_path=os.path.join(self.data_root, 'index', 'fulltext'),
                    config=BM25Config(k1=k1, b=b)
                )
                # ä¿å­˜æƒé‡ä¾›æ£€ç´¢æ—¶ä½¿ç”¨
                self._fulltext_weight = weight
                _safe_print(f"[Recall v4.0] å…¨æ–‡æ£€ç´¢å·²å¯ç”¨ (BM25 k1={k1}, b={b}, weight={weight})")
            except Exception as e:
                _safe_print(f"[Recall v4.0] å…¨æ–‡æ£€ç´¢åˆå§‹åŒ–å¤±è´¥ï¼ˆä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼‰: {e}")
        
        # 4. Phase 3: åä¸€å±‚æ£€ç´¢å™¨ï¼ˆå¯é€‰å‡çº§ï¼‰
        eleven_layer_enabled = os.environ.get('ELEVEN_LAYER_RETRIEVER_ENABLED', 'false').lower() == 'true'
        if eleven_layer_enabled:
            self._init_eleven_layer_retriever()
        
        # 5. Phase 2: é¢„ç®—ç®¡ç†å™¨ï¼ˆç”¨äºæ§åˆ¶ LLM æˆæœ¬ï¼‰
        self._init_budget_manager()
        
        # 6. Phase 2: æ™ºèƒ½æŠ½å–å™¨ï¼ˆæ›¿æ¢é»˜è®¤çš„ EntityExtractorï¼‰
        self._init_smart_extractor()
        
        # 7. Phase 2: ä¸‰é˜¶æ®µå»é‡å™¨ï¼ˆç”¨äºå®ä½“/è®°å¿†å»é‡ï¼‰
        self._init_three_stage_deduplicator()
        
        # 8. Phase 3.5: å›¾æŸ¥è¯¢è§„åˆ’å™¨ï¼ˆç”¨äºä¼˜åŒ–å¤šè·³æŸ¥è¯¢ï¼‰
        self._init_query_planner()
        
        # 9. Phase 3.5: ç¤¾åŒºæ£€æµ‹å™¨ï¼ˆç”¨äºå‘ç°å®ä½“ç¾¤ç»„ï¼‰
        self._init_community_detector()
    
    def _init_query_planner(self):
        """åˆå§‹åŒ–å›¾æŸ¥è¯¢è§„åˆ’å™¨ (Phase 3.5)
        
        ç”¨äºä¼˜åŒ–å¤šè·³å›¾æŸ¥è¯¢ï¼š
        - ç´¢å¼•ä¼˜å…ˆ - æœ‰ç´¢å¼•çš„å­—æ®µä¼˜å…ˆä½¿ç”¨ç´¢å¼•
        - æ—©æœŸè¿‡æ»¤ - å°½æ—©å‡å°‘å€™é€‰é›†
        - è·¯å¾„ç¼“å­˜ - ç¼“å­˜å¸¸è§è·¯å¾„æ¨¡å¼
        """
        self.query_planner = None
        
        # åªæœ‰å½“æ—¶æ€å›¾å¯ç”¨æ—¶æ‰åˆå§‹åŒ–
        if not self.temporal_graph:
            return
        
        query_planner_enabled = os.environ.get('QUERY_PLANNER_ENABLED', 'false').lower() == 'true'
        if query_planner_enabled:
            try:
                from .graph import QueryPlanner
                self.query_planner = QueryPlanner(self.temporal_graph)
                _safe_print("[Recall v4.0 Phase 3.5] å›¾æŸ¥è¯¢è§„åˆ’å™¨å·²å¯ç”¨")
            except Exception as e:
                _safe_print(f"[Recall v4.0] å›¾æŸ¥è¯¢è§„åˆ’å™¨åˆå§‹åŒ–å¤±è´¥ï¼ˆä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼‰: {e}")
    
    def _init_community_detector(self):
        """åˆå§‹åŒ–ç¤¾åŒºæ£€æµ‹å™¨ (Phase 3.5)
        
        ç”¨äºå‘ç°å›¾ä¸­çš„å®ä½“ç¾¤ç»„ï¼š
        - Louvain: æœ€å¸¸ç”¨ï¼Œé€‚åˆå¤§è§„æ¨¡å›¾
        - Label Propagation: å¿«é€Ÿï¼Œé€‚åˆåŠ¨æ€å›¾
        - Connected Components: åŸºç¡€è¿é€šåˆ†é‡
        """
        self.community_detector = None
        
        community_enabled = os.environ.get('COMMUNITY_DETECTION_ENABLED', 'false').lower() == 'true'
        if community_enabled:
            try:
                from .graph import CommunityDetector
                from .graph.backends import create_graph_backend
                
                # ä½¿ç”¨ legacy é€‚é…å™¨åŒ…è£…ç°æœ‰ KnowledgeGraph
                backend = create_graph_backend(
                    data_path=os.path.join(self.data_root, 'data'),
                    backend='legacy',
                    existing_knowledge_graph=self.knowledge_graph
                )
                
                algorithm = os.environ.get('COMMUNITY_DETECTION_ALGORITHM', 'louvain')
                min_size = int(os.environ.get('COMMUNITY_MIN_SIZE', '2'))
                
                self.community_detector = CommunityDetector(
                    graph_backend=backend,
                    algorithm=algorithm,
                    min_community_size=min_size
                )
                _safe_print(f"[Recall v4.0 Phase 3.5] ç¤¾åŒºæ£€æµ‹å™¨å·²å¯ç”¨ (ç®—æ³•: {algorithm})")
            except Exception as e:
                _safe_print(f"[Recall v4.0] ç¤¾åŒºæ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥ï¼ˆä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼‰: {e}")
    
    def _init_budget_manager(self):
        """åˆå§‹åŒ–é¢„ç®—ç®¡ç†å™¨ (Phase 2)
        
        ç”¨äºæ§åˆ¶ LLM API è°ƒç”¨æˆæœ¬ï¼Œæ”¯æŒï¼š
        - æ¯æ—¥/æ¯å°æ—¶é¢„ç®—é™åˆ¶
        - é¢„ç®—é¢„è­¦
        - è¶…æ”¯æ—¶è‡ªåŠ¨é™çº§
        """
        self.budget_manager = None
        
        # æ£€æŸ¥æ˜¯å¦é…ç½®äº†é¢„ç®—é™åˆ¶
        daily_limit = float(os.environ.get('BUDGET_DAILY_LIMIT', '0'))
        hourly_limit = float(os.environ.get('BUDGET_HOURLY_LIMIT', '0'))
        
        # åªæœ‰é…ç½®äº†é¢„ç®—æ‰å¯ç”¨
        if daily_limit > 0 or hourly_limit > 0:
            try:
                from .utils.budget_manager import BudgetManager, BudgetConfig
                
                reserve = float(os.environ.get('BUDGET_RESERVE', '0.1'))
                alert_threshold = float(os.environ.get('BUDGET_ALERT_THRESHOLD', '0.8'))
                
                config = BudgetConfig(
                    daily_budget=daily_limit,
                    hourly_budget=hourly_limit,
                    warning_threshold=alert_threshold,
                    auto_degrade=True  # è¶…æ”¯æ—¶è‡ªåŠ¨é™çº§åˆ°æœ¬åœ°æ¨¡å¼
                )
                
                self.budget_manager = BudgetManager(
                    data_path=os.path.join(self.data_root, 'data'),
                    config=config
                )
                _safe_print(f"[Recall v4.0] é¢„ç®—ç®¡ç†å™¨å·²å¯ç”¨ (æ¯æ—¥=${daily_limit}, æ¯å°æ—¶=${hourly_limit})")
            except Exception as e:
                _safe_print(f"[Recall v4.0] é¢„ç®—ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥ï¼ˆä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼‰: {e}")
    
    def _init_smart_extractor(self):
        """åˆå§‹åŒ–æ™ºèƒ½æŠ½å–å™¨ (Phase 2)
        
        æ›¿æ¢é»˜è®¤çš„ EntityExtractorï¼Œæ”¯æŒï¼š
        - RULES æ¨¡å¼ï¼šçº¯è§„åˆ™æŠ½å–ï¼ˆé›¶ LLM æˆæœ¬ï¼‰
        - ADAPTIVE æ¨¡å¼ï¼šç®€å•æ–‡æœ¬ç”¨è§„åˆ™ï¼Œå¤æ‚æ–‡æœ¬ç”¨ LLM
        - LLM æ¨¡å¼ï¼šå…¨éƒ¨ä½¿ç”¨ LLMï¼ˆæœ€é«˜è´¨é‡ï¼‰
        """
        self.smart_extractor = None
        
        # è¯»å–é…ç½®
        mode_str = os.environ.get('SMART_EXTRACTOR_MODE', 'RULES').upper()
        
        try:
            from .processor.smart_extractor import SmartExtractor, SmartExtractorConfig, ExtractionMode
            
            # æ¨¡å¼æ˜ å°„
            mode_map = {
                'RULES': ExtractionMode.RULES,
                'ADAPTIVE': ExtractionMode.ADAPTIVE,
                'LLM': ExtractionMode.LLM,
                # å‘åå…¼å®¹
                'LOCAL': ExtractionMode.RULES,
                'HYBRID': ExtractionMode.ADAPTIVE,
                'LLM_FULL': ExtractionMode.LLM,
            }
            mode = mode_map.get(mode_str, ExtractionMode.RULES)
            
            complexity_threshold = float(os.environ.get('SMART_EXTRACTOR_COMPLEXITY_THRESHOLD', '0.6'))
            enable_temporal = os.environ.get('SMART_EXTRACTOR_ENABLE_TEMPORAL', 'true').lower() == 'true'
            
            # æ„å»ºé…ç½®å¯¹è±¡
            config = SmartExtractorConfig(
                mode=mode,
                complexity_threshold=complexity_threshold,
                enable_temporal_detection=enable_temporal
            )
            
            self.smart_extractor = SmartExtractor(
                config=config,
                llm_client=self.llm_client if mode != ExtractionMode.RULES else None,
                budget_manager=self.budget_manager
            )
            _safe_print(f"[Recall v4.0] æ™ºèƒ½æŠ½å–å™¨å·²å¯ç”¨ (æ¨¡å¼: {mode.value})")
        except Exception as e:
            _safe_print(f"[Recall v4.0] æ™ºèƒ½æŠ½å–å™¨åˆå§‹åŒ–å¤±è´¥ï¼ˆä½¿ç”¨é»˜è®¤æŠ½å–å™¨ï¼‰: {e}")
    
    def _init_three_stage_deduplicator(self):
        """åˆå§‹åŒ–ä¸‰é˜¶æ®µå»é‡å™¨ (Phase 2)
        
        ç”¨äºå®ä½“å’Œè®°å¿†çš„æ™ºèƒ½å»é‡ï¼š
        - é˜¶æ®µ1: MinHash + LSHï¼ˆå¿«é€Ÿç²—ç­›ï¼‰
        - é˜¶æ®µ2: Embedding è¯­ä¹‰ç›¸ä¼¼åº¦
        - é˜¶æ®µ3: LLM ç¡®è®¤ï¼ˆå¯é€‰ï¼Œç”¨äºè¾¹ç•Œæƒ…å†µï¼‰
        """
        self.deduplicator = None
        
        try:
            from .processor.three_stage_deduplicator import ThreeStageDeduplicator, DedupConfig
            
            # è¯»å–é…ç½®ï¼ˆé»˜è®¤é˜ˆå€¼è¾ƒé«˜ä»¥é¿å…è¯¯åˆ¤ï¼‰
            jaccard_threshold = float(os.environ.get('DEDUP_JACCARD_THRESHOLD', '0.85'))
            semantic_high = float(os.environ.get('DEDUP_SEMANTIC_THRESHOLD', '0.90'))
            semantic_low = float(os.environ.get('DEDUP_SEMANTIC_LOW_THRESHOLD', '0.80'))
            llm_enabled = os.environ.get('DEDUP_LLM_ENABLED', 'false').lower() == 'true'
            
            # æ„å»ºé…ç½®å¯¹è±¡
            config = DedupConfig(
                jaccard_threshold=jaccard_threshold,
                semantic_threshold=semantic_high,
                semantic_low_threshold=semantic_low,
                llm_enabled=llm_enabled
            )
            
            self.deduplicator = ThreeStageDeduplicator(
                config=config,
                embedding_backend=self.embedding_backend if hasattr(self, 'embedding_backend') else None,
                llm_client=self.llm_client if llm_enabled else None,
                budget_manager=self.budget_manager
            )
            _safe_print(f"[Recall v4.0] ä¸‰é˜¶æ®µå»é‡å™¨å·²å¯ç”¨ (Jaccard={jaccard_threshold}, Semantic={semantic_low}-{semantic_high}, LLM={llm_enabled})")
        except Exception as e:
            _safe_print(f"[Recall v4.0] ä¸‰é˜¶æ®µå»é‡å™¨åˆå§‹åŒ–å¤±è´¥ï¼ˆä½¿ç”¨é»˜è®¤å»é‡ï¼‰: {e}")
    
    def _init_eleven_layer_retriever(self):
        """åˆå§‹åŒ– Phase 3 åä¸€å±‚æ£€ç´¢å™¨
        
        æ›¿æ¢é»˜è®¤çš„ EightLayerRetrieverï¼Œå¯ç”¨ï¼š
        - L2: æ—¶æ€è¿‡æ»¤ï¼ˆéœ€è¦ temporal_graphï¼‰
        - L5: å›¾éå†æ‰©å±•ï¼ˆéœ€è¦ temporal_graphï¼‰
        - L10: CrossEncoder ç²¾æ’ï¼ˆå¯é€‰ï¼‰
        - L11: LLM è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰
        
        è®¾è®¡åŸåˆ™ï¼š
        1. é€šè¿‡ç¯å¢ƒå˜é‡ ELEVEN_LAYER_RETRIEVER_ENABLED=true å¯ç”¨
        2. å³ä½¿éƒ¨åˆ†ä¾èµ–ä¸å¯ç”¨ä¹Ÿèƒ½é™çº§è¿è¡Œ
        3. ä¸å½±å“ç°æœ‰ API æ¥å£
        """
        try:
            # æ„å»ºæ£€ç´¢é…ç½®
            config = RetrievalConfig.from_env()
            
            # æ£€æŸ¥ CrossEncoder æ˜¯å¦éœ€è¦åŠ è½½
            cross_encoder = None
            if config.l10_enabled:
                cross_encoder = self._load_cross_encoder()
            
            # è·å–æ—¶æ€ç´¢å¼•ï¼ˆå¦‚æœ temporal_graph å¯ç”¨ï¼‰
            temporal_index = None
            if self.temporal_graph and hasattr(self.temporal_graph, '_temporal_index'):
                temporal_index = self.temporal_graph._temporal_index
            
            # åˆ›å»º ElevenLayerRetriever
            self.retriever = ElevenLayerRetriever(
                # ç°æœ‰ä¾èµ–ï¼ˆä¸ EightLayerRetriever ç›¸åŒï¼‰
                bloom_filter=self._ngram_index.bloom_filter if self._ngram_index else None,
                inverted_index=self._inverted_index,
                entity_index=self._entity_index,
                ngram_index=self._ngram_index,
                vector_index=self._vector_index,
                llm_client=self.llm_client,
                content_store=self._get_memory_content_by_id,
                # Phase 3 æ–°å¢ä¾èµ–
                temporal_index=temporal_index,
                knowledge_graph=self.temporal_graph,
                cross_encoder=cross_encoder,
                # Phase 3.6: ä¼ å…¥ embedding_backendï¼ˆç”¨äº VectorIndexIVFï¼‰
                embedding_backend=self.embedding_backend if hasattr(self, 'embedding_backend') else None,
                # é…ç½®
                config=config
            )
            
            # è®°å½•å¯ç”¨çŠ¶æ€
            layers_status = []
            # Phase 3.6 çŠ¶æ€
            if config.parallel_recall_enabled:
                layers_status.append("Phase3.6:å¹¶è¡Œä¸‰è·¯å¬å›")
            if config.l2_enabled and temporal_index:
                layers_status.append("L2:æ—¶æ€è¿‡æ»¤")
            if config.l5_enabled and self.temporal_graph:
                layers_status.append("L5:å›¾éå†")
            if config.l10_enabled and cross_encoder:
                layers_status.append("L10:CrossEncoder")
            if config.l11_enabled:
                layers_status.append("L11:LLMè¿‡æ»¤")
            
            status_str = ", ".join(layers_status) if layers_status else "åŸºç¡€æ¨¡å¼"
            _safe_print(f"[Recall v4.0 Phase 3] åä¸€å±‚æ£€ç´¢å™¨å·²å¯ç”¨ ({status_str})")
            
        except Exception as e:
            _safe_print(f"[Recall v4.0 Phase 3] åä¸€å±‚æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ°å…«å±‚æ£€ç´¢å™¨: {e}")
            # å¤±è´¥æ—¶ä¸ä¿®æ”¹ self.retrieverï¼Œä¿æŒ EightLayerRetriever
    
    def _load_cross_encoder(self):
        """æŒ‰éœ€åŠ è½½ CrossEncoder æ¨¡å‹
        
        Returns:
            CrossEncoder æ¨¡å‹å®ä¾‹ï¼Œæˆ– Noneï¼ˆå¦‚æœåŠ è½½å¤±è´¥ï¼‰
        """
        try:
            from sentence_transformers import CrossEncoder
            model_name = os.environ.get(
                'RETRIEVAL_L10_CROSS_ENCODER_MODEL',
                'cross-encoder/ms-marco-MiniLM-L-6-v2'
            )
            return CrossEncoder(model_name)
        except ImportError:
            _safe_print("[Recall v4.0 Phase 3] sentence-transformers æœªå®‰è£…ï¼ŒCrossEncoder ä¸å¯ç”¨")
            return None
        except Exception as e:
            _safe_print(f"[Recall v4.0 Phase 3] CrossEncoder åŠ è½½å¤±è´¥: {e}")
            return None
    
    def _check_and_rebuild_index(self):
        """æ£€æŸ¥å¹¶ä¸ºå·²æœ‰ä¼ç¬”/æ¡ä»¶è¡¥å»º VectorIndex ç´¢å¼•
        
        ä½¿ç”¨æ ‡è®°æ–‡ä»¶ .index_rebuilt_v3 æ¥åˆ¤æ–­æ˜¯å¦å·²ç»è¿ç§»è¿‡ã€‚
        v3 ç‰ˆæœ¬æ”¯æŒç´¢å¼•å½’æ¡£æ–‡ä»¶ (archive/*.jsonl)ã€‚
        å¦‚æœæ²¡æœ‰ VectorIndex æˆ–å·²ç¦ç”¨ï¼Œåˆ™è·³è¿‡ã€‚
        """
        if not self._vector_index or not self._vector_index.enabled:
            return
        
        marker_file = os.path.join(self.data_root, 'data', '.index_rebuilt_v3')
        if os.path.exists(marker_file):
            return  # å·²ç»è¿ç§»è¿‡
        
        import logging
        import glob
        logger = logging.getLogger(__name__)
        logger.info("[Recall] æ£€æµ‹åˆ°é¦–æ¬¡å‡çº§æˆ–ç‰ˆæœ¬æ›´æ–°ï¼Œå¼€å§‹ä¸ºå·²æœ‰ä¼ç¬”/æ¡ä»¶è¡¥å»º VectorIndex ç´¢å¼•...")
        
        indexed_count = 0
        archived_count = 0
        
        # 1. ç´¢å¼•æ‰€æœ‰ä¼ç¬”å’Œæ¡ä»¶ï¼ˆåŒ…æ‹¬æ´»è·ƒçš„å’Œå½’æ¡£çš„ï¼‰
        data_path = os.path.join(self.data_root, 'data')
        if os.path.exists(data_path):
            for user_id in os.listdir(data_path):
                user_path = os.path.join(data_path, user_id)
                if not os.path.isdir(user_path) or user_id.startswith('.'):
                    continue
                for character_id in os.listdir(user_path):
                    char_path = os.path.join(user_path, character_id)
                    if not os.path.isdir(char_path):
                        continue
                    
                    # 1.1 ç´¢å¼•æ´»è·ƒä¼ç¬” (foreshadowings.json)
                    fsh_file = os.path.join(char_path, 'foreshadowings.json')
                    if os.path.exists(fsh_file):
                        try:
                            import json
                            with open(fsh_file, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                            foreshadowings = data.get('foreshadowings', {})
                            for fsh_id, fsh in foreshadowings.items():
                                content = fsh.get('content', '')
                                if content:
                                    # æ³¨æ„ï¼šfsh_id å·²ç»æ˜¯ fsh_{counter}_{timestamp} æ ¼å¼
                                    # ä¸éœ€è¦å†åŠ  fsh_ å‰ç¼€ï¼Œä¸ plant_foreshadowing ä¿æŒä¸€è‡´
                                    doc_id = f"{user_id}_{character_id}_{fsh_id}"
                                    self._vector_index.add_text(doc_id, content)
                                    indexed_count += 1
                        except Exception as e:
                            logger.warning(f"[Recall] ç´¢å¼•ä¼ç¬”å¤±è´¥ ({user_id}/{character_id}): {e}")
                    
                    # 1.2 ç´¢å¼•æ´»è·ƒæ¡ä»¶ (contexts.json)
                    ctx_file = os.path.join(char_path, 'contexts.json')
                    if os.path.exists(ctx_file):
                        try:
                            import json
                            with open(ctx_file, 'r', encoding='utf-8') as f:
                                contexts = json.load(f)
                            for ctx in contexts:
                                if ctx.get('is_active', True):
                                    content = ctx.get('content', '')
                                    ctx_id = ctx.get('id', '')
                                    if content and ctx_id:
                                        doc_id = f"ctx_{user_id}_{character_id}_{ctx_id}"
                                        self._vector_index.add_text(doc_id, content)
                                        indexed_count += 1
                        except Exception as e:
                            logger.warning(f"[Recall] ç´¢å¼•æ¡ä»¶å¤±è´¥ ({user_id}/{character_id}): {e}")
                    
                    # 1.3 ç´¢å¼•å½’æ¡£ä¼ç¬” (archive/foreshadowings*.jsonl)
                    archive_dir = os.path.join(char_path, 'archive')
                    if os.path.isdir(archive_dir):
                        # åŒ¹é… foreshadowings.jsonl å’Œ foreshadowings_001.jsonl ç­‰
                        fsh_archive_files = glob.glob(os.path.join(archive_dir, 'foreshadowings*.jsonl'))
                        for archive_file in fsh_archive_files:
                            try:
                                with open(archive_file, 'r', encoding='utf-8') as f:
                                    for line in f:
                                        line = line.strip()
                                        if not line:
                                            continue
                                        fsh = json.loads(line)
                                        fsh_id = fsh.get('id', '')
                                        content = fsh.get('content', '')
                                        if content and fsh_id:
                                            doc_id = f"{user_id}_{character_id}_{fsh_id}"
                                            self._vector_index.add_text(doc_id, content)
                                            archived_count += 1
                            except Exception as e:
                                logger.warning(f"[Recall] ç´¢å¼•å½’æ¡£ä¼ç¬”å¤±è´¥ ({archive_file}): {e}")
                        
                        # 1.4 ç´¢å¼•å½’æ¡£æ¡ä»¶ (archive/contexts*.jsonl)
                        ctx_archive_files = glob.glob(os.path.join(archive_dir, 'contexts*.jsonl'))
                        for archive_file in ctx_archive_files:
                            try:
                                with open(archive_file, 'r', encoding='utf-8') as f:
                                    for line in f:
                                        line = line.strip()
                                        if not line:
                                            continue
                                        ctx = json.loads(line)
                                        ctx_id = ctx.get('id', '')
                                        content = ctx.get('content', '')
                                        if content and ctx_id:
                                            doc_id = f"ctx_{user_id}_{character_id}_{ctx_id}"
                                            self._vector_index.add_text(doc_id, content)
                                            archived_count += 1
                            except Exception as e:
                                logger.warning(f"[Recall] ç´¢å¼•å½’æ¡£æ¡ä»¶å¤±è´¥ ({archive_file}): {e}")
        
        # åˆ›å»ºæ ‡è®°æ–‡ä»¶
        os.makedirs(os.path.dirname(marker_file), exist_ok=True)
        total_count = indexed_count + archived_count
        with open(marker_file, 'w') as f:
            f.write(f"indexed_at: {time.time()}\n")
            f.write(f"active_count: {indexed_count}\n")
            f.write(f"archived_count: {archived_count}\n")
            f.write(f"total_count: {total_count}\n")
        
        logger.info(f"[Recall] VectorIndex ç´¢å¼•è¡¥å»ºå®Œæˆï¼Œå…±ç´¢å¼• {total_count} æ¡è®°å½• (æ´»è·ƒ: {indexed_count}, å½’æ¡£: {archived_count})")
        
        return total_count

    def rebuild_vector_index(self, force: bool = False) -> int:
        """æ‰‹åŠ¨é‡å»º VectorIndex ç´¢å¼•
        
        ä¸ºæ‰€æœ‰ä¼ç¬”å’Œæ¡ä»¶é‡å»ºè¯­ä¹‰ç´¢å¼•ã€‚é€šå¸¸ä¸éœ€è¦æ‰‹åŠ¨è°ƒç”¨ï¼Œ
        ç³»ç»Ÿä¼šåœ¨é¦–æ¬¡å‡çº§æ—¶è‡ªåŠ¨é‡å»ºã€‚
        
        ä½¿ç”¨åœºæ™¯ï¼š
        - ç´¢å¼•æ•°æ®æŸåéœ€è¦é‡å»º
        - æ‰‹åŠ¨å¯¼å…¥äº†æ•°æ®æ–‡ä»¶
        - ä»å¤‡ä»½æ¢å¤åéœ€è¦é‡å»ºç´¢å¼•
        
        Args:
            force: æ˜¯å¦å¼ºåˆ¶é‡å»ºï¼ˆåˆ é™¤æ ‡è®°æ–‡ä»¶åé‡å»ºï¼‰
            
        Returns:
            int: ç´¢å¼•çš„è®°å½•æ•°é‡
        """
        if force:
            # åˆ é™¤ v3 æ ‡è®°æ–‡ä»¶ï¼ˆå½“å‰ç‰ˆæœ¬ï¼‰
            marker_file_v3 = os.path.join(self.data_root, 'data', '.index_rebuilt_v3')
            if os.path.exists(marker_file_v3):
                os.remove(marker_file_v3)
            # å…¼å®¹ï¼šä¹Ÿåˆ é™¤æ—§ç‰ˆæœ¬æ ‡è®°æ–‡ä»¶
            marker_file_v2 = os.path.join(self.data_root, 'data', '.index_rebuilt_v2')
            if os.path.exists(marker_file_v2):
                os.remove(marker_file_v2)
        
        return self._check_and_rebuild_index() or 0

    def _get_recent_memories_for_analysis(self, user_id: str, limit: int) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„è®°å¿†ç”¨äºä¼ç¬”åˆ†æ
        
        è¿™æ˜¯ ForeshadowingAnalyzer çš„ memory_provider å›è°ƒå‡½æ•°ã€‚
        ä»å·²ä¿å­˜çš„è®°å¿†ä¸­è·å–å¯¹è¯ï¼Œç¡®ä¿åˆ†æåŸºäºå·²æŒä¹…åŒ–çš„æ•°æ®ã€‚
        
        Args:
            user_id: ç”¨æˆ·/è§’è‰²ID
            limit: æœ€å¤§è¿”å›æ•°é‡
            
        Returns:
            List[Dict]: è®°å¿†åˆ—è¡¨ï¼ŒæŒ‰æ—¶é—´æ’åº
        """
        try:
            scope = self.storage.get_scope(user_id)
            memories = scope.get_all(limit=limit)
            
            # æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆæ—§ -> æ–°ï¼‰
            memories.sort(key=lambda m: m.get('metadata', {}).get('timestamp', 0))
            
            return memories
        except Exception as e:
            _safe_print(f"[Recall] è·å–è®°å¿†å¤±è´¥: {e}")
            return []
    
    def _get_memory_content_by_id(self, memory_id: str) -> Optional[str]:
        """é€šè¿‡ ID è·å–è®°å¿†å†…å®¹ï¼ˆä¾›æ£€ç´¢å™¨å›è°ƒï¼‰
        
        æŸ¥æ‰¾é¡ºåºï¼š
        1. MultiTenantStorage å†…å­˜ç¼“å­˜ï¼ˆæœ€å¿«ï¼‰
        2. VolumeManager å­˜æ¡£ï¼ˆç¡®ä¿100%ä¸é—å¿˜ï¼‰
        3. N-gram ç´¢å¼•çš„åŸæ–‡ç¼“å­˜ï¼ˆå…œåº•ï¼‰
        """
        # 1. å…ˆä» MultiTenantStorage å†…å­˜ä¸­æŸ¥æ‰¾ï¼ˆæœ€å¿«ï¼‰
        for scope_key, scope in self.storage._scopes.items():
            for memory in scope._memories:
                if memory.get('metadata', {}).get('id') == memory_id:
                    return memory.get('content', '')
        
        # 2. ä» VolumeManager å­˜æ¡£ä¸­æŸ¥æ‰¾ï¼ˆç¡®ä¿100%ä¸é—å¿˜ï¼‰
        if hasattr(self, 'volume_manager') and self.volume_manager:
            turn_data = self.volume_manager.get_turn_by_memory_id(memory_id)
            if turn_data:
                return turn_data.get('content', '')
        
        # 3. ä» N-gram ç´¢å¼•çš„åŸæ–‡ç¼“å­˜ä¸­æŸ¥æ‰¾ï¼ˆå…œåº•ï¼‰
        if self._ngram_index and hasattr(self._ngram_index, 'get_raw_content'):
            content = self._ngram_index.get_raw_content(memory_id)
            if content:
                return content
        
        return None
    
    def _init_indexes(self):
        """åˆå§‹åŒ–ç´¢å¼•"""
        index_path = os.path.join(self.data_root, 'index')
        os.makedirs(index_path, exist_ok=True)
        
        self._entity_index = EntityIndex(data_path=self.data_root)
        self._inverted_index = InvertedIndex(data_path=self.data_root)
        self._vector_index = VectorIndex(
            data_path=self.data_root,
            embedding_config=self.embedding_config
        )
        # N-gram ç´¢å¼•ï¼ˆæ”¯æŒæŒä¹…åŒ–ï¼‰
        ngram_data_path = os.path.join(self.data_root, 'index', 'ngram')
        self._ngram_index = OptimizedNgramIndex(data_path=ngram_data_path)
    
    def _rebuild_content_cache(self):
        """é‡å»ºå†…å®¹ç¼“å­˜ï¼ˆä»æŒä¹…åŒ–å­˜å‚¨æ¢å¤ï¼‰"""
        # æ‰«ææ‰€æœ‰ç”¨æˆ·ç›®å½•
        data_path = os.path.join(self.data_root, 'data')
        if not os.path.exists(data_path):
            return
        
        count = 0
        for user_dir in os.listdir(data_path):
            user_path = os.path.join(data_path, user_dir)
            if not os.path.isdir(user_path):
                continue
            
            # æ‰«æè¯¥ç”¨æˆ·ä¸‹çš„æ‰€æœ‰è§’è‰²/ä¼šè¯
            for root, dirs, files in os.walk(user_path):
                if 'memories.json' in files:
                    memories_file = os.path.join(root, 'memories.json')
                    try:
                        with open(memories_file, 'r', encoding='utf-8') as f:
                            memories = __import__('json').load(f)
                            for mem in memories:
                                mem_id = mem.get('metadata', {}).get('id')
                                content = mem.get('content', '')
                                metadata = mem.get('metadata', {})
                                entities = mem.get('entities', [])
                                if mem_id and content:
                                    self.retriever.cache_content(mem_id, content)
                                    # åŒæ—¶ç¼“å­˜ metadata å’Œ entities
                                    if hasattr(self.retriever, 'cache_metadata'):
                                        self.retriever.cache_metadata(mem_id, metadata)
                                    if hasattr(self.retriever, 'cache_entities'):
                                        self.retriever.cache_entities(mem_id, entities)
                                    count += 1
                    except Exception as e:
                        _safe_print(f"[Recall] åŠ è½½ {memories_file} å¤±è´¥: {e}")
        
        if count > 0:
            _safe_print(f"[Recall] å·²æ¢å¤ {count} æ¡è®°å¿†å†…å®¹åˆ°ç¼“å­˜")
    
    def _warmup(self):
        """é¢„çƒ­æ¨¡å‹ï¼ˆä»… Local æ¨¡å¼ï¼‰"""
        warmup_manager = WarmupManager()
        
        # æ³¨å†Œé¢„çƒ­ä»»åŠ¡
        warmup_manager.register(
            'entity_extractor',
            lambda: self.entity_extractor.nlp,
            priority=10
        )
        
        # åªæœ‰æœ¬åœ°æ¨¡å¼æ‰é¢„çƒ­å‘é‡æ¨¡å‹
        if self._vector_index and self._vector_index.enabled:
            if self.embedding_config.backend == EmbeddingBackendType.LOCAL:
                warmup_manager.register(
                    'vector_model',
                    lambda: self._vector_index.embedding_backend.model,
                    priority=5
                )
        
        # åå°é¢„çƒ­
        warmup_manager.warmup_async()
    
    # ==================== æ ¸å¿ƒ API ====================
    
    def add(
        self,
        content: str,
        user_id: str = "default",
        metadata: Optional[Dict[str, Any]] = None,
        check_consistency: bool = True
    ) -> AddResult:
        """æ·»åŠ è®°å¿†
        
        Args:
            content: è®°å¿†å†…å®¹
            user_id: ç”¨æˆ·ID
            metadata: å…ƒæ•°æ®
            check_consistency: æ˜¯å¦æ£€æŸ¥ä¸€è‡´æ€§
        
        Returns:
            AddResult: æ·»åŠ ç»“æœ
        """
        start_time = time.time()
        consistency_warnings = []  # æ”¶é›†ä¸€è‡´æ€§è­¦å‘Š
        
        try:
            # ã€å‡çº§ã€‘å»é‡æ£€æŸ¥ï¼šä¼˜å…ˆä½¿ç”¨ä¸‰é˜¶æ®µå»é‡å™¨ï¼ˆPhase 2ï¼‰ï¼Œå›é€€åˆ°ç®€å•å­—ç¬¦ä¸²åŒ¹é…
            scope = self.storage.get_scope(user_id)
            existing_memories = scope.get_all(limit=100)  # æ£€æŸ¥æœ€è¿‘100æ¡
            content_normalized = content.strip()
            
            # å°è¯•ä½¿ç”¨ä¸‰é˜¶æ®µå»é‡å™¨
            if self.deduplicator is not None and existing_memories:
                try:
                    from .processor.three_stage_deduplicator import DedupItem
                    import uuid as uuid_module
                    
                    # åˆ›å»ºæ–°è®°å¿†çš„ DedupItem
                    new_item = DedupItem(
                        id=str(uuid_module.uuid4()),
                        name=content_normalized[:100],  # å‰100å­—ç¬¦ä½œä¸ºæ ‡é¢˜
                        content=content_normalized,
                        item_type="memory"
                    )
                    
                    # å°†ç°æœ‰è®°å¿†è½¬æ¢ä¸º DedupItem åˆ—è¡¨
                    existing_items = []
                    for mem in existing_memories:
                        mem_content = mem.get('content', '').strip()
                        if mem_content:
                            existing_items.append(DedupItem(
                                id=mem.get('metadata', {}).get('id', str(uuid_module.uuid4())),
                                name=mem_content[:100],
                                content=mem_content,
                                item_type="memory"
                            ))
                    
                    if existing_items:
                        # æ‰§è¡Œä¸‰é˜¶æ®µå»é‡
                        dedup_result = self.deduplicator.deduplicate([new_item], existing_items)
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…ï¼ˆé‡å¤ï¼‰
                        if dedup_result.matches:
                            match = dedup_result.matches[0]
                            _safe_print(f"[Recall] ä¸‰é˜¶æ®µå»é‡å‘ç°é‡å¤: type={match.match_type.value}, conf={match.confidence:.2f}, reason={match.reason}")
                            return AddResult(
                                id=match.matched_item.id if match.matched_item else 'unknown',
                                success=False,
                                entities=[],
                                message=f"è®°å¿†å†…å®¹å·²å­˜åœ¨ï¼ˆ{match.match_type.value}åŒ¹é…ï¼Œç½®ä¿¡åº¦{match.confidence:.0%}ï¼‰"
                            )
                except Exception as e:
                    _safe_print(f"[Recall] ä¸‰é˜¶æ®µå»é‡å¤±è´¥ï¼Œå›é€€åˆ°ç®€å•åŒ¹é…: {e}")
            
            # å›é€€ï¼šç®€å•å­—ç¬¦ä¸²ç²¾ç¡®åŒ¹é…
            for mem in existing_memories:
                existing_content = mem.get('content', '').strip()
                if existing_content == content_normalized:
                    _safe_print(f"[Recall] è·³è¿‡é‡å¤è®°å¿†: content_len={len(content)}, user={user_id}")
                    return AddResult(
                        id=mem.get('metadata', {}).get('id', 'unknown'),
                        success=False,
                        entities=[],
                        message="è®°å¿†å†…å®¹å·²å­˜åœ¨ï¼Œè·³è¿‡é‡å¤ä¿å­˜"
                    )
            
            # 1. æå–å®ä½“ï¼ˆä¼˜å…ˆä½¿ç”¨ SmartExtractorï¼Œå›é€€åˆ° EntityExtractorï¼‰
            extraction_result = None
            if self.smart_extractor is not None:
                try:
                    extraction_result = self.smart_extractor.extract(content)
                    entities = extraction_result.entities
                    entity_names = [e.name for e in entities]
                    keywords = extraction_result.keywords
                    _safe_print(f"[Recall] SmartExtractor: mode={extraction_result.mode_used.value}, entities={len(entities)}, complexity={extraction_result.complexity_score:.2f}")
                except Exception as e:
                    _safe_print(f"[Recall] SmartExtractor å¤±è´¥ï¼Œå›é€€åˆ°é»˜è®¤æŠ½å–å™¨: {e}")
                    extraction_result = None
            
            if extraction_result is None:
                # å›é€€åˆ°é»˜è®¤çš„ EntityExtractor
                entities = self.entity_extractor.extract(content)
                entity_names = [e.name for e in entities]
                keywords = self.entity_extractor.extract_keywords(content)
            
            # 2. æå–å…³é”®è¯ï¼ˆå¦‚æœ SmartExtractor æœªå¤„ç†ï¼‰
            if extraction_result is None:
                keywords = self.entity_extractor.extract_keywords(content)
            
            # 3. ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆåˆ†ä¸¤é˜¶æ®µï¼šæ­£åˆ™è§„åˆ™ + å¯é€‰LLMæ·±åº¦æ£€æµ‹ï¼‰
            if check_consistency:
                existing_memories = self.search(content, user_id=user_id, top_k=5)
                _safe_print(f"[Recall] ä¸€è‡´æ€§æ£€æŸ¥: æ‰¾åˆ° {len(existing_memories)} æ¡ç›¸å…³è®°å¿†")
                for i, m in enumerate(existing_memories):
                    _safe_print(f"[Recall]   [{i+1}] {m.content[:30]}...")
                
                # é˜¶æ®µ1ï¼šæ­£åˆ™è§„åˆ™æ£€æµ‹ï¼ˆå¿«é€Ÿï¼‰
                consistency = self.consistency_checker.check(
                    content,
                    [{'content': m.content} for m in existing_memories]
                )
                _safe_print(f"[Recall] ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ: is_consistent={consistency.is_consistent}, violations={len(consistency.violations)}")
                if not consistency.is_consistent:
                    # æ”¶é›†è­¦å‘Šå¹¶è®°å½•
                    for v in consistency.violations:
                        warning_msg = v.description
                        consistency_warnings.append(warning_msg)
                        _safe_print(f"[Recall] ä¸€è‡´æ€§è­¦å‘Š: {warning_msg}")
                    
                    # å°†ä¸€è‡´æ€§è¿è§„å­˜å‚¨åˆ°çŸ›ç›¾ç®¡ç†å™¨
                    if self.contradiction_manager is not None:
                        try:
                            from .models.temporal import TemporalFact, Contradiction, ContradictionType
                            from datetime import datetime
                            import uuid as uuid_module
                            
                            for v in consistency.violations:
                                # å°† ViolationType æ˜ å°„åˆ° ContradictionType
                                contradiction_type = ContradictionType.DIRECT
                                if hasattr(v, 'type'):
                                    type_str = v.type.value if hasattr(v.type, 'value') else str(v.type)
                                    if 'timeline' in type_str.lower() or 'temporal' in type_str.lower():
                                        contradiction_type = ContradictionType.TEMPORAL
                                    elif 'logic' in type_str.lower():
                                        contradiction_type = ContradictionType.LOGICAL
                                
                                # è·å–è¯æ®æ–‡æœ¬
                                evidence = v.evidence if hasattr(v, 'evidence') and v.evidence else [content]
                                new_text = evidence[0] if len(evidence) > 0 else content
                                old_text = evidence[1] if len(evidence) > 1 else ""
                                
                                # åˆ›å»º TemporalFact å¯¹è±¡
                                new_fact = TemporalFact(
                                    uuid=str(uuid_module.uuid4()),
                                    fact=new_text[:200],
                                    source_text=new_text[:200],
                                    user_id=user_id
                                )
                                old_fact = TemporalFact(
                                    uuid=str(uuid_module.uuid4()),
                                    fact=old_text[:200],
                                    source_text=old_text[:200],
                                    user_id=user_id
                                )
                                
                                # åˆ›å»ºçŸ›ç›¾è®°å½•
                                contradiction = Contradiction(
                                    uuid=str(uuid_module.uuid4()),
                                    old_fact=old_fact,
                                    new_fact=new_fact,
                                    contradiction_type=contradiction_type,
                                    confidence=v.severity if hasattr(v, 'severity') else 0.8,
                                    detected_at=datetime.now(),
                                    notes=v.description[:200] if hasattr(v, 'description') else ""
                                )
                                self.contradiction_manager.add_pending(contradiction)
                                _safe_print(f"[Recall] çŸ›ç›¾å·²è®°å½•: {v.description[:50]}...")
                        except Exception as e:
                            _safe_print(f"[Recall] çŸ›ç›¾è®°å½•å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
                
                # é˜¶æ®µ2ï¼šLLMæ·±åº¦çŸ›ç›¾æ£€æµ‹ï¼ˆå¯é€‰ï¼Œå½“ç­–ç•¥ä¸æ˜¯RULEæ—¶å¯ç”¨ï¼‰
                # è¿™å¯ä»¥æ£€æµ‹æ­£åˆ™æ— æ³•æ•è·çš„å¤æ‚è¯­ä¹‰çŸ›ç›¾
                if self.contradiction_manager is not None and existing_memories:
                    try:
                        from .models.temporal import TemporalFact, Contradiction
                        from .graph import DetectionStrategy
                        from datetime import datetime
                        import uuid as uuid_module
                        
                        # åªæœ‰å½“ç­–ç•¥æ˜¯ LLM/MIXED/AUTO æ—¶æ‰è¿›è¡Œæ·±åº¦æ£€æµ‹
                        if self.contradiction_manager.strategy != DetectionStrategy.RULE:
                            _safe_print(f"[Recall] å¯ç”¨LLMæ·±åº¦çŸ›ç›¾æ£€æµ‹ (ç­–ç•¥: {self.contradiction_manager.strategy.value})")
                            
                            # åˆ›å»ºæ–°äº‹å®çš„ TemporalFact
                            new_fact = TemporalFact(
                                uuid=str(uuid_module.uuid4()),
                                fact=content[:500],
                                source_text=content,
                                user_id=user_id
                            )
                            
                            # å°†ç°æœ‰è®°å¿†è½¬æ¢ä¸º TemporalFact åˆ—è¡¨
                            existing_facts = []
                            for m in existing_memories:
                                existing_facts.append(TemporalFact(
                                    uuid=m.id if hasattr(m, 'id') else str(uuid_module.uuid4()),
                                    fact=m.content[:500] if hasattr(m, 'content') else str(m)[:500],
                                    source_text=m.content if hasattr(m, 'content') else str(m),
                                    user_id=user_id
                                ))
                            
                            # è°ƒç”¨ ContradictionManager.detect() è¿›è¡Œæ·±åº¦æ£€æµ‹
                            llm_contradictions = self.contradiction_manager.detect(
                                new_fact=new_fact,
                                existing_facts=existing_facts,
                                context=content  # ä¼ é€’å®Œæ•´ä¸Šä¸‹æ–‡ç»™ LLM
                            )
                            
                            # è®°å½• LLM æ£€æµ‹åˆ°çš„çŸ›ç›¾
                            for c in llm_contradictions:
                                self.contradiction_manager.add_pending(c)
                                warning_msg = f"[LLMæ£€æµ‹] {c.old_fact.fact[:50]} vs {c.new_fact.fact[:50]}"
                                consistency_warnings.append(warning_msg)
                                _safe_print(f"[Recall] LLMæ£€æµ‹åˆ°çŸ›ç›¾: {warning_msg}")
                            
                            if llm_contradictions:
                                _safe_print(f"[Recall] LLMæ·±åº¦æ£€æµ‹å‘ç° {len(llm_contradictions)} ä¸ªé¢å¤–çŸ›ç›¾")
                    except Exception as e:
                        _safe_print(f"[Recall] LLMçŸ›ç›¾æ£€æµ‹å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
            
            # 4. ç”ŸæˆIDå¹¶å­˜å‚¨
            memory_id = f"mem_{uuid.uuid4().hex[:12]}"
            
            memory_data = {
                'id': memory_id,
                'content': content,
                'user_id': user_id,
                'entities': entity_names,
                'keywords': keywords,
                'metadata': metadata or {},
                'created_at': time.time()
            }
            
            # å­˜å‚¨åˆ°ä½œç”¨åŸŸï¼ˆæ ¸å¿ƒå­˜å‚¨ï¼‰
            scope = self.storage.get_scope(user_id)
            scope.add(content, metadata={
                'id': memory_id,
                'entities': entity_names,
                'keywords': keywords,
                **(metadata or {})
            })
            
            # === ä»¥ä¸‹æ“ä½œå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ ===
            try:
                # 4.5 ArchiveåŸæ–‡ä¿å­˜ï¼ˆç¡®ä¿100%ä¸é—å¿˜ï¼‰
                # å°†å®Œæ•´å¯¹è¯å­˜å…¥åˆ†å·å­˜å‚¨ï¼Œæ”¯æŒä»»æ„è½®æ¬¡çš„O(1)å®šä½
                turn_number = self.volume_manager.append_turn({
                    'memory_id': memory_id,
                    'user_id': user_id,
                    'content': content,
                    'entities': entity_names,
                    'keywords': keywords,
                    'metadata': metadata or {},
                    'created_at': time.time()
                })
            except Exception as e:
                _safe_print(f"[Recall] Archiveä¿å­˜å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
            
            # 5. æ›´æ–°ç´¢å¼•ï¼ˆå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼‰
            try:
                if self._entity_index:
                    for entity in entities:
                        self._entity_index.add_entity_occurrence(
                            entity_name=entity.name,
                            turn_id=memory_id,
                            context=content[:200]
                        )
                
                if self._inverted_index:
                    self._inverted_index.add_batch(keywords, memory_id)
                
                if self._ngram_index:
                    # NgamIndex.add æ¥å— (turn_id, content)
                    self._ngram_index.add(memory_id, content)
                
                if self._vector_index:
                    # VectorIndex.add_text æ¥å— (turn_id, text)
                    self._vector_index.add_text(memory_id, content)
            except Exception as e:
                # æ‰“å°æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                import traceback
                _safe_print(f"[Recall] ç´¢å¼•æ›´æ–°å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {type(e).__name__}: {e}")
                traceback.print_exc()
            
            # 5.5 ç¼“å­˜å†…å®¹åˆ°æ£€ç´¢å™¨ï¼ˆç¡®ä¿æ£€ç´¢æ—¶èƒ½è·å–å†…å®¹ï¼‰
            try:
                self.retriever.cache_content(memory_id, content)
                # åŒæ—¶ç¼“å­˜ metadata å’Œ entities
                if hasattr(self.retriever, 'cache_metadata'):
                    self.retriever.cache_metadata(memory_id, metadata or {})
                if hasattr(self.retriever, 'cache_entities'):
                    entity_names = [e.name for e in entities] if entities else []
                    self.retriever.cache_entities(memory_id, entity_names)
            except Exception as e:
                _safe_print(f"[Recall] ç¼“å­˜æ›´æ–°å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {type(e).__name__}: {e}")
            
            # 5.6 æ›´æ–°é•¿æœŸè®°å¿†ï¼ˆL1 ConsolidatedMemoryï¼‰
            # æ¯ä¸ªå®ä½“éƒ½ä¼šè¢«è‡ªåŠ¨æ•´åˆå’ŒéªŒè¯
            try:
                for entity in entities:
                    consolidated_entity = ConsolidatedEntity(
                        id=f"entity_{entity.name.lower().replace(' ', '_')}",
                        name=entity.name,
                        entity_type=entity.entity_type if hasattr(entity, 'entity_type') else "UNKNOWN",
                        source_turns=[memory_id],
                        source_memory_ids=[memory_id],  # è®°å½•æ¥æºè®°å¿†IDï¼Œç”¨äºçº§è”åˆ é™¤
                        last_verified=time.strftime('%Y-%m-%dT%H:%M:%S')
                    )
                    self.consolidated_memory.add_or_update(consolidated_entity)
            except Exception as e:
                _safe_print(f"[Recall] é•¿æœŸè®°å¿†æ›´æ–°å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
            
            # 6. æ›´æ–°çŸ¥è¯†å›¾è°±ï¼ˆå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼‰
            try:
                relations = self.relation_extractor.extract(content, 0)  # ä¼ å…¥turn=0
                for rel in relations:
                    source_id, relation_type, target_id, source_text = rel
                    self.knowledge_graph.add_relation(
                        source_id=source_id,
                        target_id=target_id,
                        relation_type=relation_type,
                        source_text=source_text
                    )
            except Exception as e:
                _safe_print(f"[Recall] çŸ¥è¯†å›¾è°±æ›´æ–°å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
            
            # 6.5 æ›´æ–°å…¨æ–‡ç´¢å¼• BM25ï¼ˆPhase 1 åŠŸèƒ½ï¼‰
            if self.fulltext_index is not None:
                try:
                    self.fulltext_index.add(memory_id, content)
                except Exception as e:
                    _safe_print(f"[Recall] å…¨æ–‡ç´¢å¼•æ›´æ–°å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
            
            # 6.6 æ›´æ–°æ—¶æ€çŸ¥è¯†å›¾è°±ï¼ˆPhase 1 åŠŸèƒ½ï¼‰
            if self.temporal_graph is not None:
                try:
                    from .models.temporal import TemporalFact
                    # ä¸ºæ¯ä¸ªå®ä½“å…³ç³»åˆ›å»ºæ—¶æ€äº‹å®
                    for rel in relations if 'relations' in dir() else []:
                        source_id, relation_type, target_id, source_text = rel
                        fact = TemporalFact(
                            uuid=f"fact_{memory_id}_{source_id}_{target_id}",
                            fact=f"{source_id} {relation_type} {target_id}",
                            source_text=source_text[:200] if source_text else "",
                            user_id=user_id,
                            entity_name=source_id
                        )
                        self.temporal_graph.add_fact(fact)
                except Exception as e:
                    _safe_print(f"[Recall] æ—¶æ€å›¾è°±æ›´æ–°å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
            
            # 7. è‡ªåŠ¨æå–æŒä¹…æ¡ä»¶ï¼ˆå·²ç§»è‡³ server.py ä¸­å¤„ç†ï¼Œé¿å… character_id ä¼ é€’é—®é¢˜ï¼‰
            # æ³¨æ„ï¼šä¹‹å‰è¿™é‡Œè°ƒç”¨ extract_from_text æ—¶æ²¡æœ‰ä¼ é€’ character_idï¼Œ
            # å¯¼è‡´æ‰€æœ‰æ¡ä»¶éƒ½å­˜å‚¨åˆ° "default" è§’è‰²ä¸‹ï¼Œä¸å…¶ä»–è§’è‰²æ•°æ®æ··æ·†ã€‚
            # ç°åœ¨ç”± server.py åœ¨æ·»åŠ è®°å¿†åæ­£ç¡®ä¼ é€’ character_id æ¥æå–æ¡ä»¶ã€‚
            
            # è®°å½•æ€§èƒ½
            try:
                self.monitor.record(
                    MetricType.LATENCY,
                    (time.time() - start_time) * 1000
                )
            except Exception:
                pass  # å¿½ç•¥æ€§èƒ½ç›‘æ§é”™è¯¯
            
            return AddResult(
                id=memory_id,
                success=True,
                entities=entity_names,
                message="è®°å¿†æ·»åŠ æˆåŠŸ",
                consistency_warnings=consistency_warnings
            )
        
        except Exception as e:
            _safe_print(f"[Recall] æ·»åŠ è®°å¿†å¼‚å¸¸: {type(e).__name__}: {e}")
            import traceback
            traceback.print_exc()
            return AddResult(
                id="",
                success=False,
                message=f"æ·»åŠ å¤±è´¥: {str(e)}"
            )
    
    def search(
        self,
        query: str,
        user_id: str = "default",
        top_k: int = 10,
        filters: Optional[Dict[str, Any]] = None,
        temporal_context: Optional[Any] = None,
        config_preset: Optional[str] = None
    ) -> List[SearchResult]:
        """æœç´¢è®°å¿†
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            user_id: ç”¨æˆ·ID
            top_k: è¿”å›æ•°é‡
            filters: è¿‡æ»¤æ¡ä»¶
            temporal_context: æ—¶æ€ä¸Šä¸‹æ–‡ï¼ˆPhase 3 æ–°å¢ï¼Œç”¨äº L2 æ—¶æ€æ£€ç´¢å±‚ï¼‰
            config_preset: é…ç½®é¢„è®¾ï¼ˆPhase 3 æ–°å¢ï¼šdefault/fast/accurateï¼‰
        
        Returns:
            List[SearchResult]: æœç´¢ç»“æœ
        """
        # 1. æå–æŸ¥è¯¢å®ä½“å’Œå…³é”®è¯
        entities = [e.name for e in self.entity_extractor.extract(query)]
        keywords = self.entity_extractor.extract_keywords(query)
        
        # 2. æ£€æµ‹åœºæ™¯
        scenario = self.scenario_detector.detect(query)
        
        # 3. Phase 3: æ„å»ºæ£€ç´¢é…ç½®
        retrieval_config = None
        if config_preset and hasattr(self.retriever, 'config'):
            from recall.retrieval.config import RetrievalConfig
            if config_preset == 'fast':
                retrieval_config = RetrievalConfig.fast()
            elif config_preset == 'accurate':
                retrieval_config = RetrievalConfig.accurate()
            # default ä½¿ç”¨ retriever çš„é»˜è®¤é…ç½®
        
        # 4. æ‰§è¡Œæ£€ç´¢ï¼ˆä¼ é€’ Phase 3 æ–°å‚æ•°ï¼‰
        # ã€BUG-003 ä¿®å¤ã€‘å…ˆè·å–å½“å‰ç”¨æˆ·çš„æ‰€æœ‰è®°å¿† IDï¼Œç”¨äºåç»­è¿‡æ»¤
        scope = self.storage.get_scope(user_id)
        user_memory_ids = set()
        for mem in scope._memories:
            mem_id = mem.get('metadata', {}).get('id', '')
            if mem_id:
                user_memory_ids.add(mem_id)
        
        # ä»å…¨å±€ç´¢å¼•æ£€ç´¢ï¼ˆå¯èƒ½åŒ…å«å…¶ä»–ç”¨æˆ·çš„ç»“æœï¼‰
        retrieval_results = self.retriever.retrieve(
            query=query,
            entities=entities,
            keywords=keywords,
            top_k=top_k * 3,  # å¤šå–ä¸€äº›ï¼Œå› ä¸ºè¦è¿‡æ»¤
            filters=filters,
            temporal_context=temporal_context,
            config=retrieval_config
        )
        
        # ã€BUG-003 ä¿®å¤ã€‘è¿‡æ»¤ç»“æœï¼Œåªä¿ç•™å±äºå½“å‰ç”¨æˆ·çš„è®°å¿†
        retrieval_results = [
            r for r in retrieval_results 
            if r.id in user_memory_ids
        ]
        
        # 4.5 è¡¥å……ä»å­˜å‚¨è·å–ï¼ˆå·²ç»æ˜¯ç”¨æˆ·éš”ç¦»çš„ï¼‰
        stored_memories = scope.search(query, limit=top_k)
        
        # 5. åˆå¹¶ç»“æœ
        results = []
        seen_ids = set()
        
        for r in retrieval_results:
            if r.id not in seen_ids:
                results.append(SearchResult(
                    id=r.id,
                    content=r.content,
                    score=r.score,
                    metadata=r.metadata,
                    entities=r.entities
                ))
                seen_ids.add(r.id)
        
        for m in stored_memories:
            mem_id = m.get('metadata', {}).get('id', '') or m.get('id', '')
            if mem_id and mem_id not in seen_ids:
                results.append(SearchResult(
                    id=mem_id,
                    content=m.get('content', m.get('memory', '')),
                    score=m.get('score', 0.5),
                    metadata=m.get('metadata', {}),
                    entities=m.get('entities', [])
                ))
                seen_ids.add(mem_id)
        
        return results[:top_k]
    
    def get_all(
        self,
        user_id: str = "default",
        limit: int = None
    ) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰è®°å¿†
        
        Args:
            user_id: ç”¨æˆ·ID
            limit: é™åˆ¶æ•°é‡ï¼ŒNoneè¡¨ç¤ºè¿”å›å…¨éƒ¨
        
        Returns:
            List[Dict]: è®°å¿†åˆ—è¡¨
        """
        scope = self.storage.get_scope(user_id)
        return scope.get_all(limit=limit)
    
    def get_paginated(
        self,
        user_id: str = "default",
        offset: int = 0,
        limit: int = 20
    ) -> tuple:
        """åˆ†é¡µè·å–è®°å¿†ï¼ˆé«˜æ•ˆç‰ˆæœ¬ï¼‰
        
        Args:
            user_id: ç”¨æˆ·ID
            offset: åç§»é‡
            limit: æ¯é¡µæ•°é‡
        
        Returns:
            tuple: (memories, total_count)
        """
        scope = self.storage.get_scope(user_id)
        total = scope.count()
        memories = scope.get_paginated(offset=offset, limit=limit)
        return memories, total
    
    def count_memories(self, user_id: str = "default") -> int:
        """è·å–è®°å¿†æ€»æ•°ï¼ˆO(1)æ“ä½œï¼‰
        
        Args:
            user_id: ç”¨æˆ·ID
        
        Returns:
            int: è®°å¿†æ€»æ•°
        """
        scope = self.storage.get_scope(user_id)
        return scope.count()
    
    def get(
        self,
        memory_id: str,
        user_id: str = "default"
    ) -> Optional[Dict[str, Any]]:
        """è·å–å•æ¡è®°å¿†
        
        Args:
            memory_id: è®°å¿†ID
            user_id: ç”¨æˆ·ID
        
        Returns:
            Dict: è®°å¿†æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
        """
        scope = self.storage.get_scope(user_id)
        all_memories = scope.get_all()
        for memory in all_memories:
            if memory.get('metadata', {}).get('id') == memory_id:
                return memory
        return None
    
    def clear(
        self,
        user_id: str = "default"
    ) -> bool:
        """æ¸…ç©ºç”¨æˆ·çš„æ‰€æœ‰è®°å¿†ï¼ˆçº§è”åˆ é™¤è¯¥ç”¨æˆ·å…³è”çš„æ•°æ®ï¼‰
        
        è¿™æ˜¯ç”¨æˆ·çº§åˆ«çš„æ¸…ç©ºæ“ä½œï¼Œåªä¼šåˆ é™¤æŒ‡å®šç”¨æˆ·çš„æ•°æ®ã€‚
        ä¼šçº§è”æ¸…ç†ï¼š
        - ç”¨æˆ·çš„è®°å¿†å­˜å‚¨
        - ç”¨æˆ·åœ¨æ—¶æ€çŸ¥è¯†å›¾è°±ä¸­çš„èŠ‚ç‚¹ã€è¾¹ã€episodes
        - å®ä½“ç´¢å¼•ä¸­ä¸è¯¥ç”¨æˆ·è®°å¿†å…³è”çš„å®ä½“å¼•ç”¨
        - å‘é‡ç´¢å¼•ä¸­å¯¹åº”è®°å¿†çš„å‘é‡
        - L1 æ•´åˆå­˜å‚¨ä¸­ä¸è¯¥ç”¨æˆ·è®°å¿†å…³è”çš„å®ä½“
        
        Args:
            user_id: ç”¨æˆ·ID
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # 1. å…ˆè·å–è¯¥ç”¨æˆ·çš„æ‰€æœ‰è®°å¿† IDï¼ˆç”¨äºåç»­æ¸…ç†ç´¢å¼•ï¼‰
            scope = self.storage.get_scope(user_id)
            all_memories = scope.get_all()
            memory_ids = [m.get('metadata', {}).get('id', '') for m in all_memories if m.get('metadata', {}).get('id')]
            
            # 2. æ¸…ç©ºè¯¥ç”¨æˆ·çš„è®°å¿†å­˜å‚¨
            scope.clear()
            
            # 3. æ¸…ç©ºè¯¥ç”¨æˆ·åœ¨æ—¶æ€çŸ¥è¯†å›¾è°±ä¸­çš„æ•°æ®
            if self.temporal_graph is not None and hasattr(self.temporal_graph, 'clear_user'):
                self.temporal_graph.clear_user(user_id)
            
            # 4. æ¸…ç†å®ä½“ç´¢å¼•ä¸­ä¸è¯¥ç”¨æˆ·è®°å¿†å…³è”çš„å¼•ç”¨
            if memory_ids and self._entity_index is not None:
                if hasattr(self._entity_index, 'remove_by_turn_references'):
                    deleted_entities = self._entity_index.remove_by_turn_references(memory_ids)
                    if deleted_entities > 0:
                        _safe_print(f"[Recall] æ¸…ç†äº† {deleted_entities} ä¸ªæ— å¼•ç”¨å®ä½“")
            
            # 5. æ¸…ç†å‘é‡ç´¢å¼•ä¸­çš„å¯¹åº”å‘é‡
            if memory_ids and self._vector_index is not None:
                if hasattr(self._vector_index, 'remove_by_doc_ids'):
                    removed_vectors = self._vector_index.remove_by_doc_ids(memory_ids)
                    if removed_vectors > 0:
                        _safe_print(f"[Recall] æ¸…ç†äº† {removed_vectors} ä¸ªå‘é‡")
            
            # 6. æ¸…ç† L1 æ•´åˆå­˜å‚¨ä¸­ä¸è¯¥ç”¨æˆ·è®°å¿†å…³è”çš„å®ä½“
            if memory_ids and self.consolidated_memory is not None:
                if hasattr(self.consolidated_memory, 'remove_by_memory_ids'):
                    deleted_consolidated = self.consolidated_memory.remove_by_memory_ids(memory_ids)
                    if deleted_consolidated > 0:
                        _safe_print(f"[Recall] æ¸…ç†äº† {deleted_consolidated} ä¸ªæ•´åˆå®ä½“")
            
            # 7. æ¸…ç†å€’æ’ç´¢å¼•ä¸­çš„å¯¹åº”æ¡ç›®
            if memory_ids and self._inverted_index is not None:
                if hasattr(self._inverted_index, 'remove_by_memory_ids'):
                    removed_inverted = self._inverted_index.remove_by_memory_ids(set(memory_ids))
                    if removed_inverted > 0:
                        _safe_print(f"[Recall] æ¸…ç†äº† {removed_inverted} ä¸ªå€’æ’ç´¢å¼•æ¡ç›®")
            
            # 8. æ¸…ç† n-gram ç´¢å¼•ä¸­çš„å¯¹åº”æ¡ç›®
            if memory_ids and self._ngram_index is not None:
                if hasattr(self._ngram_index, 'remove_by_memory_ids'):
                    removed_ngram = self._ngram_index.remove_by_memory_ids(set(memory_ids))
                    if removed_ngram > 0:
                        _safe_print(f"[Recall] æ¸…ç†äº† {removed_ngram} ä¸ª n-gram åŸæ–‡")
            
            # 9. æ¸…ç†å…¨æ–‡ç´¢å¼•ä¸­çš„å¯¹åº”æ–‡æ¡£
            if memory_ids and self.fulltext_index is not None:
                if hasattr(self.fulltext_index, 'remove_by_doc_ids'):
                    removed_fulltext = self.fulltext_index.remove_by_doc_ids(set(memory_ids))
                    if removed_fulltext > 0:
                        _safe_print(f"[Recall] æ¸…ç†äº† {removed_fulltext} ä¸ªå…¨æ–‡ç´¢å¼•æ–‡æ¡£")
            
            # 10. æ¸…ç†ä¼ç¬”è¿½è¸ªå™¨ä¸­çš„ç”¨æˆ·æ•°æ®
            if self.foreshadowing_tracker is not None:
                if hasattr(self.foreshadowing_tracker, 'clear_user'):
                    self.foreshadowing_tracker.clear_user(user_id)
            
            # 11. æ¸…ç†ä¸Šä¸‹æ–‡ç³»ç»Ÿä¸­çš„ç”¨æˆ·æ•°æ®
            if self.context_tracker is not None:
                if hasattr(self.context_tracker, 'clear_user'):
                    self.context_tracker.clear_user(user_id)
            
            # æ³¨æ„ï¼šä»¥ä¸‹å…¨å±€ç´¢å¼•ä¸æ”¯æŒæŒ‰ç”¨æˆ·ç²¾ç¡®æ¸…ç†
            # - knowledge_graph: æ—§ç‰ˆçŸ¥è¯†å›¾è°±ï¼Œç»“æ„ä¸æ”¯æŒç”¨æˆ·éš”ç¦»
            # 
            # å¦‚éœ€å®Œå…¨æ¸…ç©ºæ‰€æœ‰æ•°æ®ï¼Œè¯·ä½¿ç”¨ clear_all() æ–¹æ³•
            
            return True
        except Exception as e:
            _safe_print(f"[Recall] æ¸…ç©ºç”¨æˆ·è®°å¿†å¤±è´¥: {e}")
            return False
    
    def clear_all(self) -> bool:
        """æ¸…ç©ºæ‰€æœ‰æ•°æ®ï¼ˆç®¡ç†å‘˜æ“ä½œï¼‰
        
        âš ï¸ å±é™©æ“ä½œï¼è¿™å°†åˆ é™¤æ‰€æœ‰ç”¨æˆ·çš„å…¨éƒ¨æ•°æ®ï¼ŒåŒ…æ‹¬ï¼š
        - æ‰€æœ‰ç”¨æˆ·çš„è®°å¿†
        - çŸ¥è¯†å›¾è°±
        - å®ä½“ç´¢å¼•
        - L1 æ•´åˆå­˜å‚¨
        - å‘é‡ç´¢å¼•
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # 1. æ¸…ç©ºæ‰€æœ‰ç”¨æˆ·çš„è®°å¿†å­˜å‚¨
            for user_id in self.storage.list_users():
                scope = self.storage.get_scope(user_id)
                scope.clear()
            
            # 2. æ¸…ç©ºæ—¶æ€çŸ¥è¯†å›¾è°±
            if self.temporal_graph is not None:
                self.temporal_graph.clear()
            
            # 3. æ¸…ç©ºæ—§ç‰ˆçŸ¥è¯†å›¾è°±
            if self.knowledge_graph is not None and hasattr(self.knowledge_graph, 'clear'):
                self.knowledge_graph.clear()
            
            # 4. æ¸…ç©ºå®ä½“ç´¢å¼•
            if self._entity_index is not None and hasattr(self._entity_index, 'clear'):
                self._entity_index.clear()
            
            # 5. æ¸…ç©º L1 æ•´åˆå­˜å‚¨
            if self.consolidated_memory is not None and hasattr(self.consolidated_memory, 'clear'):
                self.consolidated_memory.clear()
            
            # 6. æ¸…ç©ºå‘é‡ç´¢å¼•
            if self._vector_index is not None and hasattr(self._vector_index, 'clear'):
                self._vector_index.clear()
            
            # 7. æ¸…ç©ºå€’æ’ç´¢å¼•
            if self._inverted_index is not None and hasattr(self._inverted_index, 'clear'):
                self._inverted_index.clear()
            
            # 8. æ¸…ç©º n-gram ç´¢å¼•
            if self._ngram_index is not None and hasattr(self._ngram_index, 'clear'):
                self._ngram_index.clear()
            
            # 9. æ¸…ç©ºå…¨æ–‡ç´¢å¼•
            if self.fulltext_index is not None and hasattr(self.fulltext_index, 'clear'):
                self.fulltext_index.clear()
            
            # 10. æ¸…ç©ºä¼ç¬”è¿½è¸ªå™¨
            if self.foreshadowing_tracker is not None and hasattr(self.foreshadowing_tracker, 'clear'):
                self.foreshadowing_tracker.clear()
            
            # 11. æ¸…ç©ºä¸Šä¸‹æ–‡ç³»ç»Ÿ
            if self.context_tracker is not None and hasattr(self.context_tracker, 'clear'):
                self.context_tracker.clear()
            
            _safe_print("[Recall] âœ… å·²æ¸…ç©ºæ‰€æœ‰æ•°æ®")
            return True
        except Exception as e:
            _safe_print(f"[Recall] æ¸…ç©ºæ‰€æœ‰æ•°æ®å¤±è´¥: {e}")
            return False
    
    def stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯ï¼ˆget_stats çš„åˆ«åï¼‰"""
        return self.get_stats()
    
    # ==================== Phase 3.5 é«˜çº§ API ====================
    
    def detect_communities(
        self,
        user_id: str = "default",
        min_size: int = 2
    ) -> List[Dict[str, Any]]:
        """æ£€æµ‹å®ä½“ç¤¾åŒº/ç¾¤ç»„ (Phase 3.5)
        
        ä½¿ç”¨ Louvain æˆ–æ ‡ç­¾ä¼ æ’­ç®—æ³•å‘ç°å›¾ä¸­çš„å®ä½“ç¾¤ç»„ã€‚
        éœ€è¦å¯ç”¨ COMMUNITY_DETECTION_ENABLED=trueã€‚
        
        Args:
            user_id: ç”¨æˆ·IDï¼ˆç”¨äºè¿‡æ»¤ç¤¾åŒºï¼‰
            min_size: æœ€å°ç¤¾åŒºå¤§å°
        
        Returns:
            List[Dict]: ç¤¾åŒºåˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«ï¼š
                - id: ç¤¾åŒºID
                - name: ç¤¾åŒºåç§°
                - member_ids: æˆå‘˜å®ä½“IDåˆ—è¡¨
                - size: ç¤¾åŒºå¤§å°
        """
        if self.community_detector is None:
            _safe_print("[Recall] ç¤¾åŒºæ£€æµ‹å™¨æœªå¯ç”¨ï¼Œè¯·è®¾ç½® COMMUNITY_DETECTION_ENABLED=true")
            return []
        
        try:
            communities = self.community_detector.detect_communities()
            # è¿‡æ»¤æœ€å°å¤§å°
            result = []
            for comm in communities:
                if comm.size >= min_size:
                    result.append({
                        'id': comm.id,
                        'name': comm.name,
                        'member_ids': comm.member_ids,
                        'size': comm.size,
                        'summary': comm.summary
                    })
            return result
        except Exception as e:
            _safe_print(f"[Recall] ç¤¾åŒºæ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def get_query_stats(self) -> Dict[str, Any]:
        """è·å–å›¾æŸ¥è¯¢ç»Ÿè®¡ä¿¡æ¯ (Phase 3.5)
        
        éœ€è¦å¯ç”¨ QUERY_PLANNER_ENABLED=trueã€‚
        
        Returns:
            Dict: æŸ¥è¯¢ç»Ÿè®¡ï¼ŒåŒ…å«ï¼š
                - total_queries: æ€»æŸ¥è¯¢æ•°
                - cache_hits: ç¼“å­˜å‘½ä¸­æ•°
                - cache_hit_rate: ç¼“å­˜å‘½ä¸­ç‡
                - avg_execution_time_ms: å¹³å‡æ‰§è¡Œæ—¶é—´
        """
        if self.query_planner is None:
            return {'enabled': False, 'message': 'å›¾æŸ¥è¯¢è§„åˆ’å™¨æœªå¯ç”¨'}
        
        try:
            stats = self.query_planner.stats
            return {
                'enabled': True,
                'total_queries': stats.total_queries,
                'cache_hits': stats.cache_hits,
                'cache_hit_rate': stats.cache_hit_rate,
                'avg_execution_time_ms': stats.avg_execution_time_ms,
                'total_nodes_visited': stats.total_nodes_visited
            }
        except Exception as e:
            return {'enabled': True, 'error': str(e)}
    
    def delete(
        self,
        memory_id: str,
        user_id: str = "default"
    ) -> bool:
        """åˆ é™¤è®°å¿†
        
        Args:
            memory_id: è®°å¿†ID
            user_id: ç”¨æˆ·ID
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        scope = self.storage.get_scope(user_id)
        return scope.delete(memory_id)
    
    def update(
        self,
        memory_id: str,
        content: str,
        user_id: str = "default",
        metadata: Optional[Dict[str, Any]] = None
    ) -> bool:
        """æ›´æ–°è®°å¿†
        
        Args:
            memory_id: è®°å¿†ID
            content: æ–°å†…å®¹
            user_id: ç”¨æˆ·ID
            metadata: æ–°å…ƒæ•°æ®
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        scope = self.storage.get_scope(user_id)
        return scope.update(memory_id, content, metadata)
    
    def build_context(
        self,
        query: str,
        user_id: str = "default",
        character_id: str = "default",
        max_tokens: int = 2000,
        include_recent: int = None,  # ä»é…ç½®è¯»å–é»˜è®¤å€¼
        include_core_facts: bool = True,
        auto_extract_context: bool = False  # é»˜è®¤å…³é—­ï¼Œé¿å…æ¯æ¬¡ç”Ÿæˆéƒ½æå–æ¡ä»¶
    ) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡ - å…¨æ–¹ä½è®°å¿†ç­–ç•¥ï¼Œç¡®ä¿100%ä¸é—æ¼ä»»ä½•ç»†èŠ‚
        
        ä¸ƒå±‚ä¸Šä¸‹æ–‡ç­–ç•¥ï¼ˆ100%ä¸é—å¿˜ä¿è¯ï¼‰ï¼š
        1. æŒä¹…æ¡ä»¶å±‚ - å·²ç¡®ç«‹çš„èƒŒæ™¯è®¾å®šï¼ˆå¦‚ç”¨æˆ·èº«ä»½ã€ç¯å¢ƒã€ç›®æ ‡ï¼‰
        2. æ ¸å¿ƒäº‹å®å±‚ - å‹ç¼©çš„å®ä½“çŸ¥è¯† + å…³ç³»å›¾è°±
        3. ç›¸å…³è®°å¿†å±‚ - ä¸æŸ¥è¯¢ç›¸å…³çš„è¯¦ç»†è®°å¿†
        4. å…³é”®å®ä½“è¡¥å……å±‚ - ä»æŒä¹…æ¡ä»¶å’Œä¼ç¬”ä¸­æå–å…³é”®è¯ï¼Œè¡¥å……æ£€ç´¢ï¼ˆæ–°å¢ï¼‰
        5. æœ€è¿‘å¯¹è¯å±‚ - ä¿æŒå¯¹è¯è¿è´¯æ€§
        6. ä¼ç¬”å±‚ - æ‰€æœ‰æ´»è·ƒä¼ç¬” + ä¸»åŠ¨æé†’
        7. åœºæ™¯ä¼˜åŒ–å±‚ - æ ¹æ®åœºæ™¯è°ƒæ•´æ£€ç´¢ç­–ç•¥
        
        Args:
            query: å½“å‰æŸ¥è¯¢
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            max_tokens: æœ€å¤§tokenæ•°ï¼ˆè¶Šå¤§èƒ½æ³¨å…¥è¶Šå¤šç»†èŠ‚ï¼‰
            include_recent: åŒ…å«çš„æœ€è¿‘å¯¹è¯æ•°ï¼ˆNone æ—¶ä»é…ç½®è¯»å– BUILD_CONTEXT_INCLUDE_RECENTï¼‰
            include_core_facts: æ˜¯å¦åŒ…å«æ ¸å¿ƒäº‹å®æ‘˜è¦
            auto_extract_context: æ˜¯å¦è‡ªåŠ¨ä»æŸ¥è¯¢ä¸­æå–æŒä¹…æ¡ä»¶ï¼ˆé»˜è®¤Falseï¼Œæ¡ä»¶æå–åœ¨ä¿å­˜è®°å¿†æ—¶è¿›è¡Œï¼‰
        
        Returns:
            str: æ„å»ºçš„ä¸Šä¸‹æ–‡
        """
        import time as _time
        import os as _os
        start_time = _time.time()
        
        # ä»é…ç½®è¯»å–é»˜è®¤å€¼
        if include_recent is None:
            include_recent = int(_os.environ.get('BUILD_CONTEXT_INCLUDE_RECENT', '10'))
        proactive_enabled = _os.environ.get('PROACTIVE_REMINDER_ENABLED', 'true').lower() in ('true', '1', 'yes')
        proactive_turns = int(_os.environ.get('PROACTIVE_REMINDER_TURNS', '50'))
        
        query_preview = query[:50].replace('\n', ' ') if len(query) > 50 else query.replace('\n', ' ')
        _safe_print(f"[Recall][Engine] ğŸ“¦ æ„å»ºä¸Šä¸‹æ–‡: user={user_id}, char={character_id}")
        _safe_print(f"[Recall][Engine]    æŸ¥è¯¢: {query_preview}{'...' if len(query) > 50 else ''}")
        _safe_print(f"[Recall][Engine]    å‚æ•°: max_tokens={max_tokens}, recent={include_recent}, proactive={proactive_enabled}")
        parts = []
        
        # ========== 0. åœºæ™¯æ£€æµ‹ï¼ˆå†³å®šæ£€ç´¢ç­–ç•¥ï¼‰==========
        scenario = self.scenario_detector.detect(query)
        retrieval_strategy = scenario.suggested_retrieval_strategy
        
        # ========== 0.5 L0 æ ¸å¿ƒè®¾å®šæ³¨å…¥ï¼ˆè§’è‰²å¡/ä¸–ç•Œè§‚/è§„åˆ™ - æœ€é«˜ä¼˜å…ˆçº§ï¼‰==========
        if hasattr(self, 'core_settings') and self.core_settings:
            # æ ¹æ®åœºæ™¯ç±»å‹è·å–å¯¹åº”çš„æ ¸å¿ƒè®¾å®š
            scenario_type = 'roleplay' if scenario.type.value in ['roleplay', 'novel_writing', 'worldbuilding'] else 'coding' if scenario.type.value == 'coding' else 'general'
            injection_text = self.core_settings.get_injection_text(scenario_type)
            if injection_text:
                parts.append(f"ã€æ ¸å¿ƒè®¾å®šã€‘\n{injection_text}")
        
        # ========== 1. æŒä¹…æ¡ä»¶å±‚ï¼ˆå·²ç¡®ç«‹çš„èƒŒæ™¯è®¾å®šï¼‰==========
        # è¿™æ˜¯æœ€é‡è¦çš„å±‚ - ç”¨æˆ·è¯´"æˆ‘æ˜¯å¤§å­¦ç”Ÿæƒ³åˆ›ä¸š"ï¼Œåç»­æ‰€æœ‰å¯¹è¯éƒ½åº”åŸºäºæ­¤
        active_contexts = self.context_tracker.get_active(user_id, character_id)
        if active_contexts:
            # æ‰¹é‡æ ‡è®°æ‰€æœ‰è¢«ä½¿ç”¨çš„æ¡ä»¶ï¼ˆæ›´æ–° last_used å’Œ use_countï¼Œåªå†™ä¸€æ¬¡æ–‡ä»¶ï¼‰
            context_ids = [ctx.id for ctx in active_contexts]
            self.context_tracker.mark_used_batch(context_ids, user_id, character_id)
            
            persistent_context = self.context_tracker.format_for_prompt(user_id, character_id)
            if persistent_context:
                parts.append(persistent_context)
        
        # è‡ªåŠ¨ä»å½“å‰æŸ¥è¯¢ä¸­æå–æ–°çš„æŒä¹…æ¡ä»¶
        if auto_extract_context and query:
            self.context_tracker.extract_from_text(query, user_id, character_id)
        
        # ========== 2. æ ¸å¿ƒäº‹å®å±‚ + å…³ç³»å›¾è°± ==========
        if include_core_facts:
            core_facts = self._build_core_facts_section(user_id, max_tokens // 5)
            if core_facts:
                parts.append(core_facts)
            
            # åˆ©ç”¨çŸ¥è¯†å›¾è°±æ‰©å±•ç›¸å…³å®ä½“
            graph_context = self._build_graph_context(query, user_id, max_tokens // 10)
            if graph_context:
                parts.append(graph_context)
        
        # ========== 3. ç›¸å…³è®°å¿†å±‚ï¼ˆè¯¦ç»†è®°å¿†ï¼‰==========
        # æ ¹æ®åœºæ™¯å’Œ token é¢„ç®—åŠ¨æ€è°ƒæ•´æ£€ç´¢æ•°é‡
        top_k = self._calculate_top_k(max_tokens, retrieval_strategy)
        memories = self.search(query, user_id=user_id, top_k=top_k)
        
        if memories:
            memory_section = self._build_memory_section(memories, max_tokens // 3)
            if memory_section:
                parts.append(memory_section)
        
        # ========== 3.5 å…³é”®å®ä½“è¡¥å……æ£€ç´¢å±‚ï¼ˆ100%ä¸é—å¿˜ä¿è¯ï¼‰==========
        # ä»æŒä¹…æ¡ä»¶å’Œä¼ç¬”ä¸­æå–å…³é”®è¯ï¼Œè¿›è¡Œè¡¥å……æ£€ç´¢
        # ç¡®ä¿å³ä½¿ query ä¸­æ²¡æœ‰ç›´æ¥æåŠï¼Œé‡è¦ä¿¡æ¯ä¹Ÿèƒ½è¢«å¬å›
        supplementary_keywords = self._extract_supplementary_keywords(user_id, character_id, active_contexts)
        if supplementary_keywords:
            supplementary_memories = self._search_by_keywords(supplementary_keywords, user_id, top_k=5)
            if supplementary_memories:
                # è¿‡æ»¤æ‰å·²ç»åœ¨ memories ä¸­çš„è®°å¿†
                existing_ids = {m.id for m in memories} if memories else set()
                new_supplementary = [m for m in supplementary_memories if m.id not in existing_ids]
                if new_supplementary:
                    supplementary_section = self._build_supplementary_section(new_supplementary)
                    if supplementary_section:
                        parts.append(supplementary_section)
        
        # ========== 4. æœ€è¿‘å¯¹è¯å±‚ ==========
        scope = self.storage.get_scope(user_id)
        recent = scope.get_recent(include_recent)
        
        if recent:
            recent_section = self._build_recent_section(recent)
            if recent_section:
                parts.append(recent_section)
        
        # ========== 5. ä¼ç¬”å±‚ï¼ˆæ‰€æœ‰æ´»è·ƒä¼ç¬” + ä¸»åŠ¨æé†’ï¼‰==========
        # ä½¿ç”¨ tracker çš„ä¸“ç”¨æ–¹æ³•ï¼ŒåŒ…å«ä¸»åŠ¨æé†’é€»è¾‘ï¼ˆé‡è¦ä¼ç¬”é•¿æœŸæœªæ¨è¿›ä¼šæé†’ AIï¼‰
        foreshadowing_context = self.foreshadowing_tracker.get_context_for_prompt(
            user_id=user_id,
            character_id=character_id,
            max_count=5,
            current_turn=self.volume_manager.get_total_turns() if self.volume_manager else None
        )
        if foreshadowing_context:
            parts.append(foreshadowing_context)
        
        # ========== 5.5 ä¸»åŠ¨æé†’å±‚ï¼ˆ100%ä¸é—å¿˜ä¿è¯ï¼‰==========
        # å¯¹é•¿æœŸæœªæåŠçš„é‡è¦æŒä¹…æ¡ä»¶è¿›è¡Œä¸»åŠ¨æé†’
        if proactive_enabled and active_contexts:
            proactive_reminders = self._build_proactive_reminders(
                active_contexts, proactive_turns, user_id
            )
            if proactive_reminders:
                parts.append(proactive_reminders)
        
        elapsed = _time.time() - start_time
        total_len = sum(len(p) for p in parts)
        _safe_print(f"[Recall][Engine] âœ… æ„å»ºå®Œæˆ: è€—æ—¶={elapsed:.3f}s")
        _safe_print(f"[Recall][Engine]    å±‚æ•°={len(parts)}, æ€»é•¿åº¦={total_len}å­—ç¬¦")
        if parts:
            _safe_print(f"[Recall][Engine]    åŒ…å«: {[p[:20] + '...' for p in parts]}")
        
        return "\n".join(parts)
    
    def _calculate_top_k(self, max_tokens: int, strategy: str) -> int:
        """æ ¹æ®ç­–ç•¥å’Œtokené¢„ç®—è®¡ç®—æ£€ç´¢æ•°é‡"""
        base_k = max(10, min(50, max_tokens // 100))
        
        # æ ¹æ®åœºæ™¯è°ƒæ•´
        strategy_multipliers = {
            'entity_focused': 1.5,      # è§’è‰²æ‰®æ¼”éœ€è¦æ›´å¤šå®ä½“ä¿¡æ¯
            'keyword_exact': 0.8,       # ä»£ç åœºæ™¯ç²¾ç¡®åŒ¹é…ï¼Œä¸éœ€è¦å¤ªå¤š
            'semantic_broad': 1.2,      # çŸ¥è¯†é—®ç­”éœ€è¦å¹¿æ³›æ£€ç´¢
            'creative_blend': 1.3,      # åˆ›æ„å†™ä½œéœ€è¦å¤šæ ·æ€§
            'task_relevant': 0.7,       # ä»»åŠ¡æ‰§è¡Œèšç„¦ç›¸å…³
            'recent_context': 0.5,      # é—²èŠä¸»è¦é æœ€è¿‘ä¸Šä¸‹æ–‡
            'hybrid_balanced': 1.0,     # é»˜è®¤å¹³è¡¡
        }
        
        multiplier = strategy_multipliers.get(strategy, 1.0)
        return int(base_k * multiplier)
    
    def _build_graph_context(self, query: str, user_id: str, budget: int) -> str:
        """åˆ©ç”¨çŸ¥è¯†å›¾è°±æ„å»ºå…³ç³»ä¸Šä¸‹æ–‡"""
        # ä»æŸ¥è¯¢ä¸­æå–å®ä½“
        entities = [e.name for e in self.entity_extractor.extract(query)]
        if not entities:
            return ""
        
        lines = []
        current_length = 0
        
        for entity_name in entities[:5]:  # æœ€å¤šå¤„ç†5ä¸ªå®ä½“
            # è·å–è¯¥å®ä½“çš„å…³ç³»
            neighbors = self.knowledge_graph.get_neighbors(entity_name, direction='both')
            if neighbors:
                for neighbor_id, relation in neighbors[:3]:  # æ¯ä¸ªå®ä½“æœ€å¤š3ä¸ªå…³ç³»
                    rel_text = f"â€¢ {entity_name} --[{relation.relation_type}]--> {neighbor_id}"
                    if current_length + len(rel_text) > budget:
                        break
                    lines.append(rel_text)
                    current_length += len(rel_text)
        
        if lines:
            return "<relationships>\nã€å…³ç³»å›¾è°±ã€‘\n" + "\n".join(lines) + "\n</relationships>"
        return ""
    
    def _build_core_facts_section(self, user_id: str, budget: int) -> str:
        """æ„å»ºæ ¸å¿ƒäº‹å®éƒ¨åˆ† - ä» L1 ConsolidatedMemory è·å–å‹ç¼©çŸ¥è¯†
        
        æ³¨æ„ï¼šåªè¿”å›ä¸å½“å‰ç”¨æˆ·è®°å¿†å…³è”çš„å®ä½“ï¼Œç¡®ä¿ç”¨æˆ·éš”ç¦»ã€‚
        """
        # 1. å…ˆè·å–è¯¥ç”¨æˆ·çš„æ‰€æœ‰è®°å¿† ID
        user_memory_ids = set()
        try:
            scope = self.storage.get_scope(user_id)
            all_memories = scope.get_all()
            user_memory_ids = {m.get('metadata', {}).get('id', '') for m in all_memories if m.get('metadata', {}).get('id')}
        except Exception:
            pass
        
        # 2. è·å–æ‰€æœ‰å®ä½“ï¼Œä½†åªä¿ç•™ä¸ç”¨æˆ·è®°å¿†å…³è”çš„
        all_entities = list(self.consolidated_memory.entities.values()) if hasattr(self, 'consolidated_memory') else []
        
        # è¿‡æ»¤ï¼šåªä¿ç•™ source_memory_ids ä¸ç”¨æˆ·è®°å¿†æœ‰äº¤é›†çš„å®ä½“
        if user_memory_ids:
            filtered_entities = [
                e for e in all_entities 
                if hasattr(e, 'source_memory_ids') and e.source_memory_ids and 
                   any(mid in user_memory_ids for mid in e.source_memory_ids)
            ]
        else:
            # ç”¨æˆ·æ²¡æœ‰è®°å¿†ï¼Œä¸åº”è¯¥æœ‰å®ä½“
            filtered_entities = []
        
        if not filtered_entities:
            # å¦‚æœæ²¡æœ‰æ•´åˆçš„è®°å¿†ï¼Œå°è¯•ç”Ÿæˆæ‘˜è¦
            return self._generate_memory_summary(user_id, budget)
        
        lines = ["<core_facts>", "ã€æ ¸å¿ƒçŸ¥è¯†åº“ã€‘ä»¥ä¸‹æ˜¯å·²ç¡®è®¤çš„å…³é”®ä¿¡æ¯ï¼š"]
        current_length = 0
        
        # æŒ‰ç½®ä¿¡åº¦æ’åºï¼Œä¼˜å…ˆé«˜ç½®ä¿¡åº¦çš„
        sorted_entities = sorted(filtered_entities, key=lambda e: -e.confidence)
        
        for entity in sorted_entities:
            fact_line = f"â€¢ {entity.name}"
            if entity.entity_type != "UNKNOWN":
                fact_line += f" ({entity.entity_type})"
            if entity.current_state:
                states = [f"{k}:{v}" for k, v in list(entity.current_state.items())[:3]]
                fact_line += f": {', '.join(states)}"
            
            if current_length + len(fact_line) > budget:
                break
            lines.append(fact_line)
            current_length += len(fact_line)
        
        lines.append("</core_facts>")
        return "\n".join(lines) if len(lines) > 3 else ""
    
    def _generate_memory_summary(self, user_id: str, budget: int) -> str:
        """ç”Ÿæˆè®°å¿†æ‘˜è¦ - å½“æ²¡æœ‰æ•´åˆè®°å¿†æ—¶ä½¿ç”¨"""
        scope = self.storage.get_scope(user_id)
        all_memories = scope.get_all(limit=100)  # è·å–æœ€å¤š100æ¡
        
        if not all_memories or len(all_memories) < 5:
            return ""
        
        # å¦‚æœæœ‰ LLMï¼Œä½¿ç”¨ LLM ç”Ÿæˆæ‘˜è¦
        if self.llm_client and self.memory_summarizer:
            try:
                from .processor.memory_summarizer import MemoryItem
                memory_items = []
                for m in all_memories:
                    memory_items.append(MemoryItem(
                        id=m.get('metadata', {}).get('id', ''),
                        content=m.get('content', ''),
                        user_id=user_id
                    ))
                summary = self.memory_summarizer.summarize_memories(memory_items, max_length=budget)
                if summary:
                    return f"<memory_summary>\nã€å†å²æ‘˜è¦ã€‘\n{summary}\n</memory_summary>"
            except Exception as e:
                pass  # é™é»˜å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
        
        # å¤‡ç”¨æ–¹æ¡ˆï¼šç®€å•æå–å…³é”®è¯å’Œå®ä½“
        entities_set = set()
        for m in all_memories:
            entities = m.get('metadata', {}).get('entities', [])
            entities_set.update(entities)
        
        if entities_set:
            return f"<memory_summary>\nã€æ¶‰åŠçš„è§’è‰²/äº‹ç‰©ã€‘{', '.join(list(entities_set)[:20])}\n</memory_summary>"
        
        return ""
    
    def _build_memory_section(self, memories, budget: int) -> str:
        """æ„å»ºè¯¦ç»†è®°å¿†éƒ¨åˆ†ï¼ˆè‡ªåŠ¨å»é‡ï¼‰"""
        if not memories:
            return ""
        
        lines = ["<memories>", "ã€ç›¸å…³è®°å¿†ã€‘"]
        current_length = 0
        seen_contents = set()  # ç”¨äºå»é‡
        
        for m in memories:
            content = m.content if hasattr(m, 'content') else m.get('content', '')
            
            # å»é‡ï¼šè·³è¿‡å·²ç»æ·»åŠ è¿‡çš„ç›¸åŒå†…å®¹
            content_key = content.strip().lower()
            if content_key in seen_contents:
                continue
            seen_contents.add(content_key)
            
            entities = m.entities if hasattr(m, 'entities') else m.get('entities', [])
            
            line = f"â€¢ {content}"
            if entities:
                line = f"â€¢ [æ¶‰åŠ: {', '.join(entities[:3])}] {content}"
            
            if current_length + len(line) > budget:
                lines.append("...")
                break
            lines.append(line)
            current_length += len(line)
        
        lines.append("</memories>")
        return "\n".join(lines) if len(lines) > 3 else ""
    
    def _build_recent_section(self, recent) -> str:
        """æ„å»ºæœ€è¿‘å¯¹è¯éƒ¨åˆ†"""
        if not recent:
            return ""
        
        lines = ["<recent_conversation>"]
        for turn in recent:
            role = turn.get('metadata', {}).get('role', 'user')
            content = turn.get('content', '')
            lines.append(f"{role}: {content}")
        lines.append("</recent_conversation>")
        return "\n".join(lines)
    
    def _extract_supplementary_keywords(
        self,
        user_id: str,
        character_id: str,
        active_contexts: List
    ) -> List[str]:
        """ä»æŒä¹…æ¡ä»¶å’Œä¼ç¬”ä¸­æå–å…³é”®è¯ç”¨äºè¡¥å……æ£€ç´¢
        
        ç¡®ä¿é‡è¦ä¿¡æ¯å³ä½¿åœ¨å½“å‰ query ä¸­æœªæåŠä¹Ÿèƒ½è¢«å¬å›
        
        Args:
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            active_contexts: æ´»è·ƒçš„æŒä¹…æ¡ä»¶åˆ—è¡¨
            
        Returns:
            List[str]: å…³é”®è¯åˆ—è¡¨
        """
        keywords = set()
        
        # ä»æŒä¹…æ¡ä»¶ä¸­æå–å…³é”®è¯
        if active_contexts:
            for ctx in active_contexts:
                # è·å–å…³é”®è¯
                ctx_keywords = ctx.keywords if hasattr(ctx, 'keywords') else ctx.get('keywords', [])
                if ctx_keywords:
                    keywords.update(ctx_keywords[:3])  # æ¯ä¸ªæ¡ä»¶æœ€å¤šå–3ä¸ªå…³é”®è¯
        
        # ä»æ´»è·ƒä¼ç¬”ä¸­æå–å…³é”®å®ä½“
        try:
            foreshadowings = self.foreshadowing_tracker.get_active(user_id, character_id)
            for fsh in foreshadowings[:5]:  # æœ€å¤š5ä¸ªä¼ç¬”
                entities = fsh.related_entities if hasattr(fsh, 'related_entities') else []
                if entities:
                    keywords.update(entities[:2])  # æ¯ä¸ªä¼ç¬”æœ€å¤šå–2ä¸ªå®ä½“
        except Exception:
            pass
        
        return list(keywords)[:10]  # æ€»å…±æœ€å¤š10ä¸ªå…³é”®è¯
    
    def _search_by_keywords(
        self,
        keywords: List[str],
        user_id: str,
        top_k: int = 5
    ) -> List:
        """æ ¹æ®å…³é”®è¯åˆ—è¡¨è¿›è¡Œè¡¥å……æ£€ç´¢
        
        Args:
            keywords: å…³é”®è¯åˆ—è¡¨
            user_id: ç”¨æˆ·ID
            top_k: è¿”å›çš„æœ€å¤§è®°å¿†æ•°
            
        Returns:
            List: ç›¸å…³è®°å¿†åˆ—è¡¨
        """
        if not keywords:
            return []
        
        all_memories = []
        seen_ids = set()
        
        for keyword in keywords[:5]:  # æœ€å¤šä½¿ç”¨5ä¸ªå…³é”®è¯
            try:
                memories = self.search(keyword, user_id=user_id, top_k=2)
                for m in memories:
                    mem_id = m.id if hasattr(m, 'id') else m.get('id', '')
                    if mem_id and mem_id not in seen_ids:
                        seen_ids.add(mem_id)
                        all_memories.append(m)
                        if len(all_memories) >= top_k:
                            return all_memories
            except Exception:
                continue
        
        return all_memories
    
    def _build_supplementary_section(self, memories) -> str:
        """æ„å»ºè¡¥å……æ£€ç´¢è®°å¿†éƒ¨åˆ†
        
        Args:
            memories: è¡¥å……æ£€ç´¢åˆ°çš„è®°å¿†åˆ—è¡¨
            
        Returns:
            str: æ ¼å¼åŒ–çš„è¡¥å……è®°å¿†æ–‡æœ¬
        """
        if not memories:
            return ""
        
        lines = ["<supplementary_memories>", "ã€ç›¸å…³èƒŒæ™¯ï¼ˆè¡¥å……å¬å›ï¼‰ã€‘"]
        
        for m in memories[:5]:  # æœ€å¤š5æ¡
            content = m.content if hasattr(m, 'content') else m.get('content', '')
            entities = m.entities if hasattr(m, 'entities') else m.get('entities', [])
            
            line = f"â€¢ {content}"
            if entities:
                line = f"â€¢ [æ¶‰åŠ: {', '.join(entities[:3])}] {content}"
            lines.append(line)
        
        lines.append("</supplementary_memories>")
        return "\n".join(lines) if len(lines) > 3 else ""
    
    def _build_proactive_reminders(
        self,
        active_contexts: List,
        threshold_turns: int,
        user_id: str
    ) -> str:
        """æ„å»ºä¸»åŠ¨æé†’æ–‡æœ¬ï¼ˆå¯¹é•¿æœŸæœªæåŠçš„é‡è¦æŒä¹…æ¡ä»¶ï¼‰
        
        ç±»ä¼¼äºä¼ç¬”çš„ä¸»åŠ¨æé†’æœºåˆ¶ï¼Œç¡®ä¿é‡è¦èƒŒæ™¯ä¿¡æ¯ä¸ä¼šè¢«é—å¿˜
        
        Args:
            active_contexts: æ´»è·ƒçš„æŒä¹…æ¡ä»¶åˆ—è¡¨
            threshold_turns: è§¦å‘æé†’çš„è½®æ¬¡é˜ˆå€¼
            user_id: ç”¨æˆ·ID
            
        Returns:
            str: ä¸»åŠ¨æé†’æ–‡æœ¬ï¼Œå¦‚æœæ²¡æœ‰éœ€è¦æé†’çš„å†…å®¹åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        if not active_contexts:
            return ""
        
        # è·å–å½“å‰æ€»è½®æ¬¡
        current_turn = 0
        if self.volume_manager:
            current_turn = self.volume_manager.get_total_turns()
        
        reminders = []
        
        for ctx in active_contexts:
            # è·å–æœ€åæåŠè½®æ¬¡ - PersistentContext æ˜¯ dataclassï¼Œä½¿ç”¨ getattr
            last_mentioned = getattr(ctx, 'last_mentioned_turn', None) or getattr(ctx, 'use_count', 0)
            importance = getattr(ctx, 'importance', None) or getattr(ctx, 'confidence', 0.5)
            content = getattr(ctx, 'content', '')
            
            # è®¡ç®—æœªæåŠçš„è½®æ¬¡æ•°
            turns_since_mention = current_turn - last_mentioned if last_mentioned else current_turn
            
            # é«˜é‡è¦æ€§æ¡ä»¶é˜ˆå€¼å‡åŠ
            effective_threshold = threshold_turns // 2 if importance > 0.7 else threshold_turns
            
            if turns_since_mention >= effective_threshold and importance >= 0.5:
                reminders.append({
                    'content': content,
                    'importance': importance,
                    'turns_since': turns_since_mention
                })
        
        if not reminders:
            return ""
        
        # æŒ‰é‡è¦æ€§å’ŒæœªæåŠæ—¶é•¿æ’åº
        reminders.sort(key=lambda x: (x['importance'], x['turns_since']), reverse=True)
        
        lines = [
            "<proactive_reminders>",
            "ã€é‡è¦èƒŒæ™¯æé†’ã€‘ä»¥ä¸‹æ˜¯ä½ å¯èƒ½éœ€è¦æ³¨æ„çš„é‡è¦èƒŒæ™¯ä¿¡æ¯ï¼ˆé•¿æœŸæœªåœ¨å¯¹è¯ä¸­æ¶‰åŠï¼‰ï¼š"
        ]
        
        for r in reminders[:3]:  # æœ€å¤šæé†’3æ¡
            importance_label = "é«˜" if r['importance'] > 0.7 else "ä¸­"
            lines.append(f"â€¢ [{importance_label}é‡è¦æ€§ï¼Œ{r['turns_since']}è½®æœªæåŠ] {r['content']}")
        
        lines.append("</proactive_reminders>")
        return "\n".join(lines)
    
    def _format_foreshadowings(self, foreshadowings) -> str:
        """æ ¼å¼åŒ–ä¼ç¬”ä¸ºæç¤ºæ–‡æœ¬"""
        if not foreshadowings:
            return ""
        
        lines = ["\n<foreshadowings>", "ä»¥ä¸‹æ˜¯å°šæœªè§£å†³çš„ä¼ç¬”ï¼Œè¯·åœ¨åˆé€‚æ—¶æœºè‡ªç„¶åœ°æ¨è¿›æˆ–å›æ”¶ï¼š"]
        for f in foreshadowings:
            importance_label = "é«˜" if f.importance > 0.7 else "ä¸­" if f.importance > 0.4 else "ä½"
            lines.append(f"â€¢ [{importance_label}] {f.content}")
            if f.related_entities:
                lines.append(f"  ç›¸å…³è§’è‰²/äº‹ç‰©: {', '.join(f.related_entities)}")
        lines.append("</foreshadowings>")
        return "\n".join(lines)
    
    # ==================== ä¼ç¬” API ====================
    
    def plant_foreshadowing(
        self,
        content: str,
        user_id: str = "default",
        character_id: str = "default",
        related_entities: Optional[List[str]] = None,
        importance: float = 0.5
    ) -> Foreshadowing:
        """åŸ‹ä¸‹ä¼ç¬”
        
        åŒæ—¶å°†ä¼ç¬”ç´¢å¼•åˆ° VectorIndex ä»¥æ”¯æŒè¯­ä¹‰æ£€ç´¢ï¼ˆå³ä½¿å½’æ¡£åä¹Ÿèƒ½æœç´¢ï¼‰
        """
        foreshadowing = self.foreshadowing_tracker.plant(
            content=content,
            user_id=user_id,
            character_id=character_id,
            related_entities=related_entities,
            importance=importance
        )
        
        # ç´¢å¼•åˆ° VectorIndexï¼ˆç¡®ä¿å½’æ¡£åä»å¯è¯­ä¹‰æ£€ç´¢ï¼‰
        # æ³¨æ„ï¼šforeshadowing.id å·²ç»æ˜¯ fsh_{counter}_{timestamp} æ ¼å¼ï¼Œä¸éœ€è¦å†åŠ  fsh_ å‰ç¼€
        if self._vector_index and self._vector_index.enabled:
            doc_id = f"{user_id}_{character_id}_{foreshadowing.id}"
            self._vector_index.add_text(doc_id, content)
        
        return foreshadowing
    
    def resolve_foreshadowing(
        self,
        foreshadowing_id: str,
        resolution: str,
        user_id: str = "default",
        character_id: str = "default"
    ) -> bool:
        """è§£å†³ä¼ç¬”"""
        return self.foreshadowing_tracker.resolve(foreshadowing_id, resolution, user_id, character_id)
    
    def add_foreshadowing_hint(
        self,
        foreshadowing_id: str,
        hint: str,
        user_id: str = "default",
        character_id: str = "default"
    ) -> bool:
        """æ·»åŠ ä¼ç¬”æç¤º
        
        ä¸ºä¼ç¬”æ·»åŠ è¿›å±•æç¤ºï¼Œä¼šå°†çŠ¶æ€ä» PLANTED æ›´æ–°ä¸º DEVELOPING
        
        Args:
            foreshadowing_id: ä¼ç¬”ID
            hint: æç¤ºå†…å®¹
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        return self.foreshadowing_tracker.add_hint(foreshadowing_id, hint, user_id, character_id)
    
    def abandon_foreshadowing(
        self,
        foreshadowing_id: str,
        user_id: str = "default",
        character_id: str = "default"
    ) -> bool:
        """æ”¾å¼ƒ/åˆ é™¤ä¼ç¬”
        
        å°†ä¼ç¬”æ ‡è®°ä¸ºå·²æ”¾å¼ƒçŠ¶æ€ï¼ˆä¸ä¼šç‰©ç†åˆ é™¤ï¼Œä¿ç•™å†å²è®°å½•ï¼‰
        
        Args:
            foreshadowing_id: ä¼ç¬”ID
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        return self.foreshadowing_tracker.abandon(foreshadowing_id, user_id, character_id)
    
    def get_active_foreshadowings(self, user_id: str = "default", character_id: str = "default") -> List[Foreshadowing]:
        """è·å–æ´»è·ƒä¼ç¬”"""
        return self.foreshadowing_tracker.get_active(user_id, character_id)
    
    def get_foreshadowing_by_id(
        self,
        foreshadowing_id: str,
        user_id: str = "default",
        character_id: str = "default"
    ) -> Optional[Foreshadowing]:
        """æ ¹æ®IDè·å–ä¼ç¬”ï¼ˆåŒ…æ‹¬å·²å½’æ¡£çš„ï¼‰
        
        ç”¨äºä» VectorIndex æœç´¢ç»“æœä¸­è·å–ä¼ç¬”è¯¦æƒ…ã€‚
        æœç´¢å‘½ä¸­å½’æ¡£ä¼ç¬”æ—¶ï¼Œé€šè¿‡æ­¤æ–¹æ³•ä»å½’æ¡£æ–‡ä»¶è¯»å–å®Œæ•´ä¿¡æ¯ã€‚
        
        Args:
            foreshadowing_id: ä¼ç¬”ID
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            
        Returns:
            Optional[Foreshadowing]: ä¼ç¬”å¯¹è±¡ï¼Œæœªæ‰¾åˆ°è¿”å› None
        """
        return self.foreshadowing_tracker.get_by_id(foreshadowing_id, user_id, character_id)
    
    def on_foreshadowing_turn(
        self, 
        content: str, 
        role: str = "user", 
        user_id: str = "default",
        character_id: str = "default"
    ) -> AnalysisResult:
        """å¤„ç†æ–°çš„ä¸€è½®å¯¹è¯ï¼ˆç”¨äºä¼ç¬”åˆ†æï¼‰
        
        åœ¨æ¯è½®å¯¹è¯åè°ƒç”¨æ­¤æ–¹æ³•ï¼Œåˆ†æå™¨ä¼šï¼š
        - æ‰‹åŠ¨æ¨¡å¼ï¼šä¸åšä»»ä½•æ“ä½œï¼Œè¿”å›ç©ºç»“æœ
        - LLMæ¨¡å¼ï¼šç´¯ç§¯å¯¹è¯ï¼Œè¾¾åˆ°è§¦å‘æ¡ä»¶æ—¶è‡ªåŠ¨åˆ†æ
        
        Args:
            content: å¯¹è¯å†…å®¹
            role: è§’è‰²ï¼ˆuser/assistantï¼‰
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            
        Returns:
            AnalysisResult: åˆ†æç»“æœ
        """
        return self.foreshadowing_analyzer.on_new_turn(
            content=content,
            role=role,
            user_id=user_id,
            character_id=character_id
        )
    
    def trigger_foreshadowing_analysis(self, user_id: str = "default", character_id: str = "default") -> AnalysisResult:
        """æ‰‹åŠ¨è§¦å‘ä¼ç¬”åˆ†æ
        
        å¯ä»¥åœ¨ä»»ä½•æ—¶å€™è°ƒç”¨ï¼Œå¼ºåˆ¶è§¦å‘ LLM åˆ†æï¼ˆå¦‚æœå·²é…ç½®ï¼‰ã€‚
        
        Args:
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            
        Returns:
            AnalysisResult: åˆ†æç»“æœ
        """
        return self.foreshadowing_analyzer.trigger_analysis(user_id, character_id)
    
    def get_foreshadowing_analyzer_config(self) -> Dict[str, Any]:
        """è·å–ä¼ç¬”åˆ†æå™¨é…ç½®"""
        return self.foreshadowing_analyzer.config.to_dict()
    
    def update_foreshadowing_analyzer_config(
        self,
        trigger_interval: Optional[int] = None,
        auto_plant: Optional[bool] = None,
        auto_resolve: Optional[bool] = None
    ):
        """æ›´æ–°ä¼ç¬”åˆ†æå™¨é…ç½®"""
        self.foreshadowing_analyzer.update_config(
            trigger_interval=trigger_interval,
            auto_plant=auto_plant,
            auto_resolve=auto_resolve
        )
    
    def enable_foreshadowing_llm_mode(
        self,
        api_key: str,
        model: str = "gpt-4o-mini",
        base_url: Optional[str] = None
    ):
        """å¯ç”¨ä¼ç¬”åˆ†æå™¨çš„ LLM æ¨¡å¼ï¼ˆåŠ¨æ€åˆ‡æ¢ï¼Œæ— éœ€é‡å¯ï¼‰"""
        self.foreshadowing_analyzer.enable_llm_mode(
            api_key=api_key,
            model=model,
            base_url=base_url
        )
    
    def disable_foreshadowing_llm_mode(self):
        """ç¦ç”¨ä¼ç¬”åˆ†æå™¨çš„ LLM æ¨¡å¼ï¼Œåˆ‡æ¢å›æ‰‹åŠ¨æ¨¡å¼"""
        self.foreshadowing_analyzer.disable_llm_mode()
    
    # ==================== æŒä¹…æ¡ä»¶ API ====================
    
    def add_persistent_context(
        self,
        content: str,
        context_type = "custom",
        user_id: str = "default",
        character_id: str = "default",
        keywords: List[str] = None
    ):
        """æ·»åŠ æŒä¹…æ¡ä»¶
        
        æŒä¹…æ¡ä»¶æ˜¯ä¸€æ—¦ç¡®ç«‹å°±åº”è¯¥åœ¨åç»­æ‰€æœ‰å¯¹è¯ä¸­é»˜è®¤æˆç«‹çš„èƒŒæ™¯ä¿¡æ¯ã€‚
        
        Args:
            content: æ¡ä»¶å†…å®¹ï¼Œå¦‚"ç”¨æˆ·æ˜¯å¤§å­¦æ¯•ä¸šç”Ÿæƒ³åˆ›ä¸š"
            context_type: ç±»å‹ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ– ContextType æšä¸¾ï¼Œå¯é€‰å€¼ï¼š
                - user_identity: ç”¨æˆ·èº«ä»½
                - user_goal: ç”¨æˆ·ç›®æ ‡
                - user_preference: ç”¨æˆ·åå¥½
                - environment: æŠ€æœ¯ç¯å¢ƒ
                - project: é¡¹ç›®ä¿¡æ¯
                - character_trait: è§’è‰²ç‰¹å¾
                - world_setting: ä¸–ç•Œè§‚
                - relationship: å…³ç³»è®¾å®š
                - assumption: å‡è®¾å‰æ
                - constraint: çº¦æŸæ¡ä»¶
                - custom: è‡ªå®šä¹‰
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            keywords: å…³é”®è¯åˆ—è¡¨
            
        Returns:
            PersistentContext: åˆ›å»ºçš„æ¡ä»¶å¯¹è±¡
        """
        from .processor.context_tracker import ContextType
        
        # æ”¯æŒå­—ç¬¦ä¸²å’Œæšä¸¾ä¸¤ç§è¾“å…¥
        if isinstance(context_type, ContextType):
            ctx_type = context_type
        else:
            try:
                ctx_type = ContextType(context_type)
            except ValueError:
                ctx_type = ContextType.CUSTOM
        
        context = self.context_tracker.add(
            content=content,
            context_type=ctx_type,
            user_id=user_id,
            character_id=character_id,
            keywords=keywords
        )
        
        # ç´¢å¼•åˆ° VectorIndexï¼ˆæ— è®ºæ˜¯å¦æ´»è·ƒï¼Œç¡®ä¿å³ä½¿è¢«æ·˜æ±°ä¹Ÿå¯è¯­ä¹‰æ£€ç´¢ï¼‰
        # è¢« _enforce_limits() æ·˜æ±°çš„æ¡ä»¶ä»éœ€å¯è¢«æœç´¢æ‰¾å›
        if self._vector_index and self._vector_index.enabled:
            doc_id = f"ctx_{user_id}_{character_id}_{context.id}"
            self._vector_index.add_text(doc_id, content)
        
        return context
    
    def get_persistent_contexts(self, user_id: str = "default", character_id: str = "default") -> List[Dict]:
        """è·å–æ‰€æœ‰æ´»è·ƒçš„æŒä¹…æ¡ä»¶"""
        contexts = self.context_tracker.get_active(user_id, character_id)
        return [c.to_dict() for c in contexts]
    
    def get_persistent_context_by_id(
        self,
        context_id: str,
        user_id: str = "default",
        character_id: str = "default"
    ) -> Optional[Dict]:
        """æ ¹æ®IDè·å–æŒä¹…æ¡ä»¶ï¼ˆåŒ…æ‹¬å·²å½’æ¡£çš„ï¼‰
        
        ç”¨äºä» VectorIndex æœç´¢ç»“æœä¸­è·å–æ¡ä»¶è¯¦æƒ…ã€‚
        æœç´¢å‘½ä¸­å½’æ¡£æ¡ä»¶æ—¶ï¼Œé€šè¿‡æ­¤æ–¹æ³•ä»å½’æ¡£æ–‡ä»¶è¯»å–å®Œæ•´ä¿¡æ¯ã€‚
        
        Args:
            context_id: æ¡ä»¶ID
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            
        Returns:
            Optional[Dict]: æ¡ä»¶æ•°æ®å­—å…¸ï¼Œæœªæ‰¾åˆ°è¿”å› None
        """
        ctx = self.context_tracker.get_context_by_id(context_id, user_id, character_id)
        return ctx.to_dict() if ctx else None
    
    def remove_persistent_context(self, context_id: str, user_id: str = "default", character_id: str = "default") -> bool:
        """ç§»é™¤ï¼ˆåœç”¨ï¼‰æŸä¸ªæŒä¹…æ¡ä»¶"""
        return self.context_tracker.deactivate(context_id, user_id, character_id)
    
    def extract_contexts_from_text(self, text: str, user_id: str = "default", character_id: str = "default") -> List[Dict]:
        """ä»æ–‡æœ¬ä¸­è‡ªåŠ¨æå–æŒä¹…æ¡ä»¶
        
        ä½¿ç”¨ LLMï¼ˆå¦‚æœå¯ç”¨ï¼‰æˆ–è§„åˆ™ä»æ–‡æœ¬ä¸­æå–åº”è¯¥æŒä¹…åŒ–çš„æ¡ä»¶ã€‚
        åŒæ—¶å°†æ–°æå–çš„æ¡ä»¶ç´¢å¼•åˆ° VectorIndex ä»¥æ”¯æŒè¯­ä¹‰æ£€ç´¢ã€‚
        
        Args:
            text: è¦åˆ†æçš„æ–‡æœ¬
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            
        Returns:
            List[Dict]: æå–å‡ºçš„æ¡ä»¶åˆ—è¡¨
        """
        contexts = self.context_tracker.extract_from_text(text, user_id, character_id)
        
        # ç´¢å¼•æ–°æå–çš„æ¡ä»¶åˆ° VectorIndexï¼ˆæ— è®ºæ´»è·ƒçŠ¶æ€ï¼‰
        if self._vector_index and self._vector_index.enabled:
            for ctx in contexts:
                doc_id = f"ctx_{user_id}_{character_id}_{ctx.id}"
                self._vector_index.add_text(doc_id, ctx.content)
        
        return [c.to_dict() for c in contexts]
    
    def consolidate_persistent_contexts(self, user_id: str = "default", character_id: str = "default", force: bool = False) -> Dict:
        """å‹ç¼©åˆå¹¶æŒä¹…æ¡ä»¶
        
        å½“æŒä¹…æ¡ä»¶æ•°é‡è¿‡å¤šæ—¶ï¼Œæ™ºèƒ½åˆå¹¶ç›¸ä¼¼çš„æ¡ä»¶ä»¥æ§åˆ¶å¢é•¿ã€‚
        å¦‚æœé…ç½®äº†LLMï¼Œä¼šä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½å‹ç¼©ï¼›å¦åˆ™åªä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„æ¡ä»¶ã€‚
        
        Args:
            user_id: ç”¨æˆ·ID
            character_id: è§’è‰²ID
            force: æ˜¯å¦å¼ºåˆ¶æ‰§è¡Œï¼ˆé»˜è®¤åªåœ¨è¶…è¿‡é˜ˆå€¼æ—¶æ‰§è¡Œï¼‰
            
        Returns:
            Dict: å‹ç¼©ç»“æœï¼ŒåŒ…å«ï¼š
                - reduced: å‡å°‘çš„æ¡ä»¶æ•°é‡
                - before: å‹ç¼©å‰çš„ç»Ÿè®¡
                - after: å‹ç¼©åçš„ç»Ÿè®¡
        """
        before_stats = self.context_tracker.get_stats(user_id=user_id, character_id=character_id)
        reduced = self.context_tracker.consolidate_contexts(user_id=user_id, character_id=character_id, force=force)
        after_stats = self.context_tracker.get_stats(user_id=user_id, character_id=character_id)
        
        return {
            'reduced': reduced,
            'before': before_stats,
            'after': after_stats
        }
    
    # ==================== å®ä½“ API ====================
    
    def get_entity(self, name: str) -> Optional[Dict[str, Any]]:
        """è·å–å®ä½“ä¿¡æ¯"""
        if self._entity_index:
            indexed = self._entity_index.get_entity(name)
            if indexed:
                return {
                    'name': indexed.name,
                    'type': indexed.entity_type,
                    'aliases': indexed.aliases,
                    'mention_count': len(indexed.turn_references),
                    'related_turns': indexed.turn_references[:10]
                }
        return None
    
    def get_related_entities(self, name: str) -> List[str]:
        """è·å–ç›¸å…³å®ä½“"""
        neighbors = self.knowledge_graph.get_neighbors(name)
        return [neighbor_id for neighbor_id, _ in neighbors]
    
    # ==================== ç®¡ç† API ====================
    
    def rebuild_vector_index(self, user_id: Optional[str] = None) -> Dict[str, Any]:
        """é‡å»ºå‘é‡ç´¢å¼•
        
        ä»ç°æœ‰è®°å¿†æ•°æ®é‡æ–°ç”Ÿæˆå‘é‡ç´¢å¼•ï¼Œç”¨äºä¿®å¤ç»´åº¦ä¸åŒ¹é…ç­‰é—®é¢˜ã€‚
        
        Args:
            user_id: å¯é€‰ï¼ŒæŒ‡å®šåªé‡å»ºæŸä¸ªç”¨æˆ·çš„ç´¢å¼•ã€‚ä¸º None æ—¶é‡å»ºæ‰€æœ‰ç”¨æˆ·ã€‚
            
        Returns:
            Dict: åŒ…å« success, message, indexed_count ç­‰ä¿¡æ¯
        """
        if self._vector_index is None:
            return {
                'success': False,
                'message': 'å‘é‡ç´¢å¼•æœªå¯ç”¨',
                'indexed_count': 0
            }
        
        # æ”¶é›†éœ€è¦ç´¢å¼•çš„è®°å¿†
        memories_to_index = []
        
        if user_id:
            # åªé‡å»ºæŒ‡å®šç”¨æˆ·
            scope = self.storage.get_scope(user_id)
            for m in scope.get_all():
                memory_id = m.get('id', '')
                content = m.get('content', m.get('memory', ''))
                if memory_id and content:
                    memories_to_index.append((memory_id, content))
            _safe_print(f"[Recall] é‡å»ºå‘é‡ç´¢å¼•: user={user_id}, è®°å¿†æ•°={len(memories_to_index)}")
        else:
            # é‡å»ºæ‰€æœ‰ç”¨æˆ·
            for scope_key, scope in self.storage._scopes.items():
                for m in scope.get_all():
                    memory_id = m.get('id', '')
                    content = m.get('content', m.get('memory', ''))
                    if memory_id and content:
                        memories_to_index.append((memory_id, content))
            _safe_print(f"[Recall] é‡å»ºå‘é‡ç´¢å¼•: å…¨éƒ¨ç”¨æˆ·, è®°å¿†æ•°={len(memories_to_index)}")
        
        if not memories_to_index:
            return {
                'success': True,
                'message': 'æ²¡æœ‰éœ€è¦ç´¢å¼•çš„è®°å¿†',
                'indexed_count': 0
            }
        
        # è°ƒç”¨å‘é‡ç´¢å¼•çš„é‡å»ºæ–¹æ³•
        try:
            indexed_count = self._vector_index.rebuild_from_memories(memories_to_index)
            return {
                'success': True,
                'message': f'å‘é‡ç´¢å¼•é‡å»ºå®Œæˆ',
                'indexed_count': indexed_count,
                'total_memories': len(memories_to_index)
            }
        except Exception as e:
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'message': f'é‡å»ºå¤±è´¥: {e}',
                'indexed_count': 0
            }
    
    def get_stats(self, user_id: Optional[str] = None) -> Dict[str, Any]:
        """è·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            user_id: å¯é€‰çš„ç”¨æˆ·IDï¼ŒæŒ‡å®šåè¿”å›è¯¥ç”¨æˆ·çš„è¯¦ç»†ç»Ÿè®¡
        
        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…å«ï¼š
                - total_memories: æ€»è®°å¿†æ•°
                - total_entities: æ€»å®ä½“æ•°
                - total_foreshadowings: ä¼ç¬”æ•°
                - å¦‚æœæŒ‡å®š user_idï¼Œè¿˜åŒ…å«è¯¥ç”¨æˆ·çš„è¯¦ç»†ç»Ÿè®¡
        """
        stats = {
            'version': __version__,
            'data_root': self.data_root,
            'mode': self._get_mode_name(),
            'lightweight': self.lightweight,  # ä¿ç•™æ—§å­—æ®µï¼ˆå‘åå…¼å®¹ï¼‰
            'lite': self.lightweight,  # æ–°å­—æ®µï¼ˆæ¨èä½¿ç”¨ï¼‰
        }
        
        # å…¨å±€ç»Ÿè®¡
        total_memories = 0
        total_entities_in_memories = 0
        
        for scope_key, scope in self.storage._scopes.items():
            memories = scope.get_all()
            total_memories += len(memories)
            for m in memories:
                entities = m.get('metadata', {}).get('entities', [])
                total_entities_in_memories += len(entities)
        
        stats['global'] = {
            'total_memories': total_memories,
            'total_scopes': len(self.storage._scopes),
            'consolidated_entities': len(self.consolidated_memory.entities) if hasattr(self, 'consolidated_memory') else 0,
            'active_foreshadowings': len(self.foreshadowing_tracker.get_active()),
        }
        
        # ç´¢å¼•ç»Ÿè®¡
        stats['indexes'] = {
            'entity_index': self._entity_index is not None,
            'inverted_index': self._inverted_index is not None,
            'vector_index': self._vector_index is not None,
            'ngram_index': self._ngram_index is not None,
            'cached_contents': len(self.retriever._content_cache) if hasattr(self.retriever, '_content_cache') else 0,
        }
        
        # ç”¨æˆ·ç‰¹å®šç»Ÿè®¡
        if user_id:
            scope = self.storage.get_scope(user_id)
            user_memories = scope.get_all()
            
            # ç»Ÿè®¡å®ä½“åˆ†å¸ƒ
            entity_counts = {}
            for m in user_memories:
                for e in m.get('metadata', {}).get('entities', []):
                    entity_counts[e] = entity_counts.get(e, 0) + 1
            
            # æŒ‰å‡ºç°æ¬¡æ•°æ’åº
            top_entities = sorted(entity_counts.items(), key=lambda x: -x[1])[:20]
            
            stats['user'] = {
                'user_id': user_id,
                'total_memories': len(user_memories),
                'unique_entities': len(entity_counts),
                'top_entities': dict(top_entities),
                'active_foreshadowings': len([f for f in self.foreshadowing_tracker.get_active() 
                                              if hasattr(f, 'user_id') and f.user_id == user_id]),
                'persistent_contexts': self.context_tracker.get_stats(user_id),
            }
        
        # æ€§èƒ½ç»Ÿè®¡
        try:
            stats['performance'] = self.monitor.get_all_stats() if hasattr(self.monitor, 'get_all_stats') else {}
        except Exception:
            stats['performance'] = {}
        
        return stats
    
    def consolidate(self, user_id: str = "default"):
        """æ‰§è¡Œè®°å¿†æ•´åˆ"""
        scope = self.storage.get_scope(user_id)
        
        # è·å–å·¥ä½œè®°å¿†
        working = scope.get_all()
        
        # ä½¿ç”¨æ‘˜è¦å™¨å‹ç¼©
        from .processor.memory_summarizer import MemoryItem, MemoryPriority
        items = [
            MemoryItem(
                id=m.get('id', ''),
                content=m.get('content', m.get('memory', '')),
                user_id=user_id,
                priority=MemoryPriority.NORMAL
            )
            for m in working
        ]
        
        # åˆå¹¶ç›¸ä¼¼è®°å¿†
        merged = self.memory_summarizer.merge_similar(items)
        
        # ç§»åŠ¨åˆ°æ•´åˆå±‚
        # TODO: å®ç°å®é™…çš„æ•´åˆé€»è¾‘
        
        _safe_print(f"[Recall] æ•´åˆå®Œæˆ: {len(working)} -> {len(merged)}")
    
    def reset(self, user_id: Optional[str] = None):
        """é‡ç½®ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰"""
        if user_id:
            scope = self.storage.get_scope(user_id)
            scope.clear()
        else:
            # é‡ç½®æ‰€æœ‰
            self.storage = MultiTenantStorage(
                base_path=os.path.join(self.data_root, 'data')
            )
            if not self.lightweight:
                self._init_indexes()
        
        _safe_print(f"[Recall] é‡ç½®å®Œæˆ")
    
    def close(self):
        """å…³é—­å¼•æ“"""
        # 1. æŒä¹…åŒ– VolumeManagerï¼ˆç¡®ä¿æ‰€æœ‰æ•°æ®ä¿å­˜ï¼‰
        if self.volume_manager:
            self.volume_manager.flush()
        
        # 2. ä¿å­˜ N-gram ç´¢å¼•ï¼ˆåŸæ–‡å­˜å‚¨ï¼‰
        if self._ngram_index:
            self._ngram_index.save()
        
        # 3. ä¿å­˜å¹¶å…³é—­å‘é‡ç´¢å¼•
        if self._vector_index:
            self._vector_index.close()
        
        _safe_print("[Recall] å¼•æ“å·²å…³é—­")


# ä¾¿æ·å‡½æ•°
def create_engine(**kwargs) -> RecallEngine:
    """åˆ›å»ºå¼•æ“çš„ä¾¿æ·å‡½æ•°"""
    return RecallEngine(**kwargs)

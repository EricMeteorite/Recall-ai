"""å‘é‡ç´¢å¼• - æ”¯æŒå¤šç§ Embedding åç«¯"""

import os
import json
from typing import List, Tuple, Optional, Any, Dict

import numpy as np

from ..embedding import EmbeddingBackend, EmbeddingConfig, create_embedding_backend
from ..embedding.base import EmbeddingBackendType


# Windows GBK ç¼–ç å…¼å®¹çš„å®‰å…¨æ‰“å°å‡½æ•°
def _safe_print(msg: str) -> None:
    """å®‰å…¨æ‰“å°å‡½æ•°ï¼Œæ›¿æ¢ emoji ä¸º ASCII ç­‰ä»·ç‰©ä»¥é¿å… Windows GBK ç¼–ç é”™è¯¯"""
    emoji_map = {
        'ğŸ“¥': '[IN]', 'ğŸ“¤': '[OUT]', 'ğŸ”': '[SEARCH]', 'âœ…': '[OK]', 'âŒ': '[FAIL]',
        'âš ï¸': '[WARN]', 'ğŸ’¾': '[SAVE]', 'ğŸ—ƒï¸': '[DB]', 'ğŸ§¹': '[CLEAN]', 'ğŸ“Š': '[STATS]',
        'ğŸ”„': '[SYNC]', 'ğŸ“¦': '[PKG]', 'ğŸš€': '[START]', 'ğŸ¯': '[TARGET]', 'ğŸ’¡': '[HINT]',
        'ğŸ”§': '[FIX]', 'ğŸ“': '[NOTE]', 'ğŸ‰': '[DONE]', 'â±ï¸': '[TIME]', 'ğŸŒ': '[NET]',
        'ğŸ§ ': '[BRAIN]', 'ğŸ’¬': '[CHAT]', 'ğŸ·ï¸': '[TAG]', 'ğŸ“': '[DIR]', 'ğŸ”’': '[LOCK]',
        'ğŸŒ±': '[PLANT]', 'ğŸ—‘ï¸': '[DEL]', 'ğŸ’«': '[MAGIC]', 'ğŸ­': '[MASK]', 'ğŸ“–': '[BOOK]',
        'âš¡': '[FAST]', 'ğŸ”¥': '[HOT]', 'ğŸ’': '[GEM]', 'ğŸŒŸ': '[STAR]', 'ğŸ¨': '[ART]'
    }
    for emoji, ascii_equiv in emoji_map.items():
        msg = msg.replace(emoji, ascii_equiv)
    try:
        print(msg)
    except UnicodeEncodeError:
        print(msg.encode('ascii', errors='replace').decode('ascii'))


class VectorIndex:
    """å‘é‡ç´¢å¼• - ä½¿ç”¨ FAISS å®ç°é«˜æ•ˆç›¸ä¼¼åº¦æœç´¢
    
    æ”¯æŒä¸‰ç§æ¨¡å¼ï¼š
    1. Local æ¨¡å¼ï¼ˆlocalï¼‰: æœ¬åœ° sentence-transformersï¼Œ~800MB å†…å­˜
    2. Cloud æ¨¡å¼ï¼ˆopenai/siliconflowï¼‰: API è°ƒç”¨ï¼Œ~50MB å†…å­˜
    3. Lite æ¨¡å¼ï¼ˆnoneï¼‰: ç¦ç”¨å‘é‡ç´¢å¼•
    """
    
    def __init__(
        self, 
        data_path: str, 
        embedding_config: Optional[EmbeddingConfig] = None
    ):
        """åˆå§‹åŒ–å‘é‡ç´¢å¼•
        
        Args:
            data_path: æ•°æ®å­˜å‚¨è·¯å¾„
            embedding_config: Embedding é…ç½®ï¼Œä¸º None æ—¶è‡ªåŠ¨é€‰æ‹©
        """
        self.data_path = data_path
        self.index_dir = os.path.join(data_path, 'indexes')
        self.index_file = os.path.join(self.index_dir, 'vector_index.faiss')
        self.mapping_file = os.path.join(self.index_dir, 'vector_mapping.json')
        self.config_file = os.path.join(self.index_dir, 'vector_config.json')
        
        # Embedding åç«¯
        self.embedding_config = embedding_config
        self._embedding_backend: Optional[EmbeddingBackend] = None
        
        # FAISS ç´¢å¼•
        self._index = None
        self.turn_mapping: List[int] = []  # FAISS å†…éƒ¨ ID â†’ turn_id
        
        # æ˜¯å¦å¯ç”¨
        self._enabled = True
        
        self._setup()
    
    def _setup(self):
        """åˆå§‹åŒ–è®¾ç½®"""
        os.makedirs(self.index_dir, exist_ok=True)
        
        # åŠ è½½æˆ–åˆ›å»ºé…ç½®
        if self.embedding_config is None:
            self.embedding_config = self._load_or_create_config()
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨
        if self.embedding_config.backend == EmbeddingBackendType.NONE:
            self._enabled = False
            _safe_print("[VectorIndex] Lite æ¨¡å¼ï¼Œå‘é‡ç´¢å¼•å·²ç¦ç”¨")
    
    def _load_or_create_config(self) -> EmbeddingConfig:
        """åŠ è½½å·²æœ‰é…ç½®æˆ–è‡ªåŠ¨é€‰æ‹©"""
        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r') as f:
                    data = json.load(f)
                return EmbeddingConfig(
                    backend=EmbeddingBackendType(data.get('backend', 'local')),
                    local_model=data.get('local_model', 'paraphrase-multilingual-MiniLM-L12-v2'),
                    api_model=data.get('api_model', 'text-embedding-3-small'),
                    dimension=data.get('dimension', 384)
                )
            except Exception as e:
                _safe_print(f"[VectorIndex] é…ç½®åŠ è½½å¤±è´¥ï¼Œè‡ªåŠ¨é€‰æ‹©: {e}")
        
        # è‡ªåŠ¨é€‰æ‹©
        from ..embedding.factory import auto_select_backend
        return auto_select_backend()
    
    def _save_config(self):
        """ä¿å­˜é…ç½®"""
        data = {
            'backend': self.embedding_config.backend.value,
            'local_model': self.embedding_config.local_model,
            'api_model': self.embedding_config.api_model,
            'dimension': self.dimension
        }
        with open(self.config_file, 'w') as f:
            json.dump(data, f, indent=2)
    
    @property
    def enabled(self) -> bool:
        """æ˜¯å¦å¯ç”¨å‘é‡ç´¢å¼•"""
        return self._enabled
    
    @property
    def embedding_backend(self) -> EmbeddingBackend:
        """è·å– Embedding åç«¯ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._embedding_backend is None:
            self._embedding_backend = create_embedding_backend(self.embedding_config)
        return self._embedding_backend
    
    @property
    def dimension(self) -> int:
        """è·å–å‘é‡ç»´åº¦"""
        return self.embedding_backend.dimension
    
    @property
    def index(self):
        """è·å– FAISS ç´¢å¼•ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._index is None:
            self._load()
        return self._index
    
    def _load(self):
        """åŠ è½½ç´¢å¼•"""
        if not self._enabled:
            return
        
        import faiss
        
        if os.path.exists(self.index_file):
            self._index = faiss.read_index(self.index_file)
            
            # æ£€æŸ¥ç»´åº¦æ˜¯å¦åŒ¹é…
            if self._index.d != self.dimension:
                _safe_print(f"[VectorIndex] è­¦å‘Š: ç´¢å¼•ç»´åº¦({self._index.d})ä¸å½“å‰æ¨¡å‹ç»´åº¦({self.dimension})ä¸åŒ¹é…")
                _safe_print(f"[VectorIndex] æ­£åœ¨é‡å»ºç´¢å¼•...")
                self._index = faiss.IndexFlatIP(self.dimension)
                self.turn_mapping = []
                self._save_config()
            elif os.path.exists(self.mapping_file):
                with open(self.mapping_file, 'r') as f:
                    self.turn_mapping = json.load(f)
        else:
            # åˆ›å»ºæ–°ç´¢å¼•
            self._index = faiss.IndexFlatIP(self.dimension)
            self._save_config()
    
    def _save(self):
        """ä¿å­˜ç´¢å¼•"""
        if not self._enabled or self._index is None:
            return
        
        import faiss
        
        faiss.write_index(self._index, self.index_file)
        
        with open(self.mapping_file, 'w') as f:
            json.dump(self.turn_mapping, f)
    
    def clear(self):
        """æ¸…ç©ºå‘é‡ç´¢å¼•"""
        if not self._enabled:
            return
        
        import faiss
        
        # é‡ç½®ç´¢å¼•
        self._index = faiss.IndexFlatIP(self.dimension)
        self.turn_mapping = []
        self._save()
    
    def remove_by_doc_ids(self, doc_ids_to_remove: List[str]) -> int:
        """ç§»é™¤æŒ‡å®šæ–‡æ¡£IDçš„å‘é‡
        
        ç”±äº FAISS IndexFlatIP ä¸æ”¯æŒç›´æ¥åˆ é™¤ï¼Œè¿™é‡Œé€šè¿‡é‡å»ºç´¢å¼•å®ç°ã€‚
        
        Args:
            doc_ids_to_remove: è¦ç§»é™¤çš„æ–‡æ¡£IDåˆ—è¡¨
        
        Returns:
            int: ç§»é™¤çš„å‘é‡æ•°é‡
        """
        if not self._enabled or self._index is None:
            return 0
        
        if not doc_ids_to_remove:
            return 0
        
        import faiss
        
        remove_set = set(doc_ids_to_remove)
        removed_count = 0
        
        # æ‰¾å‡ºéœ€è¦ä¿ç•™çš„ç´¢å¼•
        keep_indices = []
        new_mapping = []
        for idx, doc_id in enumerate(self.turn_mapping):
            if doc_id in remove_set:
                removed_count += 1
            else:
                keep_indices.append(idx)
                new_mapping.append(doc_id)
        
        if removed_count == 0:
            return 0
        
        # å¦‚æœå…¨éƒ¨è¢«åˆ é™¤
        if not keep_indices:
            self._index = faiss.IndexFlatIP(self.dimension)
            self.turn_mapping = []
            self._save()
            return removed_count
        
        # é‡å»ºç´¢å¼•ï¼ˆåªä¿ç•™éœ€è¦çš„å‘é‡ï¼‰
        try:
            # ä»åŸç´¢å¼•é‡å»ºæ‰€æœ‰éœ€ä¿ç•™çš„å‘é‡
            new_vectors = []
            for idx in keep_indices:
                vec = self._index.reconstruct(idx)
                new_vectors.append(vec)
            
            # åˆ›å»ºæ–°ç´¢å¼•
            new_index = faiss.IndexFlatIP(self.dimension)
            if new_vectors:
                vectors_array = np.array(new_vectors, dtype=np.float32)
                new_index.add(vectors_array)
            
            self._index = new_index
            self.turn_mapping = new_mapping
            self._save()
            
            return removed_count
        except Exception as e:
            _safe_print(f"[VectorIndex] é‡å»ºç´¢å¼•å¤±è´¥: {e}")
            return 0
    
    def encode(self, text: str) -> np.ndarray:
        """æ–‡æœ¬è½¬å‘é‡"""
        if not self._enabled:
            raise RuntimeError("å‘é‡ç´¢å¼•æœªå¯ç”¨")
        return self.embedding_backend.encode_with_cache(text)
    
    def add(self, doc_id: Any, embedding: np.ndarray):
        """æ·»åŠ å‘é‡"""
        if not self._enabled:
            return
        
        if embedding.ndim == 1:
            embedding = embedding.reshape(1, -1)
        
        # æ£€æŸ¥ç»´åº¦æ˜¯å¦åŒ¹é…ï¼Œä¸åŒ¹é…åˆ™é‡å»ºç´¢å¼•
        embedding_dim = embedding.shape[1]
        if self.index.d != embedding_dim:
            import faiss
            _safe_print(f"[VectorIndex] è¿è¡Œæ—¶ç»´åº¦ä¸åŒ¹é…: ç´¢å¼•ç»´åº¦={self.index.d}, å‘é‡ç»´åº¦={embedding_dim}")
            _safe_print(f"[VectorIndex] æ­£åœ¨é‡å»ºç´¢å¼•...")
            self._index = faiss.IndexFlatIP(embedding_dim)
            self.turn_mapping = []
            self._save_config()
        
        self.index.add(embedding)
        self.turn_mapping.append(doc_id)
        
        # æ¯ 100 æ¬¡æ·»åŠ ä¿å­˜ä¸€æ¬¡
        if len(self.turn_mapping) % 100 == 0:
            self._save()
    
    def add_text(self, doc_id: Any, text: str):
        """ç›´æ¥æ·»åŠ æ–‡æœ¬"""
        if not self._enabled:
            return
        embedding = self.encode(text)
        self.add(doc_id, embedding)
    
    def search(self, query: str, top_k: int = 20) -> List[Tuple[Any, float]]:
        """æœç´¢æœ€ç›¸ä¼¼çš„æ–‡æ¡£"""
        if not self._enabled:
            return []
        
        if self.index.ntotal == 0:
            return []
        
        query_embedding = self.encode(query).reshape(1, -1)
        
        # æ£€æŸ¥ç»´åº¦æ˜¯å¦åŒ¹é…
        if query_embedding.shape[1] != self.index.d:
            _safe_print(f"[VectorIndex] æœç´¢æ—¶ç»´åº¦ä¸åŒ¹é…: ç´¢å¼•ç»´åº¦={self.index.d}, æŸ¥è¯¢ç»´åº¦={query_embedding.shape[1]}")
            _safe_print(f"[VectorIndex] å‘é‡ç´¢å¼•éœ€è¦é‡å»ºï¼Œæš‚æ—¶è¿”å›ç©ºç»“æœ")
            return []
        
        distances, indices = self.index.search(
            query_embedding, 
            min(top_k, self.index.ntotal)
        )
        
        results = []
        for dist, idx in zip(distances[0], indices[0]):
            if idx >= 0 and idx < len(self.turn_mapping):
                doc_id = self.turn_mapping[idx]
                results.append((doc_id, float(dist)))
        
        return results
    
    def search_by_embedding(self, embedding: np.ndarray, top_k: int = 20) -> List[Tuple[Any, float]]:
        """é€šè¿‡å‘é‡æœç´¢"""
        if not self._enabled:
            return []
        
        if self.index.ntotal == 0:
            return []
        
        if embedding.ndim == 1:
            embedding = embedding.reshape(1, -1)
        
        distances, indices = self.index.search(
            embedding, 
            min(top_k, self.index.ntotal)
        )
        
        results = []
        for dist, idx in zip(distances[0], indices[0]):
            if idx >= 0 and idx < len(self.turn_mapping):
                doc_id = self.turn_mapping[idx]
                results.append((doc_id, float(dist)))
        
        return results
    
    def get_vector_by_doc_id(self, doc_id: Any) -> Optional[np.ndarray]:
        """é€šè¿‡æ–‡æ¡£IDè·å–å·²å­˜å‚¨çš„å‘é‡
        
        ç”¨äº L6 ç²¾æ’ç­‰åœºæ™¯ï¼Œé¿å…é‡å¤è°ƒç”¨ encode() API
        
        Args:
            doc_id: æ–‡æ¡£ID
            
        Returns:
            å­˜å‚¨çš„å‘é‡ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
        """
        if not self._enabled or self._index is None:
            return None
        
        try:
            # æŸ¥æ‰¾ doc_id åœ¨ turn_mapping ä¸­çš„ç´¢å¼•ä½ç½®
            if doc_id in self.turn_mapping:
                idx = self.turn_mapping.index(doc_id)
                # ä½¿ç”¨ FAISS çš„ reconstruct æ–¹æ³•è·å–å·²å­˜å‚¨çš„å‘é‡
                return self.index.reconstruct(idx)
        except Exception:
            pass
        return None
    
    def get_vectors_by_doc_ids(self, doc_ids: List[Any]) -> Dict[Any, np.ndarray]:
        """æ‰¹é‡è·å–å·²å­˜å‚¨çš„å‘é‡
        
        Args:
            doc_ids: æ–‡æ¡£IDåˆ—è¡¨
            
        Returns:
            æ–‡æ¡£IDåˆ°å‘é‡çš„æ˜ å°„
        """
        if not self._enabled or self._index is None:
            return {}
        
        result = {}
        # æ„å»º doc_id -> index çš„æ˜ å°„ï¼ˆé¿å…é‡å¤æŸ¥æ‰¾ï¼‰
        doc_id_to_idx = {}
        for idx, did in enumerate(self.turn_mapping):
            if did in doc_ids:
                doc_id_to_idx[did] = idx
        
        # æ‰¹é‡è·å–å‘é‡
        for doc_id in doc_ids:
            if doc_id in doc_id_to_idx:
                try:
                    idx = doc_id_to_idx[doc_id]
                    result[doc_id] = self.index.reconstruct(idx)
                except Exception:
                    pass
        
        return result
    
    def close(self):
        """å…³é—­å¹¶ä¿å­˜"""
        self._save()
        if self._embedding_backend:
            self._embedding_backend.clear_cache()
    
    def rebuild_from_memories(self, memories: List[Tuple[str, str]]) -> int:
        """ä»è®°å¿†æ•°æ®é‡å»ºå‘é‡ç´¢å¼•
        
        Args:
            memories: [(memory_id, content), ...] è®°å¿†åˆ—è¡¨
            
        Returns:
            æˆåŠŸç´¢å¼•çš„è®°å¿†æ•°é‡
        """
        if not self._enabled:
            _safe_print("[VectorIndex] å‘é‡ç´¢å¼•æœªå¯ç”¨ï¼Œè·³è¿‡é‡å»º")
            return 0
        
        import faiss
        
        # æ¸…ç©ºç°æœ‰ç´¢å¼•
        self._index = faiss.IndexFlatIP(self.dimension)
        self.turn_mapping = []
        
        _safe_print(f"[VectorIndex] å¼€å§‹é‡å»ºå‘é‡ç´¢å¼•ï¼Œå…± {len(memories)} æ¡è®°å¿†...")
        
        success_count = 0
        for i, (memory_id, content) in enumerate(memories):
            try:
                embedding = self.encode(content)
                if embedding.ndim == 1:
                    embedding = embedding.reshape(1, -1)
                self._index.add(embedding)
                self.turn_mapping.append(memory_id)
                success_count += 1
                
                # æ¯ 50 æ¡æ‰“å°è¿›åº¦
                if (i + 1) % 50 == 0:
                    _safe_print(f"[VectorIndex] é‡å»ºè¿›åº¦: {i + 1}/{len(memories)}")
            except Exception as e:
                _safe_print(f"[VectorIndex] è®°å¿† {memory_id} ç´¢å¼•å¤±è´¥: {e}")
        
        # ä¿å­˜
        self._save()
        self._save_config()
        
        _safe_print(f"[VectorIndex] é‡å»ºå®Œæˆ: æˆåŠŸ {success_count}/{len(memories)}")
        return success_count
    
    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'enabled': self._enabled,
            'backend': self.embedding_config.backend.value if self.embedding_config else 'unknown',
            'dimension': self.dimension if self._enabled else 0,
            'total_vectors': self.index.ntotal if self._enabled and self._index else 0,
            'model': (
                self.embedding_config.local_model 
                if self.embedding_config.backend == EmbeddingBackendType.LOCAL 
                else self.embedding_config.api_model
            ) if self.embedding_config else 'unknown'
        }

"""ç»Ÿä¸€ LLM åˆ†æå™¨ - Recall 4.1 æ€§èƒ½ä¼˜åŒ–

è®¾è®¡ç†å¿µï¼š
å°†å¤šä¸ª LLM è°ƒç”¨ï¼ˆçŸ›ç›¾æ£€æµ‹ + å…³ç³»æå–ï¼‰åˆå¹¶ä¸ºå•æ¬¡è°ƒç”¨ï¼Œæ˜¾è‘—å‡å°‘ API å¾€è¿”æ—¶é—´ã€‚

ä¼˜åŒ–æ•ˆæœï¼š
- åŸæ¥ï¼šçŸ›ç›¾æ£€æµ‹ 5-10s + å…³ç³»æå– 5-10s = 10-20s
- ç°åœ¨ï¼šç»Ÿä¸€åˆ†æ 8-15sï¼ŒèŠ‚çœ 30-50% æ—¶é—´

å‘åå…¼å®¹ï¼š
- å¯é€šè¿‡ç¯å¢ƒå˜é‡ UNIFIED_LLM_ANALYSIS_ENABLED æ§åˆ¶å¼€å…³
- å…³é—­æ—¶è‡ªåŠ¨å›é€€åˆ°åŸæœ‰çš„åˆ†å¼€è°ƒç”¨æ–¹å¼
"""

from __future__ import annotations

import os
import json
import re
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime

from ..utils.llm_client import LLMClient
from ..models.temporal import TemporalFact, Contradiction, ContradictionType


# Windows GBK ç¼–ç å…¼å®¹çš„å®‰å…¨æ‰“å°å‡½æ•°
def _safe_print(msg: str) -> None:
    """å®‰å…¨æ‰“å°å‡½æ•°"""
    emoji_map = {
        'ğŸ“¥': '[IN]', 'ğŸ“¤': '[OUT]', 'ğŸ”': '[SEARCH]', 'âœ…': '[OK]', 'âŒ': '[FAIL]',
        'âš ï¸': '[WARN]', 'ğŸ’¾': '[SAVE]', 'ğŸ—ƒï¸': '[DB]', 'ğŸ§¹': '[CLEAN]', 'ğŸ“Š': '[STATS]',
        'ğŸ”„': '[SYNC]', 'ğŸš€': '[START]', 'ğŸ¯': '[TARGET]', 'ğŸ’¡': '[HINT]',
        'âš¡': '[FAST]', 'ğŸ”¥': '[HOT]', 'ğŸ’': '[GEM]', 'ğŸŒŸ': '[STAR]'
    }
    for emoji, ascii_equiv in emoji_map.items():
        msg = msg.replace(emoji, ascii_equiv)
    try:
        print(msg)
    except UnicodeEncodeError:
        print(msg.encode('ascii', errors='replace').decode('ascii'))


@dataclass
class ExtractedRelation:
    """æå–çš„å…³ç³»"""
    source_id: str
    target_id: str
    relation_type: str
    fact: str
    confidence: float = 0.8
    valid_at: Optional[str] = None
    invalid_at: Optional[str] = None
    source_text: str = ""
    
    def to_legacy_tuple(self) -> Tuple[str, str, str, str]:
        """è½¬æ¢ä¸ºæ—§æ ¼å¼å…ƒç»„"""
        return (self.source_id, self.relation_type, self.target_id, self.source_text)


@dataclass
class DetectedContradiction:
    """æ£€æµ‹åˆ°çš„çŸ›ç›¾"""
    old_fact_text: str
    new_fact_text: str
    contradiction_type: str  # DIRECT, TEMPORAL, LOGICAL
    confidence: float
    reason: str = ""


@dataclass
class UnifiedAnalysisResult:
    """ç»Ÿä¸€åˆ†æç»“æœ"""
    relations: List[ExtractedRelation] = field(default_factory=list)
    contradictions: List[DetectedContradiction] = field(default_factory=list)
    success: bool = True
    error: Optional[str] = None
    tokens_used: int = 0


# ç»Ÿä¸€åˆ†ææç¤ºè¯æ¨¡æ¿
UNIFIED_ANALYSIS_PROMPT = '''ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬åˆ†æä¸“å®¶ã€‚è¯·åŒæ—¶å®Œæˆä»¥ä¸‹ä¸¤ä¸ªä»»åŠ¡ï¼š

## ä»»åŠ¡1ï¼šå…³ç³»æå–
ä»æ–°å†…å®¹ä¸­æå–å®ä½“ä¹‹é—´çš„å…³ç³»ã€‚

## ä»»åŠ¡2ï¼šçŸ›ç›¾æ£€æµ‹
æ£€æŸ¥æ–°å†…å®¹ä¸å·²æœ‰è®°å¿†æ˜¯å¦å­˜åœ¨çŸ›ç›¾ã€‚

---

## å·²è¯†åˆ«çš„å®ä½“åˆ—è¡¨ï¼š
{entities}

## æ–°å†…å®¹ï¼š
{new_content}

## å·²æœ‰è®°å¿†ï¼ˆç”¨äºçŸ›ç›¾æ£€æµ‹ï¼‰ï¼š
{existing_memories}

---

## è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»æ˜¯æœ‰æ•ˆçš„ JSONï¼‰ï¼š

```json
{{
  "relations": [
    {{
      "source_id": "å®ä½“A",
      "target_id": "å®ä½“B",
      "relation_type": "RELATION_TYPE",
      "fact": "å…³ç³»æè¿°",
      "confidence": 0.8
    }}
  ],
  "contradictions": [
    {{
      "old_fact_text": "å·²æœ‰è®°å¿†ä¸­çš„é™ˆè¿°",
      "new_fact_text": "æ–°å†…å®¹ä¸­çš„çŸ›ç›¾é™ˆè¿°",
      "contradiction_type": "DIRECT|TEMPORAL|LOGICAL",
      "confidence": 0.9,
      "reason": "çŸ›ç›¾åŸå› è¯´æ˜"
    }}
  ]
}}
```

## æå–è§„åˆ™ï¼š
1. å…³ç³»ç±»å‹ä½¿ç”¨ SCREAMING_SNAKE_CASE æ ¼å¼ï¼ˆå¦‚ WORKS_AT, FRIENDS_WITHï¼‰
2. åªæå–å®ä½“åˆ—è¡¨ä¸­å­˜åœ¨çš„å®ä½“ä¹‹é—´çš„å…³ç³»
3. çŸ›ç›¾ç±»å‹ï¼šDIRECTï¼ˆç›´æ¥å†²çªï¼‰ã€TEMPORALï¼ˆæ—¶é—´çŸ›ç›¾ï¼‰ã€LOGICALï¼ˆé€»è¾‘çŸ›ç›¾ï¼‰
4. å¦‚æœæ²¡æœ‰å…³ç³»æˆ–çŸ›ç›¾ï¼Œå¯¹åº”æ•°ç»„ä¸ºç©º []

è¯·åªè¾“å‡º JSONï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚'''


class UnifiedLLMAnalyzer:
    """ç»Ÿä¸€ LLM åˆ†æå™¨
    
    å°†çŸ›ç›¾æ£€æµ‹å’Œå…³ç³»æå–åˆå¹¶ä¸ºå•æ¬¡ LLM è°ƒç”¨ã€‚
    
    ä½¿ç”¨æ–¹å¼ï¼š
        analyzer = UnifiedLLMAnalyzer(llm_client=llm_client)
        result = analyzer.analyze(
            new_content="ç”¨æˆ·å–œæ¬¢å’–å•¡",
            entities=[Entity(name="ç”¨æˆ·"), Entity(name="å’–å•¡")],
            existing_memories=["ç”¨æˆ·è®¨åŒå’–å•¡"]
        )
        print(result.relations)
        print(result.contradictions)
    """
    
    def __init__(
        self,
        llm_client: Optional[LLMClient] = None,
        budget_manager: Any = None
    ):
        self.llm_client = llm_client
        self.budget_manager = budget_manager
        
        # ä»ç¯å¢ƒå˜é‡è¯»å–æœ€å¤§ tokens
        self.max_tokens = int(os.environ.get('UNIFIED_LLM_MAX_TOKENS', '2000'))
    
    def is_enabled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨ç»Ÿä¸€åˆ†æ"""
        enabled = os.environ.get('UNIFIED_LLM_ANALYSIS_ENABLED', 'true').lower() == 'true'
        return enabled and self.llm_client is not None
    
    def analyze(
        self,
        new_content: str,
        entities: List[Any],
        existing_memories: List[str]
    ) -> UnifiedAnalysisResult:
        """æ‰§è¡Œç»Ÿä¸€åˆ†æ
        
        Args:
            new_content: æ–°è®°å¿†å†…å®¹
            entities: å·²æå–çš„å®ä½“åˆ—è¡¨
            existing_memories: ç°æœ‰ç›¸å…³è®°å¿†å†…å®¹åˆ—è¡¨ï¼ˆç”¨äºçŸ›ç›¾æ£€æµ‹ï¼‰
        
        Returns:
            UnifiedAnalysisResult: åŒ…å«å…³ç³»å’ŒçŸ›ç›¾çš„åˆ†æç»“æœ
        """
        if not self.llm_client:
            return UnifiedAnalysisResult(
                success=False,
                error="LLM client not available"
            )
        
        # æ„å»ºå®ä½“åˆ—è¡¨å­—ç¬¦ä¸²
        entity_names = []
        for e in entities:
            if hasattr(e, 'name'):
                entity_names.append(e.name)
            elif isinstance(e, str):
                entity_names.append(e)
            elif isinstance(e, dict):
                entity_names.append(e.get('name', str(e)))
        
        entities_str = "\n".join(f"- {name}" for name in entity_names) if entity_names else "ï¼ˆæ— å®ä½“ï¼‰"
        
        # æ„å»ºç°æœ‰è®°å¿†å­—ç¬¦ä¸²
        memories_str = "\n".join(f"- {mem[:200]}" for mem in existing_memories[:5]) if existing_memories else "ï¼ˆæ— ç›¸å…³è®°å¿†ï¼‰"
        
        # æ„å»ºæç¤ºè¯
        prompt = UNIFIED_ANALYSIS_PROMPT.format(
            entities=entities_str,
            new_content=new_content[:1000],  # é™åˆ¶é•¿åº¦
            existing_memories=memories_str
        )
        
        try:
            # è°ƒç”¨ LLM
            _safe_print(f"[UnifiedLLM] æ‰§è¡Œç»Ÿä¸€åˆ†æ: å®ä½“æ•°={len(entity_names)}, è®°å¿†æ•°={len(existing_memories)}")
            
            response = self.llm_client.complete(
                prompt=prompt,
                max_tokens=self.max_tokens,
                temperature=0.1
            )
            
            # è§£æå“åº”
            result = self._parse_response(response, new_content)
            
            _safe_print(f"[UnifiedLLM] åˆ†æå®Œæˆ: å…³ç³»æ•°={len(result.relations)}, çŸ›ç›¾æ•°={len(result.contradictions)}")
            
            return result
            
        except Exception as e:
            _safe_print(f"[UnifiedLLM] åˆ†æå¤±è´¥: {e}")
            return UnifiedAnalysisResult(
                success=False,
                error=str(e)
            )
    
    def _parse_response(self, response: str, source_text: str) -> UnifiedAnalysisResult:
        """è§£æ LLM å“åº”"""
        result = UnifiedAnalysisResult()
        
        try:
            # æå– JSON å†…å®¹
            json_match = re.search(r'\{[\s\S]*\}', response)
            if not json_match:
                _safe_print("[UnifiedLLM] æœªæ‰¾åˆ° JSON å†…å®¹")
                return result
            
            data = json.loads(json_match.group())
            
            # è§£æå…³ç³»
            for rel in data.get('relations', []):
                try:
                    result.relations.append(ExtractedRelation(
                        source_id=rel.get('source_id', ''),
                        target_id=rel.get('target_id', ''),
                        relation_type=rel.get('relation_type', 'RELATED_TO'),
                        fact=rel.get('fact', ''),
                        confidence=float(rel.get('confidence', 0.8)),
                        valid_at=rel.get('valid_at'),
                        invalid_at=rel.get('invalid_at'),
                        source_text=source_text[:200]
                    ))
                except Exception as e:
                    _safe_print(f"[UnifiedLLM] è§£æå…³ç³»å¤±è´¥: {e}")
            
            # è§£æçŸ›ç›¾
            for con in data.get('contradictions', []):
                try:
                    result.contradictions.append(DetectedContradiction(
                        old_fact_text=con.get('old_fact_text', ''),
                        new_fact_text=con.get('new_fact_text', ''),
                        contradiction_type=con.get('contradiction_type', 'DIRECT'),
                        confidence=float(con.get('confidence', 0.8)),
                        reason=con.get('reason', '')
                    ))
                except Exception as e:
                    _safe_print(f"[UnifiedLLM] è§£æçŸ›ç›¾å¤±è´¥: {e}")
            
            result.success = True
            
        except json.JSONDecodeError as e:
            _safe_print(f"[UnifiedLLM] JSON è§£æå¤±è´¥: {e}")
            result.error = f"JSON parse error: {e}"
        
        return result
    
    def convert_to_legacy_format(
        self,
        result: UnifiedAnalysisResult,
        user_id: str = "default"
    ) -> Tuple[List[Tuple], List[Contradiction]]:
        """å°†ç»“æœè½¬æ¢ä¸ºå…¼å®¹æ—§ä»£ç çš„æ ¼å¼
        
        Returns:
            Tuple[List[å…³ç³»å…ƒç»„], List[Contradictionå¯¹è±¡]]
        """
        import uuid as uuid_module
        
        # è½¬æ¢å…³ç³»
        legacy_relations = [rel.to_legacy_tuple() for rel in result.relations]
        
        # è½¬æ¢çŸ›ç›¾
        legacy_contradictions = []
        for con in result.contradictions:
            try:
                old_fact = TemporalFact(
                    uuid=str(uuid_module.uuid4()),
                    fact=con.old_fact_text[:200],
                    source_text=con.old_fact_text[:200],
                    user_id=user_id
                )
                new_fact = TemporalFact(
                    uuid=str(uuid_module.uuid4()),
                    fact=con.new_fact_text[:200],
                    source_text=con.new_fact_text[:200],
                    user_id=user_id
                )
                
                # æ˜ å°„çŸ›ç›¾ç±»å‹
                type_map = {
                    'DIRECT': ContradictionType.DIRECT,
                    'TEMPORAL': ContradictionType.TEMPORAL,
                    'LOGICAL': ContradictionType.LOGICAL,
                }
                c_type = type_map.get(con.contradiction_type, ContradictionType.DIRECT)
                
                legacy_contradictions.append(Contradiction(
                    uuid=str(uuid_module.uuid4()),
                    old_fact=old_fact,
                    new_fact=new_fact,
                    contradiction_type=c_type,
                    confidence=con.confidence,
                    detected_at=datetime.now(),
                    notes=con.reason[:200] if con.reason else ""
                ))
            except Exception as e:
                _safe_print(f"[UnifiedLLM] è½¬æ¢çŸ›ç›¾å¤±è´¥: {e}")
        
        return legacy_relations, legacy_contradictions

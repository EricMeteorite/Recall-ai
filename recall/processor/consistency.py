"""ä¸€è‡´æ€§æ£€æŸ¥å™¨ - æ£€æµ‹è®°å¿†ä¸­çš„çŸ›ç›¾ï¼ˆå¢å¼ºç‰ˆ v3.1ï¼‰

å¢å¼ºåŠŸèƒ½ï¼š
- 15+ ç§å±æ€§ç±»å‹æ£€æµ‹ï¼ˆæ•°å€¼ã€å¤–è²Œã€çŠ¶æ€ã€å…³ç³»ç­‰ï¼‰
- å®Œæ•´æ—¶é—´çº¿æ¨ç†ï¼ˆäº‹ä»¶é“¾ã€å¹´é¾„ä¸€è‡´æ€§ã€ç”Ÿæ­»çŸ›ç›¾ï¼‰
- å¦å®šå¥æ£€æµ‹å’ŒçŸ›ç›¾å…³ç³»è¯†åˆ«
- æ¨¡ç³ŠåŒ¹é…ï¼ˆè¯­ä¹‰è¿‘ä¼¼è¯æ±‡åˆå¹¶ï¼‰
"""

import re
import time
from typing import List, Dict, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from enum import Enum

# Windows GBK ç¼–ç å…¼å®¹çš„å®‰å…¨æ‰“å°å‡½æ•°
def _safe_print(msg: str) -> None:
    """å®‰å…¨æ‰“å°å‡½æ•°ï¼Œæ›¿æ¢ emoji ä¸º ASCII ç­‰ä»·ç‰©ä»¥é¿å… Windows GBK ç¼–ç é”™è¯¯"""
    emoji_map = {
        'ğŸ“¥': '[IN]', 'ğŸ“¤': '[OUT]', 'ğŸ”': '[SEARCH]', 'âœ…': '[OK]', 'âŒ': '[FAIL]',
        'âš ï¸': '[WARN]', 'ğŸ’¾': '[SAVE]', 'ğŸ—ƒï¸': '[DB]', 'ğŸ§¹': '[CLEAN]', 'ğŸ“Š': '[STATS]',
        'ğŸ”„': '[SYNC]', 'ğŸ“¦': '[PKG]', 'ğŸš€': '[START]', 'ğŸ¯': '[TARGET]', 'ğŸ’¡': '[HINT]',
        'ğŸ”§': '[FIX]', 'ğŸ“': '[NOTE]', 'ğŸ‰': '[DONE]', 'â±ï¸': '[TIME]', 'ğŸŒ': '[NET]',
        'ğŸ§ ': '[BRAIN]', 'ğŸ’¬': '[CHAT]', 'ğŸ·ï¸': '[TAG]', 'ğŸ“': '[DIR]', 'ğŸ”’': '[LOCK]',
        'ğŸŒ±': '[PLANT]', 'ğŸ—‘ï¸': '[DEL]', 'ğŸ’«': '[MAGIC]', 'ğŸ­': '[MASK]', 'ğŸ“–': '[BOOK]',
        'âš¡': '[FAST]', 'ğŸ”¥': '[HOT]', 'ğŸ’': '[GEM]', 'ğŸŒŸ': '[STAR]', 'ğŸ¨': '[ART]'
    }
    for emoji, ascii_equiv in emoji_map.items():
        msg = msg.replace(emoji, ascii_equiv)
    try:
        print(msg)
    except UnicodeEncodeError:
        print(msg.encode('ascii', errors='replace').decode('ascii'))




class ViolationType(Enum):
    """è¿è§„ç±»å‹"""
    FACT_CONFLICT = "fact_conflict"           # äº‹å®å†²çª
    TIMELINE_CONFLICT = "timeline_conflict"   # æ—¶é—´çº¿å†²çª
    CHARACTER_CONFLICT = "character_conflict" # è§’è‰²è®¾å®šå†²çª
    LOCATION_CONFLICT = "location_conflict"   # åœ°ç‚¹å†²çª
    LOGIC_ERROR = "logic_error"               # é€»è¾‘é”™è¯¯
    RELATIONSHIP_CONFLICT = "relationship_conflict"  # å…³ç³»å†²çª
    STATE_CONFLICT = "state_conflict"         # çŠ¶æ€å†²çªï¼ˆæ´»/æ­»ã€å•èº«/å·²å©šï¼‰
    AGE_INCONSISTENCY = "age_inconsistency"   # å¹´é¾„æ—¶é—´çº¿ä¸ä¸€è‡´


class AttributeType(Enum):
    """å±æ€§ç±»å‹"""
    # æ•°å€¼å±æ€§
    AGE = "age"
    HEIGHT = "height"
    WEIGHT = "weight"
    # å¤–è²Œå±æ€§
    HAIR_COLOR = "hair_color"
    EYE_COLOR = "eye_color"
    SKIN_COLOR = "skin_color"
    # å›ºå®šå±æ€§
    BLOOD_TYPE = "blood_type"
    GENDER = "gender"
    SPECIES = "species"
    # çŠ¶æ€å±æ€§
    VITAL_STATUS = "vital_status"  # æ´»ç€/æ­»äº¡
    MARITAL_STATUS = "marital_status"  # å©šå§»çŠ¶æ€
    OCCUPATION = "occupation"  # èŒä¸š
    LOCATION = "location"  # å½“å‰ä½ç½®
    # èƒ½åŠ›å±æ€§
    ABILITY = "ability"  # èƒ½åŠ›/æŠ€èƒ½
    INABILITY = "inability"  # ä¸èƒ½åšçš„äº‹


@dataclass
class Violation:
    """è¿è§„/å†²çªè®°å½•"""
    type: ViolationType
    description: str
    evidence: List[str]
    severity: float  # 0-1
    suggested_resolution: Optional[str] = None
    created_at: float = field(default_factory=time.time)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'type': self.type.value,
            'description': self.description,
            'evidence': self.evidence,
            'severity': self.severity,
            'suggested_resolution': self.suggested_resolution,
            'created_at': self.created_at
        }


@dataclass
class ConsistencyResult:
    """ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ"""
    is_consistent: bool
    violations: List[Violation] = field(default_factory=list)
    confidence: float = 1.0
    checked_at: float = field(default_factory=time.time)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'is_consistent': self.is_consistent,
            'violations': [v.to_dict() for v in self.violations],
            'confidence': self.confidence,
            'checked_at': self.checked_at
        }


@dataclass
class TimelineEvent:
    """æ—¶é—´çº¿äº‹ä»¶"""
    entity: str
    event_type: str  # birth, death, action, state_change
    description: str
    timestamp: Optional[float] = None  # ç»å¯¹æ—¶é—´æˆ³
    relative_time: Optional[str] = None  # "ä¸‰å¹´å‰", "ä¹‹å"
    source: str = ""
    turn_id: int = 0


class ConsistencyChecker:
    """ä¸€è‡´æ€§æ£€æŸ¥å™¨ï¼ˆå¢å¼ºç‰ˆï¼‰
    
    æ”¯æŒçš„æ£€æµ‹èƒ½åŠ›ï¼š
    1. æ•°å€¼å±æ€§å†²çªï¼ˆå¹´é¾„/èº«é«˜/ä½“é‡ç­‰ï¼‰
    2. å¤–è²Œå±æ€§å†²çªï¼ˆå‘è‰²/çœ¼è‰²/è‚¤è‰²ç­‰ï¼‰
    3. çŠ¶æ€å±æ€§å†²çªï¼ˆç”Ÿæ­»/å©šå§»/èŒä¸šç­‰ï¼‰
    4. å…³ç³»å†²çªï¼ˆæœ‹å‹vsæ•Œäººã€äº²äººvsé™Œç”Ÿäººï¼‰
    5. æ—¶é—´çº¿æ¨ç†ï¼ˆäº‹ä»¶é¡ºåºã€å¹´é¾„ä¸€è‡´æ€§ã€ç”Ÿæ­»çŸ›ç›¾ï¼‰
    6. å¦å®šå¥æ£€æµ‹ï¼ˆä¸ä¼šX vs åšäº†Xï¼‰
    """
    
    # ========== é¢œè‰²åŒä¹‰è¯æ˜ å°„ ==========
    COLOR_SYNONYMS = {
        'black': {'é»‘è‰²', 'é»‘', 'ä¹Œé»‘', 'æ¼†é»‘', 'å¢¨é»‘', 'é»¢é»‘', 'é»‘äº®'},
        'white': {'ç™½è‰²', 'ç™½', 'é›ªç™½', 'é“¶ç™½', 'çº¯ç™½', 'æ´ç™½', 'è‹ç™½'},
        'brown': {'æ£•è‰²', 'æ£•', 'è¤è‰²', 'è¤', 'èŒ¶è‰²', 'æ —è‰²', 'å’–å•¡è‰²'},
        'red': {'çº¢è‰²', 'çº¢', 'èµ¤çº¢', 'ç»¯çº¢', 'çŒ©çº¢', 'é…’çº¢', 'æš—çº¢'},
        'blonde': {'é‡‘è‰²', 'é‡‘', 'é‡‘é»„', 'æ·¡é‡‘', 'äºšéº»è‰²', 'èœ‚èœœè‰²'},
        'blue': {'è“è‰²', 'è“', 'æ¹›è“', 'æ·±è“', 'ç¢§è“', 'å¤©è“', 'å®è“'},
        'green': {'ç»¿è‰²', 'ç»¿', 'ç¿ ç»¿', 'ç¢§ç»¿', 'å¢¨ç»¿', 'è‰ç»¿'},
        'purple': {'ç´«è‰²', 'ç´«', 'ç´«ç½—å…°', 'æ·¡ç´«', 'æ·±ç´«', 'è‘¡è„ç´«'},
        'pink': {'ç²‰è‰²', 'ç²‰', 'ç²‰çº¢', 'æ¡ƒçº¢', 'æ·¡ç²‰'},
        'gray': {'ç°è‰²', 'ç°', 'é“¶ç°', 'é“ç°', 'çƒŸç°'},
        'orange': {'æ©™è‰²', 'æ©™', 'æ©˜è‰²', 'æ©˜çº¢'},
    }
    
    # ========== å…³ç³»å¯¹ç«‹è¯å…¸ ==========
    RELATIONSHIP_OPPOSITES = {
        'æœ‹å‹': ['æ•Œäºº', 'ä»‡äºº', 'å¯¹æ‰‹', 'æ­»æ•Œ'],
        'æ•Œäºº': ['æœ‹å‹', 'ç›Ÿå‹', 'åŒä¼´', 'æŒšå‹', 'å¥½å‹'],
        'æ‹äºº': ['ä»‡äºº', 'æ•Œäºº', 'é™Œç”Ÿäºº', 'å‰ä»»'],
        'å¤«å¦»': ['é™Œç”Ÿäºº', 'å‰å¤«', 'å‰å¦»', 'ç¦»å©š'],
        'äº²äºº': ['é™Œç”Ÿäºº', 'å¤–äºº'],
        'ä¸»äºº': ['ä»†äºº', 'å¥´éš¶'],  # å¦‚æœAæ˜¯Bçš„ä¸»äººï¼Œåˆ™Bä¸æ˜¯Açš„ä¸»äºº
        'åŒç›Ÿ': ['æ•Œå¯¹', 'å¯¹ç«‹', 'æ•Œæ–¹'],
        'ä¿¡ä»»': ['èƒŒå›', 'æ¬ºéª—', 'ä¸ä¿¡ä»»'],
    }
    
    # ========== çŠ¶æ€å¯¹ç«‹è¯å…¸ ==========
    STATE_OPPOSITES = {
        # ç”Ÿæ­»çŠ¶æ€ (ä½¿ç”¨æ ‡å‡†åŒ–å€¼)
        'alive': ['dead'],
        'dead': ['alive'],
        # å©šå§»çŠ¶æ€
        'single': ['married', 'engaged'],
        'married': ['single', 'divorced', 'widowed'],
        # å¥åº·çŠ¶æ€
        'healthy': ['sick', 'injured', 'disabled'],
        'injured': ['healed', 'recovered'],
        # æ„è¯†çŠ¶æ€
        'awake': ['unconscious', 'asleep'],
        'unconscious': ['awake'],
    }
    
    # ä¸­æ–‡çŠ¶æ€æ˜ å°„åˆ°æ ‡å‡†åŒ–å€¼
    STATE_NORMALIZATION = {
        # ç”Ÿæ­»
        'æ´»ç€': 'alive', 'ç”Ÿè¿˜': 'alive', 'å¤æ´»': 'alive', 'é‡ç”Ÿ': 'alive', 'è‹é†’': 'alive',
        'æ­»äº¡': 'dead', 'æ­»äº†': 'dead', 'å»ä¸–': 'dead', 'èº«äº¡': 'dead', 
        'é‡éš¾': 'dead', 'ç‰ºç‰²': 'dead', 'é˜µäº¡': 'dead',
        # å©šå§»
        'å•èº«': 'single', 'æœªå©š': 'single',
        'å·²å©š': 'married', 'ç»“å©š': 'married', 'è®¢å©š': 'engaged',
        'ç¦»å©š': 'divorced', 'ä¸§å¶': 'widowed',
        # å¥åº·
        'å¥åº·': 'healthy', 'ç”Ÿç—…': 'sick', 'å—ä¼¤': 'injured', 'æ®‹ç–¾': 'disabled',
        'ç—Šæ„ˆ': 'healed', 'åº·å¤': 'recovered',
        # æ„è¯†
        'æ¸…é†’': 'awake', 'æ˜è¿·': 'unconscious', 'æ™•å€’': 'unconscious', 
        'ç¡ç€': 'asleep', 'é†’æ¥': 'awake',
    }
    
    def __init__(self, absolute_rules: Optional[List[str]] = None, llm_client = None):
        """åˆå§‹åŒ–ä¸€è‡´æ€§æ£€æŸ¥å™¨
        
        Args:
            absolute_rules: ç»å¯¹è§„åˆ™åˆ—è¡¨ï¼Œç”¨æˆ·å®šä¹‰çš„å¿…é¡»éµå®ˆçš„è§„åˆ™
            llm_client: LLMå®¢æˆ·ç«¯ï¼Œç”¨äºè¯­ä¹‰è§„åˆ™æ£€æµ‹ï¼ˆå¯é€‰ï¼Œæ— åˆ™å›é€€åˆ°å…³é”®è¯æ£€æµ‹ï¼‰
        """
        # v5.0 æ¨¡å¼æ„ŸçŸ¥
        from recall.mode import get_mode_config
        self._mode = get_mode_config()
        
        # ========== ç»å¯¹è§„åˆ™ï¼ˆç”¨æˆ·è‡ªå®šä¹‰ï¼‰==========
        # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²ã€çº¯ç©ºç™½è§„åˆ™ï¼Œå¹¶å»é‡ï¼ˆä¿æŒé¡ºåºï¼‰
        raw_rules = absolute_rules or []
        self.absolute_rules = self._dedupe_rules(raw_rules)
        self._llm_client = llm_client
        
        # ========== æ•°å€¼å±æ€§æ¨¡å¼ ==========
        self.number_pattern = re.compile(r'(\d+(?:\.\d+)?)\s*(å²|å¹´|å¤©|ç±³|å˜ç±³|å…¬é‡Œ|kg|æ–¤|ä¸ª|æ¬¡|%)')
        self.date_pattern = re.compile(r'(\d{4})[å¹´/-](\d{1,2})[æœˆ/-]?(\d{1,2})?')
        
        # ä¸­æ–‡åå­—æ¨¡å¼ï¼ˆ2-4ä¸ªæ±‰å­—ï¼Œæˆ–è‹±æ–‡åï¼‰- ä½¿ç”¨éæ•è·ç»„å†…ç½®
        # æ³¨æ„ï¼šä¸­æ–‡è§’è‰²åé€šå¸¸2-4å­—ï¼Œè¦é¿å…è´ªå©ªåŒ¹é…
        NAME = r'([\u4e00-\u9fa5]{2,4}|[A-Za-z]+(?:\s[A-Za-z]+)?)'
        
        # ========== æ‰©å±•çš„å±æ€§æå–æ¨¡å¼ ==========
        self.attribute_patterns = {
            # æ•°å€¼å±æ€§ - å¹´é¾„æå–éœ€è¦æ›´ç²¾ç¡®çš„æ¨¡å¼
            AttributeType.AGE: [
                (rf'{NAME}(?:ä»Šå¹´|ç°åœ¨|å·²ç»)?(\d+)å²', 2),  # å°æ˜ä»Šå¹´25å²
                (rf'{NAME}çš„å¹´é¾„(?:æ˜¯|ä¸º)?(\d+)', 2),      # å°æ˜çš„å¹´é¾„æ˜¯25
                (rf'(\d+)å²çš„{NAME}', 1),                  # 25å²çš„å°æ˜ -> å°æ˜, 25
            ],
            AttributeType.HEIGHT: [
                (rf'{NAME}(?:çš„)?èº«é«˜(?:æ˜¯|ä¸º|æœ‰)?(\d+(?:\.\d+)?)\s*(?:cm|å˜ç±³)', 2),
                (rf'{NAME}(?:çš„)?èº«é«˜(?:æ˜¯|ä¸º|æœ‰)?(\d+(?:\.\d+)?)\s*ç±³(?!å˜)', 2),
                (rf'èº«é«˜(\d+(?:\.\d+)?)\s*(?:cm|å˜ç±³|m|ç±³)çš„{NAME}', 1),
            ],
            AttributeType.WEIGHT: [
                (rf'{NAME}(?:çš„)?ä½“é‡(?:æ˜¯|ä¸º|æœ‰)?(\d+(?:\.\d+)?)\s*(?:kg|å…¬æ–¤)', 2),
                (rf'{NAME}(?:çš„)?ä½“é‡(?:æ˜¯|ä¸º|æœ‰)?(\d+(?:\.\d+)?)\s*æ–¤', 2),
            ],
            # å¤–è²Œå±æ€§ - ä½¿ç”¨ä¸­æ–‡åæ¨¡å¼
            AttributeType.HAIR_COLOR: [
                (rf'{NAME}çš„(?:å¤´å‘|å‘è‰²|å‘ä¸|ç§€å‘)(?:æ˜¯|ä¸º)?([\u4e00-\u9fa5]{{1,4}}è‰²?)', 2),
                (rf'{NAME}(?:æœ‰|é•¿ç€|æ‹¥æœ‰)ä¸€å¤´([\u4e00-\u9fa5]{{1,4}}è‰²?)(?:çš„)?(?:å¤´å‘|é•¿å‘|çŸ­å‘|å‘ä¸)', 2),
                (rf'([\u4e00-\u9fa5]{{1,4}}è‰²?)(?:å¤´å‘|å‘è‰²|é•¿å‘|çŸ­å‘)çš„{NAME}', 1),
            ],
            AttributeType.EYE_COLOR: [
                (rf'{NAME}çš„(?:çœ¼ç›|çœ¼çœ¸|çœ¼ç³|ç³å­”)(?:æ˜¯|ä¸º)?([\u4e00-\u9fa5]{{1,4}}è‰²?)', 2),
                (rf'{NAME}(?:æœ‰|é•¿ç€)ä¸€åŒ([\u4e00-\u9fa5]{{1,4}}è‰²?)(?:çš„)?(?:çœ¼ç›|çœ¼çœ¸)', 2),
                (rf'([\u4e00-\u9fa5]{{1,4}}è‰²?)(?:çœ¼ç›|çœ¼çœ¸)çš„{NAME}', 1),
            ],
            # å›ºå®šå±æ€§
            AttributeType.BLOOD_TYPE: [
                (rf'{NAME}çš„è¡€å‹(?:æ˜¯|ä¸º)?(A|B|AB|O)å‹?', 2),
                (rf'{NAME}(?:æ˜¯)?(A|B|AB|O)å‹è¡€', 2),
            ],
            AttributeType.GENDER: [
                (rf'{NAME}æ˜¯(?:ä¸€ä¸ª|ä¸€å|ä¸€ä½)?(ç”·æ€§|å¥³æ€§|ç”·äºº|å¥³äºº|ç”·å­©|å¥³å­©|ç”·ç”Ÿ|å¥³ç”Ÿ)', 2),
                (rf'(ç”·æ€§|å¥³æ€§|ç”·äºº|å¥³äºº){NAME}', 1),
            ],
            AttributeType.SPECIES: [
                (rf'{NAME}æ˜¯(?:ä¸€ä¸ª|ä¸€å|ä¸€åª|ä¸€å¤´)?(äººç±»|ç²¾çµ|çŸ®äºº|å…½äºº|å¸è¡€é¬¼|ç‹¼äºº|é¾™|æ¶é­”|å¤©ä½¿|å¦–ç²¾|äººé±¼)', 2),
                (rf'(äººç±»|ç²¾çµ|çŸ®äºº|å…½äºº|å¸è¡€é¬¼|ç‹¼äºº){NAME}', 1),
            ],
        }
        
        # ========== çŠ¶æ€å˜åŒ–æ¨¡å¼ ==========
        self.state_patterns = {
            AttributeType.VITAL_STATUS: [
                (rf'{NAME}(?:å·²ç»|å·²|ç»ˆäº)?(?:æ­»äº¡|æ­»äº†|å»ä¸–|èº«äº¡|é‡éš¾|ç‰ºç‰²|é˜µäº¡)', 'dead'),
                (rf'{NAME}(?:è¿˜|ä»ç„¶)?(?:æ´»ç€|ç”Ÿè¿˜|å¹¸å­˜)', 'alive'),
                (rf'(?:æ€æ­»|æ€å®³|æ¶ˆç­)äº†?{NAME}', 'dead'),
            ],
            AttributeType.MARITAL_STATUS: [
                (rf'{NAME}(?:å·²ç»)?(?:ç»“å©š|æˆå©š|è®¢å©š)', 'married'),
                (rf'{NAME}(?:æ˜¯|ä»æ˜¯)?å•èº«', 'single'),
                (rf'{NAME}(?:å’Œ|ä¸){NAME}(?:ç»“å©š|æˆå©š)', 'married'),  # åŒæ–¹éƒ½æ ‡è®°
            ],
        }
        
        # ========== å…³ç³»æ¨¡å¼ ==========
        self.relationship_patterns = [
            (rf'{NAME}(?:å’Œ|ä¸){NAME}(?:æ˜¯|æˆä¸ºäº†?|å˜æˆäº†?)([\u4e00-\u9fa5]{{1,4}})', 3),  # Aå’ŒBæ˜¯æœ‹å‹
            (rf'{NAME}(?:æ˜¯){NAME}çš„([\u4e00-\u9fa5]{{1,4}})', 3),  # Aæ˜¯Bçš„æœ‹å‹
            (rf'{NAME}(?:æŠŠ){NAME}(?:å½“ä½œ|è§†ä¸º|çœ‹ä½œ)([\u4e00-\u9fa5]{{1,4}})', 3),  # AæŠŠBå½“ä½œæœ‹å‹
        ]
        
        # ========== å¦å®šå¥æ¨¡å¼ ==========
        self.negation_patterns = [
            (rf'{NAME}(?:ä¸ä¼š|ä¸èƒ½|æ— æ³•|ä»ä¸|ç»ä¸|æ°¸è¿œä¸ä¼š?)([\u4e00-\u9fa5]{{2,8}})', 'cannot'),
            (rf'{NAME}(?:ä¸æ˜¯|å¹¶é|å¹¶ä¸æ˜¯)([\u4e00-\u9fa5]{{2,8}})', 'is_not'),
            (rf'{NAME}(?:æ²¡æœ‰|ä»æœª|ä»æ¥æ²¡æœ‰?)([\u4e00-\u9fa5]{{2,8}})', 'never'),
        ]
        
        # ========== æ—¶é—´è¡¨è¾¾æ¨¡å¼ ==========
        self.time_patterns = {
            'absolute': [
                (r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥?', 'date'),
                (r'(\d{4})å¹´(\d{1,2})æœˆ', 'month'),
                (r'(\d{4})å¹´', 'year'),
            ],
            'relative_past': [
                (r'(\d+)å¹´å‰', 'years_ago'),
                (r'(\d+)ä¸ª?æœˆå‰', 'months_ago'),
                (r'(\d+)å¤©å‰', 'days_ago'),
                (r'å»å¹´', 'last_year'),
                (r'ä¸Šä¸ª?æœˆ', 'last_month'),
                (r'æ˜¨å¤©', 'yesterday'),
                (r'å‰å¤©', 'day_before'),
                (r'ä¹‹å‰|ä»¥å‰|è¿‡å»|æ›¾ç»', 'past'),
            ],
            'relative_future': [
                (r'(\d+)å¹´å', 'years_later'),
                (r'(\d+)ä¸ª?æœˆå', 'months_later'),
                (r'(\d+)å¤©å', 'days_later'),
                (r'æ˜å¹´', 'next_year'),
                (r'ä¸‹ä¸ª?æœˆ', 'next_month'),
                (r'æ˜å¤©', 'tomorrow'),
                (r'åå¤©', 'day_after'),
                (r'ä¹‹å|ä»¥å|å°†æ¥|æœªæ¥', 'future'),
            ],
            'sequence': [
                (r'åœ¨.*ä¹‹å‰', 'before'),
                (r'åœ¨.*ä¹‹å', 'after'),
                (r'å…ˆ.*ç„¶å|å…ˆ.*å†', 'then'),
                (r'é¦–å…ˆ.*æ¥ç€|é¦–å…ˆ.*ç„¶å', 'sequence'),
            ],
        }
        
        # ========== ç¼“å­˜ ==========
        # å±æ€§ç¼“å­˜ï¼šentity -> {attribute -> [(value, timestamp, source, turn_id)]}
        self.entity_facts: Dict[str, Dict[str, List[Tuple[str, float, str, int]]]] = {}
        # å…³ç³»ç¼“å­˜ï¼š(entity1, entity2) -> [(relationship, timestamp, source, turn_id)]
        self.relationships: Dict[Tuple[str, str], List[Tuple[str, float, str, int]]] = {}
        # æ—¶é—´çº¿ç¼“å­˜ï¼šentity -> [TimelineEvent]
        self.timelines: Dict[str, List[TimelineEvent]] = {}
        # å¦å®šå£°æ˜ç¼“å­˜ï¼šentity -> {action -> source}
        self.negations: Dict[str, Dict[str, str]] = {}
        # å½“å‰è½®æ¬¡
        self.current_turn: int = 0
    
    def check(self, new_content: str, existing_memories: List[Dict[str, Any]], turn_id: int = 0) -> ConsistencyResult:
        """æ£€æŸ¥æ–°å†…å®¹ä¸ç°æœ‰è®°å¿†çš„ä¸€è‡´æ€§ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        æ£€æµ‹å†…å®¹ï¼š
        1. æ•°å€¼å±æ€§å†²çªï¼ˆå¹´é¾„/èº«é«˜/ä½“é‡ç­‰ï¼‰
        2. å¤–è²Œå±æ€§å†²çªï¼ˆå‘è‰²/çœ¼è‰²ç­‰ï¼Œæ”¯æŒé¢œè‰²åŒä¹‰è¯ï¼‰
        3. çŠ¶æ€å†²çªï¼ˆç”Ÿæ­»/å©šå§»çŠ¶æ€ï¼‰
        4. å…³ç³»å†²çªï¼ˆæœ‹å‹vsæ•Œäººç­‰å¯¹ç«‹å…³ç³»ï¼‰
        5. æ—¶é—´çº¿å†²çªï¼ˆäº‹ä»¶é¡ºåºã€å¹´é¾„ä¸€è‡´æ€§ï¼‰
        6. å¦å®šå¥è¿åï¼ˆå£°ç§°ä¸ä¼šXä½†åšäº†Xï¼‰
        """
        self.current_turn = turn_id
        violations = []
        
        # v5.0: æ¨¡å¼æ„ŸçŸ¥ â€” é RP æ¨¡å¼ä¸‹è·³è¿‡ RP ç‰¹æœ‰æ£€æŸ¥
        rp_enabled = self._mode.rp_consistency_enabled
        
        # 1. æå–æ–°å†…å®¹ä¸­çš„å„ç±»ä¿¡æ¯
        new_events = self._extract_timeline_events(new_content, turn_id)
        
        if rp_enabled:
            new_attributes = self._extract_all_attributes(new_content)
            new_states = self._extract_states(new_content)
            new_relationships = self._extract_relationships(new_content)
            new_negations = self._extract_negations(new_content)
        
            # 2. æ„å»ºç°æœ‰è®°å¿†çš„äº‹å®åº“
            # æ³¨æ„ï¼šä½¿ç”¨ AttributeType ä½œä¸º keyï¼Œä¿æŒç±»å‹ä¸€è‡´æ€§
            existing_attributes: Dict[str, Dict[AttributeType, List[Tuple[str, str]]]] = {}
            existing_states: Dict[str, Dict[AttributeType, List[Tuple[str, str]]]] = {}
            existing_relationships: Dict[Tuple[str, str], List[Tuple[str, str]]] = {}
            existing_negations: Dict[str, Dict[str, str]] = {}
            
            for memory in existing_memories:
                memory_content = memory.get('content', memory.get('text', ''))
                source = memory_content[:50] + '...' if len(memory_content) > 50 else memory_content
                
                # æå–å±æ€§
                mem_attrs = self._extract_all_attributes(memory_content)
                for entity, attrs in mem_attrs.items():
                    if entity not in existing_attributes:
                        existing_attributes[entity] = {}
                    for attr_type, value in attrs.items():
                        if attr_type not in existing_attributes[entity]:
                            existing_attributes[entity][attr_type] = []
                        existing_attributes[entity][attr_type].append((value, source))
                
                # æå–çŠ¶æ€
                mem_states = self._extract_states(memory_content)
                for entity, states in mem_states.items():
                    if entity not in existing_states:
                        existing_states[entity] = {}
                    for state_type, value in states.items():
                        if state_type not in existing_states[entity]:
                            existing_states[entity][state_type] = []
                        existing_states[entity][state_type].append((value, source))
                
                # æå–å…³ç³»
                mem_rels = self._extract_relationships(memory_content)
                for (e1, e2), rel in mem_rels.items():
                    key = (e1, e2)
                    if key not in existing_relationships:
                        existing_relationships[key] = []
                    existing_relationships[key].append((rel, source))
                
                # æå–å¦å®šå£°æ˜
                mem_negs = self._extract_negations(memory_content)
                for entity, actions in mem_negs.items():
                    if entity not in existing_negations:
                        existing_negations[entity] = {}
                    existing_negations[entity].update(actions)
            
            # 3. æ£€æµ‹å±æ€§å†²çª
            violations.extend(self._check_attribute_conflicts(
                new_attributes, existing_attributes, new_content
            ))
            
            # 4. æ£€æµ‹çŠ¶æ€å†²çª
            violations.extend(self._check_state_conflicts(
                new_states, existing_states, new_content
            ))
            
            # 5. æ£€æµ‹å…³ç³»å†²çª
            violations.extend(self._check_relationship_conflicts(
                new_relationships, existing_relationships, new_content
            ))
            
            # 6. æ£€æµ‹å¦å®šå¥è¿å
            violations.extend(self._check_negation_violations(
                new_content, existing_negations
            ))
            
            # 8. æ£€æµ‹ç”Ÿæ­»çŸ›ç›¾ï¼ˆè§’è‰²æ­»åä¸èƒ½è¡ŒåŠ¨ï¼‰
            violations.extend(self._check_death_consistency(
                new_content, existing_states
            ))
        
        # 7. æ£€æµ‹æ—¶é—´çº¿å†²çªï¼ˆé€šç”¨ï¼Œæ‰€æœ‰æ¨¡å¼éƒ½æ‰§è¡Œï¼‰
        violations.extend(self._check_timeline_full(
            new_content, new_events, existing_memories
        ))
        
        # 9. æ£€æµ‹ç»å¯¹è§„åˆ™è¿åï¼ˆé€šç”¨ï¼Œæ‰€æœ‰æ¨¡å¼éƒ½æ‰§è¡Œï¼‰
        violations.extend(self._check_absolute_rules(new_content))
        
        return ConsistencyResult(
            is_consistent=len(violations) == 0,
            violations=violations,
            confidence=max(0.5, 1.0 - len(violations) * 0.1)
        )
    
    # ========== å±æ€§æå–æ–¹æ³•ï¼ˆåˆ†æ­¥æå–ï¼Œé¿å…è´ªå©ªåŒ¹é…é—®é¢˜ï¼‰==========
    
    def _extract_name_from_prefix(self, prefix: str, max_len: int = 4) -> Optional[str]:
        """ä»å‰ç¼€ä¸­æå–åå­—ï¼ˆå–æœ€å2-4ä¸ªä¸­æ–‡å­—ç¬¦æˆ–å®Œæ•´è‹±æ–‡è¯ï¼‰
        
        ç”¨äºå¤„ç†å¦‚ "å¼ ä¸‰ä»Šå¹´" è¿™æ ·çš„åŒ¹é…ç»“æœï¼Œæå–å‡º "å¼ ä¸‰"
        """
        if not prefix:
            return None
        
        # å°è¯•æå–ä¸­æ–‡åå­—
        chinese_chars = re.findall(r'[\u4e00-\u9fa5]', prefix)
        if chinese_chars:
            # å–æœ€å2-4ä¸ªå­—ç¬¦ä½œä¸ºåå­—
            name_len = min(len(chinese_chars), max_len)
            if name_len >= 2:
                return ''.join(chinese_chars[-name_len:])
        
        # å°è¯•æå–è‹±æ–‡åå­—
        english_match = re.search(r'([A-Za-z]+(?:\s[A-Za-z]+)?)\s*$', prefix)
        if english_match:
            return english_match.group(1)
        
        return None
    
    def _extract_all_attributes(self, text: str) -> Dict[str, Dict[AttributeType, str]]:
        """ä»æ–‡æœ¬æå–æ‰€æœ‰ç±»å‹çš„å±æ€§ï¼ˆå¢å¼ºç‰ˆï¼Œä½¿ç”¨åˆ†æ­¥æå–é¿å…è´ªå©ªåŒ¹é…ï¼‰"""
        results: Dict[str, Dict[AttributeType, str]] = {}
        
        # ========== å¹´é¾„æå–ï¼ˆåˆ†æ­¥æ³•ï¼‰==========
        # æ¨¡å¼1: Xä»Šå¹´/ç°åœ¨Yå²
        for match in re.finditer(r'([\u4e00-\u9fa5A-Za-z]+?)(?:ä»Šå¹´|ç°åœ¨|å·²ç»)(\d+)å²', text):
            name = self._extract_name_from_prefix(match.group(1))
            if name:
                if name not in results:
                    results[name] = {}
                results[name][AttributeType.AGE] = match.group(2)
        
        # æ¨¡å¼2: Xçš„å¹´é¾„æ˜¯Y
        for match in re.finditer(r'([\u4e00-\u9fa5]{2,4}|[A-Za-z]+)çš„å¹´é¾„(?:æ˜¯|ä¸º)?(\d+)', text):
            name = match.group(1)
            if name not in results:
                results[name] = {}
            results[name][AttributeType.AGE] = match.group(2)
        
        # æ¨¡å¼3: Yå²çš„X
        for match in re.finditer(r'(\d+)å²çš„([\u4e00-\u9fa5]{2,4}|[A-Za-z]+)', text):
            name = match.group(2)
            if name not in results:
                results[name] = {}
            results[name][AttributeType.AGE] = match.group(1)
        
        # æ¨¡å¼4: X + æ•°å­— + å²äº† ï¼ˆä¾‹å¦‚: å°æ˜30å²äº†ï¼‰
        # æ³¨æ„: æ’é™¤æ—¶é—´è¯å¦‚"ä»Šå¹´25å²"ï¼Œåº”ç”±æ¨¡å¼1å¤„ç†
        for match in re.finditer(r'([\u4e00-\u9fa5]{2,4}|[A-Za-z]+)(\d+)å²äº†?(?!çš„)', text):
            name = match.group(1)
            # æ’é™¤æ—¶é—´è¯
            if name in {'ä»Šå¹´', 'ç°åœ¨', 'å·²ç»', 'å»å¹´', 'æ˜å¹´'}:
                continue
            # æ£€æŸ¥åå­—æ˜¯å¦ä»¥æ—¶é—´è¯ç»“å°¾ï¼ˆå¦‚"å°æ˜ä»Šå¹´"ï¼‰
            time_words = ['ä»Šå¹´', 'ç°åœ¨', 'å·²ç»', 'å»å¹´', 'æ˜å¹´']
            skip = False
            for tw in time_words:
                if name.endswith(tw):
                    skip = True
                    break
            if skip:
                continue
            if name not in results:
                results[name] = {}
            results[name][AttributeType.AGE] = match.group(2)
        
        # ========== èº«é«˜æå– ==========
        # æ¨¡å¼: Xçš„èº«é«˜æ˜¯Ycm/ç±³  (æ³¨æ„ï¼šåå­—åé¢ä¸è¦åŒ…å«"çš„")
        for match in re.finditer(r'([\u4e00-\u9fa5]{2,4}|[A-Za-z]+)çš„èº«é«˜(?:æ˜¯|ä¸º|æœ‰)?(\d+(?:\.\d+)?)\s*(?:cm|å˜ç±³|ç±³)', text):
            name = match.group(1)
            if name not in results:
                results[name] = {}
            results[name][AttributeType.HEIGHT] = match.group(2)
        
        # æ¨¡å¼: Xèº«é«˜Ycm (æ— "çš„", ä½¿ç”¨è´Ÿå‘å‰ç»æ’é™¤"çš„")
        for match in re.finditer(r'([\u4e00-\u9fa5]{2,4}|[A-Za-z]+)(?<!çš„)èº«é«˜(?:æ˜¯|ä¸º|æœ‰)?(\d+(?:\.\d+)?)\s*(?:cm|å˜ç±³|ç±³)', text):
            name = match.group(1)
            # ç¡®ä¿åå­—ä¸ä»¥"çš„"ç»“å°¾
            if name.endswith('çš„'):
                continue
            if name not in results:
                results[name] = {}
            results[name][AttributeType.HEIGHT] = match.group(2)
        
        # æ¨¡å¼: èº«é«˜Ycmçš„X
        for match in re.finditer(r'èº«é«˜(\d+(?:\.\d+)?)\s*(?:cm|å˜ç±³|ç±³)çš„([\u4e00-\u9fa5]{2,4}|[A-Za-z]+)', text):
            name = match.group(2)
            if name not in results:
                results[name] = {}
            results[name][AttributeType.HEIGHT] = match.group(1)
        
        # ========== ä½“é‡æå– ==========
        # æ¨¡å¼: Xçš„ä½“é‡æ˜¯Ykg
        for match in re.finditer(r'([\u4e00-\u9fa5]{2,4}|[A-Za-z]+)çš„ä½“é‡(?:æ˜¯|ä¸º|æœ‰)?(\d+(?:\.\d+)?)\s*(?:kg|å…¬æ–¤|æ–¤)', text):
            name = match.group(1)
            if name not in results:
                results[name] = {}
            results[name][AttributeType.WEIGHT] = match.group(2)
        
        # æ¨¡å¼: Xä½“é‡Ykg (æ— "çš„")
        for match in re.finditer(r'([\u4e00-\u9fa5]{2,4}|[A-Za-z]+)ä½“é‡(?:æ˜¯|ä¸º|æœ‰)?(\d+(?:\.\d+)?)\s*(?:kg|å…¬æ–¤|æ–¤)', text):
            name = match.group(1)
            # ç¡®ä¿åå­—ä¸ä»¥"çš„"ç»“å°¾
            if name.endswith('çš„'):
                continue
            if name not in results:
                results[name] = {}
            results[name][AttributeType.WEIGHT] = match.group(2)
        
        # ========== å‘è‰²æå– ==========
        # æ¨¡å¼: Xæœ‰ä¸€å¤´Yè‰²çš„å¤´å‘
        for match in re.finditer(r'([\u4e00-\u9fa5]{2,4}|[A-Za-z]+)(?:æœ‰|é•¿ç€|æ‹¥æœ‰)ä¸€å¤´([\u4e00-\u9fa5]{1,4})(?:è‰²)?(?:çš„)?(?:å¤´å‘|é•¿å‘|çŸ­å‘)', text):
            name = match.group(1)
            color = self._normalize_color(match.group(2))
            if name not in results:
                results[name] = {}
            results[name][AttributeType.HAIR_COLOR] = color
        
        # æ¨¡å¼: Xçš„å¤´å‘æ˜¯Yè‰²
        for match in re.finditer(r'([\u4e00-\u9fa5]{2,4}|[A-Za-z]+)çš„(?:å¤´å‘|å‘è‰²)(?:æ˜¯|ä¸º)?([\u4e00-\u9fa5]{1,4})(?:è‰²)?', text):
            name = match.group(1)
            color = self._normalize_color(match.group(2))
            if name not in results:
                results[name] = {}
            results[name][AttributeType.HAIR_COLOR] = color
        
        # ========== çœ¼è‰²æå– ==========
        for match in re.finditer(r'([\u4e00-\u9fa5]{2,4}|[A-Za-z]+)(?:æœ‰|é•¿ç€)?ä¸€åŒ([\u4e00-\u9fa5]{1,4})(?:è‰²)?(?:çš„)?(?:çœ¼ç›|çœ¼çœ¸)', text):
            name = match.group(1)
            color = self._normalize_color(match.group(2))
            if name not in results:
                results[name] = {}
            results[name][AttributeType.EYE_COLOR] = color
        
        for match in re.finditer(r'([\u4e00-\u9fa5]{2,4}|[A-Za-z]+)çš„(?:çœ¼ç›|çœ¼çœ¸|çœ¼ç³)(?:æ˜¯|ä¸º)?([\u4e00-\u9fa5]{1,4})(?:è‰²)?', text):
            name = match.group(1)
            color = self._normalize_color(match.group(2))
            if name not in results:
                results[name] = {}
            results[name][AttributeType.EYE_COLOR] = color
        
        # ========== è¡€å‹æå– ==========
        for match in re.finditer(r'([\u4e00-\u9fa5]{2,4}|[A-Za-z]+)(?:çš„)?è¡€å‹(?:æ˜¯|ä¸º)?(A|B|AB|O)å‹?', text):
            name = match.group(1)
            if name not in results:
                results[name] = {}
            results[name][AttributeType.BLOOD_TYPE] = match.group(2)
        
        # ========== æ€§åˆ«æå– ==========
        for match in re.finditer(r'([\u4e00-\u9fa5]{2,4}|[A-Za-z]+)æ˜¯(?:ä¸€ä¸ª|ä¸€å|ä¸€ä½)?(ç”·æ€§|å¥³æ€§|ç”·äºº|å¥³äºº|ç”·å­©|å¥³å­©|ç”·ç”Ÿ|å¥³ç”Ÿ)', text):
            name = match.group(1)
            if name not in results:
                results[name] = {}
            results[name][AttributeType.GENDER] = match.group(2)
        
        # ========== ç§æ—æå– ==========
        for match in re.finditer(r'([\u4e00-\u9fa5]{2,4}|[A-Za-z]+)æ˜¯(?:ä¸€ä¸ª|ä¸€å|ä¸€åª|ä¸€å¤´)?(äººç±»|ç²¾çµ|çŸ®äºº|å…½äºº|å¸è¡€é¬¼|ç‹¼äºº|é¾™|æ¶é­”|å¤©ä½¿|å¦–ç²¾|äººé±¼)', text):
            name = match.group(1)
            if name not in results:
                results[name] = {}
            results[name][AttributeType.SPECIES] = match.group(2)
        
        return results
    
    def _normalize_color(self, color: str) -> str:
        """é¢œè‰²æ ‡å‡†åŒ–ï¼ˆåˆå¹¶åŒä¹‰è¯ï¼‰"""
        color = color.lower().strip()
        for standard, synonyms in self.COLOR_SYNONYMS.items():
            if color in synonyms or any(syn in color for syn in synonyms):
                return standard
        return color
    
    def _extract_states(self, text: str) -> Dict[str, Dict[AttributeType, str]]:
        """æå–çŠ¶æ€ä¿¡æ¯ï¼ˆç”Ÿæ­»ã€å©šå§»ç­‰ï¼‰- ä½¿ç”¨åˆ†æ­¥æå–"""
        results: Dict[str, Dict[AttributeType, str]] = {}
        
        # åå­—æå–è¾…åŠ©ï¼šæ’é™¤å¸¸è§çŠ¶æ€è¯
        exclude_words = {'å·²ç»', 'å·²', 'ç»ˆäº', 'ä¸', 'è¿˜', 'ä»ç„¶', 'æ˜¯', 'ä»æ˜¯'}
        
        def clean_name(raw_name: str) -> str:
            """æ¸…ç†åå­—ï¼Œç§»é™¤çŠ¶æ€è¯åç¼€"""
            for word in exclude_words:
                if raw_name.endswith(word):
                    raw_name = raw_name[:-len(word)]
            return raw_name if len(raw_name) >= 2 else ""
        
        # ========== ç”Ÿæ­»çŠ¶æ€ ==========
        # æ­»äº¡æ¨¡å¼ - ä½¿ç”¨æ›´ç²¾ç¡®çš„è¾¹ç•Œ
        death_patterns = [
            r'([\u4e00-\u9fa5]{2,4}?)(?:å·²ç»|å·²|ç»ˆäº)(?:æ­»äº¡|æ­»äº†|å»ä¸–|èº«äº¡|é‡éš¾|ç‰ºç‰²|é˜µäº¡)',
            r'([\u4e00-\u9fa5]{2,4})(?:æ­»äº¡|æ­»äº†|å»ä¸–|èº«äº¡|é‡éš¾|ç‰ºç‰²|é˜µäº¡)',
            r'(?:æ€æ­»|æ€å®³|æ¶ˆç­)äº†?([\u4e00-\u9fa5]{2,4})',
        ]
        for pattern in death_patterns:
            for match in re.finditer(pattern, text):
                name = clean_name(match.group(1))
                if name and len(name) >= 2:
                    if name not in results:
                        results[name] = {}
                    results[name][AttributeType.VITAL_STATUS] = 'dead'
        
        # å­˜æ´»æ¨¡å¼
        alive_patterns = [
            r'([\u4e00-\u9fa5]{2,4}?)(?:è¿˜|ä»ç„¶)(?:æ´»ç€|ç”Ÿè¿˜|å¹¸å­˜)',
            r'([\u4e00-\u9fa5]{2,4})(?:æ´»ç€|ç”Ÿè¿˜|å¹¸å­˜)',
        ]
        for pattern in alive_patterns:
            for match in re.finditer(pattern, text):
                name = clean_name(match.group(1))
                if name and len(name) >= 2:
                    if name not in results:
                        results[name] = {}
                    results[name][AttributeType.VITAL_STATUS] = 'alive'
        
        # ========== å©šå§»çŠ¶æ€ ==========
        # å·²å©š
        for match in re.finditer(r'([\u4e00-\u9fa5]{2,4})(?:å·²ç»)?(?:ç»“å©š|æˆå©š|è®¢å©š)', text):
            name = match.group(1)
            if name not in results:
                results[name] = {}
            results[name][AttributeType.MARITAL_STATUS] = 'married'
        
        # åŒäººç»“å©š
        for match in re.finditer(r'([\u4e00-\u9fa5]{2,4})(?:å’Œ|ä¸)([\u4e00-\u9fa5]{2,4})(?:ç»“å©š|æˆå©š)', text):
            for name in [match.group(1), match.group(2)]:
                if name not in results:
                    results[name] = {}
                results[name][AttributeType.MARITAL_STATUS] = 'married'
        
        # å•èº«
        for match in re.finditer(r'([\u4e00-\u9fa5]{2,4})(?:æ˜¯|ä»æ˜¯)?å•èº«', text):
            name = match.group(1)
            if name not in results:
                results[name] = {}
            results[name][AttributeType.MARITAL_STATUS] = 'single'
        
        return results
    
    def _extract_relationships(self, text: str) -> Dict[Tuple[str, str], str]:
        """æå–å…³ç³»ä¿¡æ¯"""
        results: Dict[Tuple[str, str], str] = {}
        
        for pattern, rel_group in self.relationship_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if len(match) >= 3:
                    e1, e2, relationship = match[0].strip(), match[1].strip(), match[2].strip()
                    # åŒå‘å­˜å‚¨
                    results[(e1, e2)] = relationship
                    results[(e2, e1)] = relationship
        
        return results
    
    def _extract_negations(self, text: str) -> Dict[str, Dict[str, str]]:
        """æå–å¦å®šå£°æ˜ï¼ˆä¸ä¼š/ä¸èƒ½/ä»ä¸ï¼‰"""
        results: Dict[str, Dict[str, str]] = {}
        
        for pattern, neg_type in self.negation_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if isinstance(match, tuple) and len(match) >= 2:
                    entity, action = match[0].strip(), match[1].strip()
                    if entity not in results:
                        results[entity] = {}
                    results[entity][action] = f"{neg_type}:{text[:50]}"
        
        return results
    
    def _extract_timeline_events(self, text: str, turn_id: int) -> List[TimelineEvent]:
        """æå–æ—¶é—´çº¿äº‹ä»¶"""
        events = []
        
        # æå–æ­»äº¡äº‹ä»¶
        death_patterns = [
            (r'(\w{1,10})(?:å·²ç»|å·²)?(?:æ­»äº¡|æ­»äº†|å»ä¸–|èº«äº¡|é‡éš¾|ç‰ºç‰²)', 'death'),
            (r'(?:æ€æ­»|æ€å®³|æ¶ˆç­)äº†?(\w{1,10})', 'death'),
        ]
        
        for pattern, event_type in death_patterns:
            matches = re.findall(pattern, text)
            for entity in matches:
                events.append(TimelineEvent(
                    entity=entity.strip(),
                    event_type=event_type,
                    description=f"{entity}æ­»äº¡",
                    source=text[:100],
                    turn_id=turn_id
                ))
        
        # æå–å‡ºç”Ÿ/å¹´é¾„å£°æ˜ï¼ˆç”¨äºå¹´é¾„ä¸€è‡´æ€§æ£€æŸ¥ï¼‰
        age_patterns = [
            (r'(\w{1,10})(?:ä»Šå¹´|ç°åœ¨)?(\d+)å²', 'age_declaration'),
            (r'(\d+)å¹´å‰.*(\w{1,10})(\d+)å²', 'past_age'),  # Nå¹´å‰Xæ˜¯Må²
        ]
        
        for pattern, event_type in age_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if event_type == 'age_declaration' and len(match) >= 2:
                    events.append(TimelineEvent(
                        entity=match[0].strip(),
                        event_type='age',
                        description=f"å¹´é¾„:{match[1]}",
                        source=text[:100],
                        turn_id=turn_id
                    ))
        
        return events
    
    # ========== å†²çªæ£€æµ‹æ–¹æ³• ==========
    
    def _check_attribute_conflicts(
        self,
        new_attrs: Dict[str, Dict[AttributeType, str]],
        existing_attrs: Dict[str, Dict[AttributeType, List[Tuple[str, str]]]],
        new_content: str
    ) -> List[Violation]:
        """æ£€æµ‹å±æ€§å†²çªï¼ˆæ”¯æŒé¢œè‰²åŒä¹‰è¯åˆå¹¶ï¼‰"""
        violations = []
        
        for entity, attrs in new_attrs.items():
            if entity not in existing_attrs:
                continue
            
            for attr_type, new_value in attrs.items():
                if attr_type not in existing_attrs[entity]:
                    continue
                
                attr_name = attr_type.value if isinstance(attr_type, AttributeType) else str(attr_type)
                
                for old_value, source in existing_attrs[entity][attr_type]:
                    # é¢œè‰²ç±»å±æ€§ä½¿ç”¨æ ‡å‡†åŒ–æ¯”è¾ƒ
                    if attr_type in [AttributeType.HAIR_COLOR, AttributeType.EYE_COLOR, AttributeType.SKIN_COLOR]:
                        new_normalized = self._normalize_color(new_value)
                        old_normalized = self._normalize_color(old_value)
                        if new_normalized != old_normalized:
                            violations.append(Violation(
                                type=ViolationType.CHARACTER_CONFLICT,
                                description=f"ã€{entity}ã€‘çš„{attr_name}å­˜åœ¨å†²çªï¼šæ–°å€¼'{new_value}'({new_normalized}) vs æ—§å€¼'{old_value}'({old_normalized})",
                                evidence=[new_content[:100], source],
                                severity=0.8,
                                suggested_resolution=f"ç¡®è®¤{entity}çš„{attr_name}åº”è¯¥æ˜¯{new_value}è¿˜æ˜¯{old_value}"
                            ))
                    else:
                        # å…¶ä»–å±æ€§ç›´æ¥æ¯”è¾ƒ
                        if new_value != old_value:
                            violations.append(Violation(
                                type=ViolationType.FACT_CONFLICT,
                                description=f"ã€{entity}ã€‘çš„{attr_name}å­˜åœ¨å†²çªï¼šæ–°å€¼'{new_value}' vs æ—§å€¼'{old_value}'",
                                evidence=[new_content[:100], source],
                                severity=0.7,
                                suggested_resolution=f"ç¡®è®¤{entity}çš„{attr_name}åº”è¯¥æ˜¯{new_value}è¿˜æ˜¯{old_value}"
                            ))
        
        return violations
    
    def _check_state_conflicts(
        self,
        new_states: Dict[str, Dict[AttributeType, str]],
        existing_states: Dict[str, Dict[AttributeType, List[Tuple[str, str]]]],
        new_content: str
    ) -> List[Violation]:
        """æ£€æµ‹çŠ¶æ€å†²çªï¼ˆç”Ÿæ­»ã€å©šå§»ç­‰ï¼‰"""
        violations = []
        
        for entity, states in new_states.items():
            if entity not in existing_states:
                continue
            
            for state_type, new_value in states.items():
                if state_type not in existing_states[entity]:
                    continue
                
                state_name = state_type.value if isinstance(state_type, AttributeType) else str(state_type)
                
                for old_value, source in existing_states[entity][state_type]:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å¯¹ç«‹çŠ¶æ€
                    if self._are_opposite_states(old_value, new_value):
                        violations.append(Violation(
                            type=ViolationType.STATE_CONFLICT,
                            description=f"ã€{entity}ã€‘çŠ¶æ€å†²çªï¼šä¹‹å‰'{old_value}' â†’ ç°åœ¨'{new_value}'",
                            evidence=[new_content[:100], source],
                            severity=0.9,
                            suggested_resolution=f"è¯·ç¡®è®¤{entity}çš„çŠ¶æ€å˜åŒ–æ˜¯å¦æœ‰åˆç†è§£é‡Šï¼ˆå¦‚å¤æ´»æƒ…èŠ‚ï¼‰"
                        ))
        
        return violations
    
    def _are_opposite_states(self, state1: str, state2: str) -> bool:
        """æ£€æŸ¥ä¸¤ä¸ªçŠ¶æ€æ˜¯å¦å¯¹ç«‹"""
        for key, opposites in self.STATE_OPPOSITES.items():
            if state1 == key or state1 in opposites:
                if state2 in opposites or state2 == key:
                    if state1 != state2:
                        return True
        return False
    
    def _check_relationship_conflicts(
        self,
        new_rels: Dict[Tuple[str, str], str],
        existing_rels: Dict[Tuple[str, str], List[Tuple[str, str]]],
        new_content: str
    ) -> List[Violation]:
        """æ£€æµ‹å…³ç³»å†²çªï¼ˆæœ‹å‹vsæ•Œäººç­‰ï¼‰"""
        violations = []
        
        for (e1, e2), new_rel in new_rels.items():
            if (e1, e2) not in existing_rels:
                continue
            
            for old_rel, source in existing_rels[(e1, e2)]:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¯¹ç«‹å…³ç³»
                if self._are_opposite_relationships(old_rel, new_rel):
                    violations.append(Violation(
                        type=ViolationType.RELATIONSHIP_CONFLICT,
                        description=f"ã€{e1}ã€‘å’Œã€{e2}ã€‘çš„å…³ç³»å†²çªï¼šä¹‹å‰'{old_rel}' â†’ ç°åœ¨'{new_rel}'",
                        evidence=[new_content[:100], source],
                        severity=0.75,
                        suggested_resolution=f"è¯·ç¡®è®¤{e1}å’Œ{e2}çš„å…³ç³»å˜åŒ–æ˜¯å¦æœ‰æƒ…èŠ‚æ”¯æŒ"
                    ))
        
        return violations
    
    def _are_opposite_relationships(self, rel1: str, rel2: str) -> bool:
        """æ£€æŸ¥ä¸¤ä¸ªå…³ç³»æ˜¯å¦å¯¹ç«‹"""
        for key, opposites in self.RELATIONSHIP_OPPOSITES.items():
            if key in rel1 or rel1 in [key]:
                if any(opp in rel2 for opp in opposites):
                    return True
            if key in rel2 or rel2 in [key]:
                if any(opp in rel1 for opp in opposites):
                    return True
        return False
    
    def _check_negation_violations(
        self,
        new_content: str,
        existing_negations: Dict[str, Dict[str, str]]
    ) -> List[Violation]:
        """æ£€æµ‹å¦å®šå¥è¿åï¼ˆå£°ç§°ä¸ä¼šXä½†åšäº†Xï¼‰"""
        violations = []
        
        # æå–æ–°å†…å®¹ä¸­çš„åŠ¨ä½œ
        action_patterns = [
            (r'(\w{1,10})(?:å¼€å§‹|æ­£åœ¨)?(\S{2,6})(?:äº†|ç€|è¿‡)', 'did'),  # Xåšäº†Y
            (r'(\w{1,10})(\S{2,6})äº†(\S+)', 'did'),  # Xæ€äº†Y
        ]
        
        for pattern, _ in action_patterns:
            matches = re.findall(pattern, new_content)
            for match in matches:
                entity = match[0].strip()
                action = match[1].strip() if len(match) > 1 else ""
                
                if entity in existing_negations:
                    for negated_action, source in existing_negations[entity].items():
                        # æ£€æŸ¥åŠ¨ä½œæ˜¯å¦åŒ¹é…å¦å®šå£°æ˜
                        if self._action_matches_negation(action, negated_action):
                            violations.append(Violation(
                                type=ViolationType.LOGIC_ERROR,
                                description=f"ã€{entity}ã€‘è¿åäº†ä¹‹å‰çš„å£°æ˜ï¼šæ›¾è¯´'{negated_action}'ï¼Œç°åœ¨å´'{action}'",
                                evidence=[new_content[:100], source],
                                severity=0.85,
                                suggested_resolution=f"è¯·ç¡®è®¤{entity}çš„è¡Œä¸ºæ˜¯å¦æœ‰ç‰¹æ®ŠåŸå› "
                            ))
        
        return violations
    
    def _action_matches_negation(self, action: str, negated_action: str) -> bool:
        """æ£€æŸ¥åŠ¨ä½œæ˜¯å¦ä¸å¦å®šå£°æ˜å†²çª"""
        # ç®€å•åŒ¹é…ï¼šåŠ¨ä½œåŒ…å«å¦å®šå£°æ˜ä¸­çš„å…³é”®è¯
        if len(action) < 2 or len(negated_action) < 2:
            return False
        return action in negated_action or negated_action in action
    
    # ========== æ—¶é—´çº¿æ£€æµ‹æ–¹æ³•ï¼ˆå®Œæ•´ç‰ˆï¼‰==========
    
    def _check_timeline_full(
        self,
        new_content: str,
        new_events: List[TimelineEvent],
        existing_memories: List[Dict[str, Any]]
    ) -> List[Violation]:
        """å®Œæ•´ç‰ˆæ—¶é—´çº¿æ£€æŸ¥
        
        æ£€æµ‹å†…å®¹ï¼š
        1. æ—¶æ€å†²çªï¼ˆåŒä¸€äº‹ä»¶çš„è¿‡å»/å°†æ¥æè¿°å†²çªï¼‰
        2. å¹´é¾„ä¸€è‡´æ€§ï¼ˆNå¹´å‰Xå² â†’ ç°åœ¨åº”è¯¥X+Nå²ï¼‰
        3. äº‹ä»¶é¡ºåºï¼ˆå£°ç§°Aåœ¨Bä¹‹å‰ï¼Œä½†æè¿°é¡ºåºç›¸åï¼‰
        4. æ—¥æœŸçŸ›ç›¾ï¼ˆå…·ä½“æ—¥æœŸçš„å†²çªï¼‰
        """
        violations = []
        
        # 1. æ—¶æ€å†²çªæ£€æµ‹
        violations.extend(self._check_tense_conflicts(new_content, existing_memories))
        
        # 2. å¹´é¾„ä¸€è‡´æ€§æ£€æµ‹
        violations.extend(self._check_age_consistency(new_content, existing_memories))
        
        # 3. äº‹ä»¶é¡ºåºæ£€æµ‹
        violations.extend(self._check_event_sequence(new_content, existing_memories))
        
        return violations
    
    def _check_tense_conflicts(
        self,
        new_content: str,
        existing_memories: List[Dict[str, Any]]
    ) -> List[Violation]:
        """æ£€æµ‹æ—¶æ€å†²çª"""
        violations = []
        
        # æå–æ–°å†…å®¹çš„æ—¶é—´è¡¨è¾¾
        new_dates = self.date_pattern.findall(new_content)
        past_indicators = ['ä¹‹å‰', 'ä»¥å‰', 'å»å¹´', 'ä¸Šä¸ªæœˆ', 'æ˜¨å¤©', 'æ›¾ç»', 'å¹´å‰', 'æœˆå‰', 'å¤©å‰']
        future_indicators = ['ä¹‹å', 'ä»¥å', 'æ˜å¹´', 'ä¸‹ä¸ªæœˆ', 'æ˜å¤©', 'å°†æ¥', 'å¹´å', 'æœˆå', 'å¤©å']
        
        new_has_past = any(ind in new_content for ind in past_indicators)
        new_has_future = any(ind in new_content for ind in future_indicators)
        
        for memory in existing_memories:
            memory_content = memory.get('content', memory.get('text', ''))
            memory_dates = self.date_pattern.findall(memory_content)
            
            if not memory_dates and not new_dates:
                continue
            
            mem_has_past = any(ind in memory_content for ind in past_indicators)
            mem_has_future = any(ind in memory_content for ind in future_indicators)
            
            # æ£€æµ‹å…·ä½“æ—¥æœŸçš„æ—¶æ€å†²çª
            for new_date in new_dates:
                for mem_date in memory_dates:
                    if new_date == mem_date:
                        if (new_has_past and mem_has_future) or (new_has_future and mem_has_past):
                            violations.append(Violation(
                                type=ViolationType.TIMELINE_CONFLICT,
                                description=f"æ—¶é—´çº¿å†²çªï¼šæ—¥æœŸ {'-'.join(filter(None, new_date))} çš„æ—¶æ€æè¿°çŸ›ç›¾",
                                evidence=[new_content[:100], memory_content[:100]],
                                severity=0.6,
                                suggested_resolution="è¯·ç¡®è®¤è¯¥æ—¥æœŸæ˜¯è¿‡å»è¿˜æ˜¯å°†æ¥"
                            ))
        
        return violations
    
    def _check_age_consistency(
        self,
        new_content: str,
        existing_memories: List[Dict[str, Any]]
    ) -> List[Violation]:
        """æ£€æµ‹å¹´é¾„ä¸€è‡´æ€§
        
        è§„åˆ™ï¼š
        - å¦‚æœä¹‹å‰è¯´"Nå¹´å‰Xæ˜¯Må²"ï¼Œç°åœ¨Xåº”è¯¥æ˜¯M+Nå²
        - å¦‚æœä¹‹å‰è¯´"Xä»Šå¹´Må²"ï¼Œåé¢å†è¯´"Xä»Šå¹´Kå²"ä¸”Kâ‰ Mï¼Œåˆ™å†²çª
        """
        violations = []
        
        # æå–æ–°å†…å®¹ä¸­çš„å¹´é¾„å£°æ˜
        # ä¿®å¤ï¼šä½¿ç”¨éè´ªå©ªåŒ¹é…å’Œä¸­æ–‡å­—ç¬¦èŒƒå›´ï¼Œé¿å…"ä»Šå¹´"è¢«åŒ…å«åœ¨åå­—ä¸­
        current_age_pattern = r'([\u4e00-\u9fa5\w]{1,10}?)(?:ä»Šå¹´|ç°åœ¨|å·²ç»)?(\d+)å²'
        past_age_pattern = r'(\d+)å¹´å‰.*?([\u4e00-\u9fa5\w]{1,10}?).*?(\d+)å²'
        
        new_ages = {}
        for match in re.findall(current_age_pattern, new_content):
            entity, age = match[0].strip(), int(match[1])
            # è¿‡æ»¤æ‰ç©ºåå­—æˆ–çº¯æ•°å­—
            if entity and not entity.isdigit():
                new_ages[entity] = age
        
        # æ£€æŸ¥ä¸å†å²è®°å½•çš„ä¸€è‡´æ€§
        for memory in existing_memories:
            memory_content = memory.get('content', memory.get('text', ''))
            
            # æ£€æŸ¥å†å²å¹´é¾„å£°æ˜
            for match in re.findall(current_age_pattern, memory_content):
                entity, old_age = match[0].strip(), int(match[1])
                # è¿‡æ»¤æ‰ç©ºåå­—æˆ–çº¯æ•°å­—
                if not entity or entity.isdigit():
                    continue
                if entity in new_ages and new_ages[entity] != old_age:
                    # å…è®¸1å²çš„å·®å¼‚ï¼ˆå¯èƒ½æ˜¯ç”Ÿæ—¥ç»è¿‡ï¼‰
                    age_diff = abs(new_ages[entity] - old_age)
                    if age_diff > 1:
                        violations.append(Violation(
                            type=ViolationType.AGE_INCONSISTENCY,
                            description=f"ã€{entity}ã€‘çš„å¹´é¾„ä¸ä¸€è‡´ï¼šä¹‹å‰'{old_age}å²' â†’ ç°åœ¨'{new_ages[entity]}å²'ï¼ˆå·®{age_diff}å²ï¼‰",
                            evidence=[new_content[:100], memory_content[:100]],
                            severity=0.7,
                            suggested_resolution=f"è¯·ç¡®è®¤{entity}çš„å®é™…å¹´é¾„ï¼Œæˆ–è¯´æ˜æ—¶é—´æµé€"
                        ))
            
            # æ£€æŸ¥"Nå¹´å‰Må²"çš„æ¨ç®—
            for match in re.findall(past_age_pattern, memory_content):
                years_ago, entity, past_age = int(match[0]), match[1].strip(), int(match[2])
                expected_current_age = past_age + years_ago
                
                if entity in new_ages:
                    actual_age = new_ages[entity]
                    # å…è®¸2å²çš„è¯¯å·®
                    if abs(actual_age - expected_current_age) > 2:
                        violations.append(Violation(
                            type=ViolationType.AGE_INCONSISTENCY,
                            description=f"ã€{entity}ã€‘å¹´é¾„æ¨ç®—ä¸ä¸€è‡´ï¼š{years_ago}å¹´å‰{past_age}å² â†’ ç°åœ¨åº”è¯¥çº¦{expected_current_age}å²ï¼Œä½†å®é™…æ˜¯{actual_age}å²",
                            evidence=[new_content[:100], memory_content[:100]],
                            severity=0.65,
                            suggested_resolution=f"è¯·ç¡®è®¤æ—¶é—´çº¿æˆ–{entity}çš„å¹´é¾„"
                        ))
        
        return violations
    
    def _check_event_sequence(
        self,
        new_content: str,
        existing_memories: List[Dict[str, Any]]
    ) -> List[Violation]:
        """æ£€æµ‹äº‹ä»¶é¡ºåºå†²çª"""
        violations = []
        
        # æå–"åœ¨Xä¹‹å‰/ä¹‹å"çš„è¡¨è¿°
        sequence_pattern = r'åœ¨(.{2,20})(ä¹‹å‰|ä¹‹å).*?(.{2,20})'
        
        for match in re.findall(sequence_pattern, new_content):
            event_a, relation, event_b = match[0], match[1], match[2]
            
            # åœ¨å†å²è®°å½•ä¸­æŸ¥æ‰¾ç›¸åçš„é¡ºåºå£°æ˜
            for memory in existing_memories:
                memory_content = memory.get('content', memory.get('text', ''))
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸åçš„é¡ºåºå£°æ˜
                opposite_relation = 'ä¹‹å' if relation == 'ä¹‹å‰' else 'ä¹‹å‰'
                reverse_pattern = rf'åœ¨{re.escape(event_b)}.*?{opposite_relation}.*?{re.escape(event_a)}'
                
                if re.search(reverse_pattern, memory_content):
                    violations.append(Violation(
                        type=ViolationType.TIMELINE_CONFLICT,
                        description=f"äº‹ä»¶é¡ºåºå†²çªï¼šæ–°å†…å®¹è¯´'{event_a}åœ¨{event_b}{relation}'ï¼Œä½†ä¹‹å‰è¯´çš„æ˜¯ç›¸åé¡ºåº",
                        evidence=[new_content[:100], memory_content[:100]],
                        severity=0.7,
                        suggested_resolution="è¯·ç¡®è®¤äº‹ä»¶çš„å®é™…å‘ç”Ÿé¡ºåº"
                    ))
        
        return violations
    
    def _check_death_consistency(
        self,
        new_content: str,
        existing_states: Dict[str, Dict[str, List[Tuple[str, str]]]]
    ) -> List[Violation]:
        """æ£€æµ‹ç”Ÿæ­»çŸ›ç›¾ï¼ˆè§’è‰²æ­»åä¸èƒ½è¡ŒåŠ¨ï¼‰"""
        violations = []
        
        # æ‰¾å‡ºå·²çŸ¥æ­»äº¡çš„è§’è‰²
        dead_entities = set()
        for entity, states in existing_states.items():
            vital_key = AttributeType.VITAL_STATUS.value
            if vital_key in states:
                for value, _ in states[vital_key]:
                    if value == 'dead':
                        dead_entities.add(entity)
        
        # æ£€æŸ¥æ–°å†…å®¹ä¸­æ­»äº¡è§’è‰²æ˜¯å¦æœ‰è¡ŒåŠ¨
        action_patterns = [
            r'(\w{1,10})(?:è¯´|è¯´é“|é—®|å›ç­”|èµ°|è·‘|ç«™|å|ç¬‘|å“­|çœ‹|å¬|æƒ³|åš|æ‹¿|ç»™|æ‰“|æ€|åƒ|å–)',
            r'(\w{1,10})çš„(?:å£°éŸ³|è„šæ­¥|èº«å½±|ç¬‘å£°)',
        ]
        
        for pattern in action_patterns:
            matches = re.findall(pattern, new_content)
            for entity in matches:
                entity = entity.strip()
                if entity in dead_entities:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å›å¿†/é—ªå›åœºæ™¯
                    flashback_indicators = ['å›å¿†', 'æƒ³èµ·', 'è®°å¾—', 'æ›¾ç»', 'ä»¥å‰', 'é‚£æ—¶', 'ç”Ÿå‰']
                    is_flashback = any(ind in new_content for ind in flashback_indicators)
                    
                    if not is_flashback:
                        violations.append(Violation(
                            type=ViolationType.LOGIC_ERROR,
                            description=f"ã€{entity}ã€‘å·²æ­»äº¡ï¼Œä½†ä»åœ¨è¡ŒåŠ¨",
                            evidence=[new_content[:100], f"{entity}ä¹‹å‰è¢«è®°å½•ä¸ºæ­»äº¡"],
                            severity=0.95,
                            suggested_resolution=f"å¦‚æœæ˜¯å›å¿†åœºæ™¯è¯·æ˜ç¡®è¯´æ˜ï¼Œå¦åˆ™è¯·ç¡®è®¤{entity}æ˜¯å¦å¤æ´»"
                        ))
        
        return violations
    
    # ========== å…¼å®¹æ—§æ¥å£ ==========
    
    def _extract_facts(self, text: str) -> Dict[str, Dict[str, str]]:
        """ä»æ–‡æœ¬ä¸­æå–äº‹å®ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
        attrs = self._extract_all_attributes(text)
        facts: Dict[str, Dict[str, str]] = {}
        for entity, attr_dict in attrs.items():
            facts[entity] = {
                attr_type.value if isinstance(attr_type, AttributeType) else str(attr_type): value
                for attr_type, value in attr_dict.items()
            }
        return facts
    
    def _check_timeline(
        self,
        new_content: str,
        existing_memories: List[Dict[str, Any]]
    ) -> List[Violation]:
        """æ£€æŸ¥æ—¶é—´çº¿ä¸€è‡´æ€§ï¼ˆå…¼å®¹æ—§æ¥å£ï¼Œè°ƒç”¨å®Œæ•´ç‰ˆï¼‰"""
        new_events = self._extract_timeline_events(new_content, self.current_turn)
        return self._check_timeline_full(new_content, new_events, existing_memories)
    
    def record_fact(
        self,
        entity: str,
        attribute: str,
        value: str,
        source: str,
        turn_id: int = 0
    ):
        """è®°å½•äº‹å®åˆ°ç¼“å­˜"""
        if entity not in self.entity_facts:
            self.entity_facts[entity] = {}
        if attribute not in self.entity_facts[entity]:
            self.entity_facts[entity][attribute] = []
        
        self.entity_facts[entity][attribute].append((value, time.time(), source, turn_id))
    
    def record_relationship(
        self,
        entity1: str,
        entity2: str,
        relationship: str,
        source: str,
        turn_id: int = 0
    ):
        """è®°å½•å…³ç³»åˆ°ç¼“å­˜"""
        key = (entity1, entity2)
        if key not in self.relationships:
            self.relationships[key] = []
        self.relationships[key].append((relationship, time.time(), source, turn_id))
        
        # åŒå‘å­˜å‚¨
        key_reverse = (entity2, entity1)
        if key_reverse not in self.relationships:
            self.relationships[key_reverse] = []
        self.relationships[key_reverse].append((relationship, time.time(), source, turn_id))
    
    def record_state(
        self,
        entity: str,
        state_type: str,
        value: str,
        source: str,
        turn_id: int = 0
    ):
        """è®°å½•çŠ¶æ€åˆ°ç¼“å­˜"""
        if entity not in self.entity_facts:
            self.entity_facts[entity] = {}
        if state_type not in self.entity_facts[entity]:
            self.entity_facts[entity][state_type] = []
        
        self.entity_facts[entity][state_type].append((value, time.time(), source, turn_id))
    
    def record_negation(
        self,
        entity: str,
        action: str,
        source: str
    ):
        """è®°å½•å¦å®šå£°æ˜"""
        if entity not in self.negations:
            self.negations[entity] = {}
        self.negations[entity][action] = source
    
    def get_conflicts(self, entity: str) -> List[str]:
        """è·å–æŸå®ä½“çš„å†²çª"""
        if entity not in self.entity_facts:
            return []
        
        conflicts = []
        for attr, values in self.entity_facts[entity].items():
            if len(values) > 1:
                unique_values = set(v[0] for v in values)
                if len(unique_values) > 1:
                    conflicts.append(f"{attr}: {unique_values}")
        
        return conflicts
    
    def get_entity_profile(self, entity: str) -> Dict[str, Any]:
        """è·å–å®ä½“çš„å®Œæ•´æ¡£æ¡ˆ"""
        profile = {
            'entity': entity,
            'attributes': {},
            'states': {},
            'relationships': [],
            'negations': [],
            'conflicts': []
        }
        
        # å±æ€§
        if entity in self.entity_facts:
            for attr, values in self.entity_facts[entity].items():
                if values:
                    # å–æœ€æ–°çš„å€¼
                    latest = max(values, key=lambda x: x[1])
                    profile['attributes'][attr] = latest[0]
                    
                    # æ£€æŸ¥å†²çª
                    unique_values = set(v[0] for v in values)
                    if len(unique_values) > 1:
                        profile['conflicts'].append({
                            'attribute': attr,
                            'values': list(unique_values)
                        })
        
        # å…³ç³»
        for (e1, e2), rels in self.relationships.items():
            if e1 == entity and rels:
                latest = max(rels, key=lambda x: x[1])
                profile['relationships'].append({
                    'target': e2,
                    'relationship': latest[0]
                })
        
        # å¦å®šå£°æ˜
        if entity in self.negations:
            profile['negations'] = list(self.negations[entity].keys())
        
        return profile
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–ä¸€è‡´æ€§æ£€æŸ¥æ‘˜è¦"""
        total_entities = len(self.entity_facts)
        entities_with_conflicts = 0
        total_conflicts = 0
        
        for entity, attrs in self.entity_facts.items():
            has_conflict = False
            for attr, values in attrs.items():
                unique_values = set(v[0] for v in values)
                if len(unique_values) > 1:
                    has_conflict = True
                    total_conflicts += 1
            if has_conflict:
                entities_with_conflicts += 1
        
        return {
            'total_entities': total_entities,
            'entities_with_conflicts': entities_with_conflicts,
            'total_conflicts': total_conflicts,
            'total_relationships': len(self.relationships) // 2,  # åŒå‘å­˜å‚¨ï¼Œé™¤ä»¥2
            'total_negations': sum(len(v) for v in self.negations.values()),
            'health_score': 1.0 - (entities_with_conflicts / max(total_entities, 1)),
            'absolute_rules_count': len(self.absolute_rules),
            'capabilities': [
                'æ•°å€¼å±æ€§æ£€æµ‹ (å¹´é¾„/èº«é«˜/ä½“é‡)',
                'å¤–è²Œå±æ€§æ£€æµ‹ (å‘è‰²/çœ¼è‰²/è‚¤è‰²)',
                'çŠ¶æ€å†²çªæ£€æµ‹ (ç”Ÿæ­»/å©šå§»)',
                'å…³ç³»å†²çªæ£€æµ‹ (æœ‹å‹vsæ•Œäºº)',
                'æ—¶é—´çº¿æ£€æµ‹ (å¹´é¾„ä¸€è‡´æ€§/äº‹ä»¶é¡ºåº)',
                'å¦å®šå¥è¿åæ£€æµ‹ (ä¸ä¼šXä½†åšäº†X)',
                'ç”Ÿæ­»çŸ›ç›¾æ£€æµ‹ (æ­»åè¡ŒåŠ¨)',
                'ç»å¯¹è§„åˆ™æ£€æµ‹ (LLMè¯­ä¹‰ç†è§£)',
            ]
        }

    # ========== ç»å¯¹è§„åˆ™æ£€æµ‹ï¼ˆLLMè¯­ä¹‰ç†è§£ï¼‰==========
    
    def set_llm_client(self, llm_client) -> None:
        """è®¾ç½®LLMå®¢æˆ·ç«¯ç”¨äºè§„åˆ™æ£€æµ‹
        
        Args:
            llm_client: LLMClientå®ä¾‹
        """
        self._llm_client = llm_client
        _safe_print(f"[ConsistencyChecker] LLMå®¢æˆ·ç«¯å·²è®¾ç½®ï¼Œç»å¯¹è§„åˆ™æ£€æµ‹å·²å¯ç”¨")
    
    def _check_absolute_rules(self, content: str) -> List[Violation]:
        """ä½¿ç”¨LLMæ£€æµ‹å†…å®¹æ˜¯å¦è¿åç»å¯¹è§„åˆ™
        
        è¿™æ˜¯çœŸæ­£çš„è¯­ä¹‰ç†è§£æ£€æµ‹ï¼Œæ”¯æŒä»»æ„å¤æ‚çš„è‡ªç„¶è¯­è¨€è§„åˆ™ã€‚
        """
        # æ²¡æœ‰è§„åˆ™æˆ–æ²¡æœ‰LLMå®¢æˆ·ç«¯ï¼Œè·³è¿‡
        if not self.absolute_rules:
            return []
        
        if not hasattr(self, '_llm_client') or self._llm_client is None:
            # æ²¡æœ‰LLMå®¢æˆ·ç«¯ï¼Œå›é€€åˆ°ç®€å•çš„å…³é”®è¯æ£€æµ‹ï¼ˆä½œä¸ºå…œåº•ï¼‰
            return self._check_absolute_rules_fallback(content)
        
        try:
            return self._check_rules_with_llm(content)
        except Exception as e:
            _safe_print(f"[ConsistencyChecker] LLMè§„åˆ™æ£€æµ‹å¤±è´¥: {e}ï¼Œå›é€€åˆ°å…³é”®è¯æ£€æµ‹")
            return self._check_absolute_rules_fallback(content)
    
    def _check_rules_with_llm(self, content: str) -> List[Violation]:
        """ä½¿ç”¨LLMè¿›è¡Œè¯­ä¹‰è§„åˆ™æ£€æµ‹"""
        violations = []
        
        # æ„å»ºè§„åˆ™åˆ—è¡¨æ–‡æœ¬
        rules_text = "\n".join([f"{i+1}. {rule}" for i, rule in enumerate(self.absolute_rules)])
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„è§„åˆ™æ£€æŸ¥å™¨ã€‚è¯·æ£€æŸ¥ä»¥ä¸‹å†…å®¹æ˜¯å¦è¿åäº†ä»»ä½•è§„åˆ™ã€‚

## è§„åˆ™åˆ—è¡¨ï¼ˆç”¨æˆ·å®šä¹‰çš„ç»å¯¹è§„åˆ™ï¼Œå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š
{rules_text}

## å¾…æ£€æŸ¥å†…å®¹ï¼š
{content[:2000]}

## æ£€æŸ¥è¦æ±‚ï¼š
1. ä»”ç»†ç†è§£æ¯æ¡è§„åˆ™çš„å«ä¹‰ï¼ˆå¯èƒ½æ˜¯ä¸€é•¿æ®µæè¿°ï¼‰
2. åˆ¤æ–­å†…å®¹æ˜¯å¦è¿åäº†ä»»ä½•è§„åˆ™
3. è€ƒè™‘è¯­ä¹‰ç­‰ä»·ï¼ˆå¦‚"å‘ç«"="ç”Ÿæ°”"="æ„¤æ€’"ï¼‰
4. è€ƒè™‘éšå«è¿åï¼ˆå¦‚è§„åˆ™æ˜¯"è§’è‰²æ¸©æŸ”"ï¼Œå†…å®¹æ˜¯"å¥¹ç‹ ç‹ åœ°è¸¢äº†ä»–ä¸€è„š"å°±æ˜¯è¿åï¼‰

## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆï¼‰ï¼š
å¦‚æœæ²¡æœ‰è¿åä»»ä½•è§„åˆ™ï¼Œåªè¾“å‡ºï¼š
PASS

å¦‚æœè¿åäº†è§„åˆ™ï¼ŒæŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼ˆæ¯ä¸ªè¿åä¸€è¡Œï¼‰ï¼š
VIOLATION|è§„åˆ™ç¼–å·|è¿åè¯´æ˜

ç¤ºä¾‹è¾“å‡ºï¼š
VIOLATION|1|å†…å®¹ä¸­è§’è‰²è¡¨ç°å‡ºæ„¤æ€’æƒ…ç»ªï¼Œè¿åäº†"è§’è‰²ä»ä¸å‘ç«"çš„è§„åˆ™
VIOLATION|3|å†…å®¹ä¸­å‡ºç°äº†è„è¯"XXX"ï¼Œè¿åäº†ç¦æ­¢è„è¯çš„è§„åˆ™

è¯·å¼€å§‹æ£€æŸ¥ï¼š"""

        try:
            # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®çš„æœ€å¤§ tokens
            max_tokens = int(os.environ.get('CONTRADICTION_MAX_TOKENS', '1000'))
            response = self._llm_client.complete(
                prompt=prompt,
                max_tokens=max_tokens,
                temperature=0.1  # ä½æ¸©åº¦ä¿è¯ä¸€è‡´æ€§
            )
            
            # è§£æå“åº”
            response_text = response.strip()
            
            if response_text == "PASS" or response_text.startswith("PASS"):
                return []
            
            # è§£æè¿è§„
            for line in response_text.split('\n'):
                line = line.strip()
                if line.startswith('VIOLATION|'):
                    parts = line.split('|', 2)
                    if len(parts) >= 3:
                        try:
                            rule_num = int(parts[1]) - 1
                            description = parts[2]
                            rule_text = self.absolute_rules[rule_num] if 0 <= rule_num < len(self.absolute_rules) else "æœªçŸ¥è§„åˆ™"
                            
                            violations.append(Violation(
                                type=ViolationType.LOGIC_ERROR,
                                description=f"è¿åè§„åˆ™ã€Œ{rule_text[:50]}{'...' if len(rule_text) > 50 else ''}ã€ï¼š{description}",
                                evidence=[content[:200]],
                                severity=0.9,
                                suggested_resolution=f"è¯·ä¿®æ”¹å†…å®¹ä»¥ç¬¦åˆè§„åˆ™"
                            ))
                        except (ValueError, IndexError):
                            continue
            
            return violations
            
        except Exception as e:
            _safe_print(f"[ConsistencyChecker] LLMè°ƒç”¨å¤±è´¥: {e}")
            return []
    
    def _check_absolute_rules_fallback(self, content: str) -> List[Violation]:
        """æ—  LLM æ—¶çš„å›é€€å¤„ç†
        
        ç”±äºç”¨æˆ·å®šä¹‰çš„ç»å¯¹è§„åˆ™é€šå¸¸æ˜¯å¤æ‚çš„è‡ªç„¶è¯­è¨€æè¿°ï¼ˆå¦‚"è§’è‰²æ€§æ ¼æ¸©æŸ”"ã€
        "æ•…äº‹èƒŒæ™¯æ˜¯å¤ä»£"ï¼‰ï¼Œç®€å•çš„å…³é”®è¯åŒ¹é…æ— æ³•å‡†ç¡®æ£€æµ‹ã€‚
        
        å› æ­¤ï¼Œå½“æ²¡æœ‰ LLM æ—¶ï¼Œæˆ‘ä»¬åªè¿”å›ä¸€ä¸ªæç¤ºæ€§è­¦å‘Šï¼Œå»ºè®®ç”¨æˆ·é…ç½® LLMã€‚
        """
        # å¦‚æœæœ‰è§„åˆ™ä½†æ²¡æœ‰ LLMï¼Œé¦–æ¬¡è°ƒç”¨æ—¶æç¤ºä¸€æ¬¡
        if self.absolute_rules and not hasattr(self, '_fallback_warned'):
            self._fallback_warned = True
            _safe_print(f"[ConsistencyChecker] âš ï¸ æ£€æµ‹åˆ° {len(self.absolute_rules)} æ¡ç»å¯¹è§„åˆ™ï¼Œä½†æœªé…ç½® LLM")
            _safe_print(f"[ConsistencyChecker]    ç»å¯¹è§„åˆ™éœ€è¦è¯­ä¹‰ç†è§£æ‰èƒ½å‡†ç¡®æ£€æµ‹")
            _safe_print(f"[ConsistencyChecker]    å»ºè®®åœ¨ api_keys.env ä¸­é…ç½® LLM_API_KEY ä»¥å¯ç”¨è¯­ä¹‰æ£€æµ‹")
        
        # ä¸åšè¯¯å¯¼æ€§çš„å…³é”®è¯æ£€æµ‹ï¼Œç›´æ¥è¿”å›ç©º
        # ç”¨æˆ·è‡ªå®šä¹‰çš„è§„åˆ™ï¼ˆå¦‚"è§’è‰²æ¸©æŸ”"ï¼‰æ— æ³•é€šè¿‡å…³é”®è¯åŒ¹é…
        return []
    
    def update_rules(self, rules: List[str]) -> None:
        """æ›´æ–°ç»å¯¹è§„åˆ™ï¼ˆè¿è¡Œæ—¶æ›´æ–°ï¼‰"""
        # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²ã€çº¯ç©ºç™½è§„åˆ™ï¼Œå¹¶å»é‡
        self.absolute_rules = self._dedupe_rules(rules)
        llm_status = "LLMè¯­ä¹‰æ£€æµ‹" if self._llm_client else "âš ï¸ æ— LLMï¼ˆè§„åˆ™æ£€æµ‹æœªç”Ÿæ•ˆï¼‰"
        _safe_print(f"[ConsistencyChecker] å·²æ›´æ–° {len(self.absolute_rules)} æ¡ç»å¯¹è§„åˆ™ï¼ˆ{llm_status}ï¼‰")
    
    def _dedupe_rules(self, rules: List[str]) -> List[str]:
        """å»é‡è§„åˆ™åˆ—è¡¨ï¼Œä¿æŒé¡ºåº"""
        seen = set()
        result = []
        for r in rules:
            if not r or not r.strip():
                continue
            normalized = r.strip()
            if normalized not in seen:
                seen.add(normalized)
                result.append(normalized)
        return result

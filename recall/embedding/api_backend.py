"""API Embedding åç«¯ - æ”¯æŒ OpenAI å’Œç¡…åŸºæµåŠ¨"""

import os
import time
import threading
from typing import List, Optional
import numpy as np

from .base import EmbeddingBackend, EmbeddingConfig, EmbeddingBackendType


# Windows GBK ç¼–ç å…¼å®¹çš„å®‰å…¨æ‰“å°å‡½æ•°
def _safe_print(msg: str) -> None:
    """å®‰å…¨æ‰“å°å‡½æ•°ï¼Œæ›¿æ¢ emoji ä¸º ASCII ç­‰ä»·ç‰©ä»¥é¿å… Windows GBK ç¼–ç é”™è¯¯"""
    emoji_map = {
        'ğŸ“¥': '[IN]', 'ğŸ“¤': '[OUT]', 'ğŸ”': '[SEARCH]', 'âœ…': '[OK]', 'âŒ': '[FAIL]',
        'âš ï¸': '[WARN]', 'ğŸ’¾': '[SAVE]', 'ğŸ—ƒï¸': '[DB]', 'ğŸ§¹': '[CLEAN]', 'ğŸ“Š': '[STATS]',
        'ğŸ”„': '[SYNC]', 'ğŸ“¦': '[PKG]', 'ğŸš€': '[START]', 'ğŸ¯': '[TARGET]', 'ğŸ’¡': '[HINT]',
        'ğŸ”§': '[FIX]', 'ğŸ“': '[NOTE]', 'ğŸ‰': '[DONE]', 'â±ï¸': '[TIME]', 'ğŸŒ': '[NET]',
        'ğŸ§ ': '[BRAIN]', 'ğŸ’¬': '[CHAT]', 'ğŸ·ï¸': '[TAG]', 'ğŸ“': '[DIR]', 'ğŸ”’': '[LOCK]',
        'ğŸŒ±': '[PLANT]', 'ğŸ—‘ï¸': '[DEL]', 'ğŸ’«': '[MAGIC]', 'ğŸ­': '[MASK]', 'ğŸ“–': '[BOOK]',
        'âš¡': '[FAST]', 'ğŸ”¥': '[HOT]', 'ğŸ’': '[GEM]', 'ğŸŒŸ': '[STAR]', 'ğŸ¨': '[ART]'
    }
    for emoji, ascii_equiv in emoji_map.items():
        msg = msg.replace(emoji, ascii_equiv)
    try:
        print(msg)
    except UnicodeEncodeError:
        print(msg.encode('ascii', errors='replace').decode('ascii'))


class RateLimiter:
    """ç®€å•çš„é€Ÿç‡é™åˆ¶å™¨
    
    é™åˆ¶å•ä½æ—¶é—´å†…çš„è¯·æ±‚æ¬¡æ•°ï¼Œè¶…é™æ—¶è‡ªåŠ¨ç­‰å¾…ã€‚
    """
    
    def __init__(self, max_requests: int = 5, window_seconds: int = 60):
        """
        Args:
            max_requests: æ—¶é—´çª—å£å†…æœ€å¤§è¯·æ±‚æ•°
            window_seconds: æ—¶é—´çª—å£é•¿åº¦ï¼ˆç§’ï¼‰
        """
        self.max_requests = max_requests
        self.window_seconds = window_seconds
        self.requests: List[float] = []
        self._lock = threading.Lock()
    
    def acquire(self, timeout: float = 120.0) -> bool:
        """è·å–è®¸å¯ï¼Œè¶…é™æ—¶é˜»å¡ç­‰å¾…
        
        Args:
            timeout: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸè·å–è®¸å¯
        """
        start_time = time.time()
        
        while True:
            with self._lock:
                now = time.time()
                
                # æ¸…ç†è¿‡æœŸçš„è¯·æ±‚è®°å½•
                self.requests = [t for t in self.requests if now - t < self.window_seconds]
                
                # æ£€æŸ¥æ˜¯å¦å¯ä»¥å‘é€
                if len(self.requests) < self.max_requests:
                    self.requests.append(now)
                    return True
                
                # è®¡ç®—éœ€è¦ç­‰å¾…çš„æ—¶é—´
                oldest = min(self.requests) if self.requests else now
                wait_time = self.window_seconds - (now - oldest) + 0.1
            
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if time.time() - start_time + wait_time > timeout:
                _safe_print(f"[Embedding] é€Ÿç‡é™åˆ¶ç­‰å¾…è¶…æ—¶ ({timeout}ç§’)")
                return False
            
            # ç­‰å¾…
            _safe_print(f"[Embedding] API é™æµï¼Œç­‰å¾… {wait_time:.1f} ç§’...")
            time.sleep(min(wait_time, 10))  # æœ€å¤šç­‰å¾…10ç§’åé‡æ–°æ£€æŸ¥


class APIEmbeddingBackend(EmbeddingBackend):
    """API Embedding åç«¯
    
    æ”¯æŒï¼š
    - OpenAI text-embedding-3-small / text-embedding-3-large
    - ç¡…åŸºæµåŠ¨ BAAI/bge-large-zh-v1.5
    - è‡ªå®šä¹‰ OpenAI å…¼å®¹ APIï¼ˆä¸­è½¬ç«™ã€Azureã€Ollama ç­‰ï¼‰
    
    ä¼˜ç‚¹ï¼š
    - å†…å­˜å ç”¨æä½ (~50MB)
    - æ— éœ€ä¸‹è½½å¤§æ¨¡å‹
    - æ”¯æŒæœ€æ–°æ¨¡å‹
    
    ç¼ºç‚¹ï¼š
    - éœ€è¦ç½‘ç»œè¿æ¥
    - æœ‰ API è´¹ç”¨ï¼ˆå¾ˆä¾¿å®œï¼‰
    """
    
    # æ¨¡å‹ç»´åº¦æ˜ å°„
    MODEL_DIMENSIONS = {
        # OpenAI
        "text-embedding-3-small": 1536,
        "text-embedding-3-large": 3072,
        "text-embedding-ada-002": 1536,
        # ç¡…åŸºæµåŠ¨
        "BAAI/bge-large-zh-v1.5": 1024,
        "BAAI/bge-large-en-v1.5": 1024,
        "BAAI/bge-m3": 1024,
        # Google (é€šè¿‡å…¼å®¹æ¥å£)
        "text-embedding-004": 768,
        "embedding-001": 768,
        # v5.0 æ–°å¢
        "voyage-3": 1024,
        "voyage-3-lite": 512,
        "voyage-code-3": 1024,
        "embed-multilingual-v3.0": 1024,
        "embed-english-v3.0": 1024,
        "embed-multilingual-light-v3.0": 384,
    }
    
    # é»˜è®¤ API åŸºåœ°å€
    DEFAULT_BASES = {
        EmbeddingBackendType.OPENAI: "https://api.openai.com/v1",
        EmbeddingBackendType.SILICONFLOW: "https://api.siliconflow.cn/v1",
        EmbeddingBackendType.CUSTOM: None,  # å¿…é¡»æŒ‡å®š
    }
    
    def __init__(self, config: EmbeddingConfig, cache_dir: str = None):
        super().__init__(config, cache_dir=cache_dir)
        self._client = None
        
        # ç¡®å®š API åŸºåœ°å€ï¼ˆä¼˜å…ˆä½¿ç”¨é…ç½®ï¼Œç„¶åç¯å¢ƒå˜é‡ï¼Œæœ€åé»˜è®¤å€¼ï¼‰
        self.api_base = (
            config.api_base or 
            os.environ.get('EMBEDDING_API_BASE') or
            self.DEFAULT_BASES.get(config.backend, "https://api.openai.com/v1")
        )
        
        # è·å– API key
        self.api_key = config.api_key or self._get_api_key_from_env()
        
        # ç¡®å®šç»´åº¦ï¼ˆä¼˜å…ˆä½¿ç”¨é…ç½®ï¼Œç„¶åæŸ¥è¡¨ï¼‰
        self._dimension = config.dimension or self.MODEL_DIMENSIONS.get(
            config.api_model, 
            1536  # é»˜è®¤
        )
        
        # ã€æ–°å¢ã€‘é€Ÿç‡é™åˆ¶å™¨ - ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        rate_limit = int(os.environ.get('EMBEDDING_RATE_LIMIT', '10'))  # é»˜è®¤æ¯åˆ†é’Ÿ10æ¬¡
        rate_window = int(os.environ.get('EMBEDDING_RATE_WINDOW', '60'))  # é»˜è®¤60ç§’çª—å£
        self._rate_limiter = RateLimiter(max_requests=rate_limit, window_seconds=rate_window)
        # v5.0: è‡ªåŠ¨æ£€æµ‹ Embedding æä¾›å•†
        self._embedding_provider = self._detect_embedding_provider()
    
    def _get_api_key_from_env(self) -> Optional[str]:
        """ä»ç¯å¢ƒå˜é‡è·å– API key
        
        ç»Ÿä¸€ä½¿ç”¨ EMBEDDING_API_KEYï¼Œä¸ server.py é…ç½®ä¸€è‡´
        """
        return os.environ.get('EMBEDDING_API_KEY')
    
    @property
    def dimension(self) -> int:
        return self._dimension
    
    @property
    def is_available(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰ API key"""
        return bool(self.api_key)
    
    def _detect_embedding_provider(self) -> str:
        """æ ¹æ® api_base åŸŸåå’Œæ¨¡å‹åç§°è‡ªåŠ¨æ£€æµ‹ Embedding æä¾›å•†"""
        if self.api_base:
            from urllib.parse import urlparse
            hostname = urlparse(self.api_base.lower()).hostname or ''
            if hostname.endswith('.googleapis.com') or 'generativelanguage' in hostname:
                return 'google'
            if hostname.endswith('.voyageai.com') or 'voyage' in hostname:
                return 'voyage'
            if hostname.endswith('.cohere.com') or 'cohere' in hostname:
                return 'cohere'
            return 'openai'
        if self.config.api_model:
            model_lower = self.config.api_model.lower()
            if model_lower.startswith('voyage'):
                return 'voyage'
            if model_lower.startswith('embed-') and ('multilingual' in model_lower or 'english' in model_lower):
                return 'cohere'
            if model_lower.startswith('text-embedding-004') or model_lower.startswith('embedding-001'):
                return 'google'
        return 'openai'
    
    @property
    def client(self):
        """è·å– Embedding å®¢æˆ·ç«¯ï¼ˆv5.0: è‡ªåŠ¨é€‰æ‹©åç«¯ï¼‰"""
        if self._client is None:
            if not self.is_available:
                raise ValueError(
                    f"æœªé…ç½® API keyã€‚\n"
                    f"è¯·åœ¨é…ç½®æ–‡ä»¶ recall_data/config/api_keys.env ä¸­è®¾ç½®:\n"
                    f"  EMBEDDING_API_KEY=your-api-key\n"
                    f"  EMBEDDING_API_BASE=https://api.openai.com/v1"
                )
            if self._embedding_provider == 'google':
                self._client = self._create_google_embedding_client()
            elif self._embedding_provider == 'voyage':
                self._client = self._create_voyage_client()
            elif self._embedding_provider == 'cohere':
                self._client = self._create_cohere_client()
            else:
                self._client = self._create_openai_embedding_client()
        return self._client
    
    def _create_openai_embedding_client(self):
        """åˆ›å»º OpenAI Embedding å®¢æˆ·ç«¯"""
        from openai import OpenAI
        return OpenAI(api_key=self.api_key, base_url=self.api_base)
    
    def _create_google_embedding_client(self):
        """åˆ›å»º Google Embedding å®¢æˆ·ç«¯"""
        try:
            import google.generativeai as genai
            genai.configure(api_key=self.api_key)
            return genai
        except ImportError:
            raise ImportError("ä½¿ç”¨ Google Embedding éœ€è¦å®‰è£… google-generativeai: pip install google-generativeai")
    
    def _create_voyage_client(self):
        """åˆ›å»º Voyage AI å®¢æˆ·ç«¯"""
        try:
            import voyageai
            return voyageai.Client(api_key=self.api_key)
        except ImportError:
            raise ImportError("ä½¿ç”¨ Voyage Embedding éœ€è¦å®‰è£… voyageai: pip install voyageai")
    
    def _create_cohere_client(self):
        """åˆ›å»º Cohere å®¢æˆ·ç«¯"""
        try:
            import cohere
            return cohere.Client(api_key=self.api_key)
        except ImportError:
            raise ImportError("ä½¿ç”¨ Cohere Embedding éœ€è¦å®‰è£… cohere: pip install cohere")
    
    def encode(self, text: str) -> np.ndarray:
        """ç¼–ç å•ä¸ªæ–‡æœ¬ï¼ˆv5.0: è‡ªåŠ¨è·¯ç”±åˆ°å¯¹åº”æä¾›å•†ï¼‰"""
        if self._embedding_provider == 'google':
            return self._encode_google(text)
        elif self._embedding_provider == 'voyage':
            return self._encode_voyage(text)
        elif self._embedding_provider == 'cohere':
            return self._encode_cohere(text)
        else:
            return self._encode_openai(text)
    
    def _encode_openai(self, text: str) -> np.ndarray:
        """OpenAI Embedding ç¼–ç ï¼ˆå¸¦é€Ÿç‡é™åˆ¶å’Œé‡è¯•ï¼‰"""
        max_retries = 3
        
        for attempt in range(max_retries):
            # ç­‰å¾…é€Ÿç‡é™åˆ¶è®¸å¯
            if not self._rate_limiter.acquire():
                raise RuntimeError("Embedding API é€Ÿç‡é™åˆ¶è¶…æ—¶")
            
            try:
                response = self.client.embeddings.create(
                    model=self.config.api_model,
                    input=text
                )
                embedding = np.array(response.data[0].embedding, dtype='float32')
                
                if self.config.normalize:
                    embedding = embedding / np.linalg.norm(embedding)
                
                return embedding
                
            except Exception as e:
                error_str = str(e).lower()
                
                # å¤„ç† 429 é”™è¯¯ï¼ˆé€Ÿç‡é™åˆ¶ï¼‰
                if '429' in error_str or 'rate limit' in error_str:
                    if attempt < max_retries - 1:
                        wait_time = (attempt + 1) * 3  # æ›´å¿«é€€é¿: 3, 6, 9 ç§’ï¼ˆæ€»å…±æœ€å¤š18ç§’ï¼‰
                        _safe_print(f"[Embedding] API é™æµ (429)ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯• ({attempt + 1}/{max_retries})")
                        time.sleep(wait_time)
                        continue
                
                # å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡º
                raise
        
        raise RuntimeError(f"Embedding API è°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡")
    
    def _encode_google(self, text: str) -> np.ndarray:
        """Google Embedding ç¼–ç """
        if not self._rate_limiter.acquire():
            raise RuntimeError("Embedding API é€Ÿç‡é™åˆ¶è¶…æ—¶")
        result = self.client.embed_content(
            model=f"models/{self.config.api_model}",
            content=text
        )
        embedding = np.array(result['embedding'], dtype='float32')
        if self.config.normalize:
            embedding = embedding / np.linalg.norm(embedding)
        return embedding
    
    def _encode_voyage(self, text: str) -> np.ndarray:
        """Voyage AI Embedding ç¼–ç """
        if not self._rate_limiter.acquire():
            raise RuntimeError("Embedding API é€Ÿç‡é™åˆ¶è¶…æ—¶")
        result = self.client.embed([text], model=self.config.api_model)
        embedding = np.array(result.embeddings[0], dtype='float32')
        if self.config.normalize:
            embedding = embedding / np.linalg.norm(embedding)
        return embedding
    
    def _encode_cohere(self, text: str) -> np.ndarray:
        """Cohere Embedding ç¼–ç """
        if not self._rate_limiter.acquire():
            raise RuntimeError("Embedding API é€Ÿç‡é™åˆ¶è¶…æ—¶")
        result = self.client.embed(
            texts=[text],
            model=self.config.api_model,
            input_type="search_document"
        )
        embedding = np.array(result.embeddings[0], dtype='float32')
        if self.config.normalize:
            embedding = embedding / np.linalg.norm(embedding)
        return embedding
    
    def encode_batch(self, texts: List[str]) -> np.ndarray:
        """æ‰¹é‡ç¼–ç ï¼ˆv5.0: è‡ªåŠ¨è·¯ç”±åˆ°å¯¹åº”æä¾›å•†ï¼‰"""
        if self._embedding_provider == 'google':
            return self._encode_batch_google(texts)
        elif self._embedding_provider == 'voyage':
            return self._encode_batch_voyage(texts)
        elif self._embedding_provider == 'cohere':
            return self._encode_batch_cohere(texts)
        else:
            return self._encode_batch_openai(texts)
    
    def _encode_batch_openai(self, texts: List[str]) -> np.ndarray:
        """OpenAI æ‰¹é‡ç¼–ç ï¼ˆå¸¦é€Ÿç‡é™åˆ¶å’Œé‡è¯•ï¼‰"""
        # API é€šå¸¸æœ‰æ‰¹é‡é™åˆ¶ï¼Œåˆ†æ‰¹å¤„ç†
        all_embeddings = []
        batch_size = min(self.config.batch_size, 100)  # OpenAI é™åˆ¶
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            
            max_retries = 3
            for attempt in range(max_retries):
                # ç­‰å¾…é€Ÿç‡é™åˆ¶è®¸å¯
                if not self._rate_limiter.acquire():
                    raise RuntimeError("Embedding API é€Ÿç‡é™åˆ¶è¶…æ—¶")
                
                try:
                    response = self.client.embeddings.create(
                        model=self.config.api_model,
                        input=batch
                    )
                    
                    for item in response.data:
                        embedding = np.array(item.embedding, dtype='float32')
                        if self.config.normalize:
                            embedding = embedding / np.linalg.norm(embedding)
                        all_embeddings.append(embedding)
                    
                    break  # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    
                except Exception as e:
                    error_str = str(e).lower()
                    
                    # å¤„ç† 429 é”™è¯¯
                    if '429' in error_str or 'rate limit' in error_str:
                        if attempt < max_retries - 1:
                            wait_time = (attempt + 1) * 3  # æ›´å¿«é€€é¿: 3, 6, 9 ç§’
                            _safe_print(f"[Embedding] API é™æµ (429)ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•")
                            time.sleep(wait_time)
                            continue
                    
                    raise
        
        return np.array(all_embeddings)
    
    def _encode_batch_google(self, texts: List[str]) -> np.ndarray:
        """Google Embedding æ‰¹é‡ç¼–ç """
        all_embeddings = []
        for text in texts:
            if not self._rate_limiter.acquire():
                raise RuntimeError("Embedding API é€Ÿç‡é™åˆ¶è¶…æ—¶")
            result = self.client.embed_content(
                model=f"models/{self.config.api_model}",
                content=text
            )
            embedding = np.array(result['embedding'], dtype='float32')
            if self.config.normalize:
                embedding = embedding / np.linalg.norm(embedding)
            all_embeddings.append(embedding)
        return np.array(all_embeddings)
    
    def _encode_batch_voyage(self, texts: List[str]) -> np.ndarray:
        """Voyage AI Embedding æ‰¹é‡ç¼–ç """
        all_embeddings = []
        batch_size = min(self.config.batch_size, 128)
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            if not self._rate_limiter.acquire():
                raise RuntimeError("Embedding API é€Ÿç‡é™åˆ¶è¶…æ—¶")
            result = self.client.embed(batch, model=self.config.api_model)
            for emb in result.embeddings:
                embedding = np.array(emb, dtype='float32')
                if self.config.normalize:
                    embedding = embedding / np.linalg.norm(embedding)
                all_embeddings.append(embedding)
        return np.array(all_embeddings)
    
    def _encode_batch_cohere(self, texts: List[str]) -> np.ndarray:
        """Cohere Embedding æ‰¹é‡ç¼–ç """
        all_embeddings = []
        batch_size = min(self.config.batch_size, 96)
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            if not self._rate_limiter.acquire():
                raise RuntimeError("Embedding API é€Ÿç‡é™åˆ¶è¶…æ—¶")
            result = self.client.embed(
                texts=batch,
                model=self.config.api_model,
                input_type="search_document"
            )
            for emb in result.embeddings:
                embedding = np.array(emb, dtype='float32')
                if self.config.normalize:
                    embedding = embedding / np.linalg.norm(embedding)
                all_embeddings.append(embedding)
        return np.array(all_embeddings)

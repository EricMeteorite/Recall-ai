"""API Embedding åç«¯ - æ”¯æŒ OpenAI å’Œç¡…åŸºæµåŠ¨"""

import os
import time
import threading
from typing import List, Optional
import numpy as np

from .base import EmbeddingBackend, EmbeddingConfig, EmbeddingBackendType


# Windows GBK ç¼–ç å…¼å®¹çš„å®‰å…¨æ‰“å°å‡½æ•°
def _safe_print(msg: str) -> None:
    """å®‰å…¨æ‰“å°å‡½æ•°ï¼Œæ›¿æ¢ emoji ä¸º ASCII ç­‰ä»·ç‰©ä»¥é¿å… Windows GBK ç¼–ç é”™è¯¯"""
    emoji_map = {
        'ğŸ“¥': '[IN]', 'ğŸ“¤': '[OUT]', 'ğŸ”': '[SEARCH]', 'âœ…': '[OK]', 'âŒ': '[FAIL]',
        'âš ï¸': '[WARN]', 'ğŸ’¾': '[SAVE]', 'ğŸ—ƒï¸': '[DB]', 'ğŸ§¹': '[CLEAN]', 'ğŸ“Š': '[STATS]',
        'ğŸ”„': '[SYNC]', 'ğŸ“¦': '[PKG]', 'ğŸš€': '[START]', 'ğŸ¯': '[TARGET]', 'ğŸ’¡': '[HINT]',
        'ğŸ”§': '[FIX]', 'ğŸ“': '[NOTE]', 'ğŸ‰': '[DONE]', 'â±ï¸': '[TIME]', 'ğŸŒ': '[NET]',
        'ğŸ§ ': '[BRAIN]', 'ğŸ’¬': '[CHAT]', 'ğŸ·ï¸': '[TAG]', 'ğŸ“': '[DIR]', 'ğŸ”’': '[LOCK]',
        'ğŸŒ±': '[PLANT]', 'ğŸ—‘ï¸': '[DEL]', 'ğŸ’«': '[MAGIC]', 'ğŸ­': '[MASK]', 'ğŸ“–': '[BOOK]',
        'âš¡': '[FAST]', 'ğŸ”¥': '[HOT]', 'ğŸ’': '[GEM]', 'ğŸŒŸ': '[STAR]', 'ğŸ¨': '[ART]'
    }
    for emoji, ascii_equiv in emoji_map.items():
        msg = msg.replace(emoji, ascii_equiv)
    try:
        print(msg)
    except UnicodeEncodeError:
        print(msg.encode('ascii', errors='replace').decode('ascii'))


class RateLimiter:
    """ç®€å•çš„é€Ÿç‡é™åˆ¶å™¨
    
    é™åˆ¶å•ä½æ—¶é—´å†…çš„è¯·æ±‚æ¬¡æ•°ï¼Œè¶…é™æ—¶è‡ªåŠ¨ç­‰å¾…ã€‚
    """
    
    def __init__(self, max_requests: int = 5, window_seconds: int = 60):
        """
        Args:
            max_requests: æ—¶é—´çª—å£å†…æœ€å¤§è¯·æ±‚æ•°
            window_seconds: æ—¶é—´çª—å£é•¿åº¦ï¼ˆç§’ï¼‰
        """
        self.max_requests = max_requests
        self.window_seconds = window_seconds
        self.requests: List[float] = []
        self._lock = threading.Lock()
    
    def acquire(self, timeout: float = 120.0) -> bool:
        """è·å–è®¸å¯ï¼Œè¶…é™æ—¶é˜»å¡ç­‰å¾…
        
        Args:
            timeout: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸè·å–è®¸å¯
        """
        start_time = time.time()
        
        while True:
            with self._lock:
                now = time.time()
                
                # æ¸…ç†è¿‡æœŸçš„è¯·æ±‚è®°å½•
                self.requests = [t for t in self.requests if now - t < self.window_seconds]
                
                # æ£€æŸ¥æ˜¯å¦å¯ä»¥å‘é€
                if len(self.requests) < self.max_requests:
                    self.requests.append(now)
                    return True
                
                # è®¡ç®—éœ€è¦ç­‰å¾…çš„æ—¶é—´
                oldest = min(self.requests) if self.requests else now
                wait_time = self.window_seconds - (now - oldest) + 0.1
            
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if time.time() - start_time + wait_time > timeout:
                _safe_print(f"[Embedding] é€Ÿç‡é™åˆ¶ç­‰å¾…è¶…æ—¶ ({timeout}ç§’)")
                return False
            
            # ç­‰å¾…
            _safe_print(f"[Embedding] API é™æµï¼Œç­‰å¾… {wait_time:.1f} ç§’...")
            time.sleep(min(wait_time, 10))  # æœ€å¤šç­‰å¾…10ç§’åé‡æ–°æ£€æŸ¥


class APIEmbeddingBackend(EmbeddingBackend):
    """API Embedding åç«¯
    
    æ”¯æŒï¼š
    - OpenAI text-embedding-3-small / text-embedding-3-large
    - ç¡…åŸºæµåŠ¨ BAAI/bge-large-zh-v1.5
    - è‡ªå®šä¹‰ OpenAI å…¼å®¹ APIï¼ˆä¸­è½¬ç«™ã€Azureã€Ollama ç­‰ï¼‰
    
    ä¼˜ç‚¹ï¼š
    - å†…å­˜å ç”¨æä½ (~50MB)
    - æ— éœ€ä¸‹è½½å¤§æ¨¡å‹
    - æ”¯æŒæœ€æ–°æ¨¡å‹
    
    ç¼ºç‚¹ï¼š
    - éœ€è¦ç½‘ç»œè¿æ¥
    - æœ‰ API è´¹ç”¨ï¼ˆå¾ˆä¾¿å®œï¼‰
    """
    
    # æ¨¡å‹ç»´åº¦æ˜ å°„
    MODEL_DIMENSIONS = {
        # OpenAI
        "text-embedding-3-small": 1536,
        "text-embedding-3-large": 3072,
        "text-embedding-ada-002": 1536,
        # ç¡…åŸºæµåŠ¨
        "BAAI/bge-large-zh-v1.5": 1024,
        "BAAI/bge-large-en-v1.5": 1024,
        "BAAI/bge-m3": 1024,
        # Google (é€šè¿‡å…¼å®¹æ¥å£)
        "text-embedding-004": 768,
        "embedding-001": 768,
    }
    
    # é»˜è®¤ API åŸºåœ°å€
    DEFAULT_BASES = {
        EmbeddingBackendType.OPENAI: "https://api.openai.com/v1",
        EmbeddingBackendType.SILICONFLOW: "https://api.siliconflow.cn/v1",
        EmbeddingBackendType.CUSTOM: None,  # å¿…é¡»æŒ‡å®š
    }
    
    def __init__(self, config: EmbeddingConfig):
        super().__init__(config)
        self._client = None
        
        # ç¡®å®š API åŸºåœ°å€ï¼ˆä¼˜å…ˆä½¿ç”¨é…ç½®ï¼Œç„¶åç¯å¢ƒå˜é‡ï¼Œæœ€åé»˜è®¤å€¼ï¼‰
        self.api_base = (
            config.api_base or 
            os.environ.get('EMBEDDING_API_BASE') or
            self.DEFAULT_BASES.get(config.backend, "https://api.openai.com/v1")
        )
        
        # è·å– API key
        self.api_key = config.api_key or self._get_api_key_from_env()
        
        # ç¡®å®šç»´åº¦ï¼ˆä¼˜å…ˆä½¿ç”¨é…ç½®ï¼Œç„¶åæŸ¥è¡¨ï¼‰
        self._dimension = config.dimension or self.MODEL_DIMENSIONS.get(
            config.api_model, 
            1536  # é»˜è®¤
        )
        
        # ã€æ–°å¢ã€‘é€Ÿç‡é™åˆ¶å™¨ - ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        rate_limit = int(os.environ.get('EMBEDDING_RATE_LIMIT', '10'))  # é»˜è®¤æ¯åˆ†é’Ÿ10æ¬¡
        rate_window = int(os.environ.get('EMBEDDING_RATE_WINDOW', '60'))  # é»˜è®¤60ç§’çª—å£
        self._rate_limiter = RateLimiter(max_requests=rate_limit, window_seconds=rate_window)
    
    def _get_api_key_from_env(self) -> Optional[str]:
        """ä»ç¯å¢ƒå˜é‡è·å– API key"""
        # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥
        if self.config.backend == EmbeddingBackendType.OPENAI:
            return os.environ.get('OPENAI_API_KEY')
        elif self.config.backend == EmbeddingBackendType.SILICONFLOW:
            return os.environ.get('SILICONFLOW_API_KEY')
        elif self.config.backend == EmbeddingBackendType.CUSTOM:
            # è‡ªå®šä¹‰æ¨¡å¼ï¼šæ£€æŸ¥é€šç”¨ç¯å¢ƒå˜é‡
            return (
                os.environ.get('EMBEDDING_API_KEY') or
                os.environ.get('OPENAI_API_KEY')  # å…¼å®¹
            )
        return os.environ.get('EMBEDDING_API_KEY')
    
    @property
    def dimension(self) -> int:
        return self._dimension
    
    @property
    def is_available(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰ API key"""
        return bool(self.api_key)
    
    @property
    def client(self):
        """è·å– OpenAI å®¢æˆ·ç«¯ï¼ˆå…¼å®¹ç¡…åŸºæµåŠ¨ï¼‰"""
        if self._client is None:
            if not self.is_available:
                raise ValueError(
                    f"æœªé…ç½® API keyã€‚\n"
                    f"è¯·è®¾ç½®ç¯å¢ƒå˜é‡æˆ–åœ¨é…ç½®ä¸­æä¾› api_keyã€‚\n"
                    f"OpenAI: OPENAI_API_KEY\n"
                    f"ç¡…åŸºæµåŠ¨: SILICONFLOW_API_KEY"
                )
            
            from openai import OpenAI
            self._client = OpenAI(
                api_key=self.api_key,
                base_url=self.api_base
            )
        return self._client
    
    def encode(self, text: str) -> np.ndarray:
        """ç¼–ç å•ä¸ªæ–‡æœ¬ï¼ˆå¸¦é€Ÿç‡é™åˆ¶å’Œé‡è¯•ï¼‰"""
        max_retries = 3
        
        for attempt in range(max_retries):
            # ç­‰å¾…é€Ÿç‡é™åˆ¶è®¸å¯
            if not self._rate_limiter.acquire():
                raise RuntimeError("Embedding API é€Ÿç‡é™åˆ¶è¶…æ—¶")
            
            try:
                response = self.client.embeddings.create(
                    model=self.config.api_model,
                    input=text
                )
                embedding = np.array(response.data[0].embedding, dtype='float32')
                
                if self.config.normalize:
                    embedding = embedding / np.linalg.norm(embedding)
                
                return embedding
                
            except Exception as e:
                error_str = str(e).lower()
                
                # å¤„ç† 429 é”™è¯¯ï¼ˆé€Ÿç‡é™åˆ¶ï¼‰
                if '429' in error_str or 'rate limit' in error_str:
                    if attempt < max_retries - 1:
                        wait_time = (attempt + 1) * 15  # æŒ‡æ•°é€€é¿: 15, 30, 45 ç§’
                        _safe_print(f"[Embedding] API é™æµ (429)ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯• ({attempt + 1}/{max_retries})")
                        time.sleep(wait_time)
                        continue
                
                # å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡º
                raise
        
        raise RuntimeError(f"Embedding API è°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡")
    
    def encode_batch(self, texts: List[str]) -> np.ndarray:
        """æ‰¹é‡ç¼–ç ï¼ˆå¸¦é€Ÿç‡é™åˆ¶å’Œé‡è¯•ï¼‰"""
        # API é€šå¸¸æœ‰æ‰¹é‡é™åˆ¶ï¼Œåˆ†æ‰¹å¤„ç†
        all_embeddings = []
        batch_size = min(self.config.batch_size, 100)  # OpenAI é™åˆ¶
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            
            max_retries = 3
            for attempt in range(max_retries):
                # ç­‰å¾…é€Ÿç‡é™åˆ¶è®¸å¯
                if not self._rate_limiter.acquire():
                    raise RuntimeError("Embedding API é€Ÿç‡é™åˆ¶è¶…æ—¶")
                
                try:
                    response = self.client.embeddings.create(
                        model=self.config.api_model,
                        input=batch
                    )
                    
                    for item in response.data:
                        embedding = np.array(item.embedding, dtype='float32')
                        if self.config.normalize:
                            embedding = embedding / np.linalg.norm(embedding)
                        all_embeddings.append(embedding)
                    
                    break  # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    
                except Exception as e:
                    error_str = str(e).lower()
                    
                    # å¤„ç† 429 é”™è¯¯
                    if '429' in error_str or 'rate limit' in error_str:
                        if attempt < max_retries - 1:
                            wait_time = (attempt + 1) * 15
                            _safe_print(f"[Embedding] API é™æµ (429)ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•")
                            time.sleep(wait_time)
                            continue
                    
                    raise
        
        return np.array(all_embeddings)

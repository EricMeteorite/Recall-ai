"""å…«å±‚æ¼æ–—æ£€ç´¢æ¶æ„"""

import time
from typing import List, Dict, Any, Optional, Set, Callable
from dataclasses import dataclass, field
from enum import Enum


# Windows GBK ç¼–ç å…¼å®¹çš„å®‰å…¨æ‰“å°å‡½æ•°
def _safe_print(msg: str) -> None:
    """å®‰å…¨æ‰“å°å‡½æ•°ï¼Œæ›¿æ¢ emoji ä¸º ASCII ç­‰ä»·ç‰©ä»¥é¿å… Windows GBK ç¼–ç é”™è¯¯"""
    emoji_map = {
        'ğŸ“¥': '[IN]', 'ğŸ“¤': '[OUT]', 'ğŸ”': '[SEARCH]', 'âœ…': '[OK]', 'âŒ': '[FAIL]',
        'âš ï¸': '[WARN]', 'ğŸ’¾': '[SAVE]', 'ğŸ—ƒï¸': '[DB]', 'ğŸ§¹': '[CLEAN]', 'ğŸ“Š': '[STATS]',
        'ğŸ”„': '[SYNC]', 'ğŸ“¦': '[PKG]', 'ğŸš€': '[START]', 'ğŸ¯': '[TARGET]', 'ğŸ’¡': '[HINT]',
        'ğŸ”§': '[FIX]', 'ğŸ“': '[NOTE]', 'ğŸ‰': '[DONE]', 'â±ï¸': '[TIME]', 'ğŸŒ': '[NET]',
        'ğŸ§ ': '[BRAIN]', 'ğŸ’¬': '[CHAT]', 'ğŸ·ï¸': '[TAG]', 'ğŸ“': '[DIR]', 'ğŸ”’': '[LOCK]',
        'ğŸŒ±': '[PLANT]', 'ğŸ—‘ï¸': '[DEL]', 'ğŸ’«': '[MAGIC]', 'ğŸ­': '[MASK]', 'ğŸ“–': '[BOOK]',
        'âš¡': '[FAST]', 'ğŸ”¥': '[HOT]', 'ğŸ’': '[GEM]', 'ğŸŒŸ': '[STAR]', 'ğŸ¨': '[ART]'
    }
    for emoji, ascii_equiv in emoji_map.items():
        msg = msg.replace(emoji, ascii_equiv)
    try:
        print(msg)
    except UnicodeEncodeError:
        print(msg.encode('ascii', errors='replace').decode('ascii'))


class RetrievalLayer(Enum):
    """æ£€ç´¢å±‚çº§"""
    L1_BLOOM_FILTER = "bloom_filter"           # å¸ƒéš†è¿‡æ»¤å™¨å¿«é€Ÿå¦å®š
    L2_INVERTED_INDEX = "inverted_index"       # å€’æ’ç´¢å¼•å…³é”®è¯åŒ¹é…
    L3_ENTITY_INDEX = "entity_index"           # å®ä½“ç´¢å¼•
    L4_NGRAM_INDEX = "ngram_index"             # N-gramç´¢å¼•
    L5_VECTOR_COARSE = "vector_coarse"         # å‘é‡ç²—ç­›
    L6_VECTOR_FINE = "vector_fine"             # å‘é‡ç²¾æ’
    L7_RERANK = "rerank"                       # é‡æ’åº
    L8_LLM_FILTER = "llm_filter"               # LLMè¿‡æ»¤


@dataclass
class RetrievalResult:
    """æ£€ç´¢ç»“æœ"""
    id: str
    content: str
    score: float
    source_layer: RetrievalLayer
    metadata: Dict[str, Any] = field(default_factory=dict)
    entities: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'id': self.id,
            'content': self.content,
            'score': self.score,
            'source_layer': self.source_layer.value,
            'metadata': self.metadata,
            'entities': self.entities
        }


@dataclass
class LayerStats:
    """å±‚çº§ç»Ÿè®¡"""
    layer: RetrievalLayer
    input_count: int
    output_count: int
    time_ms: float
    filtered_count: int = 0


class EightLayerRetriever:
    """å…«å±‚æ¼æ–—æ£€ç´¢å™¨
    
    æ£€ç´¢æµç¨‹ï¼š
    L1: å¸ƒéš†è¿‡æ»¤å™¨ - O(1) å¿«é€Ÿå¦å®šä¸å¯èƒ½çš„å€™é€‰
    L2: å€’æ’ç´¢å¼• - O(log n) å…³é”®è¯åŒ¹é…
    L3: å®ä½“ç´¢å¼• - O(1) å®ä½“å…³è”æŸ¥æ‰¾
    L4: N-gramç´¢å¼• - O(k) æ¨¡ç³ŠåŒ¹é…
    L5: å‘é‡ç²—ç­› - O(n) è¿‘ä¼¼æœ€è¿‘é‚»
    L6: å‘é‡ç²¾æ’ - O(k) ç²¾ç¡®è·ç¦»è®¡ç®—
    L7: é‡æ’åº - O(k log k) å¤šå› ç´ ç»¼åˆæ’åº
    L8: LLMè¿‡æ»¤ - O(k) è¯­ä¹‰ç›¸å…³æ€§åˆ¤æ–­
    """
    
    def __init__(
        self,
        bloom_filter: Optional[Any] = None,
        inverted_index: Optional[Any] = None,
        entity_index: Optional[Any] = None,
        ngram_index: Optional[Any] = None,
        vector_index: Optional[Any] = None,
        llm_client: Optional[Any] = None,
        content_store: Optional[Callable[[str], Optional[str]]] = None
    ):
        self.bloom_filter = bloom_filter
        self.inverted_index = inverted_index
        self.entity_index = entity_index
        self.ngram_index = ngram_index
        self.vector_index = vector_index
        self.llm_client = llm_client
        # å†…å®¹å­˜å‚¨å›è°ƒï¼šé€šè¿‡ ID æŸ¥è¯¢å†…å®¹
        self.content_store = content_store
        
        # å†…éƒ¨å†…å®¹ç¼“å­˜ï¼ˆç”¨äºç´¢å¼•æ—¶å­˜å‚¨å†…å®¹ï¼‰
        self._content_cache: Dict[str, str] = {}
        
        # ç»Ÿè®¡
        self.stats: List[LayerStats] = []
        
        # é…ç½®
        self.config = {
            'l1_enabled': True,
            'l2_enabled': True,
            'l3_enabled': True,
            'l4_enabled': True,
            'l5_enabled': True,
            'l6_enabled': True,
            'l7_enabled': True,
            'l8_enabled': False,  # LLMè¿‡æ»¤é»˜è®¤å…³é—­ï¼ˆæ¶ˆè€—èµ„æºï¼‰
            'l5_top_k': 100,      # ç²—ç­›è¿”å›æ•°é‡
            'l6_top_k': 20,       # ç²¾æ’è¿”å›æ•°é‡
            'l7_top_k': 10,       # é‡æ’åºè¿”å›æ•°é‡
            'l8_top_k': 5,        # LLMè¿‡æ»¤è¿”å›æ•°é‡
        }
    
    def cache_content(self, doc_id: str, content: str):
        """ç¼“å­˜æ–‡æ¡£å†…å®¹ï¼ˆåœ¨æ·»åŠ ç´¢å¼•æ—¶è°ƒç”¨ï¼‰"""
        self._content_cache[doc_id] = content
    
    def get_content(self, doc_id: str) -> str:
        """è·å–æ–‡æ¡£å†…å®¹"""
        # ä¼˜å…ˆä»ç¼“å­˜è·å–
        if doc_id in self._content_cache:
            return self._content_cache[doc_id]
        # å¦åˆ™ä»å¤–éƒ¨å­˜å‚¨è·å–
        if self.content_store:
            content = self.content_store(doc_id)
            if content:
                return content
        return ""
    
    def retrieve(
        self,
        query: str,
        entities: Optional[List[str]] = None,
        keywords: Optional[List[str]] = None,
        top_k: int = 10,
        filters: Optional[Dict[str, Any]] = None,
        temporal_context: Optional[Any] = None,  # Phase 3 å…¼å®¹ï¼šæ¥å—ä½†å¿½ç•¥
        config: Optional[Any] = None  # Phase 3 å…¼å®¹ï¼šæ¥å—ä½†å¿½ç•¥
    ) -> List[RetrievalResult]:
        """æ‰§è¡Œå…«å±‚æ£€ç´¢
        
        Note: temporal_context å’Œ config å‚æ•°ç”¨äº Phase 3 å…¼å®¹ï¼Œ
        åœ¨ EightLayerRetriever ä¸­è¢«å¿½ç•¥ï¼Œä»… ElevenLayerRetriever ä½¿ç”¨ã€‚
        """
        self.stats = []
        candidates: Set[str] = set()  # å€™é€‰IDé›†åˆ
        results: List[RetrievalResult] = []
        
        # L1: å¸ƒéš†è¿‡æ»¤å™¨ï¼ˆé¢„è¿‡æ»¤å…³é”®è¯ï¼‰
        filtered_keywords = keywords or []
        if self.config['l1_enabled'] and self.bloom_filter and keywords:
            start = time.time()
            # å¸ƒéš†è¿‡æ»¤å™¨ç”¨äºå¿«é€Ÿæ’é™¤ä¸å­˜åœ¨çš„å…³é”®è¯
            # ä½¿ç”¨ in è¿ç®—ç¬¦æ£€æŸ¥ï¼ˆBloomFilter å®ç°äº† __contains__ï¼‰
            filtered_keywords = [
                kw for kw in keywords 
                if kw in self.bloom_filter
            ]
            self._record_stats(RetrievalLayer.L1_BLOOM_FILTER, len(keywords), len(filtered_keywords), start)
        
        # L2: å€’æ’ç´¢å¼•
        if self.config['l2_enabled'] and self.inverted_index:
            start = time.time()
            input_count = len(candidates)
            
            # ä½¿ç”¨è¿‡æ»¤åçš„å…³é”®è¯ï¼ˆå¦‚æœL1å¯ç”¨ï¼‰æˆ–åŸå§‹å…³é”®è¯
            search_keywords = filtered_keywords if filtered_keywords else keywords
            if search_keywords:
                # ä½¿ç”¨ search_any æ¥æœç´¢ä»»ä¸€å…³é”®è¯
                inverted_results = self.inverted_index.search_any(search_keywords)
                candidates.update(inverted_results)
            
            self._record_stats(RetrievalLayer.L2_INVERTED_INDEX, input_count, len(candidates), start)
        
        # L3: å®ä½“ç´¢å¼•
        if self.config['l3_enabled'] and self.entity_index and entities:
            start = time.time()
            input_count = len(candidates)
            
            for entity in entities:
                entity_results = self.entity_index.get_related_turns(entity)
                # entity_results æ˜¯ IndexedEntity åˆ—è¡¨ï¼Œéœ€è¦æå– turn_references
                for indexed_entity in entity_results:
                    candidates.update(indexed_entity.turn_references)
            
            self._record_stats(RetrievalLayer.L3_ENTITY_INDEX, input_count, len(candidates), start)
        
        # L4: N-gramç´¢å¼•
        if self.config['l4_enabled'] and self.ngram_index:
            start = time.time()
            input_count = len(candidates)
            
            ngram_results = self.ngram_index.search(query)
            # ngram_results æ˜¯ turn_id åˆ—è¡¨ï¼Œä¸æ˜¯å…ƒç»„
            for doc_id in ngram_results:
                candidates.add(doc_id)
            
            self._record_stats(RetrievalLayer.L4_NGRAM_INDEX, input_count, len(candidates), start)
        
        # L5: å‘é‡ç²—ç­›
        # æ£€æŸ¥å‘é‡ç´¢å¼•æ˜¯å¦å­˜åœ¨ä¸”å¯ç”¨ï¼ˆæ”¯æŒ Lite æ¨¡å¼ï¼‰
        vector_enabled = self.vector_index and getattr(self.vector_index, 'enabled', True)
        if self.config['l5_enabled'] and vector_enabled:
            start = time.time()
            input_count = len(candidates)
            
            vector_results = self.vector_index.search(
                query, 
                top_k=self.config['l5_top_k']
            )
            
            # åˆå¹¶å‘é‡ç»“æœ
            for doc_id, score in vector_results:
                candidates.add(doc_id)
                # è·å–å®é™…å†…å®¹
                content = self.get_content(doc_id)
                results.append(RetrievalResult(
                    id=doc_id,
                    content=content,
                    score=score,
                    source_layer=RetrievalLayer.L5_VECTOR_COARSE
                ))
            
            self._record_stats(RetrievalLayer.L5_VECTOR_COARSE, input_count, len(results), start)
        
        # å…³é”®ï¼šå°† L2-L4 æ”¶é›†çš„å€™é€‰ ID ä¹Ÿè½¬æ¢ä¸ºç»“æœ
        # è¿™ç¡®ä¿äº† Lite æ¨¡å¼ï¼ˆæ— å‘é‡ç´¢å¼•ï¼‰ä¹Ÿèƒ½è¿”å›ç»“æœ
        seen_ids = {r.id for r in results}
        for doc_id in candidates:
            if doc_id not in seen_ids:
                content = self.get_content(doc_id)
                if content:  # åªæ·»åŠ æœ‰å†…å®¹çš„ç»“æœ
                    results.append(RetrievalResult(
                        id=doc_id,
                        content=content,
                        score=0.5,  # å…³é”®è¯/å®ä½“åŒ¹é…çš„åŸºç¡€åˆ†æ•°
                        source_layer=RetrievalLayer.L4_NGRAM_INDEX
                    ))
                    seen_ids.add(doc_id)
        
        # L6: å‘é‡ç²¾æ’ï¼ˆå®Œæ•´å®ç° - é‡æ–°è®¡ç®—ç²¾ç¡®å‘é‡è·ç¦»ï¼‰
        if self.config['l6_enabled'] and vector_enabled and results:
            start = time.time()
            input_count = len(results)
            
            # å®Œæ•´å®ç°ï¼šé‡æ–°è®¡ç®—æŸ¥è¯¢ä¸å€™é€‰æ–‡æ¡£çš„ç²¾ç¡®ä½™å¼¦ç›¸ä¼¼åº¦
            results = self._vector_fine_ranking(query, results)
            results = results[:self.config['l6_top_k']]
            
            for r in results:
                r.source_layer = RetrievalLayer.L6_VECTOR_FINE
            
            self._record_stats(RetrievalLayer.L6_VECTOR_FINE, input_count, len(results), start)
        
        # L7: é‡æ’åº
        if self.config['l7_enabled'] and results:
            start = time.time()
            input_count = len(results)
            
            results = self._rerank(results, query, entities, keywords)
            results = results[:self.config['l7_top_k']]
            
            for r in results:
                r.source_layer = RetrievalLayer.L7_RERANK
            
            self._record_stats(RetrievalLayer.L7_RERANK, input_count, len(results), start)
        
        # L8: LLMè¿‡æ»¤
        if self.config['l8_enabled'] and self.llm_client and results:
            start = time.time()
            input_count = len(results)
            
            results = self._llm_filter(results, query)
            results = results[:self.config['l8_top_k']]
            
            self._record_stats(RetrievalLayer.L8_LLM_FILTER, input_count, len(results), start)
        
        # ç»ˆæå…œåº•ï¼šå¦‚æœæ‰€æœ‰å±‚éƒ½æ²¡æ‰¾åˆ°ç»“æœï¼Œä½¿ç”¨ N-gram åŸæ–‡æœç´¢
        # è¿™ç¡®ä¿äº†"100%ä¸é—å¿˜"â€”â€”åªè¦åŸæ–‡ä¸­åŒ…å«æŸ¥è¯¢å†…å®¹å°±èƒ½æ‰¾åˆ°
        if not results and self.ngram_index:
            start = time.time()
            # è°ƒç”¨ raw_search ç›´æ¥æœç´¢åŸæ–‡
            if hasattr(self.ngram_index, 'raw_search'):
                fallback_ids = self.ngram_index.raw_search(query, max_results=top_k)
            else:
                fallback_ids = self.ngram_index.search(query)
            
            for doc_id in fallback_ids[:top_k]:
                content = self.get_content(doc_id)
                if content:
                    results.append(RetrievalResult(
                        id=doc_id,
                        content=content,
                        score=0.3,  # å…œåº•æœç´¢çš„åŸºç¡€åˆ†æ•°
                        source_layer=RetrievalLayer.L4_NGRAM_INDEX,
                        metadata={'fallback': True}  # æ ‡è®°ä¸ºå…œåº•ç»“æœ
                    ))
            
            if results:
                self._record_stats(RetrievalLayer.L4_NGRAM_INDEX, 0, len(results), start)
        
        return results[:top_k]
    
    def _vector_fine_ranking(
        self,
        query: str,
        results: List[RetrievalResult]
    ) -> List[RetrievalResult]:
        """L6 å‘é‡ç²¾æ’ - ä½¿ç”¨å·²å­˜å‚¨çš„å‘é‡è®¡ç®—ç²¾ç¡®ç›¸ä¼¼åº¦
        
        ä¼˜åŒ–ï¼šç›´æ¥ä» FAISS ç´¢å¼•è·å–å·²å­˜å‚¨çš„æ–‡æ¡£å‘é‡ï¼Œ
        é¿å…é‡å¤è°ƒç”¨ encode() APIï¼ˆè¿™ä¼šæ¶ˆè€—å¤§é‡é…é¢ï¼‰ã€‚
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            results: L5 ç²—ç­›åçš„å€™é€‰ç»“æœ
        
        Returns:
            æŒ‰ç²¾ç¡®ç›¸ä¼¼åº¦é‡æ–°æ’åºçš„ç»“æœ
        """
        if not self.vector_index or not results:
            # æ²¡æœ‰å‘é‡ç´¢å¼•ï¼Œå›é€€åˆ°ç®€å•æ’åº
            return sorted(results, key=lambda r: -r.score)
        
        try:
            import numpy as np
            
            # 1. è·å–æŸ¥è¯¢å‘é‡ï¼ˆåªéœ€è¦ç¼–ç ä¸€æ¬¡ï¼‰
            query_embedding = self.vector_index.encode(query)
            query_embedding = query_embedding / np.linalg.norm(query_embedding)  # å½’ä¸€åŒ–
            
            # 2. æ‰¹é‡è·å–å€™é€‰æ–‡æ¡£çš„å·²å­˜å‚¨å‘é‡ï¼ˆä¸è°ƒç”¨ APIï¼ï¼‰
            doc_ids = [r.id for r in results]
            stored_vectors = {}
            if hasattr(self.vector_index, 'get_vectors_by_doc_ids'):
                stored_vectors = self.vector_index.get_vectors_by_doc_ids(doc_ids)
            
            # 3. å¯¹æ¯ä¸ªå€™é€‰æ–‡æ¡£è®¡ç®—ç²¾ç¡®ç›¸ä¼¼åº¦
            for result in results:
                doc_id = result.id
                
                # ä¼˜å…ˆä½¿ç”¨å·²å­˜å‚¨çš„å‘é‡
                if doc_id in stored_vectors:
                    doc_embedding = stored_vectors[doc_id]
                    doc_embedding = doc_embedding / np.linalg.norm(doc_embedding)  # å½’ä¸€åŒ–
                    
                    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                    cosine_sim = float(np.dot(query_embedding, doc_embedding))
                    
                    # æ›´æ–°åˆ†æ•°
                    result.score = 0.7 * cosine_sim + 0.3 * result.score
                    result.metadata['l6_cosine_sim'] = cosine_sim
                    result.metadata['l6_source'] = 'stored_vector'
                else:
                    # æ²¡æœ‰å­˜å‚¨çš„å‘é‡ï¼ˆå¯èƒ½æ˜¯æ—§æ•°æ®ï¼‰ï¼Œä¿æŒåŸåˆ†æ•°
                    result.metadata['l6_source'] = 'no_vector'
            
            # 4. æŒ‰æ–°åˆ†æ•°æ’åº
            return sorted(results, key=lambda r: -r.score)
            
        except Exception as e:
            # æ•´ä½“å¤±è´¥ï¼Œå›é€€åˆ°ç®€å•æ’åº
            _safe_print(f"[EightLayerRetriever] L6 ç²¾æ’å¤±è´¥ï¼Œå›é€€åˆ°ç®€å•æ’åº: {e}")
            return sorted(results, key=lambda r: -r.score)
    
    def _rerank(
        self,
        results: List[RetrievalResult],
        query: str,
        entities: Optional[List[str]],
        keywords: Optional[List[str]]
    ) -> List[RetrievalResult]:
        """é‡æ’åº"""
        for result in results:
            bonus = 0.0
            
            # å®ä½“åŒ¹é…åŠ åˆ†
            if entities:
                matched_entities = set(result.entities) & set(entities)
                bonus += len(matched_entities) * 0.1
            
            # å…³é”®è¯åŒ¹é…åŠ åˆ†
            if keywords:
                for kw in keywords:
                    if kw.lower() in result.content.lower():
                        bonus += 0.05
            
            # æ–°é²œåº¦åŠ åˆ†ï¼ˆå¦‚æœæœ‰æ—¶é—´æˆ³ï¼‰
            if 'timestamp' in result.metadata:
                recency = time.time() - result.metadata['timestamp']
                if recency < 3600:  # 1å°æ—¶å†…
                    bonus += 0.1
                elif recency < 86400:  # 1å¤©å†…
                    bonus += 0.05
            
            result.score += bonus
        
        return sorted(results, key=lambda r: -r.score)
    
    def _llm_filter(
        self,
        results: List[RetrievalResult],
        query: str
    ) -> List[RetrievalResult]:
        """ä½¿ç”¨LLMè¿‡æ»¤ä¸ç›¸å…³ç»“æœ"""
        if not self.llm_client:
            return results
        
        prompt = f"""åˆ¤æ–­ä»¥ä¸‹è®°å¿†æ˜¯å¦ä¸æŸ¥è¯¢ç›¸å…³ã€‚

æŸ¥è¯¢ï¼š{query}

è®°å¿†åˆ—è¡¨ï¼š
{chr(10).join([f"{i+1}. {r.content[:100]}" for i, r in enumerate(results)])}

è¯·è¿”å›ç›¸å…³è®°å¿†çš„ç¼–å·ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰ï¼Œå¦‚æœéƒ½ä¸ç›¸å…³è¿”å›"æ— "ï¼š"""
        
        try:
            response = self.llm_client.complete(prompt, max_tokens=50)
            
            if response.strip() == "æ— ":
                return []
            
            # è§£æè¿”å›çš„ç¼–å·
            indices = [int(x.strip()) - 1 for x in response.split(',') if x.strip().isdigit()]
            return [results[i] for i in indices if 0 <= i < len(results)]
        
        except Exception:
            return results
    
    def _record_stats(self, layer: RetrievalLayer, input_count: int, output_count: int, start_time: float):
        """è®°å½•å±‚çº§ç»Ÿè®¡"""
        self.stats.append(LayerStats(
            layer=layer,
            input_count=input_count,
            output_count=output_count,
            time_ms=(time.time() - start_time) * 1000,
            filtered_count=input_count - output_count if input_count > output_count else 0
        ))
    
    def get_stats_summary(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        total_time = sum(s.time_ms for s in self.stats)
        return {
            'total_time_ms': total_time,
            'layers': [
                {
                    'layer': s.layer.value,
                    'input': s.input_count,
                    'output': s.output_count,
                    'time_ms': s.time_ms,
                    'filtered': s.filtered_count
                }
                for s in self.stats
            ]
        }

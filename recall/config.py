"""é…ç½®ç®¡ç† - åŒ…å« Lite æ¨¡å¼é…ç½®"""

import re
from typing import List
from dataclasses import dataclass


# Windows GBK ç¼–ç å…¼å®¹çš„å®‰å…¨æ‰“å°å‡½æ•°
def _safe_print(msg: str) -> None:
    """å®‰å…¨æ‰“å°å‡½æ•°ï¼Œæ›¿æ¢ emoji ä¸º ASCII ç­‰ä»·ç‰©ä»¥é¿å… Windows GBK ç¼–ç é”™è¯¯"""
    emoji_map = {
        'ğŸ“¥': '[IN]', 'ğŸ“¤': '[OUT]', 'ğŸ”': '[SEARCH]', 'âœ…': '[OK]', 'âŒ': '[FAIL]',
        'âš ï¸': '[WARN]', 'ğŸ’¾': '[SAVE]', 'ğŸ—ƒï¸': '[DB]', 'ğŸ§¹': '[CLEAN]', 'ğŸ“Š': '[STATS]',
        'ğŸ”„': '[SYNC]', 'ğŸ“¦': '[PKG]', 'ğŸš€': '[START]', 'ğŸ¯': '[TARGET]', 'ğŸ’¡': '[HINT]',
        'ğŸ”§': '[FIX]', 'ğŸ“': '[NOTE]', 'ğŸ‰': '[DONE]', 'â±ï¸': '[TIME]', 'ğŸŒ': '[NET]',
        'ğŸ§ ': '[BRAIN]', 'ğŸ’¬': '[CHAT]', 'ğŸ·ï¸': '[TAG]', 'ğŸ“': '[DIR]', 'ğŸ”’': '[LOCK]',
        'ğŸŒ±': '[PLANT]', 'ğŸ—‘ï¸': '[DEL]', 'ğŸ’«': '[MAGIC]', 'ğŸ­': '[MASK]', 'ğŸ“–': '[BOOK]',
        'âš¡': '[FAST]', 'ğŸ”¥': '[HOT]', 'ğŸ’': '[GEM]', 'ğŸŒŸ': '[STAR]', 'ğŸ¨': '[ART]'
    }
    for emoji, ascii_equiv in emoji_map.items():
        msg = msg.replace(emoji, ascii_equiv)
    try:
        print(msg)
    except UnicodeEncodeError:
        print(msg.encode('ascii', errors='replace').decode('ascii'))


class LiteConfig:
    """Lite æ¨¡å¼ - é€‚åˆä½é…ç”µè„‘ï¼ˆåŸ LightweightConfigï¼‰"""
    
    # ç¦ç”¨é‡å‹ç»„ä»¶
    ENABLE_VECTOR_INDEX = False      # ä¸åŠ è½½ sentence-transformers (~400MB)
    ENABLE_SPACY_FULL = False        # ä¸åŠ è½½å®Œæ•´ spaCy æ¨¡å‹ (~50MB)
    
    # ä½¿ç”¨è½»é‡æ›¿ä»£
    ENTITY_EXTRACTOR = 'jieba_rules'  # ç”¨ jieba + è§„åˆ™æ›¿ä»£ spaCy
    RETRIEVAL_LAYERS = [1, 2, 3, 5, 7, 8]  # è·³è¿‡ç¬¬4å±‚(å‘é‡)å’Œç¬¬6å±‚(è¯­ä¹‰)
    
    # å†…å­˜é™åˆ¶
    MAX_CACHED_TURNS = 1000          # å‡å°‘ç¼“å­˜
    MAX_INDEX_SIZE_MB = 30           # é™åˆ¶ç´¢å¼•å¤§å°
    
    @classmethod
    def apply(cls, engine):
        """åº”ç”¨è½»é‡é…ç½®"""
        engine.config = engine.config or {}
        engine.config.update({
            'vector_enabled': False,
            'spacy_model': 'blank',
            'retrieval_layers': cls.RETRIEVAL_LAYERS,
            'max_cache': cls.MAX_CACHED_TURNS,
        })
        _safe_print("[Recall] Lite æ¨¡å¼å·²å¯ç”¨ï¼Œå†…å­˜å ç”¨çº¦ ~80MB")


@dataclass
class LightweightExtractedEntity:
    """è½»é‡ç‰ˆæå–å®ä½“"""
    name: str
    entity_type: str
    confidence: float = 0.5
    source_text: str = ""


class LightweightEntityExtractor:
    """è½»é‡çº§å®ä½“æå–å™¨ - ä¸ä¾èµ– spaCy"""
    
    def __init__(self):
        self.re = re
        self._jieba = None  # æ‡’åŠ è½½
        
        # ç®€å•çš„å‘½åå®ä½“æ¨¡å¼
        self.patterns = {
            'PERSON': r'[ã€Œã€"]([\u4e00-\u9fa5]{2,4})[ã€ã€"]è¯´|(\w{2,10})å…ˆç”Ÿ|(\w{2,10})å¥³å£«',
            'LOCATION': r'åœ¨([\u4e00-\u9fa5]{2,10})|å»([\u4e00-\u9fa5]{2,10})',
            'ITEM': r'[ã€Œã€"]([\u4e00-\u9fa5a-zA-Z]{2,20})[ã€ã€"]',
        }
        
        # åœç”¨è¯
        self.stopwords = {
            'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'å’Œ', 'æœ‰', 'è¿™', 'é‚£', 'å°±', 'éƒ½', 
            'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been',
            'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would'
        }
    
    @property
    def jieba(self):
        """æ‡’åŠ è½½ jieba"""
        if self._jieba is None:
            import jieba
            self._jieba = jieba
        return self._jieba
    
    def extract(self, text: str) -> List[LightweightExtractedEntity]:
        """æå–å®ä½“ï¼ˆè½»é‡ç‰ˆï¼‰ï¼Œè¿”å›ä¸ EntityExtractor å…¼å®¹çš„å¯¹è±¡"""
        entities = []
        seen_names = set()
        
        # 1. æ­£åˆ™æ¨¡å¼åŒ¹é…
        for entity_type, pattern in self.patterns.items():
            for match in self.re.finditer(pattern, text):
                name = next((g for g in match.groups() if g), None)
                if name and len(name) >= 2 and name not in seen_names:
                    entities.append(LightweightExtractedEntity(
                        name=name,
                        entity_type=entity_type,
                        confidence=0.6,
                        source_text=text[max(0, match.start()-20):match.end()+20]
                    ))
                    seen_names.add(name)
        
        # 2. jieba åˆ†è¯ + è¯æ€§æ ‡æ³¨
        try:
            import jieba.posseg as pseg
            words = pseg.cut(text[:5000])  # é™åˆ¶é•¿åº¦
            for word, flag in words:
                if flag in ('nr', 'ns', 'nt', 'nz') and len(word) >= 2 and word not in seen_names:
                    entity_type = {
                        'nr': 'PERSON', 
                        'ns': 'LOCATION', 
                        'nt': 'ORG', 
                        'nz': 'ITEM'
                    }.get(flag, 'MISC')
                    entities.append(LightweightExtractedEntity(
                        name=word,
                        entity_type=entity_type,
                        confidence=0.5,
                        source_text=""
                    ))
                    seen_names.add(word)
        except ImportError:
            pass  # jieba æœªå®‰è£…æ—¶è·³è¿‡
        
        return entities
    
    def extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯ï¼ˆè½»é‡ç‰ˆï¼‰"""
        # ä¸­æ–‡è¯ç»„
        chinese = self.re.findall(r'[\u4e00-\u9fa5]{2,6}', text)
        # è‹±æ–‡å•è¯
        english = self.re.findall(r'[a-zA-Z]{3,}', text.lower())
        # è¿‡æ»¤åœç”¨è¯
        return [w for w in chinese + english if w not in self.stopwords]


# ============================================================================
# å‘åå…¼å®¹åˆ«å
# ============================================================================
LightweightConfig = LiteConfig  # å…¼å®¹æ—§ä»£ç 

# Recall 4.1 è¡¥å……å‡çº§è®¡åˆ’

> **ç‰ˆæœ¬**: v4.1.0  
> **æ—¥æœŸ**: 2026-01-28  
> **ç›®æ ‡**: åœ¨ä¿æŒç°æœ‰åŠŸèƒ½100%å…¼å®¹çš„å‰æä¸‹ï¼Œå¢å¼ºå®ä½“/å…³ç³»æå–çš„æ™ºèƒ½åŒ–ç¨‹åº¦ï¼Œå…¨é¢è¶…è¶Š Graphiti

---

## ğŸ“‹ æ–‡æ¡£å¯¼èˆª

1. [å¯¹æ¯”åˆ†æ](#å¯¹æ¯”åˆ†æ) - Recall vs Graphiti å…¨æ–¹ä½å¯¹æ¯”
2. [å·²è¯†åˆ«çŸ­æ¿](#å·²è¯†åˆ«çŸ­æ¿) - éœ€è¦æ”¹è¿›çš„5ä¸ªå…³é”®çŸ­æ¿
3. [å‡çº§ä»»åŠ¡æ¸…å•](#å‡çº§ä»»åŠ¡æ¸…å•) - å…·ä½“çš„å®ç°ä»»åŠ¡
4. [è¯¦ç»†å®ç°æ–¹æ¡ˆ](#è¯¦ç»†å®ç°æ–¹æ¡ˆ) - æ¯ä¸ªä»»åŠ¡çš„ä»£ç çº§å®ç°
5. [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜) - æ–°å¢é…ç½®é¡¹
6. [æµ‹è¯•éªŒè¯](#æµ‹è¯•éªŒè¯) - éªŒè¯å‡çº§æˆåŠŸçš„æµ‹è¯•ç”¨ä¾‹
7. [å›æ»šæ–¹æ¡ˆ](#å›æ»šæ–¹æ¡ˆ) - å¦‚ä½•å®‰å…¨å›æ»š

---

## å¯¹æ¯”åˆ†æ

### 1. æ ¸å¿ƒæ¶æ„å¯¹æ¯”

| ç»´åº¦ | Recall | Graphiti | è¯„ä»· |
|------|--------|----------|------|
| **æ•°æ®åº“ä¾èµ–** | é›¶ä¾èµ–ï¼ˆçº¯æœ¬åœ° JSONï¼‰ | ä¾èµ– Neo4j/FalkorDB/Neptune | âœ… Recall æ›´è½»é‡ |
| **éƒ¨ç½²å¤æ‚åº¦** | å•æ–‡ä»¶è¿è¡Œ | éœ€é…ç½®å›¾æ•°æ®åº“ | âœ… Recall æ›´ç®€å• |
| **åµŒå…¥æ¨¡å¼** | Lite/Local/Cloud ä¸‰æ¨¡å¼ | ä»… Cloud API | âœ… Recall æ›´çµæ´» |
| **LLM ä¾èµ–** | å¯é€‰ï¼ˆå¤§éƒ¨åˆ†åŠŸèƒ½ä¸éœ€è¦ï¼‰ | æ ¸å¿ƒæµç¨‹å¼ºä¾èµ– | âœ… Recall æˆæœ¬æ›´ä½ |

### 2. å®ä½“æå–å¯¹æ¯”

| ç‰¹æ€§ | Recall | Graphiti | è¯„ä»· |
|------|--------|----------|------|
| **æå–æ–¹å¼** | spaCy NER + jieba + è§„åˆ™ + å·²çŸ¥è¯å…¸ | LLM è°ƒç”¨ | âš ï¸ å„æœ‰ä¼˜åŠ£ |
| **ä¸­æ–‡æ”¯æŒ** | åŸç”Ÿä¼˜åŒ–ï¼ˆjieba, zh_core_web_smï¼‰ | é€šç”¨ LLM | âœ… Recall ä¸­æ–‡æ›´å¼º |
| **æˆæœ¬** | æ¥è¿‘é›¶æˆæœ¬ | æ¯æ¬¡è°ƒç”¨æ¶ˆè€— Token | âœ… Recall æ›´çœé’± |
| **å‡†ç¡®ç‡** | è§„åˆ™å—é™ï¼Œå¯èƒ½æ¼æ | LLM æ›´çµæ´» | âŒ **Recall è¾ƒå¼±** |
| **è‡ªå®šä¹‰å®ä½“ç±»å‹** | æœ‰é™æ”¯æŒï¼ˆknown_entities å­—å…¸ï¼‰ | å®Œæ•´çš„ Pydantic Schema | âŒ **Recall è¾ƒå¼±** |

### 3. å»é‡ç³»ç»Ÿå¯¹æ¯”

| ç‰¹æ€§ | Recall | Graphiti | è¯„ä»· |
|------|--------|----------|------|
| **é˜¶æ®µæ•°** | ä¸‰é˜¶æ®µ | ä¸¤é˜¶æ®µ | âœ… Recall æ›´ç²¾ç»† |
| **é˜¶æ®µ 1** | ç²¾ç¡®åŒ¹é… + MinHash + LSH | ç²¾ç¡®åŒ¹é… + MinHash + LSH | ç›¸å½“ |
| **é˜¶æ®µ 2** | **è¯­ä¹‰ç›¸ä¼¼åº¦** | ç›´æ¥ LLM | âœ… Recall æ›´é«˜æ•ˆ |
| **é˜¶æ®µ 3** | å¯é€‰ LLM ç¡®è®¤ | LLM ç¡®è®¤ | ç›¸å½“ |
| **è®¾è®¡ä¼˜åŠ¿** | è¯­ä¹‰å±‚è¿‡æ»¤å‡å°‘ LLM è°ƒç”¨ | - | âœ… Recall æˆæœ¬æ›´ä½ |

### 4. æ—¶æ€ç³»ç»Ÿå¯¹æ¯”

| ç‰¹æ€§ | Recall | Graphiti | è¯„ä»· |
|------|--------|----------|------|
| **æ—¶æ€æ¨¡å‹** | **ä¸‰æ—¶æ€**ï¼ˆäº‹å®/çŸ¥è¯†/ç³»ç»Ÿï¼‰ | åŒæ—¶æ€ï¼ˆvalid_at/invalid_at + expired_atï¼‰ | âœ… Recall æ›´å®Œæ•´ |
| **æ—¶æ€ç´¢å¼•** | TemporalIndex ä¸“ç”¨ç´¢å¼• | ä¾èµ–å›¾æ•°æ®åº“ç´¢å¼• | âœ… Recall æ›´é«˜æ•ˆ |
| **æ—¶æ€æŸ¥è¯¢** | åŸç”Ÿæ”¯æŒ | é€šè¿‡ Cypher æŸ¥è¯¢ | ç›¸å½“ |

### 5. æ£€ç´¢ç³»ç»Ÿå¯¹æ¯”

| ç‰¹æ€§ | Recall | Graphiti | è¯„ä»· |
|------|--------|----------|------|
| **æ£€ç´¢å±‚æ•°** | **11 å±‚æ¼æ–—** | æ··åˆæ£€ç´¢ï¼ˆBM25 + Vector + BFSï¼‰ | âœ… Recall æ›´ç²¾ç»† |
| **å¬å›æ–¹å¼** | å¹¶è¡Œä¸‰è·¯å¬å› | å¹¶è¡Œå¤šè·¯å¬å› | ç›¸å½“ |
| **èåˆç®—æ³•** | RRF | RRF | ç›¸å½“ |
| **é‡æ’åº** | L9 å¤šå› ç´  + L10 CrossEncoder | Cross-Encoder å¯é€‰ | ç›¸å½“ |
| **å…œåº•æœºåˆ¶** | N-gram åŸæ–‡åŒ¹é…ï¼ˆ100% ä¸é—å¿˜ï¼‰ | æ— æ˜ç¡®æœºåˆ¶ | âœ… Recall æ›´å¯é  |
| **å›¾éå†** | L5 BFS æ‰©å±• | BFS å›¾éå† | ç›¸å½“ |

### 6. å…³ç³»/äº‹å®æå–å¯¹æ¯”

| ç‰¹æ€§ | Recall | Graphiti | è¯„ä»· |
|------|--------|----------|------|
| **æå–æ–¹å¼** | æ­£åˆ™æ¨¡å¼ + å…±ç° | LLM æå– | âŒ **Recall è¾ƒå¼±** |
| **å…³ç³»ç±»å‹** | é¢„å®šä¹‰ + MENTIONED_WITH | LLM åŠ¨æ€ç”Ÿæˆ | âŒ **Recall è¾ƒå¼±** |
| **æ—¶æ€ä¿¡æ¯** | ä»æ–‡æœ¬æå–æœ‰é™ | LLM æå– valid_at/invalid_at | âŒ **Recall è¾ƒå¼±** |
| **äº‹å®æè¿°** | åŸæ–‡æˆªå– | LLM ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿° | âŒ **Recall è¾ƒå¼±** |

### 7. çŸ›ç›¾æ£€æµ‹å¯¹æ¯”

| ç‰¹æ€§ | Recall | Graphiti | è¯„ä»· |
|------|--------|----------|------|
| **æ£€æµ‹ç­–ç•¥** | è§„åˆ™ + å¯é€‰ LLM | LLM ä¸ºä¸» | âœ… Recall æˆæœ¬æ›´ä½ |
| **è§£å†³ç­–ç•¥** | SUPERSEDE/COEXIST/REJECT/MANUAL | ç±»ä¼¼ | ç›¸å½“ |
| **æŒä¹…åŒ–** | ç‹¬ç«‹è®°å½•å­˜å‚¨ | è¾¹å±æ€§å­˜å‚¨ | ç›¸å½“ |

---

## å·²è¯†åˆ«çŸ­æ¿

### çŸ­æ¿ 1: å®ä½“æå–å‡†ç¡®ç‡ä¸è¶³ â­ å·²æœ‰ SmartExtractor éƒ¨åˆ†è§£å†³

**é—®é¢˜åˆ†æ**ï¼š
- spaCy zh_core_web_sm å¯¹ä¸­æ–‡ä¸“æœ‰åè¯è¯†åˆ«ç‡ä½
- known_entities å­—å…¸éœ€è¦æ‰‹åŠ¨ç»´æŠ¤
- æ— æ³•è¯†åˆ«ä¸Šä¸‹æ–‡ç›¸å…³çš„éšå¼å®ä½“

**å½“å‰çŠ¶æ€**ï¼š
- `SmartExtractor` å·²æ”¯æŒ RULES/ADAPTIVE/LLM ä¸‰æ¨¡å¼
- ä½† LLM æ¨¡å¼çš„å®ä½“ç±»å‹å®šä¹‰ä»ç„¶æœ‰é™

**éœ€è¦è¡¥å……**ï¼š
1. è‡ªå®šä¹‰å®ä½“ç±»å‹ Schema ç³»ç»Ÿ
2. å®ä½“æ‘˜è¦è‡ªåŠ¨ç”Ÿæˆ

---

### çŸ­æ¿ 2: å…³ç³»æå–è¿‡äºç®€å• â­ æ ¸å¿ƒçŸ­æ¿

**é—®é¢˜åˆ†æ**ï¼š
```python
# å½“å‰å®ç°ï¼ˆrelation_extractor.pyï¼‰åªæœ‰ï¼š
# 1. æ­£åˆ™æ¨¡å¼åŒ¹é…ï¼ˆå›ºå®šæ¨¡å¼ï¼‰
# 2. å…±ç°æ£€æµ‹ï¼ˆåªäº§ç”Ÿ MENTIONED_WITHï¼‰
```

**éœ€è¦è¡¥å……**ï¼š
1. LLM å…³ç³»æå–é€‰é¡¹
2. äº‹å®æ—¶æ€è‡ªåŠ¨æå–ï¼ˆvalid_at/invalid_atï¼‰
3. è‡ªç„¶è¯­è¨€äº‹å®æè¿°ç”Ÿæˆ
4. å…³ç³»ç½®ä¿¡åº¦è¯„ä¼°

---

### çŸ­æ¿ 3: å®ä½“-å…³ç³»ä¸€è‡´æ€§ âœ… å·²ä¿®å¤

**å·²å®Œæˆ**ï¼šä¿®æ”¹ `relation_extractor.extract()` æ–¹æ³•ï¼Œæ”¯æŒä¼ å…¥å·²æå–çš„å®ä½“åˆ—è¡¨ï¼Œé¿å…é‡å¤æå–å¯¼è‡´ä¸ä¸€è‡´ã€‚

---

### çŸ­æ¿ 4: ç¼ºå°‘ Episodeï¼ˆæƒ…èŠ‚ï¼‰æ¦‚å¿µ

**é—®é¢˜åˆ†æ**ï¼š
- Recall åªæœ‰ Memory æ¦‚å¿µ
- æ²¡æœ‰ Episode â†’ Memory â†’ Entity/Relation çš„å±‚æ¬¡ç»“æ„
- æ— æ³•è¿½æº¯åŸå§‹è¾“å…¥

**éœ€è¦è¡¥å……**ï¼š
1. EpisodeNode æ•°æ®æ¨¡å‹
2. Episode ä¸ Memory/Entity/Relation çš„å…³è”

---

### çŸ­æ¿ 5: ç¼ºå°‘èŠ‚ç‚¹æ‘˜è¦ç”Ÿæˆ

**é—®é¢˜åˆ†æ**ï¼š
- å®ä½“åªæœ‰åç§°å’Œç±»å‹
- æ²¡æœ‰è‡ªåŠ¨ç”Ÿæˆçš„æ‘˜è¦
- æ²¡æœ‰åŠ¨æ€å±æ€§

**éœ€è¦è¡¥å……**ï¼š
1. å®ä½“æ‘˜è¦è‡ªåŠ¨ç”Ÿæˆï¼ˆå¯é€‰ LLMï¼‰
2. åŠ¨æ€å±æ€§æ”¯æŒ

---

## âœ… Recall çš„ä¼˜åŠ¿ï¼ˆä¿æŒä¸å˜ï¼‰

1. **é›¶ä¾èµ–éƒ¨ç½²** - æ— éœ€å›¾æ•°æ®åº“
2. **ä¸‰é˜¶æ®µå»é‡** - æ¯” Graphiti å¤šä¸€å±‚è¯­ä¹‰è¿‡æ»¤ï¼Œé™ä½ LLM æˆæœ¬
3. **ä¸‰æ—¶æ€æ¨¡å‹** - æ¯” Graphiti çš„åŒæ—¶æ€æ›´å®Œæ•´
4. **åä¸€å±‚æ£€ç´¢** - æ›´ç²¾ç»†çš„å¬å›æ§åˆ¶
5. **100% ä¸é—å¿˜ä¿è¯** - N-gram åŸæ–‡å…œåº•
6. **ä¸­æ–‡ä¼˜åŒ–** - jieba + spaCy ä¸­æ–‡æ¨¡å‹
7. **æˆæœ¬æ§åˆ¶** - å¤§éƒ¨åˆ†åŠŸèƒ½ä¸ä¾èµ– LLM

---

## å‡çº§ä»»åŠ¡æ¸…å•

### ä»»åŠ¡ä¼˜å…ˆçº§

| ä¼˜å…ˆçº§ | ä»»åŠ¡ID | ä»»åŠ¡åç§° | å¤æ‚åº¦ | å½±å“ | çŠ¶æ€ |
|--------|--------|----------|--------|------|------|
| P0 | T1 | LLM å…³ç³»æå–å¢å¼º | ä¸­ | é«˜ | å¾…å¼€å§‹ |
| P0 | T2 | å…³ç³»æ—¶æ€ä¿¡æ¯æå– | ä¸­ | é«˜ | å¾…å¼€å§‹ |
| P1 | T3 | è‡ªå®šä¹‰å®ä½“ç±»å‹ Schema | é«˜ | é«˜ | å¾…å¼€å§‹ |
| P1 | T4 | LLM å®ä½“æå–å¢å¼º | ä¸­ | é«˜ | éƒ¨åˆ†å®Œæˆ |
| P2 | T5 | Episode æ¦‚å¿µå¼•å…¥ | é«˜ | ä¸­ | å¾…å¼€å§‹ |
| P2 | T6 | å®ä½“æ‘˜è¦ç”Ÿæˆ | ä½ | ä¸­ | å¾…å¼€å§‹ |
| P3 | T7 | åŠ¨æ€å®ä½“å±æ€§ | ä¸­ | ä½ | å¾…å¼€å§‹ |

---

## è¯¦ç»†å®ç°æ–¹æ¡ˆ

### T1: LLM å…³ç³»æå–å¢å¼º

#### 1.1 ç›®æ ‡

åœ¨ä¸å½±å“ç°æœ‰ `RelationExtractor` çš„å‰æä¸‹ï¼Œæ·»åŠ å¯é€‰çš„ LLM å…³ç³»æå–èƒ½åŠ›ã€‚

#### 1.2 è®¾è®¡åŸåˆ™

- **å‘åå…¼å®¹**ï¼šé»˜è®¤ä½¿ç”¨è§„åˆ™æ¨¡å¼ï¼ŒLLM æ¨¡å¼éœ€è¦æ˜¾å¼å¯ç”¨
- **æˆæœ¬å¯æ§**ï¼šé›†æˆ BudgetManagerï¼Œé˜²æ­¢è¶…æ”¯
- **æ¸è¿›å¼**ï¼šè§„åˆ™æ¨¡å¼ â†’ è‡ªé€‚åº”æ¨¡å¼ â†’ LLM æ¨¡å¼

#### 1.3 æ–°å¢æ–‡ä»¶

**æ–‡ä»¶è·¯å¾„**: `recall/graph/llm_relation_extractor.py`

```python
"""LLM å…³ç³»æå–å™¨ - Recall 4.1 å¢å¼ºæ¨¡å—

è®¾è®¡ç†å¿µï¼š
1. ä¸‰æ¨¡å¼æ”¯æŒï¼šRULES / ADAPTIVE / LLM
2. å¤ç”¨ç°æœ‰ RelationExtractor çš„è§„åˆ™é€»è¾‘
3. LLM æ¨¡å¼æ”¯æŒåŠ¨æ€å…³ç³»ç±»å‹ã€æ—¶æ€ä¿¡æ¯ã€äº‹å®æè¿°
4. å‘åå…¼å®¹ï¼šä¸ä¿®æ”¹ç°æœ‰ RelationExtractor
"""

from __future__ import annotations

import re
import json
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Tuple
from enum import Enum
from datetime import datetime

from .relation_extractor import RelationExtractor
from ..utils.llm_client import LLMClient
from ..utils.budget_manager import BudgetManager


class RelationExtractionMode(str, Enum):
    """å…³ç³»æå–æ¨¡å¼"""
    RULES = "rules"           # çº¯è§„åˆ™ï¼ˆé»˜è®¤ï¼Œé›¶æˆæœ¬ï¼‰
    ADAPTIVE = "adaptive"     # è‡ªé€‚åº”ï¼ˆè§„åˆ™ + LLM ç²¾ç‚¼ï¼‰
    LLM = "llm"               # çº¯ LLMï¼ˆæœ€é«˜è´¨é‡ï¼‰


@dataclass
class ExtractedRelationV2:
    """å¢å¼ºç‰ˆå…³ç³»ç»“æ„ - å…¼å®¹ Graphiti çš„ Edge æ¨¡å‹"""
    source_id: str              # æºå®ä½“
    target_id: str              # ç›®æ ‡å®ä½“
    relation_type: str          # å…³ç³»ç±»å‹ï¼ˆå¦‚ WORKS_AT, FRIENDS_WITHï¼‰
    fact: str                   # è‡ªç„¶è¯­è¨€äº‹å®æè¿°
    source_text: str            # åŸæ–‡ä¾æ®
    confidence: float = 0.5     # ç½®ä¿¡åº¦
    valid_at: Optional[str] = None    # äº‹å®ç”Ÿæ•ˆæ—¶é—´ï¼ˆISO 8601ï¼‰
    invalid_at: Optional[str] = None  # äº‹å®å¤±æ•ˆæ—¶é—´ï¼ˆISO 8601ï¼‰
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'source_id': self.source_id,
            'target_id': self.target_id,
            'relation_type': self.relation_type,
            'fact': self.fact,
            'source_text': self.source_text,
            'confidence': self.confidence,
            'valid_at': self.valid_at,
            'invalid_at': self.invalid_at,
        }
    
    def to_legacy_tuple(self) -> Tuple[str, str, str, str]:
        """è½¬æ¢ä¸ºæ—§æ ¼å¼å…ƒç»„ï¼Œå…¼å®¹ç°æœ‰ä»£ç """
        return (self.source_id, self.relation_type, self.target_id, self.source_text)


@dataclass
class LLMRelationExtractorConfig:
    """é…ç½®"""
    mode: RelationExtractionMode = RelationExtractionMode.RULES
    complexity_threshold: float = 0.5  # è‡ªé€‚åº”æ¨¡å¼ä¸‹è§¦å‘ LLM çš„é˜ˆå€¼
    max_relations_per_call: int = 20   # å•æ¬¡ LLM è°ƒç”¨æœ€å¤§å…³ç³»æ•°
    enable_temporal: bool = True       # æ˜¯å¦æå–æ—¶æ€ä¿¡æ¯
    enable_fact_description: bool = True  # æ˜¯å¦ç”Ÿæˆäº‹å®æè¿°


# LLM æç¤ºè¯æ¨¡æ¿
RELATION_EXTRACTION_PROMPT = '''ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†å›¾è°±å…³ç³»æå–ä¸“å®¶ã€‚è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å®ä½“ä¹‹é—´çš„å…³ç³»ã€‚

## å·²è¯†åˆ«çš„å®ä½“åˆ—è¡¨ï¼š
{entities}

## åŸå§‹æ–‡æœ¬ï¼š
{text}

## æå–è¦æ±‚ï¼š
1. åªæå–ä¸Šè¿°å®ä½“åˆ—è¡¨ä¸­å­˜åœ¨çš„å®ä½“ä¹‹é—´çš„å…³ç³»
2. å…³ç³»ç±»å‹ä½¿ç”¨ SCREAMING_SNAKE_CASE æ ¼å¼ï¼ˆå¦‚ WORKS_AT, FRIENDS_WITH, LIVES_INï¼‰
3. ä¸ºæ¯ä¸ªå…³ç³»ç”Ÿæˆç®€æ´çš„è‡ªç„¶è¯­è¨€äº‹å®æè¿°
4. å¦‚æœæ–‡æœ¬ä¸­åŒ…å«æ—¶é—´ä¿¡æ¯ï¼Œæå– valid_atï¼ˆç”Ÿæ•ˆæ—¶é—´ï¼‰å’Œ invalid_atï¼ˆå¤±æ•ˆæ—¶é—´ï¼‰
5. è¯„ä¼°æ¯ä¸ªå…³ç³»çš„ç½®ä¿¡åº¦ï¼ˆ0.0-1.0ï¼‰

## è¾“å‡ºæ ¼å¼ï¼ˆJSONæ•°ç»„ï¼‰ï¼š
[
  {{
    "source_id": "å®ä½“A",
    "target_id": "å®ä½“B",
    "relation_type": "RELATION_TYPE",
    "fact": "å®ä½“Aä¸å®ä½“Bçš„å…³ç³»æè¿°",
    "confidence": 0.8,
    "valid_at": "2023-01-01" æˆ– null,
    "invalid_at": null
  }}
]

è¯·åªè¾“å‡º JSON æ•°ç»„ï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚'''


class LLMRelationExtractor:
    """LLM å¢å¼ºçš„å…³ç³»æå–å™¨
    
    ä½¿ç”¨æ–¹å¼ï¼š
        # æ–¹å¼1ï¼šçº¯è§„åˆ™æ¨¡å¼ï¼ˆé»˜è®¤ï¼Œé›¶æˆæœ¬ï¼‰
        extractor = LLMRelationExtractor()
        relations = extractor.extract(text, entities)
        
        # æ–¹å¼2ï¼šè‡ªé€‚åº”æ¨¡å¼ï¼ˆæ¨èï¼‰
        extractor = LLMRelationExtractor(
            llm_client=llm_client,
            config=LLMRelationExtractorConfig(mode=RelationExtractionMode.ADAPTIVE)
        )
        relations = extractor.extract(text, entities)
        
        # æ–¹å¼3ï¼šçº¯ LLM æ¨¡å¼ï¼ˆæœ€é«˜è´¨é‡ï¼‰
        extractor = LLMRelationExtractor(
            llm_client=llm_client,
            config=LLMRelationExtractorConfig(mode=RelationExtractionMode.LLM)
        )
        relations = extractor.extract(text, entities)
    """
    
    def __init__(
        self,
        llm_client: Optional[LLMClient] = None,
        budget_manager: Optional[BudgetManager] = None,
        entity_extractor=None,
        config: Optional[LLMRelationExtractorConfig] = None
    ):
        self.llm_client = llm_client
        self.budget_manager = budget_manager
        self.config = config or LLMRelationExtractorConfig()
        
        # å¤ç”¨ç°æœ‰çš„è§„åˆ™æå–å™¨
        self._rule_extractor = RelationExtractor(entity_extractor=entity_extractor)
    
    def extract(
        self,
        text: str,
        entities: Optional[List] = None,
        turn: int = 0
    ) -> List[ExtractedRelationV2]:
        """æå–å…³ç³»
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            entities: å·²æå–çš„å®ä½“åˆ—è¡¨
            turn: è½®æ¬¡
        
        Returns:
            List[ExtractedRelationV2]: æå–çš„å…³ç³»åˆ—è¡¨
        """
        mode = self.config.mode
        
        if mode == RelationExtractionMode.RULES:
            return self._extract_by_rules(text, entities, turn)
        elif mode == RelationExtractionMode.LLM:
            return self._extract_by_llm(text, entities)
        else:  # ADAPTIVE
            return self._extract_adaptive(text, entities, turn)
    
    def _extract_by_rules(
        self,
        text: str,
        entities: Optional[List],
        turn: int
    ) -> List[ExtractedRelationV2]:
        """è§„åˆ™æ¨¡å¼æå–"""
        # å¤ç”¨ç°æœ‰é€»è¾‘
        raw_relations = self._rule_extractor.extract(text, turn, entities)
        
        # è½¬æ¢ä¸ºæ–°æ ¼å¼
        return [
            ExtractedRelationV2(
                source_id=source,
                target_id=target,
                relation_type=rel_type,
                fact=f"{source} {rel_type} {target}",
                source_text=src_text,
                confidence=0.5 if rel_type == 'MENTIONED_WITH' else 0.8
            )
            for source, rel_type, target, src_text in raw_relations
        ]
    
    def _extract_by_llm(
        self,
        text: str,
        entities: Optional[List]
    ) -> List[ExtractedRelationV2]:
        """LLM æ¨¡å¼æå–"""
        if not self.llm_client:
            # é™çº§åˆ°è§„åˆ™æ¨¡å¼
            return self._extract_by_rules(text, entities, 0)
        
        # æ£€æŸ¥é¢„ç®—
        if self.budget_manager and not self.budget_manager.can_spend(0.01):
            return self._extract_by_rules(text, entities, 0)
        
        # å‡†å¤‡å®ä½“åˆ—è¡¨å­—ç¬¦ä¸²
        entity_names = self._get_entity_names(entities)
        entities_str = ", ".join(entity_names) if entity_names else "ï¼ˆæœªæä¾›å®ä½“åˆ—è¡¨ï¼‰"
        
        # æ„å»ºæç¤ºè¯
        prompt = RELATION_EXTRACTION_PROMPT.format(
            entities=entities_str,
            text=text[:3000]  # é™åˆ¶é•¿åº¦
        )
        
        try:
            response = self.llm_client.chat(prompt)
            relations = self._parse_llm_response(response, text)
            
            # è®°å½•æˆæœ¬
            if self.budget_manager:
                self.budget_manager.record_usage(0.01)
            
            return relations
        except Exception as e:
            print(f"[LLMRelationExtractor] LLM æå–å¤±è´¥ï¼Œé™çº§åˆ°è§„åˆ™æ¨¡å¼: {e}")
            return self._extract_by_rules(text, entities, 0)
    
    def _extract_adaptive(
        self,
        text: str,
        entities: Optional[List],
        turn: int
    ) -> List[ExtractedRelationV2]:
        """è‡ªé€‚åº”æ¨¡å¼ï¼šè§„åˆ™ + LLM ç²¾ç‚¼"""
        # 1. å…ˆç”¨è§„åˆ™æå–
        rule_relations = self._extract_by_rules(text, entities, turn)
        
        # 2. è¯„ä¼°æ–‡æœ¬å¤æ‚åº¦
        complexity = self._evaluate_complexity(text, entities)
        
        # 3. å¦‚æœå¤æ‚åº¦é«˜ä¸”æœ‰ LLMï¼Œä½¿ç”¨ LLM è¡¥å……
        if complexity > self.config.complexity_threshold and self.llm_client:
            llm_relations = self._extract_by_llm(text, entities)
            # åˆå¹¶å»é‡
            return self._merge_relations(rule_relations, llm_relations)
        
        return rule_relations
    
    def _evaluate_complexity(self, text: str, entities: Optional[List]) -> float:
        """è¯„ä¼°æ–‡æœ¬å¤æ‚åº¦"""
        score = 0.0
        
        # 1. æ–‡æœ¬é•¿åº¦
        if len(text) > 500:
            score += 0.2
        if len(text) > 1000:
            score += 0.1
        
        # 2. å®ä½“æ•°é‡
        entity_count = len(self._get_entity_names(entities))
        if entity_count > 5:
            score += 0.2
        if entity_count > 10:
            score += 0.1
        
        # 3. å¥å­å¤æ‚åº¦ï¼ˆåˆ†å·ã€é€—å·æ•°é‡ï¼‰
        complex_punct = len(re.findall(r'[;ï¼›,ï¼Œ]', text))
        if complex_punct > 10:
            score += 0.2
        
        # 4. æ—¶æ€è¯æ±‡
        temporal_words = ['ä»', 'åˆ°', 'å¼€å§‹', 'ç»“æŸ', 'ä¹‹å‰', 'ä¹‹å', 'å¹´', 'æœˆ', 'æ—¥']
        for word in temporal_words:
            if word in text:
                score += 0.05
        
        return min(score, 1.0)
    
    def _get_entity_names(self, entities: Optional[List]) -> List[str]:
        """ç»Ÿä¸€è·å–å®ä½“ååˆ—è¡¨"""
        if not entities:
            return []
        
        names = []
        for e in entities:
            if hasattr(e, 'name'):
                names.append(e.name)
            elif isinstance(e, str):
                names.append(e)
            elif isinstance(e, dict) and 'name' in e:
                names.append(e['name'])
        return names
    
    def _parse_llm_response(self, response: str, source_text: str) -> List[ExtractedRelationV2]:
        """è§£æ LLM å“åº”"""
        try:
            # å°è¯•æå– JSON
            json_match = re.search(r'\[[\s\S]*\]', response)
            if json_match:
                data = json.loads(json_match.group())
                return [
                    ExtractedRelationV2(
                        source_id=item.get('source_id', ''),
                        target_id=item.get('target_id', ''),
                        relation_type=item.get('relation_type', 'RELATED'),
                        fact=item.get('fact', ''),
                        source_text=source_text[:200],
                        confidence=float(item.get('confidence', 0.7)),
                        valid_at=item.get('valid_at'),
                        invalid_at=item.get('invalid_at'),
                    )
                    for item in data
                    if item.get('source_id') and item.get('target_id')
                ]
        except (json.JSONDecodeError, Exception) as e:
            print(f"[LLMRelationExtractor] è§£æå¤±è´¥: {e}")
        
        return []
    
    def _merge_relations(
        self,
        rule_relations: List[ExtractedRelationV2],
        llm_relations: List[ExtractedRelationV2]
    ) -> List[ExtractedRelationV2]:
        """åˆå¹¶è§„åˆ™å’Œ LLM æå–çš„å…³ç³»"""
        seen = set()
        merged = []
        
        # LLM ç»“æœä¼˜å…ˆï¼ˆè´¨é‡æ›´é«˜ï¼‰
        for rel in llm_relations:
            key = (rel.source_id, rel.target_id)
            if key not in seen:
                seen.add(key)
                merged.append(rel)
        
        # è¡¥å……è§„åˆ™ç»“æœ
        for rel in rule_relations:
            key = (rel.source_id, rel.target_id)
            if key not in seen:
                seen.add(key)
                merged.append(rel)
        
        return merged
    
    # å…¼å®¹æ—§æ¥å£
    def extract_legacy(
        self,
        text: str,
        turn: int = 0,
        entities: Optional[List] = None
    ) -> List[Tuple[str, str, str, str]]:
        """å…¼å®¹æ—§æ¥å£ï¼Œè¿”å›å…ƒç»„æ ¼å¼"""
        relations = self.extract(text, entities, turn)
        return [rel.to_legacy_tuple() for rel in relations]
```

#### 1.4 ä¿®æ”¹æ–‡ä»¶æ¸…å•

**æ–‡ä»¶ 1**: `recall/graph/__init__.py`

åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ ï¼š

```python
# === Recall 4.1 æ–°å¢ ===
from .llm_relation_extractor import (
    LLMRelationExtractor,
    LLMRelationExtractorConfig,
    RelationExtractionMode,
    ExtractedRelationV2
)
```

**æ–‡ä»¶ 2**: `recall/engine.py`

åœ¨ `__init__` æ–¹æ³•ä¸­ï¼ˆçº¦ç¬¬ 200 è¡Œï¼Œåœ¨ `self.relation_extractor` åˆå§‹åŒ–ä¹‹åï¼‰æ·»åŠ ï¼š

```python
# === Recall 4.1: LLM å…³ç³»æå–å™¨ï¼ˆå¯é€‰ï¼Œå‘åå…¼å®¹ï¼‰===
self._llm_relation_extractor = None
llm_relation_mode = os.environ.get('LLM_RELATION_MODE', 'rules').lower()
if llm_relation_mode != 'rules' and self.llm_client:
    try:
        from .graph.llm_relation_extractor import (
            LLMRelationExtractor, LLMRelationExtractorConfig, RelationExtractionMode
        )
        mode_map = {
            'adaptive': RelationExtractionMode.ADAPTIVE,
            'llm': RelationExtractionMode.LLM,
        }
        self._llm_relation_extractor = LLMRelationExtractor(
            llm_client=self.llm_client,
            budget_manager=self.budget_manager if hasattr(self, 'budget_manager') else None,
            entity_extractor=self.entity_extractor,
            config=LLMRelationExtractorConfig(
                mode=mode_map.get(llm_relation_mode, RelationExtractionMode.RULES),
                enable_temporal=True,
                enable_fact_description=True
            )
        )
        _safe_print(f"[Recall v4.1] LLM å…³ç³»æå–å™¨å·²å¯ç”¨ (æ¨¡å¼: {llm_relation_mode})")
    except ImportError:
        pass  # æ¨¡å—ä¸å­˜åœ¨æ—¶é™é»˜è·³è¿‡
```

åœ¨ `add()` æ–¹æ³•çš„å…³ç³»æå–éƒ¨åˆ†ï¼ˆçº¦ç¬¬ 1405 è¡Œï¼‰ï¼Œå°†åŸæœ‰ä»£ç ï¼š

```python
# 6. æ›´æ–°çŸ¥è¯†å›¾è°±ï¼ˆå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼‰
try:
    # å¤ç”¨å·²æå–çš„å®ä½“åˆ—è¡¨ï¼Œé¿å…é‡å¤æå–å¯¼è‡´ä¸ä¸€è‡´
    relations = self.relation_extractor.extract(content, 0, entities=entities)
    for rel in relations:
        source_id, relation_type, target_id, source_text = rel
        self.knowledge_graph.add_relation(
            source_id=source_id,
            target_id=target_id,
            relation_type=relation_type,
            source_text=source_text
        )
except Exception as e:
    _safe_print(f"[Recall] çŸ¥è¯†å›¾è°±æ›´æ–°å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
```

ä¿®æ”¹ä¸ºï¼š

```python
# 6. æ›´æ–°çŸ¥è¯†å›¾è°±ï¼ˆå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼‰
try:
    # === Recall 4.1: ä¼˜å…ˆä½¿ç”¨ LLM å…³ç³»æå–å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰===
    if self._llm_relation_extractor:
        relations_v2 = self._llm_relation_extractor.extract(content, entities)
        for rel in relations_v2:
            self.knowledge_graph.add_relation(
                source_id=rel.source_id,
                target_id=rel.target_id,
                relation_type=rel.relation_type,
                source_text=rel.source_text,
                confidence=rel.confidence,
                valid_at=getattr(rel, 'valid_at', None),
                invalid_at=getattr(rel, 'invalid_at', None),
                fact=getattr(rel, 'fact', '')
            )
    else:
        # ä½¿ç”¨ä¼ ç»Ÿè§„åˆ™æå–å™¨
        relations = self.relation_extractor.extract(content, 0, entities=entities)
        for rel in relations:
            source_id, relation_type, target_id, source_text = rel
            self.knowledge_graph.add_relation(
                source_id=source_id,
                target_id=target_id,
                relation_type=relation_type,
                source_text=source_text
            )
except Exception as e:
    _safe_print(f"[Recall] çŸ¥è¯†å›¾è°±æ›´æ–°å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
```

#### 1.5 æ–°å¢é…ç½®é¡¹

åœ¨ `recall_data/config/api_keys.env` æœ«å°¾æ·»åŠ ï¼š

```bash
# ============================================
# Recall 4.1 æ–°å¢é…ç½®
# ============================================

# === LLM å…³ç³»æå–é…ç½® ===
# æ¨¡å¼: rulesï¼ˆçº¯è§„åˆ™ï¼Œé»˜è®¤ï¼‰/ adaptiveï¼ˆè‡ªé€‚åº”ï¼‰/ llmï¼ˆçº¯LLMï¼‰
LLM_RELATION_MODE=rules

# è‡ªé€‚åº”æ¨¡å¼ä¸‹è§¦å‘ LLM çš„å¤æ‚åº¦é˜ˆå€¼ (0.0-1.0)
LLM_RELATION_COMPLEXITY_THRESHOLD=0.5

# æ˜¯å¦æå–æ—¶æ€ä¿¡æ¯
LLM_RELATION_ENABLE_TEMPORAL=true

# æ˜¯å¦ç”Ÿæˆäº‹å®æè¿°
LLM_RELATION_ENABLE_FACT_DESCRIPTION=true
```

---

### T2: å…³ç³»æ—¶æ€ä¿¡æ¯å­˜å‚¨

#### 2.1 ç›®æ ‡

å°† LLM æå–çš„ `valid_at`/`invalid_at` æ—¶æ€ä¿¡æ¯å­˜å‚¨åˆ° `KnowledgeGraph`ã€‚

#### 2.2 ä¿®æ”¹æ–‡ä»¶

**æ–‡ä»¶**: `recall/graph/knowledge_graph.py`

åœ¨ `Relation` æ•°æ®ç±»ä¸­æ·»åŠ æ—¶æ€å­—æ®µï¼ˆçº¦ç¬¬ 10 è¡Œï¼‰ï¼š

å°†ï¼š
```python
@dataclass
class Relation:
    """å®ä½“é—´çš„å…³ç³»"""
    source_id: str           # æºå®ä½“ID
    target_id: str           # ç›®æ ‡å®ä½“ID
    relation_type: str       # å…³ç³»ç±»å‹
    properties: Dict = field(default_factory=dict)  # å…³ç³»å±æ€§
    created_turn: int = 0    # åˆ›å»ºè½®æ¬¡
    confidence: float = 0.5  # ç½®ä¿¡åº¦
    source_text: str = ""    # åŸæ–‡ä¾æ®
```

ä¿®æ”¹ä¸ºï¼š
```python
@dataclass
class Relation:
    """å®ä½“é—´çš„å…³ç³»"""
    source_id: str           # æºå®ä½“ID
    target_id: str           # ç›®æ ‡å®ä½“ID
    relation_type: str       # å…³ç³»ç±»å‹
    properties: Dict = field(default_factory=dict)  # å…³ç³»å±æ€§
    created_turn: int = 0    # åˆ›å»ºè½®æ¬¡
    confidence: float = 0.5  # ç½®ä¿¡åº¦
    source_text: str = ""    # åŸæ–‡ä¾æ®
    # === Recall 4.1 æ–°å¢æ—¶æ€å­—æ®µ ===
    valid_at: Optional[str] = None      # äº‹å®ç”Ÿæ•ˆæ—¶é—´ (ISO 8601)
    invalid_at: Optional[str] = None    # äº‹å®å¤±æ•ˆæ—¶é—´ (ISO 8601)
    fact: str = ""                      # è‡ªç„¶è¯­è¨€äº‹å®æè¿°
```

åŒæ—¶åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ å¯¼å…¥ï¼š
```python
from typing import Dict, List, Optional, Tuple
```

ä¿®æ”¹ `add_relation` æ–¹æ³•ç­¾åï¼ˆçº¦ç¬¬ 98 è¡Œï¼‰ï¼š

å°†ï¼š
```python
def add_relation(self, source_id: str, target_id: str, relation_type: str,
                 properties: Dict = None, turn: int = 0, source_text: str = "",
                 confidence: float = 0.5) -> Relation:
```

ä¿®æ”¹ä¸ºï¼š
```python
def add_relation(self, source_id: str, target_id: str, relation_type: str,
                 properties: Dict = None, turn: int = 0, source_text: str = "",
                 confidence: float = 0.5,
                 valid_at: str = None, invalid_at: str = None,
                 fact: str = "") -> Relation:
```

ä¿®æ”¹æ–¹æ³•å†…éƒ¨çš„ `Relation` åˆ›å»ºï¼ˆçº¦ç¬¬ 120 è¡Œï¼‰ï¼š

å°†ï¼š
```python
rel = Relation(
    source_id=source_id,
    target_id=target_id,
    relation_type=relation_type,
    properties=properties or {},
    created_turn=turn,
    confidence=confidence,
    source_text=source_text
)
```

ä¿®æ”¹ä¸ºï¼š
```python
rel = Relation(
    source_id=source_id,
    target_id=target_id,
    relation_type=relation_type,
    properties=properties or {},
    created_turn=turn,
    confidence=confidence,
    source_text=source_text,
    valid_at=valid_at,
    invalid_at=invalid_at,
    fact=fact
)
```

---

### T3: è‡ªå®šä¹‰å®ä½“ç±»å‹ Schema

#### 3.1 æ–°å¢æ–‡ä»¶

**æ–‡ä»¶è·¯å¾„**: `recall/models/entity_schema.py`

```python
"""è‡ªå®šä¹‰å®ä½“ç±»å‹ Schema - Recall 4.1

æ”¯æŒç”¨æˆ·å®šä¹‰è‡ªå®šä¹‰å®ä½“ç±»å‹ï¼ŒåŒ…æ‹¬ï¼š
1. ç±»å‹åç§°å’Œæè¿°
2. å¿…éœ€/å¯é€‰å±æ€§
3. éªŒè¯è§„åˆ™
"""

from __future__ import annotations

import os
import json
from dataclasses import dataclass, field, asdict
from typing import Dict, List, Any, Optional
from enum import Enum


class AttributeType(str, Enum):
    """å±æ€§ç±»å‹"""
    STRING = "string"
    NUMBER = "number"
    BOOLEAN = "boolean"
    DATE = "date"
    LIST = "list"


@dataclass
class AttributeDefinition:
    """å±æ€§å®šä¹‰"""
    name: str
    attr_type: AttributeType = AttributeType.STRING
    required: bool = False
    default: Any = None
    description: str = ""
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'name': self.name,
            'type': self.attr_type.value,
            'required': self.required,
            'default': self.default,
            'description': self.description
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'AttributeDefinition':
        return cls(
            name=data['name'],
            attr_type=AttributeType(data.get('type', 'string')),
            required=data.get('required', False),
            default=data.get('default'),
            description=data.get('description', '')
        )


@dataclass
class EntityTypeDefinition:
    """å®ä½“ç±»å‹å®šä¹‰"""
    name: str                               # ç±»å‹åç§°ï¼ˆå¦‚ PERSON, LOCATIONï¼‰
    display_name: str = ""                  # æ˜¾ç¤ºåç§°ï¼ˆå¦‚ "äººç‰©", "åœ°ç‚¹"ï¼‰
    description: str = ""                   # ç±»å‹æè¿°
    attributes: List[AttributeDefinition] = field(default_factory=list)
    examples: List[str] = field(default_factory=list)  # ç¤ºä¾‹å®ä½“
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'name': self.name,
            'display_name': self.display_name or self.name,
            'description': self.description,
            'attributes': [a.to_dict() for a in self.attributes],
            'examples': self.examples
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'EntityTypeDefinition':
        return cls(
            name=data['name'],
            display_name=data.get('display_name', data['name']),
            description=data.get('description', ''),
            attributes=[AttributeDefinition.from_dict(a) for a in data.get('attributes', [])],
            examples=data.get('examples', [])
        )


class EntitySchemaRegistry:
    """å®ä½“ç±»å‹æ³¨å†Œè¡¨
    
    ä½¿ç”¨æ–¹å¼ï¼š
        registry = EntitySchemaRegistry(data_path)
        
        # æ³¨å†Œè‡ªå®šä¹‰ç±»å‹
        registry.register(EntityTypeDefinition(
            name="CHARACTER",
            display_name="è§’è‰²",
            description="æ•…äº‹ä¸­çš„è§’è‰²äººç‰©",
            attributes=[
                AttributeDefinition(name="age", attr_type=AttributeType.NUMBER),
                AttributeDefinition(name="occupation", attr_type=AttributeType.STRING),
            ],
            examples=["è‰¾ç³", "å°æ˜", "è€ç‹"]
        ))
        
        # è·å–ç±»å‹
        char_type = registry.get("CHARACTER")
        
        # è·å–æ‰€æœ‰ç±»å‹ï¼ˆç”¨äº LLM æç¤ºè¯ï¼‰
        all_types = registry.get_all_for_prompt()
    """
    
    # é¢„å®šä¹‰çš„åŸºç¡€ç±»å‹
    BUILTIN_TYPES = [
        EntityTypeDefinition(
            name="PERSON",
            display_name="äººç‰©",
            description="çœŸå®æˆ–è™šæ„çš„äººç‰©",
            examples=["å¼ ä¸‰", "æå››"]
        ),
        EntityTypeDefinition(
            name="LOCATION",
            display_name="åœ°ç‚¹",
            description="åœ°ç†ä½ç½®ã€åœ°å",
            examples=["åŒ—äº¬", "ä¸œäº¬", "å’–å•¡å…"]
        ),
        EntityTypeDefinition(
            name="ORGANIZATION",
            display_name="ç»„ç»‡",
            description="å…¬å¸ã€æœºæ„ã€å›¢ä½“",
            examples=["å¾®è½¯", "æ¸…åå¤§å­¦"]
        ),
        EntityTypeDefinition(
            name="ITEM",
            display_name="ç‰©å“",
            description="ç‰©å“ã€é“å…·",
            examples=["æ‰‹æœº", "é­”æ³•å‰‘"]
        ),
        EntityTypeDefinition(
            name="CONCEPT",
            display_name="æ¦‚å¿µ",
            description="æŠ½è±¡æ¦‚å¿µã€æœ¯è¯­",
            examples=["AI", "æœºå™¨å­¦ä¹ "]
        ),
        EntityTypeDefinition(
            name="EVENT",
            display_name="äº‹ä»¶",
            description="äº‹ä»¶ã€æ´»åŠ¨",
            examples=["æ˜¥èŠ‚", "å©šç¤¼"]
        ),
        EntityTypeDefinition(
            name="TIME",
            display_name="æ—¶é—´",
            description="æ—¶é—´ç‚¹ã€æ—¶é—´æ®µ",
            examples=["2023å¹´", "ä¸‹åˆä¸‰ç‚¹"]
        ),
    ]
    
    def __init__(self, data_path: str):
        self.data_path = data_path
        self.schema_file = os.path.join(data_path, 'config', 'entity_schema.json')
        
        self._types: Dict[str, EntityTypeDefinition] = {}
        
        # åŠ è½½å†…ç½®ç±»å‹
        for t in self.BUILTIN_TYPES:
            self._types[t.name] = t
        
        # åŠ è½½è‡ªå®šä¹‰ç±»å‹
        self._load()
    
    def _load(self):
        """åŠ è½½è‡ªå®šä¹‰ç±»å‹"""
        if os.path.exists(self.schema_file):
            try:
                with open(self.schema_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for item in data.get('custom_types', []):
                        t = EntityTypeDefinition.from_dict(item)
                        self._types[t.name] = t
            except Exception as e:
                print(f"[EntitySchemaRegistry] åŠ è½½å¤±è´¥: {e}")
    
    def _save(self):
        """ä¿å­˜è‡ªå®šä¹‰ç±»å‹"""
        os.makedirs(os.path.dirname(self.schema_file), exist_ok=True)
        
        # åªä¿å­˜éå†…ç½®ç±»å‹
        builtin_names = {t.name for t in self.BUILTIN_TYPES}
        custom_types = [
            t.to_dict() for name, t in self._types.items()
            if name not in builtin_names
        ]
        
        with open(self.schema_file, 'w', encoding='utf-8') as f:
            json.dump({'custom_types': custom_types}, f, ensure_ascii=False, indent=2)
    
    def register(self, entity_type: EntityTypeDefinition):
        """æ³¨å†Œè‡ªå®šä¹‰ç±»å‹"""
        self._types[entity_type.name] = entity_type
        self._save()
    
    def get(self, name: str) -> Optional[EntityTypeDefinition]:
        """è·å–ç±»å‹å®šä¹‰"""
        return self._types.get(name)
    
    def get_all(self) -> List[EntityTypeDefinition]:
        """è·å–æ‰€æœ‰ç±»å‹"""
        return list(self._types.values())
    
    def get_all_for_prompt(self) -> str:
        """ç”Ÿæˆç”¨äº LLM æç¤ºè¯çš„ç±»å‹æè¿°"""
        lines = []
        for i, t in enumerate(self._types.values()):
            examples = ", ".join(t.examples[:3]) if t.examples else "æ— "
            lines.append(f"{i+1}. {t.name}ï¼ˆ{t.display_name}ï¼‰: {t.description}ã€‚ç¤ºä¾‹: {examples}")
        return "\n".join(lines)
    
    def get_type_id_map(self) -> Dict[str, int]:
        """è·å–ç±»å‹åç§°åˆ°IDçš„æ˜ å°„ï¼ˆç”¨äº LLM è¾“å‡ºè§£æï¼‰"""
        return {t.name: i for i, t in enumerate(self._types.values())}
```

---

### T5: Episode æ¦‚å¿µå¼•å…¥

#### 5.1 æ–°å¢æ–‡ä»¶

**æ–‡ä»¶è·¯å¾„**: `recall/models/episode.py`

```python
"""Episode æ•°æ®æ¨¡å‹ - Recall 4.1

Episodeï¼ˆæƒ…èŠ‚ï¼‰æ˜¯åŸå§‹è¾“å…¥çš„è¿½æº¯å•å…ƒï¼Œä¸ Memoryã€Entityã€Relation å½¢æˆå…³è”é“¾ï¼š
Episode â†’ Memory â†’ Entity/Relation
"""

from __future__ import annotations

import uuid as uuid_lib
from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, List, Any, Optional
from enum import Enum


class EpisodeType(str, Enum):
    """æƒ…èŠ‚ç±»å‹"""
    TEXT = "text"           # çº¯æ–‡æœ¬
    MESSAGE = "message"     # å¯¹è¯æ¶ˆæ¯
    JSON = "json"           # ç»“æ„åŒ–æ•°æ®
    DOCUMENT = "document"   # æ–‡æ¡£


@dataclass
class EpisodeNode:
    """æƒ…èŠ‚èŠ‚ç‚¹ - åŸå§‹è¾“å…¥çš„è¿½æº¯å•å…ƒ"""
    uuid: str = field(default_factory=lambda: str(uuid_lib.uuid4()))
    
    # åŸºæœ¬ä¿¡æ¯
    source_type: EpisodeType = EpisodeType.TEXT
    source_description: str = ""        # æ¥æºæè¿°ï¼ˆå¦‚ "ç”¨æˆ·å¯¹è¯"ï¼‰
    content: str = ""                   # åŸå§‹å†…å®¹
    
    # æ—¶æ€ä¿¡æ¯
    valid_at: Optional[datetime] = None  # åŸå§‹æ–‡æ¡£æ—¶é—´ï¼ˆå¦‚æœæœ‰ï¼‰
    created_at: datetime = field(default_factory=datetime.now)
    
    # å…³è”ä¿¡æ¯
    user_id: str = ""
    character_id: str = ""
    group_id: str = ""
    
    # äº§ç”Ÿçš„å®ä½“å’Œå…³ç³»
    memory_ids: List[str] = field(default_factory=list)
    entity_ids: List[str] = field(default_factory=list)
    relation_ids: List[str] = field(default_factory=list)
    
    # å…ƒæ•°æ®
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'uuid': self.uuid,
            'source_type': self.source_type.value,
            'source_description': self.source_description,
            'content': self.content,
            'valid_at': self.valid_at.isoformat() if self.valid_at else None,
            'created_at': self.created_at.isoformat(),
            'user_id': self.user_id,
            'character_id': self.character_id,
            'group_id': self.group_id,
            'memory_ids': self.memory_ids,
            'entity_ids': self.entity_ids,
            'relation_ids': self.relation_ids,
            'metadata': self.metadata,
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'EpisodeNode':
        return cls(
            uuid=data.get('uuid', str(uuid_lib.uuid4())),
            source_type=EpisodeType(data.get('source_type', 'text')),
            source_description=data.get('source_description', ''),
            content=data.get('content', ''),
            valid_at=datetime.fromisoformat(data['valid_at']) if data.get('valid_at') else None,
            created_at=datetime.fromisoformat(data['created_at']) if data.get('created_at') else datetime.now(),
            user_id=data.get('user_id', ''),
            character_id=data.get('character_id', ''),
            group_id=data.get('group_id', ''),
            memory_ids=data.get('memory_ids', []),
            entity_ids=data.get('entity_ids', []),
            relation_ids=data.get('relation_ids', []),
            metadata=data.get('metadata', {}),
        )
```

---

### T6: å®ä½“æ‘˜è¦ç”Ÿæˆ

#### 6.1 æ–°å¢æ–‡ä»¶

**æ–‡ä»¶è·¯å¾„**: `recall/processor/entity_summarizer.py`

```python
"""å®ä½“æ‘˜è¦ç”Ÿæˆå™¨ - Recall 4.1

ä¸ºå®ä½“è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦ï¼Œæ€»ç»“å®ä½“çš„æ‰€æœ‰å·²çŸ¥ä¿¡æ¯ã€‚
"""

from __future__ import annotations

from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass

from ..utils.llm_client import LLMClient


@dataclass
class EntitySummary:
    """å®ä½“æ‘˜è¦"""
    entity_name: str
    summary: str
    key_facts: List[str]
    relation_count: int
    mention_count: int
    last_updated: str = ""


SUMMARIZE_PROMPT = '''è¯·ä¸ºä»¥ä¸‹å®ä½“ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ã€‚

## å®ä½“åç§°ï¼š{entity_name}

## ç›¸å…³äº‹å®ï¼š
{facts}

## ç›¸å…³å…³ç³»ï¼š
{relations}

## è¾“å‡ºè¦æ±‚ï¼š
1. ç”Ÿæˆä¸€ä¸ª 2-3 å¥è¯çš„æ‘˜è¦ï¼Œæ€»ç»“å®ä½“çš„æ ¸å¿ƒä¿¡æ¯
2. åˆ—å‡º 3-5 ä¸ªå…³é”®äº‹å®è¦ç‚¹

è¯·ç”¨ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
æ‘˜è¦ï¼š[æ‘˜è¦å†…å®¹]
å…³é”®äº‹å®ï¼š
- [äº‹å®1]
- [äº‹å®2]
- [äº‹å®3]
'''


class EntitySummarizer:
    """å®ä½“æ‘˜è¦ç”Ÿæˆå™¨"""
    
    def __init__(self, llm_client: Optional[LLMClient] = None):
        self.llm_client = llm_client
    
    def generate(
        self,
        entity_name: str,
        facts: List[str],
        relations: List[Tuple[str, str, str]],
        force_llm: bool = False
    ) -> EntitySummary:
        """ç”Ÿæˆå®ä½“æ‘˜è¦"""
        if self.llm_client and (force_llm or len(facts) > 3):
            return self._generate_with_llm(entity_name, facts, relations)
        else:
            return self._generate_simple(entity_name, facts, relations)
    
    def _generate_simple(
        self,
        entity_name: str,
        facts: List[str],
        relations: List[Tuple[str, str, str]]
    ) -> EntitySummary:
        """ç®€å•è§„åˆ™ç”Ÿæˆ"""
        key_facts = facts[:5]
        summary = f"{entity_name}ã€‚" + " ".join(key_facts[:2]) if key_facts else f"{entity_name}ã€‚"
        
        return EntitySummary(
            entity_name=entity_name,
            summary=summary,
            key_facts=key_facts,
            relation_count=len(relations),
            mention_count=len(facts)
        )
    
    def _generate_with_llm(
        self,
        entity_name: str,
        facts: List[str],
        relations: List[Tuple[str, str, str]]
    ) -> EntitySummary:
        """LLM ç”Ÿæˆ"""
        facts_str = "\n".join([f"- {f}" for f in facts[:10]])
        relations_str = "\n".join([f"- {s} {r} {t}" for s, r, t in relations[:10]])
        
        prompt = SUMMARIZE_PROMPT.format(
            entity_name=entity_name,
            facts=facts_str or "ï¼ˆæ— ï¼‰",
            relations=relations_str or "ï¼ˆæ— ï¼‰"
        )
        
        try:
            response = self.llm_client.chat(prompt)
            return self._parse_response(entity_name, response, facts, relations)
        except Exception as e:
            print(f"[EntitySummarizer] LLM å¤±è´¥: {e}")
            return self._generate_simple(entity_name, facts, relations)
    
    def _parse_response(
        self,
        entity_name: str,
        response: str,
        facts: List[str],
        relations: List[Tuple[str, str, str]]
    ) -> EntitySummary:
        """è§£æ LLM å“åº”"""
        summary = ""
        key_facts = []
        
        lines = response.strip().split('\n')
        parsing_facts = False
        
        for line in lines:
            line = line.strip()
            if line.startswith('æ‘˜è¦ï¼š') or line.startswith('æ‘˜è¦:'):
                summary = line.split('ï¼š', 1)[-1].split(':', 1)[-1].strip()
            elif 'å…³é”®äº‹å®' in line:
                parsing_facts = True
            elif parsing_facts and line.startswith('-'):
                key_facts.append(line[1:].strip())
        
        if not summary:
            summary = response[:200]
        
        return EntitySummary(
            entity_name=entity_name,
            summary=summary,
            key_facts=key_facts or facts[:5],
            relation_count=len(relations),
            mention_count=len(facts)
        )
```

---

### T7: åŠ¨æ€å®ä½“å±æ€§

#### 7.1 ä¿®æ”¹æ–‡ä»¶

**æ–‡ä»¶**: `recall/index/entity_index.py`

åœ¨ `IndexedEntity` æ•°æ®ç±»ä¸­æ·»åŠ æ–°å­—æ®µã€‚å°†ï¼š

```python
@dataclass
class IndexedEntity:
    """ç´¢å¼•ä¸­çš„å®ä½“"""
    id: str
    name: str
    aliases: List[str] = field(default_factory=list)
    entity_type: str = "UNKNOWN"
    turn_references: List[str] = field(default_factory=list)
    confidence: float = 0.5
```

ä¿®æ”¹ä¸ºï¼š

```python
@dataclass
class IndexedEntity:
    """ç´¢å¼•ä¸­çš„å®ä½“"""
    id: str
    name: str
    aliases: List[str] = field(default_factory=list)
    entity_type: str = "UNKNOWN"
    turn_references: List[str] = field(default_factory=list)
    confidence: float = 0.5
    # === Recall 4.1 æ–°å¢å­—æ®µ ===
    summary: str = ""                           # å®ä½“æ‘˜è¦
    attributes: Dict[str, Any] = field(default_factory=dict)  # åŠ¨æ€å±æ€§
    last_summary_update: Optional[str] = None   # æ‘˜è¦æœ€åæ›´æ–°æ—¶é—´
```

åŒæ—¶åœ¨æ–‡ä»¶é¡¶éƒ¨ç¡®ä¿æœ‰å¯¼å…¥ï¼š
```python
from typing import List, Dict, Any, Optional
```

---

## é…ç½®è¯´æ˜

### æ–°å¢ç¯å¢ƒå˜é‡

åœ¨ `recall_data/config/api_keys.env` æœ«å°¾æ·»åŠ ï¼š

```bash
# ============================================
# Recall 4.1 æ–°å¢é…ç½®
# ============================================

# === LLM å…³ç³»æå– ===
# æ¨¡å¼: rules / adaptive / llm
LLM_RELATION_MODE=rules
LLM_RELATION_COMPLEXITY_THRESHOLD=0.5
LLM_RELATION_ENABLE_TEMPORAL=true
LLM_RELATION_ENABLE_FACT_DESCRIPTION=true

# === å®ä½“æ‘˜è¦ ===
# æ˜¯å¦å¯ç”¨å®ä½“æ‘˜è¦ç”Ÿæˆ
ENTITY_SUMMARY_ENABLED=false
# è§¦å‘ LLM æ‘˜è¦çš„æœ€å°äº‹å®æ•°
ENTITY_SUMMARY_MIN_FACTS=5

# === Episode è¿½æº¯ ===
# æ˜¯å¦å¯ç”¨ Episode è¿½æº¯
EPISODE_TRACKING_ENABLED=false
```

### é…ç½®ä¼˜å…ˆçº§

1. ç¯å¢ƒå˜é‡ > api_keys.env > é»˜è®¤å€¼
2. æ‰€æœ‰æ–°åŠŸèƒ½é»˜è®¤å…³é—­ï¼Œéœ€è¦æ˜¾å¼å¯ç”¨
3. å¯ç”¨æ–°åŠŸèƒ½ä¸ä¼šå½±å“ç°æœ‰æ•°æ®

---

## æµ‹è¯•éªŒè¯

### æµ‹è¯•ç”¨ä¾‹æ¸…å•

**æ–‡ä»¶**: `tests/test_v41_upgrade.py`

```python
"""Recall 4.1 å‡çº§æµ‹è¯•"""

import pytest
import tempfile
import os


def test_llm_relation_extractor_rules_mode():
    """æµ‹è¯• LLM å…³ç³»æå–å™¨ - è§„åˆ™æ¨¡å¼"""
    from recall.graph.llm_relation_extractor import (
        LLMRelationExtractor, LLMRelationExtractorConfig, RelationExtractionMode
    )
    
    extractor = LLMRelationExtractor(
        config=LLMRelationExtractorConfig(mode=RelationExtractionMode.RULES)
    )
    
    text = "å¼ ä¸‰æ˜¯æå››çš„æœ‹å‹ï¼Œä»–ä»¬ä½åœ¨åŒ—äº¬ã€‚"
    entities = ["å¼ ä¸‰", "æå››", "åŒ—äº¬"]
    
    relations = extractor.extract(text, entities)
    
    assert len(relations) >= 1
    assert any(r.relation_type == "IS_FRIEND_OF" for r in relations)


def test_llm_relation_extractor_backward_compatible():
    """æµ‹è¯•å‘åå…¼å®¹æ€§"""
    from recall.graph.llm_relation_extractor import LLMRelationExtractor
    
    extractor = LLMRelationExtractor()
    
    # ä½¿ç”¨ legacy æ¥å£
    relations = extractor.extract_legacy("å¼ ä¸‰å–œæ¬¢æå››", entities=["å¼ ä¸‰", "æå››"])
    
    assert isinstance(relations, list)
    assert all(isinstance(r, tuple) and len(r) == 4 for r in relations)


def test_entity_schema_registry():
    """æµ‹è¯•å®ä½“ç±»å‹æ³¨å†Œè¡¨"""
    from recall.models.entity_schema import EntitySchemaRegistry, EntityTypeDefinition
    
    with tempfile.TemporaryDirectory() as tmpdir:
        registry = EntitySchemaRegistry(tmpdir)
        
        # æ£€æŸ¥å†…ç½®ç±»å‹
        assert registry.get("PERSON") is not None
        assert registry.get("LOCATION") is not None
        
        # æ³¨å†Œè‡ªå®šä¹‰ç±»å‹
        registry.register(EntityTypeDefinition(
            name="CHARACTER",
            display_name="è§’è‰²",
            description="æ•…äº‹ä¸­çš„è§’è‰²"
        ))
        
        assert registry.get("CHARACTER") is not None


def test_episode_node():
    """æµ‹è¯• Episode èŠ‚ç‚¹"""
    from recall.models.episode import EpisodeNode, EpisodeType
    
    ep = EpisodeNode(
        source_type=EpisodeType.MESSAGE,
        content="æµ‹è¯•å†…å®¹",
        user_id="user1",
        character_id="char1"
    )
    
    assert ep.uuid is not None
    assert ep.content == "æµ‹è¯•å†…å®¹"
    
    # æµ‹è¯•åºåˆ—åŒ–
    data = ep.to_dict()
    assert data['source_type'] == 'message'
    
    # æµ‹è¯•ååºåˆ—åŒ–
    ep2 = EpisodeNode.from_dict(data)
    assert ep2.content == ep.content


def test_entity_summarizer_simple():
    """æµ‹è¯•å®ä½“æ‘˜è¦ç”Ÿæˆå™¨ - ç®€å•æ¨¡å¼"""
    from recall.processor.entity_summarizer import EntitySummarizer
    
    summarizer = EntitySummarizer()  # æ—  LLM
    
    summary = summarizer.generate(
        entity_name="å¼ ä¸‰",
        facts=["å¼ ä¸‰æ˜¯ç¨‹åºå‘˜", "å¼ ä¸‰å–œæ¬¢å–å’–å•¡"],
        relations=[("å¼ ä¸‰", "WORKS_AT", "è…¾è®¯")]
    )
    
    assert summary.entity_name == "å¼ ä¸‰"
    assert len(summary.key_facts) <= 5


def test_existing_relation_extractor_unchanged():
    """æµ‹è¯•ç°æœ‰ RelationExtractor ä¸å—å½±å“"""
    from recall.graph.relation_extractor import RelationExtractor
    
    extractor = RelationExtractor()
    relations = extractor.extract("å¼ ä¸‰å–œæ¬¢æå››", entities=["å¼ ä¸‰", "æå››"])
    
    assert isinstance(relations, list)
    # éªŒè¯è¿”å›æ ¼å¼
    for rel in relations:
        assert isinstance(rel, tuple)
        assert len(rel) == 4


def test_existing_entity_extractor_unchanged():
    """æµ‹è¯•ç°æœ‰ EntityExtractor ä¸å—å½±å“"""
    from recall.processor.entity_extractor import EntityExtractor
    
    extractor = EntityExtractor()
    entities = extractor.extract("å¼ ä¸‰å’Œæå››åœ¨åŒ—äº¬è§é¢")
    
    assert isinstance(entities, list)


def test_knowledge_graph_backward_compatible():
    """æµ‹è¯• KnowledgeGraph å‘åå…¼å®¹"""
    from recall.graph.knowledge_graph import KnowledgeGraph
    
    with tempfile.TemporaryDirectory() as tmpdir:
        kg = KnowledgeGraph(tmpdir)
        
        # æ—§æ¥å£ä»ç„¶å¯ç”¨
        rel = kg.add_relation(
            source_id="A",
            target_id="B",
            relation_type="KNOWS"
        )
        
        assert rel is not None
        
        # æ–°æ¥å£å¯é€‰ä½¿ç”¨
        rel2 = kg.add_relation(
            source_id="C",
            target_id="D",
            relation_type="WORKS_AT",
            valid_at="2023-01-01",
            fact="C åœ¨ D å·¥ä½œ"
        )
        
        assert rel2 is not None
```

### è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰ v4.1 æµ‹è¯•
python -m pytest tests/test_v41_upgrade.py -v

# è¿è¡Œå®Œæ•´å›å½’æµ‹è¯•
python -m pytest tests/ -v --ignore=tests/test_stress.py
```

---

## å›æ»šæ–¹æ¡ˆ

### å¦‚ä½•å®‰å…¨å›æ»š

1. **é…ç½®å›æ»š**ï¼šå°†æ‰€æœ‰æ–°å¢é…ç½®è®¾ä¸ºå…³é—­çŠ¶æ€
   ```bash
   LLM_RELATION_MODE=rules
   ENTITY_SUMMARY_ENABLED=false
   EPISODE_TRACKING_ENABLED=false
   ```

2. **ä»£ç å›æ»š**ï¼šåˆ é™¤æ–°å¢æ–‡ä»¶ï¼ˆä¸å½±å“ç°æœ‰åŠŸèƒ½ï¼‰
   ```bash
   rm recall/graph/llm_relation_extractor.py
   rm recall/models/entity_schema.py
   rm recall/models/episode.py
   rm recall/processor/entity_summarizer.py
   ```

3. **æ•°æ®å…¼å®¹**ï¼šæ–°å¢å­—æ®µï¼ˆå¦‚ `valid_at`ã€`summary`ï¼‰åœ¨åŠ è½½æ—¶ä¼šè¢«å¿½ç•¥ï¼Œä¸ä¼šå¯¼è‡´é”™è¯¯

### å…¼å®¹æ€§ä¿è¯

| ç»„ä»¶ | å‘åå…¼å®¹ | è¯´æ˜ |
|------|----------|------|
| RelationExtractor | âœ… 100% | æ–°æ–¹æ³•åœ¨æ—§ç±»åŸºç¡€ä¸Šå¢åŠ ï¼Œä¸ä¿®æ”¹åŸæœ‰æ–¹æ³•ç­¾å |
| EntityExtractor | âœ… 100% | ä¸ä¿®æ”¹ |
| KnowledgeGraph | âœ… 100% | æ–°å¢å­—æ®µæœ‰é»˜è®¤å€¼ï¼Œæ—§æ•°æ®å¯æ­£å¸¸åŠ è½½ |
| Engine.add() | âœ… 100% | ä½¿ç”¨æ¡ä»¶åˆ†æ”¯ï¼Œæ—  LLM æ—¶é™çº§åˆ°è§„åˆ™æ¨¡å¼ |
| æ£€ç´¢ç³»ç»Ÿ | âœ… 100% | ä¸ä¿®æ”¹ |

---

## å®æ–½æ£€æŸ¥æ¸…å•

### Phase 1: T1 + T2ï¼ˆLLM å…³ç³»æå– + æ—¶æ€ä¿¡æ¯ï¼‰

- [ ] åˆ›å»º `recall/graph/llm_relation_extractor.py`
- [ ] ä¿®æ”¹ `recall/graph/__init__.py` å¯¼å‡ºæ–°ç±»
- [ ] ä¿®æ”¹ `recall/graph/knowledge_graph.py` æ·»åŠ æ—¶æ€å­—æ®µ
- [ ] ä¿®æ”¹ `recall/engine.py` é›†æˆ LLM å…³ç³»æå–å™¨
- [ ] æ·»åŠ é…ç½®é¡¹åˆ° `api_keys.env`
- [ ] æ·»åŠ é…ç½®é¡¹åˆ° `start.ps1` / `start.sh`
- [ ] ç¼–å†™æµ‹è¯•ç”¨ä¾‹
- [ ] è¿è¡Œå›å½’æµ‹è¯•

### Phase 2: T3 + T4ï¼ˆè‡ªå®šä¹‰å®ä½“ç±»å‹ï¼‰

- [ ] åˆ›å»º `recall/models/entity_schema.py`
- [ ] ä¿®æ”¹ `recall/processor/smart_extractor.py` é›†æˆ Schema
- [ ] ä¿®æ”¹ `recall/engine.py` åˆå§‹åŒ– Schema Registry
- [ ] ç¼–å†™æµ‹è¯•ç”¨ä¾‹
- [ ] è¿è¡Œå›å½’æµ‹è¯•

### Phase 3: T5ï¼ˆEpisode è¿½æº¯ï¼‰

- [ ] åˆ›å»º `recall/models/episode.py`
- [ ] åˆ›å»º `recall/storage/episode_store.py`ï¼ˆå¯é€‰ï¼‰
- [ ] ä¿®æ”¹ `recall/engine.py` é›†æˆ Episode è¿½æº¯
- [ ] ç¼–å†™æµ‹è¯•ç”¨ä¾‹
- [ ] è¿è¡Œå›å½’æµ‹è¯•

### Phase 4: T6 + T7ï¼ˆæ‘˜è¦ + åŠ¨æ€å±æ€§ï¼‰

- [ ] åˆ›å»º `recall/processor/entity_summarizer.py`
- [ ] ä¿®æ”¹ `recall/index/entity_index.py` æ·»åŠ å­—æ®µ
- [ ] ä¿®æ”¹ `recall/engine.py` é›†æˆæ‘˜è¦ç”Ÿæˆ
- [ ] ç¼–å†™æµ‹è¯•ç”¨ä¾‹
- [ ] è¿è¡Œå›å½’æµ‹è¯•

---

## æ€»ç»“

æœ¬å‡çº§è®¡åˆ’çš„æ ¸å¿ƒåŸåˆ™ï¼š

1. **å‘åå…¼å®¹**ï¼šæ‰€æœ‰æ–°åŠŸèƒ½é»˜è®¤å…³é—­ï¼Œéœ€è¦æ˜¾å¼å¯ç”¨
2. **æ¸è¿›å¼**ï¼šå¯ä»¥æŒ‰ Phase åˆ†æ­¥å®æ–½ï¼Œæ¯ä¸ª Phase ç‹¬ç«‹å¯æµ‹è¯•
3. **æˆæœ¬å¯æ§**ï¼šLLM åŠŸèƒ½éƒ½æœ‰è§„åˆ™æ¨¡å¼é™çº§
4. **æ•°æ®å®‰å…¨**ï¼šæ–°å¢å­—æ®µæœ‰é»˜è®¤å€¼ï¼Œä¸å½±å“æ—§æ•°æ®åŠ è½½

é¢„è®¡å®æ–½æ—¶é—´ï¼š
- Phase 1ï¼š2-3 å°æ—¶
- Phase 2ï¼š2-3 å°æ—¶
- Phase 3ï¼š2-3 å°æ—¶
- Phase 4ï¼š1-2 å°æ—¶

æ€»è®¡ï¼šçº¦ 8-11 å°æ—¶

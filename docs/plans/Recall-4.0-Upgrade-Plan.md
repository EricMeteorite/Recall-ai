# Recall 4.0 å‡çº§è®¡åˆ’ï¼šå…¨é¢è¶…è¶Š Graphiti

> ğŸ“… åˆ›å»ºæ—¥æœŸï¼š2026-01-23
> ğŸ¯ ç›®æ ‡ï¼šåœ¨ä¿æŒ Recall æ‰€æœ‰ç°æœ‰ä¼˜åŠ¿çš„åŸºç¡€ä¸Šï¼Œå…¨é¢è¶…è¶Š Graphitiï¼Œæˆä¸ºé€šç”¨ AI çŸ¥è¯†å›¾è°±æ¡†æ¶

---

## ğŸ“Š ç«å“åˆ†æï¼šGraphiti æ ¸å¿ƒèƒ½åŠ›çŸ©é˜µ

åŸºäº [GraphitiAnalysis.md](./GraphitiAnalysis.md) çš„æ·±åº¦åˆ†æï¼š

| èƒ½åŠ›ç»´åº¦ | Graphiti å®ç° | æŠ€æœ¯ç»†èŠ‚ |
|----------|---------------|----------|
| **æ•°æ®æ¨¡å‹** | åŒæ—¶æ€ (Bi-temporal) | `valid_at/invalid_at` + `expired_at` |
| **èŠ‚ç‚¹ç±»å‹** | 4ç§ | EntityNode, EpisodicNode, CommunityNode, SagaNode |
| **è¾¹ç±»å‹** | 3ç§ | EntityEdge, EpisodicEdge, CommunityEdge |
| **LLM é›†æˆ** | 6ä¸ªæä¾›å•† | OpenAI, Anthropic, Gemini, Groq, Azure, Ollama |
| **å›¾æ•°æ®åº“** | 4ç§ | Neo4j, FalkorDB, Neptune, Kuzu |
| **æ£€ç´¢æ–¹æ³•** | 3ç§ | BM25, Vector, Graph Traversal |
| **é‡æ’åºå™¨** | 5ç§ | RRF, MMR, CrossEncoder, NodeDistance, EpisodeMentions |
| **å»é‡æœºåˆ¶** | 2é˜¶æ®µ | MinHash+LSH â†’ LLM |
| **MCP æ”¯æŒ** | âœ… | 8ä¸ªå·¥å…· |
| **å®ä½“æŠ½å–** | çº¯ LLM | å¼ºåˆ¶ä¾èµ– |

---

## ğŸ¯ Recall 4.0 è¶…è¶Šç­–ç•¥

### æ ¸å¿ƒåŸåˆ™

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Recall 4.0 è®¾è®¡åŸåˆ™                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. é›¶ä¾èµ–ä¼˜å…ˆ - æ— éœ€å¤–éƒ¨æ•°æ®åº“ï¼Œå¼€ç®±å³ç”¨                        â”‚
â”‚  2. æˆæœ¬å¯æ§ - LLM å¯é€‰ï¼Œæœ¬åœ°ä¼˜å…ˆ                               â”‚
â”‚  3. å‘åå…¼å®¹ - ç°æœ‰åŠŸèƒ½ 100% ä¿ç•™                               â”‚
â”‚  4. åœºæ™¯é€šç”¨ - RP/ä»£ç /ä¼ä¸š/Agent å…¨è¦†ç›–                        â”‚
â”‚  5. æ€§èƒ½å“è¶Š - è¶…è¶Šè€Œéè¿½èµ¶                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ åŠŸèƒ½å¯¹æ¯”ä¸è¶…è¶Šæ–¹æ¡ˆ

### 1. æ—¶æ€ç³»ç»Ÿ

| ç»´åº¦ | Graphiti | Recall 4.0 | è¶…è¶Šç‚¹ |
|------|----------|------------|--------|
| æ—¶æ€å±‚æ•° | 2å±‚ | **3å±‚** | æ–°å¢"çŸ¥è¯†æ—¶é—´" |
| äº‹å®å¤±æ•ˆ | LLM æ£€æµ‹ | **æ··åˆæ£€æµ‹** | è§„åˆ™+LLMï¼Œæˆæœ¬æ›´ä½ |
| å†å²å›æº¯ | æ”¯æŒ | **æ”¯æŒ+å¯è§†åŒ–** | æ—¶é—´çº¿æŸ¥è¯¢ API |
| çŸ›ç›¾å¤„ç† | è‡ªåŠ¨å¤±æ•ˆ | **å¤šç­–ç•¥** | å–ä»£/å…±å­˜/æ‰‹åŠ¨ |

```python
# Recall 4.0 ä¸‰æ—¶æ€æ¨¡å‹
@dataclass
class TemporalFact:
    # T1: äº‹å®æ—¶é—´ (Fact Time) - äº‹å®åœ¨ç°å®ä¸­ä½•æ—¶æœ‰æ•ˆ
    valid_from: datetime | None      # "Alice ä» 2023-01 å¼€å§‹åœ¨ OpenAI å·¥ä½œ"
    valid_until: datetime | None     # "Alice äº 2024-06 ç¦»å¼€ OpenAI"
    
    # T2: çŸ¥è¯†æ—¶é—´ (Knowledge Time) - æˆ‘ä»¬ä½•æ—¶è·çŸ¥æ­¤äº‹å®ã€æ–°å¢ã€‘
    known_at: datetime               # æˆ‘ä»¬åœ¨ 2024-07 å¾—çŸ¥å¥¹ç¦»èŒ
    superseded_at: datetime | None   # æ­¤çŸ¥è¯†è¢«æ›´æ–°çš„ä¿¡æ¯å–ä»£
    
    # T3: ç³»ç»Ÿæ—¶é—´ (System Time) - æ•°æ®åº“è®°å½•ç”Ÿå‘½å‘¨æœŸ
    created_at: datetime
    expired_at: datetime | None
```

### 2. æ•°æ®æ¨¡å‹

| ç»´åº¦ | Graphiti | Recall 4.0 | è¶…è¶Šç‚¹ |
|------|----------|------------|--------|
| èŠ‚ç‚¹ç±»å‹ | 4ç§å›ºå®š | **å¯æ‰©å±•** | æ’ä»¶å¼èŠ‚ç‚¹ç±»å‹ |
| è¾¹ç±»å‹ | 3ç§å›ºå®š | **å¯æ‰©å±•** | æ’ä»¶å¼è¾¹ç±»å‹ |
| åŠ¨æ€å±æ€§ | Dict | **ç±»å‹å®‰å…¨ Dict** | Schema éªŒè¯ |
| å‘é‡åµŒå…¥ | å¯é€‰ | **å¤šå‘é‡** | åç§°+å†…å®¹+æ‘˜è¦ |

```python
# Recall 4.0 ç»Ÿä¸€æ•°æ®æ¨¡å‹
class UnifiedNode(BaseModel):
    """ç»Ÿä¸€èŠ‚ç‚¹æ¨¡å‹ - è¶…è¶Š Graphiti çš„ 4 ç§èŠ‚ç‚¹"""
    uuid: str
    name: str
    node_type: NodeType              # å¯æ‰©å±•æšä¸¾
    group_id: str                    # å¤šç§Ÿæˆ·éš”ç¦»
    
    # å¤šå‘é‡åµŒå…¥ã€è¶…è¶Šç‚¹ã€‘
    name_embedding: List[float] | None
    content_embedding: List[float] | None
    summary_embedding: List[float] | None
    
    # åŠ¨æ€å±æ€§ + Schema éªŒè¯ã€è¶…è¶Šç‚¹ã€‘
    attributes: Dict[str, Any]
    _attribute_schema: Dict[str, type] | None  # è¿è¡Œæ—¶ç±»å‹æ£€æŸ¥
    
    # æ¥æºè¿½è¸ªã€å¢å¼ºã€‘
    source_episodes: List[str]
    confidence: float
    verification_count: int

class NodeType(str, Enum):
    """å¯æ‰©å±•èŠ‚ç‚¹ç±»å‹"""
    ENTITY = "entity"           # å®ä½“ï¼ˆäººã€ç‰©ã€åœ°ç‚¹ï¼‰
    EPISODE = "episode"         # æƒ…èŠ‚/äº‹ä»¶
    COMMUNITY = "community"     # ç¤¾åŒº/èšç±»
    CONCEPT = "concept"         # æ¦‚å¿µ/æŠ½è±¡
    # Recall ç‹¬æœ‰
    FORESHADOWING = "foreshadowing"  # ä¼ç¬”
    CONDITION = "condition"          # æŒä¹…æ¡ä»¶
    RULE = "rule"                    # è§„åˆ™
    # å¯é€šè¿‡æ’ä»¶æ‰©å±•...
```

### 3. æ™ºèƒ½æŠ½å–ç³»ç»Ÿ

| ç»´åº¦ | Graphiti | Recall 4.0 | è¶…è¶Šç‚¹ |
|------|----------|------------|--------|
| æŠ½å–æ–¹å¼ | çº¯ LLM | **ä¸‰æ¨¡å¼** | Local/Hybrid/LLM |
| æˆæœ¬ | é«˜ï¼ˆå¼ºåˆ¶ï¼‰ | **å¯æ§** | é¢„ç®—ç®¡ç† |
| é€Ÿåº¦ | æ…¢ï¼ˆAPIï¼‰ | **è‡ªé€‚åº”** | ç®€å•å†…å®¹æœ¬åœ°å¤„ç† |
| ç¦»çº¿ | âŒ | **âœ…** | å®Œå…¨æœ¬åœ°è¿è¡Œ |

```python
class SmartExtractor:
    """æ™ºèƒ½æŠ½å–å™¨ - ä¸‰æ¨¡å¼è‡ªé€‚åº”"""
    
    class Mode(Enum):
        LOCAL = "local"       # çº¯æœ¬åœ°ï¼šspaCy + jieba + è§„åˆ™
        HYBRID = "hybrid"     # æ··åˆï¼šæœ¬åœ°åˆç­› + LLM ç²¾ç‚¼
        LLM_FULL = "llm"      # çº¯ LLMï¼šæœ€é«˜è´¨é‡
    
    def __init__(
        self,
        mode: Mode = Mode.HYBRID,
        daily_budget: float = 1.0,      # æ¯æ—¥ LLM é¢„ç®—ï¼ˆç¾å…ƒï¼‰
        complexity_threshold: float = 0.6,  # å¤æ‚åº¦é˜ˆå€¼
        local_extractor: EntityExtractor = None,
        llm_client: LLMClient = None
    ):
        self.mode = mode
        self.budget_manager = BudgetManager(daily_budget)
        self.complexity_threshold = complexity_threshold
        self.local = local_extractor or EntityExtractor()
        self.llm = llm_client
    
    async def extract(self, text: str, context: Dict = None) -> ExtractionResult:
        """è‡ªé€‚åº”æŠ½å–"""
        # 1. å§‹ç»ˆæ‰§è¡Œæœ¬åœ°æŠ½å–ï¼ˆå…è´¹ã€å¿«é€Ÿï¼‰
        local_result = self.local.extract(text)
        
        if self.mode == Mode.LOCAL:
            return local_result
        
        # 2. è¯„ä¼°å¤æ‚åº¦
        complexity = self._assess_complexity(text, local_result)
        
        # 3. å†³ç­–æ˜¯å¦éœ€è¦ LLM
        need_llm = (
            self.mode == Mode.LLM_FULL or
            (self.mode == Mode.HYBRID and complexity >= self.complexity_threshold)
        )
        
        if need_llm and self.budget_manager.can_afford():
            llm_result = await self._llm_extract(text, local_result, context)
            self.budget_manager.record_cost(llm_result.cost)
            return self._merge_results(local_result, llm_result)
        
        return local_result
    
    def _assess_complexity(self, text: str, local_result) -> float:
        """è¯„ä¼°æ–‡æœ¬å¤æ‚åº¦"""
        score = 0.0
        
        # é•¿åº¦
        if len(text) > 500: score += 0.15
        if len(text) > 1000: score += 0.15
        
        # å®ä½“å¯†åº¦
        entity_density = len(local_result.entities) / max(len(text) / 100, 1)
        if entity_density > 0.5: score += 0.2
        
        # å…³ç³»å¤æ‚åº¦
        if len(local_result.entities) > 3: score += 0.15
        
        # æ—¶æ€æ ‡è®°
        if self._has_temporal_markers(text): score += 0.15
        
        # æœ¬åœ°æŠ½å–ç½®ä¿¡åº¦ä½
        if local_result.avg_confidence < 0.6: score += 0.2
        
        return min(1.0, score)
```

### 4. çŸ¥è¯†å›¾è°±å­˜å‚¨

| ç»´åº¦ | Graphiti | Recall 4.0 | è¶…è¶Šç‚¹ |
|------|----------|------------|--------|
| å­˜å‚¨åç«¯ | Neo4j ç­‰ï¼ˆå¿…éœ€ï¼‰ | **çº¯æœ¬åœ°** | é›¶ä¾èµ– |
| æŸ¥è¯¢è¯­è¨€ | Cypher | **å¤šç§** | Python API + ç±» Cypher DSL |
| æ€§èƒ½ | ä¾èµ–æ•°æ®åº“ | **å†…å­˜ä¼˜åŒ–** | çƒ­æ•°æ®å¸¸é©» |
| å¯é€‰å¤–éƒ¨ | - | **âœ…** | å¯é€‰æ¥å…¥ Neo4j |

```python
class TemporalKnowledgeGraph:
    """æ—¶åºçŸ¥è¯†å›¾è°± - æ— éœ€å¤–éƒ¨æ•°æ®åº“"""
    
    def __init__(
        self, 
        data_path: str,
        backend: str = "local",  # local | neo4j | falkordb
        scope: str = "global"    # global | isolated
    ):
        self.data_path = data_path
        self.scope = scope
        
        # æ ¸å¿ƒå­˜å‚¨
        self.nodes: Dict[str, UnifiedNode] = {}
        self.edges: Dict[str, TemporalFact] = {}
        self.episodes: Dict[str, EpisodicNode] = {}
        
        # é«˜æ•ˆç´¢å¼•
        self._indexes = GraphIndexes(
            outgoing=defaultdict(set),      # node_id -> edge_ids
            incoming=defaultdict(set),      # node_id -> edge_ids
            by_type=defaultdict(set),       # node_type -> node_ids
            by_predicate=defaultdict(set),  # predicate -> edge_ids
            temporal=TemporalIndex(),       # æ—¶é—´èŒƒå›´ç´¢å¼•
            fulltext=FullTextIndex(),       # BM25 å…¨æ–‡ç´¢å¼•
        )
        
        # å¯é€‰ï¼šå‘é‡ç´¢å¼•
        self.vector_index: Optional[VectorIndex] = None
        
        # å¯é€‰ï¼šå¤–éƒ¨æ•°æ®åº“åç«¯
        if backend == "neo4j":
            self._backend = Neo4jBackend(...)
        elif backend == "falkordb":
            self._backend = FalkorDBBackend(...)
        else:
            self._backend = None  # çº¯æœ¬åœ°
    
    # === æ—¶æ€æŸ¥è¯¢ API ===
    
    def query_at_time(
        self,
        subject: str,
        as_of: datetime,
        predicate: str = None
    ) -> List[TemporalFact]:
        """æŸ¥è¯¢æŸæ—¶é—´ç‚¹çš„æœ‰æ•ˆäº‹å®"""
        results = []
        for edge_id in self._indexes.outgoing.get(subject, []):
            edge = self.edges[edge_id]
            if predicate and edge.predicate != predicate:
                continue
            if self._is_valid_at(edge, as_of):
                results.append(edge)
        return results
    
    def query_timeline(
        self,
        subject: str,
        predicate: str = None,
        start: datetime = None,
        end: datetime = None
    ) -> List[Tuple[datetime, TemporalFact, str]]:
        """è·å–å®ä½“æ—¶é—´çº¿ï¼ˆæ‰€æœ‰å†å²çŠ¶æ€å˜åŒ–ï¼‰"""
        timeline = []
        for edge_id in self._indexes.outgoing.get(subject, []):
            edge = self.edges[edge_id]
            if predicate and edge.predicate != predicate:
                continue
            
            # è®°å½•çŠ¶æ€å˜åŒ–ç‚¹
            if edge.valid_from:
                timeline.append((edge.valid_from, edge, "started"))
            if edge.valid_until:
                timeline.append((edge.valid_until, edge, "ended"))
            if edge.superseded_at:
                timeline.append((edge.superseded_at, edge, "superseded"))
        
        # æŒ‰æ—¶é—´æ’åº
        timeline.sort(key=lambda x: x[0])
        
        # åº”ç”¨æ—¶é—´èŒƒå›´è¿‡æ»¤
        if start:
            timeline = [t for t in timeline if t[0] >= start]
        if end:
            timeline = [t for t in timeline if t[0] <= end]
        
        return timeline
    
    # === çŸ›ç›¾æ£€æµ‹ä¸å¤„ç† ===
    
    def detect_contradictions(
        self,
        new_fact: TemporalFact,
        strategy: str = "auto"  # auto | strict | permissive
    ) -> List[Contradiction]:
        """æ£€æµ‹çŸ›ç›¾"""
        contradictions = []
        
        # æŸ¥æ‰¾åŒä¸»ä½“ã€åŒè°“è¯çš„ç°æœ‰äº‹å®
        existing = self.query_at_time(
            new_fact.subject,
            new_fact.valid_from or datetime.now(),
            new_fact.predicate
        )
        
        for old_fact in existing:
            if old_fact.object != new_fact.object:
                contradiction = Contradiction(
                    old_fact=old_fact,
                    new_fact=new_fact,
                    type=self._classify_contradiction(old_fact, new_fact),
                    confidence=self._compute_contradiction_confidence(old_fact, new_fact)
                )
                contradictions.append(contradiction)
        
        return contradictions
    
    def resolve_contradiction(
        self,
        contradiction: Contradiction,
        resolution: str = "supersede"  # supersede | coexist | reject | manual
    ) -> ResolutionResult:
        """è§£å†³çŸ›ç›¾"""
        if resolution == "supersede":
            # æ–°äº‹å®å–ä»£æ—§äº‹å®
            old = contradiction.old_fact
            old.valid_until = contradiction.new_fact.valid_from
            old.superseded_at = datetime.now()
            return ResolutionResult(success=True, action="superseded")
        
        elif resolution == "coexist":
            # ä¸¤ä¸ªäº‹å®å…±å­˜ï¼ˆå¯èƒ½æ¥è‡ªä¸åŒè§†è§’/æ¥æºï¼‰
            return ResolutionResult(success=True, action="coexist")
        
        elif resolution == "reject":
            # æ‹’ç»æ–°äº‹å®
            return ResolutionResult(success=False, action="rejected")
        
        else:
            # æ ‡è®°ä¸ºå¾…äººå·¥å¤„ç†
            self._pending_contradictions.append(contradiction)
            return ResolutionResult(success=True, action="pending_manual")
    
    # === å›¾éå† ===
    
    def bfs(
        self,
        start: str,
        max_depth: int = 3,
        predicate_filter: List[str] = None,
        time_filter: datetime = None,
        direction: str = "both"  # out | in | both
    ) -> Dict[int, List[Tuple[str, TemporalFact]]]:
        """å¹¿åº¦ä¼˜å…ˆæœç´¢ï¼Œè¿”å›æŒ‰æ·±åº¦åˆ†ç»„çš„ç»“æœ"""
        visited = {start}
        queue = [(start, 0)]
        results = defaultdict(list)
        
        while queue:
            node_id, depth = queue.pop(0)
            if depth >= max_depth:
                continue
            
            # è·å–è¾¹
            edge_ids = set()
            if direction in ("out", "both"):
                edge_ids.update(self._indexes.outgoing.get(node_id, []))
            if direction in ("in", "both"):
                edge_ids.update(self._indexes.incoming.get(node_id, []))
            
            for edge_id in edge_ids:
                edge = self.edges[edge_id]
                
                # æ—¶æ€è¿‡æ»¤
                if time_filter and not self._is_valid_at(edge, time_filter):
                    continue
                
                # è°“è¯è¿‡æ»¤
                if predicate_filter and edge.predicate not in predicate_filter:
                    continue
                
                # ç¡®å®šç›®æ ‡èŠ‚ç‚¹
                target = edge.object if edge.subject == node_id else edge.subject
                
                results[depth].append((target, edge))
                
                if target not in visited:
                    visited.add(target)
                    queue.append((target, depth + 1))
        
        return results
    
    # === ç±» Cypher æŸ¥è¯¢ DSL ===
    
    def query(self, pattern: str) -> QueryBuilder:
        """
        ç±» Cypher æŸ¥è¯¢è¯­æ³•
        
        ç¤ºä¾‹:
            graph.query("(p:PERSON)-[r:WORKS_AT]->(c:COMPANY)")
                 .where(r.valid_at >= "2024-01-01")
                 .return_("p.name", "c.name", "r.fact")
                 .execute()
        """
        return QueryBuilder(self, pattern)
```

### 5. æ£€ç´¢ç³»ç»Ÿ

| ç»´åº¦ | Graphiti | Recall 4.0 | è¶…è¶Šç‚¹ |
|------|----------|------------|--------|
| æ£€ç´¢å±‚æ•° | 3å±‚ | **11å±‚** | æ›´ç²¾ç»†çš„æ¼æ–— |
| é‡æ’åºå™¨ | 5ç§ | **7ç§** | æ–°å¢æ—¶æ€/ä¼ç¬”é‡æ’ |
| èåˆç®—æ³• | RRF | **RRF + è‡ªé€‚åº”æƒé‡** | åœºæ™¯æ„ŸçŸ¥èåˆ |
| å›¾éå† | ç®€å• BFS | **å¤šç­–ç•¥** | BFS/DFS/éšæœºæ¸¸èµ° |

```python
class ElevenLayerRetriever:
    """åä¸€å±‚æ¼æ–—æ£€ç´¢å™¨ï¼ˆæ¦‚è¿°ç‰ˆï¼Œè¯¦è§ Phase 3ï¼‰"""
    
    class Layer(Enum):
        L1_BLOOM_FILTER = "bloom"            # å¿«é€Ÿå¦å®š
        L2_TEMPORAL_FILTER = "temporal"      # æ—¶æ€è¿‡æ»¤ã€æ–°å¢ã€‘
        L3_INVERTED_INDEX = "inverted"       # å…³é”®è¯åŒ¹é…
        L4_ENTITY_INDEX = "entity"           # å®ä½“å…³è”
        L5_GRAPH_TRAVERSAL = "graph"         # å›¾éå†ã€æ–°å¢ã€‘
        L6_NGRAM_INDEX = "ngram"             # æ¨¡ç³ŠåŒ¹é…
        L7_VECTOR_COARSE = "vector_coarse"   # å‘é‡ç²—ç­›
        L8_VECTOR_FINE = "vector_fine"       # å‘é‡ç²¾æ’
        L9_RERANK = "rerank"                 # TF-IDF é‡æ’åº
        L10_CROSS_ENCODER = "cross_encoder"  # äº¤å‰ç¼–ç å™¨ã€æ–°å¢ã€‘
        L11_LLM_FILTER = "llm_filter"        # LLM è¿‡æ»¤
    
    async def retrieve(
        self,
        query: str,
        config: RetrievalConfig = None,
        temporal_context: TemporalContext = None,
        entities: List[str] = None
    ) -> List[RetrievalResult]:
        """æ‰§è¡Œåä¸€å±‚æ£€ç´¢ï¼ˆè¯¦ç»†å®ç°è§ Phase 3ï¼‰"""
        
        config = config or RetrievalConfig.default()
        candidates = set()
        scores = defaultdict(float)
        
        # L1: Bloom Filter - O(1) å¿«é€Ÿå¦å®š
        if config.l1_enabled:
            keywords = self._extract_keywords(query)
            keywords = [k for k in keywords if k in self.bloom_filter]
        
        # L2: æ—¶æ€è¿‡æ»¤ã€æ–°å¢ã€‘
        if config.l2_enabled and temporal_context:
            # é¢„å…ˆè¿‡æ»¤æ—¶é—´èŒƒå›´å¤–çš„æ–‡æ¡£
            temporal_candidates = self._l2_temporal_filter(temporal_context, config)
        
        # L3: å€’æ’ç´¢å¼• - å…³é”®è¯åŒ¹é…
        if config.l3_enabled:
            inverted_results = self.inverted_index.search(keywords)
            for doc_id, score in inverted_results:
                candidates.add(doc_id)
                scores[doc_id] += score * config.weights.inverted
        
        # L4: å®ä½“ç´¢å¼•
        if config.l4_enabled:
            for entity in entities or []:
                for doc_id in self.entity_index.get_docs(entity):
                    candidates.add(doc_id)
                    scores[doc_id] += config.weights.entity
        
        # L5: å›¾éå†ã€æ–°å¢ã€‘
        if config.l5_enabled and entities:
            self._l5_graph_traversal(entities, candidates, scores, config)
        
        # L6: N-gram ç´¢å¼• - æ¨¡ç³ŠåŒ¹é…
        if config.l6_enabled:
            ngram_results = self.ngram_index.search(query)
            for doc_id in ngram_results:
                candidates.add(doc_id)
                scores[doc_id] += config.weights.ngram
        
        # L7: å‘é‡ç²—ç­›
        if config.l7_enabled and self.vector_index:
            vector_results = self.vector_index.search(query, top_k=config.l7_vector_top_k)
            for doc_id, sim in vector_results:
                candidates.add(doc_id)
                scores[doc_id] += sim * config.weights.vector
        
        # L8: å‘é‡ç²¾æ’
        if config.l8_enabled and len(candidates) > config.fine_rank_threshold:
            self._l8_vector_fine(query, candidates, scores, config)
        
        # L9: TF-IDF é‡æ’åº
        if config.l9_enabled:
            self._l9_rerank(query, candidates, scores)
        
        # L10: Cross-Encoder é‡æ’åºã€æ–°å¢ï¼Œå¯é€‰ã€‘
        if config.l10_enabled and self.cross_encoder:
            self._l10_cross_encoder(query, candidates, scores, config)
        
        # L11: LLM é‡æ’åºã€å¯é€‰ï¼Œé«˜æˆæœ¬ã€‘
        if config.l11_enabled and self.llm_client:
            candidates, scores = await self._l11_llm_filter(query, candidates, scores, config)
        
        # æœ€ç»ˆæ’åº
        final_results = sorted(
            [(doc_id, scores[doc_id]) for doc_id in candidates],
            key=lambda x: x[1],
            reverse=True
        )
        
        return [
            RetrievalResult(id=doc_id, score=score, content=self._get_content(doc_id))
            for doc_id, score in final_results[:config.final_top_k]
        ]
```

### 6. å»é‡ç³»ç»Ÿ

| ç»´åº¦ | Graphiti | Recall 4.0 | è¶…è¶Šç‚¹ |
|------|----------|------------|--------|
| é˜¶æ®µæ•° | 2é˜¶æ®µ | **3é˜¶æ®µ** | æ–°å¢è¯­ä¹‰å±‚ |
| ç¬¬ä¸€é˜¶æ®µ | MinHash+LSH | **ç›¸åŒ** | ä¿æŒ |
| ç¬¬äºŒé˜¶æ®µ | LLM | **Embedding** | æˆæœ¬æ›´ä½ |
| ç¬¬ä¸‰é˜¶æ®µ | - | **LLMï¼ˆå¯é€‰ï¼‰** | ä»…é«˜ä»·å€¼åœºæ™¯ |

```python
class ThreeStageDeduplicator:
    """ä¸‰é˜¶æ®µå»é‡ç³»ç»Ÿ"""
    
    async def deduplicate(
        self,
        new_items: List[Entity],
        existing_items: List[Entity],
        config: DedupConfig = None
    ) -> DedupResult:
        
        config = config or DedupConfig.default()
        result = DedupResult()
        
        # æ„å»ºç´¢å¼•
        indexes = self._build_indexes(existing_items)
        
        for item in new_items:
            # === é˜¶æ®µ 1: ç¡®å®šæ€§åŒ¹é… O(1) ===
            # 1.1 ç²¾ç¡®åŒ¹é…
            normalized = self._normalize(item.name)
            if normalized in indexes.exact_map:
                result.add_match(item, indexes.exact_map[normalized], "exact", 1.0)
                continue
            
            # 1.2 MinHash + LSH è¿‘ä¼¼åŒ¹é…
            shingles = self._get_shingles(item.name)
            signature = self._minhash(shingles)
            candidates = self._lsh_query(signature, indexes.lsh_buckets)
            
            if candidates:
                best_match, jaccard = self._best_jaccard_match(shingles, candidates, indexes)
                if jaccard >= config.jaccard_threshold:
                    result.add_match(item, best_match, "fuzzy", jaccard)
                    continue
            
            # === é˜¶æ®µ 2: è¯­ä¹‰åŒ¹é…ã€æ–°å¢ã€‘ ===
            if config.enable_semantic and self.embedding_backend:
                item_embedding = await self.embedding_backend.embed(item.name)
                
                # åœ¨å‘é‡ç´¢å¼•ä¸­æœç´¢
                similar = self.entity_vectors.search(item_embedding, top_k=5)
                
                for candidate_id, similarity in similar:
                    if similarity >= config.semantic_threshold:
                        candidate = indexes.by_id[candidate_id]
                        result.add_match(item, candidate, "semantic", similarity)
                        break
                else:
                    # æ²¡æœ‰æ‰¾åˆ°è¶³å¤Ÿç›¸ä¼¼çš„ï¼Œè¿›å…¥é˜¶æ®µ3æˆ–æ ‡è®°ä¸ºæ–°å®ä½“
                    if config.enable_llm and similarity >= config.llm_threshold:
                        # è¾¹ç•Œæƒ…å†µï¼Œéœ€è¦ LLM ç¡®è®¤
                        result.add_pending(item, similar[:3])
                    else:
                        result.add_new(item)
                continue
            
            # === é˜¶æ®µ 3: LLM ç¡®è®¤ï¼ˆå¯é€‰ï¼‰===
            # ä»…å¤„ç†é˜¶æ®µ2ä¸­çš„è¾¹ç•Œæƒ…å†µ
        
        # æ‰¹é‡ LLM ç¡®è®¤
        if result.pending and config.enable_llm and self.llm_client:
            llm_results = await self._llm_batch_confirm(result.pending)
            for item, is_dup, match in llm_results:
                if is_dup:
                    result.move_to_match(item, match, "llm")
                else:
                    result.move_to_new(item)
        
        return result
```

### 7. MCP Server

| ç»´åº¦ | Graphiti | Recall 4.0 | è¶…è¶Šç‚¹ |
|------|----------|------------|--------|
| å·¥å…·æ•°é‡ | 8ä¸ª | **15+** | æ›´ä¸°å¯Œçš„åŠŸèƒ½ |
| Recall ç‹¬æœ‰ | - | **âœ…** | ä¼ç¬”/æ¡ä»¶/è§„åˆ™ |
| æ—¶æ€æŸ¥è¯¢ | åŸºç¡€ | **å®Œæ•´** | æ—¶é—´çº¿/å†å²/å¿«ç…§ |

```python
class RecallMCPServer:
    """Recall MCP Server - è¶…è¶Š Graphiti çš„å·¥å…·é›†"""
    
    def _register_tools(self):
        # === åŸºç¡€å·¥å…·ï¼ˆå¯¹æ ‡ Graphitiï¼‰===
        
        @self.server.tool()
        async def add_memory(content: str, user_id: str = "default", ...) -> dict:
            """æ·»åŠ è®°å¿†/çŸ¥è¯†"""
            ...
        
        @self.server.tool()
        async def search_facts(query: str, top_k: int = 10, ...) -> list:
            """æœç´¢äº‹å®å…³ç³»"""
            ...
        
        @self.server.tool()
        async def search_nodes(query: str, node_type: str = None, ...) -> list:
            """æœç´¢å®ä½“èŠ‚ç‚¹"""
            ...
        
        @self.server.tool()
        async def get_episodes(user_id: str, limit: int = 20, ...) -> list:
            """è·å–æƒ…èŠ‚åˆ—è¡¨"""
            ...
        
        @self.server.tool()
        async def delete_episode(episode_id: str) -> bool:
            """åˆ é™¤æƒ…èŠ‚"""
            ...
        
        @self.server.tool()
        async def clear_graph(user_id: str, confirm: bool = False) -> bool:
            """æ¸…ç©ºå›¾è°±"""
            ...
        
        # === æ—¶æ€æŸ¥è¯¢å·¥å…·ã€è¶…è¶Šç‚¹ã€‘===
        
        @self.server.tool()
        async def query_at_time(
            entity: str,
            as_of: str,  # ISO 8601 æ—¶é—´
            predicate: str = None
        ) -> list:
            """æŸ¥è¯¢æŸæ—¶é—´ç‚¹çš„æœ‰æ•ˆäº‹å®"""
            ...
        
        @self.server.tool()
        async def get_timeline(
            entity: str,
            predicate: str = None,
            start: str = None,
            end: str = None
        ) -> list:
            """è·å–å®ä½“çš„å®Œæ•´æ—¶é—´çº¿"""
            ...
        
        @self.server.tool()
        async def compare_snapshots(
            entity: str,
            time1: str,
            time2: str
        ) -> dict:
            """å¯¹æ¯”ä¸¤ä¸ªæ—¶é—´ç‚¹çš„çŠ¶æ€å·®å¼‚"""
            ...
        
        # === Recall ç‹¬æœ‰å·¥å…·ã€å·®å¼‚åŒ–ä¼˜åŠ¿ã€‘===
        
        @self.server.tool()
        async def plant_foreshadowing(
            content: str,
            keywords: list,
            importance: float = 0.5,
            user_id: str = "default",
            character_id: str = "default"
        ) -> dict:
            """åŸ‹ä¸‹ä¼ç¬”ï¼ˆå™äº‹åœºæ™¯ï¼‰"""
            ...
        
        @self.server.tool()
        async def get_active_foreshadowings(
            user_id: str,
            character_id: str,
            relevance_query: str = None
        ) -> list:
            """è·å–æ´»è·ƒä¼ç¬”ï¼ˆå¯æŒ‰ç›¸å…³æ€§è¿‡æ»¤ï¼‰"""
            ...
        
        @self.server.tool()
        async def resolve_foreshadowing(
            foreshadowing_id: str,
            resolution: str
        ) -> bool:
            """è§£å†³ä¼ç¬”"""
            ...
        
        @self.server.tool()
        async def add_persistent_context(
            content: str,
            context_type: str,  # user_identity | environment | character_trait | ...
            user_id: str = "default"
        ) -> dict:
            """æ·»åŠ æŒä¹…æ¡ä»¶"""
            ...
        
        @self.server.tool()
        async def get_persistent_contexts(
            user_id: str,
            context_type: str = None,
            active_only: bool = True
        ) -> list:
            """è·å–æŒä¹…æ¡ä»¶"""
            ...
        
        @self.server.tool()
        async def build_context(
            query: str,
            user_id: str = "default",
            character_id: str = "default",
            max_tokens: int = 2000,
            include_foreshadowing: bool = True,
            include_conditions: bool = True,
            include_graph_context: bool = True
        ) -> str:
            """æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆRecall æ ¸å¿ƒèƒ½åŠ›ï¼‰"""
            ...
```

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           Recall 4.0 ç³»ç»Ÿæ¶æ„                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚ MCP Server  â”‚  â”‚ REST API   â”‚  â”‚ Python SDK  â”‚  â”‚ CLI å·¥å…·    â”‚           â”‚
â”‚   â”‚ (AIåŠ©æ‰‹)    â”‚  â”‚ (FastAPI)  â”‚  â”‚ (ç›´æ¥è°ƒç”¨)  â”‚  â”‚ (å‘½ä»¤è¡Œ)    â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚          â”‚                â”‚                â”‚                â”‚                   â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                           â–¼                                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                         RecallEngine (æ ¸å¿ƒå¼•æ“)                          â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
â”‚   â”‚  â”‚  add() | search() | build_context() | query_timeline() | ...    â”‚    â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                   â”‚                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚   â”‚                               â”‚                               â”‚            â”‚
â”‚   â–¼                               â–¼                               â–¼            â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚   æ™ºèƒ½æŠ½å–å±‚    â”‚  â”‚      çŸ¥è¯†å›¾è°±å±‚          â”‚  â”‚       æ£€ç´¢å±‚            â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚SmartExtract â”‚ â”‚  â”‚ â”‚TemporalKnowledgeGraphâ”‚ â”‚  â”‚ â”‚ ElevenLayerRetrieverâ”‚ â”‚ â”‚
â”‚ â”‚ â”‚ - Local     â”‚ â”‚  â”‚ â”‚ - Nodes (Unified)   â”‚ â”‚  â”‚ â”‚ - Bloom Filter     â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ - Hybrid    â”‚ â”‚  â”‚ â”‚ - Edges (Temporal)  â”‚ â”‚  â”‚ â”‚ - Temporal Filter  â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ - LLM       â”‚ â”‚  â”‚ â”‚ - Episodes          â”‚ â”‚  â”‚ â”‚ - Inverted Index   â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â”‚ - Temporal Index    â”‚ â”‚  â”‚ â”‚ - Entity Index     â”‚ â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”‚ - Vector Index      â”‚ â”‚  â”‚ â”‚ - Graph Traversal  â”‚ â”‚ â”‚
â”‚ â”‚ â”‚RelationExt  â”‚ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â”‚ - N-gram Index     â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”‚ - Vector Search    â”‚ â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”‚ ContradictionMgr    â”‚ â”‚  â”‚ â”‚ - Cross-Encoder    â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ 3-Stage     â”‚ â”‚  â”‚ â”‚ - Detect            â”‚ â”‚  â”‚ â”‚ - LLM Rerank       â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ Deduplicatorâ”‚ â”‚  â”‚ â”‚ - Resolve           â”‚ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚ ContextBuilder      â”‚ â”‚ â”‚
â”‚                                                   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚                                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚                         Recall ç‹¬æœ‰æ¨¡å—ï¼ˆå®Œæ•´ä¿ç•™ï¼‰                       â”‚ â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚
â”‚   â”‚  â”‚Foreshadowingâ”‚  â”‚ContextTrack â”‚  â”‚ CoreSettingsâ”‚  â”‚ VolumeManagerâ”‚     â”‚ â”‚
â”‚   â”‚  â”‚ Tracker     â”‚  â”‚ er          â”‚  â”‚ (L0)        â”‚  â”‚ (100%ä¸é—å¿˜) â”‚     â”‚ â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚ â”‚
â”‚   â”‚  â”‚Consistency  â”‚  â”‚ Memory      â”‚  â”‚ Multi-Tenantâ”‚                      â”‚ â”‚
â”‚   â”‚  â”‚ Checker     â”‚  â”‚ Summarizer  â”‚  â”‚ Storage     â”‚                      â”‚ â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚                           å­˜å‚¨å±‚                                         â”‚ â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”‚
â”‚   â”‚  â”‚  æœ¬åœ°å­˜å‚¨ï¼ˆé»˜è®¤ï¼Œé›¶ä¾èµ–ï¼‰                                         â”‚    â”‚ â”‚
â”‚   â”‚  â”‚  - JSON æ–‡ä»¶ï¼ˆèŠ‚ç‚¹ã€è¾¹ã€ç´¢å¼•ï¼‰                                    â”‚    â”‚ â”‚
â”‚   â”‚  â”‚  - FAISS å‘é‡ç´¢å¼•                                                â”‚    â”‚ â”‚
â”‚   â”‚  â”‚  - SQLiteï¼ˆå¯é€‰ï¼Œå¤§è§„æ¨¡åœºæ™¯ï¼‰                                     â”‚    â”‚ â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”‚
â”‚   â”‚  â”‚  å¯é€‰å¤–éƒ¨åç«¯                                                     â”‚    â”‚ â”‚
â”‚   â”‚  â”‚  - Neo4j | FalkorDB | Neptuneï¼ˆä¼ä¸šçº§åœºæ™¯ï¼‰                       â”‚    â”‚ â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“… å®æ–½è®¡åˆ’

### Phase 1: æ ¸å¿ƒåŸºç¡€ï¼ˆ3å‘¨ï¼‰âœ… å·²å®Œæˆ

**ç›®æ ‡ï¼šä¸‰æ—¶æ€æ•°æ®æ¨¡å‹ + æ—¶åºçŸ¥è¯†å›¾è°±**

| å‘¨æ¬¡ | ä»»åŠ¡ | äº§å‡º | çŠ¶æ€ |
|------|------|------|------|
| W1 | æ•°æ®æ¨¡å‹è®¾è®¡ | `TemporalFact`, `UnifiedNode`, `EpisodicNode` | âœ… å®Œæˆ |
| W1 | è¿ç§»å·¥å…· | v3 â†’ v4 æ•°æ®è¿ç§»è„šæœ¬ | âœ… å®Œæˆ |
| W2 | `TemporalKnowledgeGraph` å®ç° | æ ¸å¿ƒ CRUD + æ—¶æ€æŸ¥è¯¢ | âœ… å®Œæˆ |
| W2 | ç´¢å¼•ç³»ç»Ÿ | `TemporalIndex`, `FullTextIndex` é›†æˆ | âœ… å®Œæˆ |
| W3 | çŸ›ç›¾æ£€æµ‹ä¸å¤„ç† | `ContradictionManager` | âœ… å®Œæˆ |
| W3 | å›¾éå† API | BFS/DFS + æ—¶æ€è¿‡æ»¤ | âœ… å®Œæˆ |

**å·²å®Œæˆçš„æ–‡ä»¶ï¼š**
```
recall/models/temporal.py          # ~575 è¡Œ - ä¸‰æ—¶æ€æ•°æ®æ¨¡å‹
recall/index/temporal_index.py     # ~495 è¡Œ - æ—¶æ€ç´¢å¼•
recall/index/fulltext_index.py     # ~413 è¡Œ - BM25 å…¨æ–‡ç´¢å¼•
recall/graph/temporal_knowledge_graph.py  # ~1230 è¡Œ - æ—¶æ€çŸ¥è¯†å›¾è°±
recall/graph/contradiction_manager.py     # ~554 è¡Œ - çŸ›ç›¾ç®¡ç†å™¨
tools/migrate_v3_to_v4.py          # ~721 è¡Œ - æ•°æ®è¿ç§»å·¥å…·
recall/models/__init__.py          # æ›´æ–°å¯¼å‡º
recall/index/__init__.py           # æ›´æ–°å¯¼å‡º
recall/graph/__init__.py           # æ›´æ–°å¯¼å‡º
```

**ğŸ“Š ä»£ç ç»Ÿè®¡ï¼š**
| ç±»åˆ« | æ–‡ä»¶æ•° | æ€»è¡Œæ•° |
|------|--------|--------|
| æ ¸å¿ƒæ¨¡å— | 5 | ~3,267 è¡Œ |
| è¿ç§»å·¥å…· | 1 | ~721 è¡Œ |
| å¯¼å‡ºæ›´æ–° | 3 | ~30 è¡Œ |
| **åˆè®¡** | **9** | **~4,018 è¡Œ** |

**ğŸ”‘ å…³é”® API æ‘˜è¦ï¼š**

| æ¨¡å— | æ ¸å¿ƒç±»/æ–¹æ³• | åŠŸèƒ½ |
|------|-------------|------|
| `temporal.py` | `TemporalFact`, `UnifiedNode`, `EpisodicNode` | ä¸‰æ—¶æ€æ•°æ®æ¨¡å‹ |
| `temporal.py` | `NodeType`, `EdgeType`, `ContradictionType` | å¯æ‰©å±•æšä¸¾ç±»å‹ |
| `temporal_index.py` | `TemporalIndex.query_at_time()` | æ—¶é—´ç‚¹æŸ¥è¯¢ |
| `temporal_index.py` | `TemporalIndex.query_range()` | æ—¶é—´èŒƒå›´æŸ¥è¯¢ |
| `temporal_index.py` | `TemporalIndex.query_timeline()` | æ—¶é—´çº¿æŸ¥è¯¢ |
| `fulltext_index.py` | `FullTextIndex.search()` | BM25 å…¨æ–‡æœç´¢ |
| `temporal_knowledge_graph.py` | `add_node()`, `add_edge()` | èŠ‚ç‚¹/è¾¹ CRUD |
| `temporal_knowledge_graph.py` | `query_at_time()`, `query_timeline()` | æ—¶æ€æŸ¥è¯¢ |
| `temporal_knowledge_graph.py` | `bfs()`, `dfs()` | å›¾éå† |
| `temporal_knowledge_graph.py` | `compare_snapshots()` | å¿«ç…§å¯¹æ¯” |
| `contradiction_manager.py` | `detect()` | çŸ›ç›¾æ£€æµ‹ |
| `contradiction_manager.py` | `resolve()` | çŸ›ç›¾è§£å†³ |
| `migrate_v3_to_v4.py` | `migrate()` | æ•°æ®è¿ç§» |

**ğŸŒ é€šç”¨æ€§è¯´æ˜ï¼š**

Phase 1 æ‰€æœ‰ä»£ç éƒ½æ˜¯ **100% å¹³å°æ— å…³** çš„é€šç”¨å®ç°ï¼š
- âœ… çº¯ Python æ ‡å‡†åº“ + dataclasses
- âœ… JSON æŒä¹…åŒ–ï¼Œæ— å¤–éƒ¨æ•°æ®åº“ä¾èµ–
- âœ… æ— ä»»ä½• SillyTavern æˆ–å…¶ä»–å‰ç«¯ç‰¹å®šä»£ç 
- âœ… å¯è¢«ä»»ä½•å®¢æˆ·ç«¯/å‰ç«¯é€šè¿‡ REST API é›†æˆ

> ğŸ’¡ **SillyTavern é›†æˆè¯´æ˜**ï¼šPhase 1 æ˜¯åç«¯åŸºç¡€è®¾æ–½å±‚ï¼ŒSillyTavern æ’ä»¶éœ€ç­‰å¾… Phase 2 å®Œæˆ REST API ç«¯ç‚¹åæ‰èƒ½ä½¿ç”¨æ–°åŠŸèƒ½ã€‚

**éªŒæ”¶æ ‡å‡†ï¼š**
- [x] æ‰€æœ‰ç°æœ‰æµ‹è¯•é€šè¿‡ï¼ˆRecallEngine, MultiTenantStorage, EntityExtractor ç­‰æ ¸å¿ƒæ¨¡å—æ­£å¸¸ï¼‰
- [x] æ—¶æ€æŸ¥è¯¢ API å¯ç”¨ï¼ˆquery_at_time, query_timeline, compare_snapshotsï¼‰
- [x] v3 æ•°æ®å¯æ— æŸè¿ç§»ï¼ˆmigrate_v3_to_v4.py æ”¯æŒè‡ªåŠ¨å¤‡ä»½å’Œå¢é‡è¿ç§»ï¼‰

**å®Œæˆæ—¥æœŸï¼š** 2026-01-23

### Phase 2: æ™ºèƒ½å±‚ï¼ˆ2å‘¨ï¼‰âœ… å·²å®Œæˆ

**ç›®æ ‡ï¼šæ··åˆæ™ºèƒ½æŠ½å– + ä¸‰é˜¶æ®µå»é‡ + REST API æ‰©å±• + é…ç½®ç³»ç»Ÿå‡çº§**

| å‘¨æ¬¡ | ä»»åŠ¡ | äº§å‡º | çŠ¶æ€ |
|------|------|------|------|
| W4 | `SmartExtractor` æ¡†æ¶ | ä¸‰æ¨¡å¼åˆ‡æ¢ + å¤æ‚åº¦è¯„ä¼° | âœ… å®Œæˆ |
| W4 | LLM æŠ½å– Prompt | å®ä½“/å…³ç³»/æ—¶æ€æŠ½å–æç¤ºè¯ | âœ… å®Œæˆ |
| W4 | **é…ç½®ç³»ç»Ÿå‡çº§** | ç»Ÿä¸€é…ç½® + Phase 1 æ¨¡å—é…ç½®é¡¹ | âœ… å®Œæˆ |
| W5 | `ThreeStageDeduplicator` | MinHash+LSH â†’ Semantic â†’ LLM | âœ… å®Œæˆ |
| W5 | é¢„ç®—ç®¡ç†ç³»ç»Ÿ | `BudgetManager` | âœ… å®Œæˆ |
| W5 | **REST API æ‰©å±•** | Phase 1 åŠŸèƒ½çš„ HTTP ç«¯ç‚¹ | âœ… å®Œæˆ |
| W5 | **RecallEngine é›†æˆ** | å°† Phase 1 æ¨¡å—æ¥å…¥å¼•æ“ | âœ… å®Œæˆ |

**å·²å®Œæˆçš„æ–‡ä»¶ï¼š**
```
recall/processor/smart_extractor.py        # ~580 è¡Œ - æ™ºèƒ½æŠ½å–å™¨ï¼ˆä¸‰æ¨¡å¼ï¼‰
recall/processor/three_stage_deduplicator.py  # ~622 è¡Œ - ä¸‰é˜¶æ®µå»é‡å™¨
recall/utils/budget_manager.py             # ~445 è¡Œ - LLM é¢„ç®—ç®¡ç†å™¨
recall/server.py                           # æ›´æ–° - REST API ç«¯ç‚¹ + é…ç½®ç³»ç»Ÿ
recall/engine.py                           # æ›´æ–° - Phase 1 æ¨¡å—é›†æˆ
recall/utils/environment.py                # æ›´æ–° - åºŸå¼ƒ recall.json
recall/processor/__init__.py               # æ›´æ–° - æ¨¡å—å¯¼å‡º
recall/utils/__init__.py                   # æ›´æ–° - æ¨¡å—å¯¼å‡º
start.ps1                                  # æ›´æ–° - 51 ä¸ªé…ç½®é¡¹
start.sh                                   # æ›´æ–° - 51 ä¸ªé…ç½®é¡¹
tests/test_phase2.py                       # æ–°å¢ - Phase 2 æµ‹è¯•
tools/verify_config.py                     # æ–°å¢ - é…ç½®ä¸€è‡´æ€§éªŒè¯
tools/verify_phase2.py                     # æ–°å¢ - éªŒæ”¶æ ‡å‡†éªŒè¯
```

**ğŸ“Š ä»£ç ç»Ÿè®¡ï¼š**
| ç±»åˆ« | æ–‡ä»¶æ•° | æ€»è¡Œæ•° |
|------|--------|--------|
| æ ¸å¿ƒæ¨¡å— | 3 | ~1,647 è¡Œ |
| æ›´æ–°æ–‡ä»¶ | 5 | ~500+ è¡Œä¿®æ”¹ |
| æµ‹è¯•/å·¥å…· | 3 | ~300 è¡Œ |
| **åˆè®¡** | **11** | **~2,500 è¡Œ** |

**ğŸ”‘ å…³é”® API æ‘˜è¦ï¼š**

| æ¨¡å— | æ ¸å¿ƒç±»/æ–¹æ³• | åŠŸèƒ½ |
|------|-------------|------|
| `smart_extractor.py` | `SmartExtractor` | ä¸‰æ¨¡å¼æ™ºèƒ½æŠ½å– |
| `smart_extractor.py` | `ExtractionMode.LOCAL/HYBRID/LLM_FULL` | æŠ½å–æ¨¡å¼æšä¸¾ |
| `smart_extractor.py` | `_assess_complexity()` | æ–‡æœ¬å¤æ‚åº¦è¯„ä¼° |
| `three_stage_deduplicator.py` | `ThreeStageDeduplicator` | ä¸‰é˜¶æ®µå»é‡ |
| `three_stage_deduplicator.py` | `Stage 1: MinHash+LSH` | ç¡®å®šæ€§å¿«é€ŸåŒ¹é… |
| `three_stage_deduplicator.py` | `Stage 2: Semantic` | è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é… |
| `three_stage_deduplicator.py` | `Stage 3: LLM` | LLM ç¡®è®¤ï¼ˆå¯é€‰ï¼‰ |
| `budget_manager.py` | `BudgetManager` | LLM é¢„ç®—æ§åˆ¶ |
| `budget_manager.py` | `can_afford()` | é¢„ç®—æ£€æŸ¥ |
| `budget_manager.py` | `record_usage()` | ä½¿ç”¨è®°å½• |
| `server.py` | `/v1/temporal/*` | æ—¶æ€æŸ¥è¯¢ API |
| `server.py` | `/v1/contradictions/*` | çŸ›ç›¾ç®¡ç† API |
| `server.py` | `/v1/search/fulltext` | å…¨æ–‡æœç´¢ API |
| `server.py` | `/v1/graph/traverse` | å›¾éå† API |

---

#### ğŸ“ é…ç½®ç³»ç»Ÿå‡çº§

**ç°çŠ¶åˆ†æï¼š**
| é…ç½®æ–‡ä»¶ | ä½ç½® | çŠ¶æ€ |
|---------|------|------|
| `api_keys.env` | `recall_data/config/` | âœ… **ä¸»é…ç½®æ–‡ä»¶** - å·²ç»Ÿä¸€å¤§éƒ¨åˆ†é…ç½® |
| `recall.json` | `recall_data/config/` | âš ï¸ **åºŸå¼ƒ** - v3.0.0 é—ç•™ï¼Œä¸å†ä½¿ç”¨ |

**å‡çº§æ–¹æ¡ˆï¼šå°†æ‰€æœ‰é…ç½®ç»Ÿä¸€åˆ° `api_keys.env`**

**éœ€è¦æ·»åŠ çš„ Phase 1 é…ç½®é¡¹ï¼š**

```env
# ============================================================================
# Recall 4.0 æ–°å¢é…ç½®é¡¹
# Recall 4.0 New Configuration
# ============================================================================

# ----------------------------------------------------------------------------
# æ—¶æ€çŸ¥è¯†å›¾è°±é…ç½®
# Temporal Knowledge Graph Configuration
# ----------------------------------------------------------------------------
# æ˜¯å¦å¯ç”¨æ—¶æ€çŸ¥è¯†å›¾è°± (true/false)
TEMPORAL_GRAPH_ENABLED=true

# å›¾è°±å­˜å‚¨åç«¯: local(æœ¬åœ°JSON) | neo4j | falkordb
# Graph storage backend
TEMPORAL_GRAPH_BACKEND=local

# å›¾è°±ä½œç”¨åŸŸ: global(å…¨å±€å…±äº«) | isolated(ç”¨æˆ·éš”ç¦»)
# Graph scope
TEMPORAL_GRAPH_SCOPE=global

# ----------------------------------------------------------------------------
# çŸ›ç›¾æ£€æµ‹é…ç½®
# Contradiction Detection Configuration
# ----------------------------------------------------------------------------
# æ£€æµ‹ç­–ç•¥: rule_only(ä»…è§„åˆ™) | llm_only(ä»…LLM) | hybrid(æ··åˆ) | auto(è‡ªåŠ¨)
# Detection strategy
CONTRADICTION_STRATEGY=rule_only

# æ˜¯å¦è‡ªåŠ¨è§£å†³ä½ç½®ä¿¡åº¦çŸ›ç›¾ (true/false)
# Auto-resolve low-confidence contradictions
CONTRADICTION_AUTO_RESOLVE=false

# é»˜è®¤è§£å†³ç­–ç•¥: supersede(å–ä»£) | coexist(å…±å­˜) | reject(æ‹’ç») | manual(äººå·¥)
# Default resolution strategy
CONTRADICTION_DEFAULT_RESOLUTION=manual

# ----------------------------------------------------------------------------
# å…¨æ–‡ç´¢å¼•é…ç½® (BM25)
# Full-text Index Configuration (BM25)
# ----------------------------------------------------------------------------
# æ˜¯å¦å¯ç”¨ BM25 å…¨æ–‡ç´¢å¼• (true/false)
FULLTEXT_INDEX_ENABLED=true

# BM25 å‚æ•° k1 (æ§åˆ¶è¯é¢‘é¥±å’Œåº¦ï¼Œé»˜è®¤1.5)
FULLTEXT_BM25_K1=1.5

# BM25 å‚æ•° b (æ§åˆ¶æ–‡æ¡£é•¿åº¦å½’ä¸€åŒ–ï¼Œé»˜è®¤0.75)
FULLTEXT_BM25_B=0.75

# BM25 å‚æ•° delta (IDF å¹³æ»‘ï¼Œé»˜è®¤0.5)
FULLTEXT_BM25_DELTA=0.5

# ----------------------------------------------------------------------------
# æ—¶æ€ç´¢å¼•é…ç½®
# Temporal Index Configuration
# ----------------------------------------------------------------------------
# æ˜¯å¦å¯ç”¨æ—¶æ€ç´¢å¼• (true/false)
TEMPORAL_INDEX_ENABLED=true

# ----------------------------------------------------------------------------
# æ™ºèƒ½æŠ½å–é…ç½® (Phase 2 æ–°å¢)
# Smart Extraction Configuration
# ----------------------------------------------------------------------------
# æŠ½å–æ¨¡å¼: local(çº¯æœ¬åœ°) | hybrid(æ··åˆ) | llm(çº¯LLM)
SMART_EXTRACTOR_MODE=hybrid

# å¤æ‚åº¦é˜ˆå€¼ (0.0-1.0ï¼Œè¶…è¿‡æ­¤å€¼ä½¿ç”¨ LLM)
SMART_EXTRACTOR_COMPLEXITY_THRESHOLD=0.6

# æ¯æ—¥ LLM é¢„ç®—ï¼ˆç¾å…ƒï¼Œ0=ä¸é™åˆ¶ï¼‰
SMART_EXTRACTOR_DAILY_BUDGET=1.0
```

**é…ç½®åŠ è½½ä¼˜å…ˆçº§ï¼š**
1. ç¯å¢ƒå˜é‡ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œç”¨äº Docker/CIï¼‰
2. `api_keys.env` æ–‡ä»¶ï¼ˆç”¨æˆ·ä¸»é…ç½®ï¼‰
3. ä»£ç å†…é»˜è®¤å€¼ï¼ˆä¿åº•ï¼‰

**åºŸå¼ƒ `recall.json`ï¼š**
- Phase 2 å®Œæˆåï¼Œ`recall.json` å°†ä¸å†è¢«è¯»å–
- è¿ç§»è„šæœ¬ä¼šè‡ªåŠ¨å°† `recall.json` ä¸­çš„æœ‰æ•ˆé…ç½®è½¬ç§»åˆ° `api_keys.env`

---

#### ğŸ“œ è„šæœ¬æ–‡ä»¶é…ç½®åŒæ­¥

**éœ€è¦æ›´æ–°çš„æ–‡ä»¶ï¼š**

| æ–‡ä»¶ | ç±»å‹ | å½“å‰çŠ¶æ€ | Phase 2 ä»»åŠ¡ |
|------|------|---------|-------------|
| `start.ps1` | Windows å¯åŠ¨è„šæœ¬ | âœ… å·²ä½¿ç”¨ `api_keys.env` | æ·»åŠ  Phase 1 é…ç½®é¡¹ |
| `start.sh` | Linux å¯åŠ¨è„šæœ¬ | âœ… å·²ä½¿ç”¨ `api_keys.env` | æ·»åŠ  Phase 1 é…ç½®é¡¹ |
| `manage.ps1` | Windows ç®¡ç†è„šæœ¬ | âš ï¸ ä½¿ç”¨ `manager.json` | å¯ä¿ç•™ï¼ˆç®¡ç†å™¨ä¸“ç”¨é…ç½®ï¼‰ |
| `manage.sh` | Linux ç®¡ç†è„šæœ¬ | âš ï¸ ä½¿ç”¨ç‹¬ç«‹é…ç½® | å¯ä¿ç•™ï¼ˆç®¡ç†å™¨ä¸“ç”¨é…ç½®ï¼‰ |
| `install.ps1` | Windows å®‰è£…è„šæœ¬ | âœ… æ— é…ç½®ä¾èµ– | æ— éœ€ä¿®æ”¹ |
| `install.sh` | Linux å®‰è£…è„šæœ¬ | âœ… æ— é…ç½®ä¾èµ– | æ— éœ€ä¿®æ”¹ |
| `recall/utils/environment.py` | Python ç¯å¢ƒç®¡ç† | âš ï¸ ä½¿ç”¨ `recall.json` | **åºŸå¼ƒ JSON é…ç½®** |
| `recall/server.py` | API æœåŠ¡å™¨ | âœ… å·²ä½¿ç”¨ `api_keys.env` | æ·»åŠ  Phase 1 é…ç½®é¡¹ |

**å…·ä½“æ›´æ–°ä»»åŠ¡ï¼š**

1. **`start.ps1` / `start.sh`** - æ·»åŠ  Phase 1 æ”¯æŒçš„é…ç½®é¡¹ï¼š
   ```powershell
   # æ–°å¢é…ç½®é¡¹åˆ—è¡¨
   $supportedKeys = @(
       # ... ç°æœ‰é…ç½®é¡¹ ...
       # Phase 1 æ–°å¢
       'TEMPORAL_GRAPH_ENABLED', 'TEMPORAL_GRAPH_BACKEND', 'TEMPORAL_GRAPH_SCOPE',
       'CONTRADICTION_STRATEGY', 'CONTRADICTION_AUTO_RESOLVE', 'CONTRADICTION_DEFAULT_RESOLUTION',
       'FULLTEXT_INDEX_ENABLED', 'FULLTEXT_BM25_K1', 'FULLTEXT_BM25_B', 'FULLTEXT_BM25_DELTA',
       'TEMPORAL_INDEX_ENABLED',
       'SMART_EXTRACTOR_MODE', 'SMART_EXTRACTOR_COMPLEXITY_THRESHOLD', 'SMART_EXTRACTOR_DAILY_BUDGET'
   )
   ```

2. **`recall/utils/environment.py`** - åºŸå¼ƒ `recall.json` ç›¸å…³ä»£ç ï¼š
   ```python
   # åˆ é™¤ _create_default_config() ä¸­çš„ recall.json é€»è¾‘
   # åˆ é™¤ load_config() å’Œ save_config() ä¸­çš„ recall.json å¼•ç”¨
   # æ”¹ä¸ºè¯»å– api_keys.env æˆ–ç›´æ¥ä½¿ç”¨ç¯å¢ƒå˜é‡
   ```

3. **`recall/server.py`** - æ·»åŠ  Phase 1 é…ç½®é¡¹åˆ° `SUPPORTED_CONFIG_KEYS`ï¼š
   ```python
   SUPPORTED_CONFIG_KEYS = {
       # ... ç°æœ‰é…ç½®é¡¹ ...
       # Phase 1 æ–°å¢
       'TEMPORAL_GRAPH_ENABLED',
       'TEMPORAL_GRAPH_BACKEND',
       'TEMPORAL_GRAPH_SCOPE',
       'CONTRADICTION_STRATEGY',
       'CONTRADICTION_AUTO_RESOLVE',
       'CONTRADICTION_DEFAULT_RESOLUTION',
       'FULLTEXT_INDEX_ENABLED',
       'FULLTEXT_BM25_K1',
       'FULLTEXT_BM25_B',
       'FULLTEXT_BM25_DELTA',
       'TEMPORAL_INDEX_ENABLED',
       'SMART_EXTRACTOR_MODE',
       'SMART_EXTRACTOR_COMPLEXITY_THRESHOLD',
       'SMART_EXTRACTOR_DAILY_BUDGET',
   }
   ```

4. **é»˜è®¤é…ç½®æ¨¡æ¿** - æ›´æ–° `get_default_config_content()` æ·»åŠ  Phase 1 é…ç½®æ®µ

---

**ğŸ“¡ éœ€è¦æ·»åŠ çš„ REST API ç«¯ç‚¹ï¼ˆæš´éœ² Phase 1 åŠŸèƒ½ï¼‰ï¼š**

| ç«¯ç‚¹ | æ–¹æ³• | åŠŸèƒ½ | å¯¹åº”æ¨¡å— |
|------|------|------|----------|
| `/v1/temporal/at` | GET | æ—¶é—´ç‚¹å¿«ç…§æŸ¥è¯¢ | `TemporalKnowledgeGraph.query_at_time()` |
| `/v1/temporal/range` | GET | æ—¶é—´èŒƒå›´æŸ¥è¯¢ | `TemporalIndex.query_range()` |
| `/v1/temporal/timeline` | GET | å®ä½“æ—¶é—´çº¿ | `TemporalKnowledgeGraph.query_timeline()` |
| `/v1/temporal/snapshot` | GET | è·å–å¿«ç…§ | `TemporalKnowledgeGraph.get_snapshot()` |
| `/v1/temporal/snapshot/compare` | GET | å¿«ç…§å¯¹æ¯” | `TemporalKnowledgeGraph.compare_snapshots()` |
| `/v1/contradictions` | GET | çŸ›ç›¾åˆ—è¡¨ | `ContradictionManager.get_pending()` |
| `/v1/contradictions/{id}/resolve` | POST | è§£å†³çŸ›ç›¾ | `ContradictionManager.resolve()` |
| `/v1/search/fulltext` | GET | BM25 å…¨æ–‡æœç´¢ | `FullTextIndex.search()` |
| `/v1/graph/traverse` | POST | å›¾éå† | `TemporalKnowledgeGraph.bfs()` |
| `/v1/migrate/v3-to-v4` | POST | è§¦å‘è¿ç§» | `migrate_v3_to_v4.migrate()` |

> ğŸ’¡ **SillyTavern é›†æˆ**ï¼šä¸Šè¿° API å®Œæˆåï¼ŒSillyTavern æ’ä»¶å¯æ·»åŠ ã€Œæ—¶é—´çº¿ã€ã€ŒçŸ›ç›¾ç®¡ç†ã€ç­‰æ–°åŠŸèƒ½æ ‡ç­¾é¡µã€‚

**éªŒæ”¶æ ‡å‡†ï¼š**
- [x] æœ¬åœ°æ¨¡å¼å¯å®Œå…¨ç¦»çº¿è¿è¡Œ
- [x] æ··åˆæ¨¡å¼æˆæœ¬å¯æ§
- [x] å»é‡å‡†ç¡®ç‡ â‰¥95%
- [x] Phase 1 åŠŸèƒ½çš„ REST API å…¨éƒ¨å¯ç”¨
- [x] é…ç½®ç³»ç»Ÿç»Ÿä¸€åˆ° `api_keys.env`
- [x] `recall.json` å®Œå…¨åºŸå¼ƒ
- [x] Phase 1 æ¨¡å—é›†æˆåˆ° RecallEngine
- [x] `start.ps1` / `start.sh` æ”¯æŒæ‰€æœ‰ Phase 1 é…ç½®é¡¹
- [x] `recall/server.py` çš„ `SUPPORTED_CONFIG_KEYS` å·²æ›´æ–°
- [x] `recall/utils/environment.py` ä¸å†ä¾èµ– `recall.json`

**å®Œæˆæ—¥æœŸï¼š** 2026-01-23

### Phase 3: æ£€ç´¢å‡çº§ï¼ˆ2å‘¨ï¼‰

**ç›®æ ‡ï¼šåä¸€å±‚æ¼æ–—æ£€ç´¢å™¨ + æ—¶æ€/å›¾è°±æ£€ç´¢èƒ½åŠ›**

å°†ç°æœ‰ 8 å±‚æ£€ç´¢å™¨å‡çº§ä¸º 11 å±‚ï¼Œæ–°å¢ï¼š
- **L2 æ—¶æ€è¿‡æ»¤**ï¼šåˆ©ç”¨ Phase 1 çš„ `TemporalIndex` å®ç°æ—¶é—´èŒƒå›´é¢„ç­›é€‰
- **L5 å›¾éå†**ï¼šåˆ©ç”¨ Phase 1 çš„ `TemporalKnowledgeGraph.bfs()` å®ç°å…³ç³»æ‰©å±•æ£€ç´¢
- **L10 CrossEncoder**ï¼šå¯é€‰çš„äº¤å‰ç¼–ç å™¨ç²¾æ’ï¼Œæå‡æ’åºè´¨é‡

åŒæ—¶é‡æ„é…ç½®ç³»ç»Ÿï¼Œä» dict å‡çº§ä¸ºç±»å‹å®‰å…¨çš„ `RetrievalConfig` dataclassã€‚

| å‘¨æ¬¡ | ä»»åŠ¡ | äº§å‡º | çŠ¶æ€ |
|------|------|------|------|
| W6 | `RetrievalConfig` é…ç½®ç±» | å¯é…ç½®çš„æ£€ç´¢ç­–ç•¥ | âœ… å·²å®Œæˆ |
| W6 | `ElevenLayerRetriever` æ¡†æ¶ | 11 å±‚æ£€ç´¢å™¨éª¨æ¶ | âœ… å·²å®Œæˆ |
| W6 | L2 æ—¶æ€è¿‡æ»¤å±‚ | æ—¶é—´èŒƒå›´é¢„ç­›é€‰ | âœ… å·²å®Œæˆ |
| W6 | L5 å›¾éå†å±‚ | BFS å…³ç³»æ‰©å±• | âœ… å·²å®Œæˆ |
| W7 | è¿ç§»ç°æœ‰å±‚é€»è¾‘ | ä» `EightLayerRetriever` è¿ç§» | âœ… å·²å®Œæˆ |
| W7 | Engine é›†æˆ | æ›¿æ¢æ—§æ£€ç´¢å™¨ | âœ… å·²å®Œæˆ |
| W7 | L10 CrossEncoderï¼ˆå¯é€‰ï¼‰ | äº¤å‰ç¼–ç å™¨é‡æ’åº | âœ… å·²å®Œæˆ |
| W7 | æ€§èƒ½ä¼˜åŒ– | ç¼“å­˜ + å¹¶è¡Œ | â³ å¾…ä¼˜åŒ– |

---

#### ğŸ“ ç°æœ‰æ¶æ„åˆ†æ

**å½“å‰ `EightLayerRetriever` (445 è¡Œ) - L1 è‡³ L8ï¼š**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EightLayerRetriever (ç°æœ‰)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  L1: Bloom Filter      â†’ å¿«é€Ÿå¦å®šï¼ŒO(1) æ’é™¤ä¸ç›¸å…³æ–‡æ¡£           â”‚
â”‚  L2: Inverted Index    â†’ å…³é”®è¯åŒ¹é…ï¼ŒBM25 è¯„åˆ†                  â”‚
â”‚  L3: Entity Index      â†’ å®ä½“å…³è”ï¼Œå‘½ä¸­å®ä½“åŠ åˆ†                  â”‚
â”‚  L4: N-gram Index      â†’ æ¨¡ç³ŠåŒ¹é…ï¼Œå¤„ç†é”™åˆ«å­—/å˜ä½“              â”‚
â”‚  L5: Vector Coarse     â†’ å‘é‡ç²—ç­›ï¼Œtop_k=200                    â”‚
â”‚  L6: Vector Fine       â†’ å‘é‡ç²¾æ’ï¼Œé‡è®¡ç®—ç›¸ä¼¼åº¦                  â”‚
â”‚  L7: Rerank            â†’ TF-IDF é‡æ’åº                          â”‚
â”‚  L8: LLM Filter        â†’ LLM ç›¸å…³æ€§è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ç°æœ‰é…ç½®æ–¹å¼ï¼š**
```python
# å½“å‰ä½¿ç”¨ dict é…ç½®
self.config = {
    'l1_enabled': True,   # Bloom Filter
    'l2_enabled': True,   # Inverted Index
    'l3_enabled': True,   # Entity Index
    'l4_enabled': True,   # N-gram Index
    'l5_enabled': True,   # Vector Coarse
    'l6_enabled': True,   # Vector Fine
    'l7_enabled': True,   # Rerank
    'l8_enabled': False,  # LLM Filter (é»˜è®¤å…³é—­)
}
```

**Engine é›†æˆç‚¹ï¼š**
- åˆå§‹åŒ–ä½ç½®ï¼š[engine.py#L272](recall/engine.py#L272)
- è°ƒç”¨ä½ç½®ï¼š[engine.py#L862](recall/engine.py#L862) `retriever.retrieve(query, entities, keywords, top_k, filters)`

---

#### ğŸ¯ å‡çº§æ–¹æ¡ˆï¼š8 å±‚ â†’ 11 å±‚

**å‡çº§ç­–ç•¥ï¼šåœ¨ç°æœ‰ 8 å±‚åŸºç¡€ä¸Šæ’å…¥ 3 ä¸ªæ–°å±‚ï¼Œä¿æŒåŸæœ‰å±‚çš„ç›¸å¯¹é¡ºåº**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         å±‚çº§æ˜ å°„ï¼šEightLayer â†’ ElevenLayer                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ—§å±‚å·    æ–°å±‚å·    åç§°                    å˜åŒ–                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  L1    â†’   L1      Bloom Filter           [ä¿ç•™] å¿«é€Ÿå¦å®š                       â”‚
â”‚  -     â†’   L2      Temporal Filter        [æ–°å¢] æ—¶é—´èŒƒå›´é¢„ç­›é€‰                 â”‚
â”‚  L2    â†’   L3      Inverted Index         [ä¿ç•™] å…³é”®è¯åŒ¹é…                     â”‚
â”‚  L3    â†’   L4      Entity Index           [ä¿ç•™] å®ä½“å…³è”                       â”‚
â”‚  -     â†’   L5      Graph Traversal        [æ–°å¢] BFS å›¾éå†æ‰©å±•                 â”‚
â”‚  L4    â†’   L6      N-gram Index           [ä¿ç•™] æ¨¡ç³ŠåŒ¹é…                       â”‚
â”‚  L5    â†’   L7      Vector Coarse          [ä¿ç•™] å‘é‡ç²—ç­›                       â”‚
â”‚  L6    â†’   L8      Vector Fine            [ä¿ç•™] å‘é‡ç²¾æ’                       â”‚
â”‚  L7    â†’   L9      Rerank                 [ä¿ç•™] TF-IDF é‡æ’åº                  â”‚
â”‚  -     â†’   L10     Cross-Encoder          [æ–°å¢] äº¤å‰ç¼–ç å™¨ç²¾æ’ï¼ˆå¯é€‰ï¼‰         â”‚
â”‚  L8    â†’   L11     LLM Filter             [ä¿ç•™] LLM æœ€ç»ˆè¿‡æ»¤ï¼ˆå¯é€‰ï¼‰           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ–°æ¶æ„ `ElevenLayerRetriever`ï¼š**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ElevenLayerRetriever (ç›®æ ‡)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        === å¿«é€Ÿè¿‡æ»¤é˜¶æ®µ ===                      â”‚
â”‚  L1:  Bloom Filter       â†’ [ä¿ç•™] O(1) å¿«é€Ÿå¦å®š                  â”‚
â”‚  L2:  Temporal Filter    â†’ [æ–°å¢] æ—¶é—´èŒƒå›´é¢„ç­›é€‰                 â”‚
â”‚                                                                 â”‚
â”‚                        === å¬å›é˜¶æ®µ ===                          â”‚
â”‚  L3:  Inverted Index     â†’ [ä¿ç•™] å…³é”®è¯åŒ¹é…ï¼ŒBM25              â”‚
â”‚  L4:  Entity Index       â†’ [ä¿ç•™] å®ä½“å…³è”å¬å›                   â”‚
â”‚  L5:  Graph Traversal    â†’ [æ–°å¢] BFS å›¾éå†æ‰©å±•                 â”‚
â”‚  L6:  N-gram Index       â†’ [ä¿ç•™] æ¨¡ç³ŠåŒ¹é…å¬å›                   â”‚
â”‚  L7:  Vector Coarse      â†’ [ä¿ç•™] å‘é‡ç²—ç­›ï¼ŒANN                  â”‚
â”‚                                                                 â”‚
â”‚                        === ç²¾æ’é˜¶æ®µ ===                          â”‚
â”‚  L8:  Vector Fine        â†’ [ä¿ç•™] å‘é‡ç²¾æ’ï¼Œç²¾ç¡®è·ç¦»             â”‚
â”‚  L9:  Rerank             â†’ [ä¿ç•™] TF-IDF å¤šå› ç´ é‡æ’              â”‚
â”‚  L10: Cross-Encoder      â†’ [æ–°å¢] äº¤å‰ç¼–ç å™¨ç²¾æ’ï¼ˆå¯é€‰ï¼‰         â”‚
â”‚  L11: LLM Filter         â†’ [ä¿ç•™] LLM è¯­ä¹‰è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**è®¾è®¡åŸåˆ™ï¼š**
1. **å¿«é€Ÿè¿‡æ»¤åœ¨å‰** - L1-L2 å¿«é€Ÿæ’é™¤å¤§é‡ä¸ç›¸å…³æ–‡æ¡£
2. **å¬å›åœ¨ä¸­** - L3-L7 å¤šè·¯å¬å›ï¼Œç¡®ä¿é«˜å¬å›ç‡
3. **ç²¾æ’åœ¨å** - L8-L11 é€æ­¥ç²¾ç»†åŒ–æ’åºï¼Œç¡®ä¿é«˜ç²¾åº¦
4. **æˆæœ¬é€’å¢** - è¶Šå¾€åæˆæœ¬è¶Šé«˜ï¼Œå€™é€‰æ•°è¶Šå°‘

---

#### ğŸ“‹ è¯¦ç»†å®æ–½è®¡åˆ’

##### æ­¥éª¤ 1: åˆ›å»º `RetrievalConfig` ç±» (~150 è¡Œ)

**æ–‡ä»¶ï¼š** `recall/retrieval/config.py` (æ–°å»º)

```python
from dataclasses import dataclass, field
from typing import Optional, Dict, Any, List
from datetime import datetime

@dataclass
class LayerWeights:
    """å„å±‚æƒé‡é…ç½®"""
    inverted: float = 1.0      # å€’æ’ç´¢å¼•æƒé‡
    entity: float = 1.2        # å®ä½“ç´¢å¼•æƒé‡
    graph: float = 1.0         # å›¾éå†æƒé‡
    ngram: float = 0.8         # N-gram æƒé‡
    vector: float = 1.0        # å‘é‡æƒé‡
    temporal: float = 0.5      # æ—¶æ€æƒé‡

@dataclass
class TemporalContext:
    """æ—¶æ€æŸ¥è¯¢ä¸Šä¸‹æ–‡"""
    start: Optional[datetime] = None    # æ—¶é—´èŒƒå›´èµ·ç‚¹
    end: Optional[datetime] = None      # æ—¶é—´èŒƒå›´ç»ˆç‚¹
    reference: Optional[datetime] = None  # å‚è€ƒæ—¶é—´ç‚¹
    
    def has_time_constraint(self) -> bool:
        """æ˜¯å¦æœ‰æ—¶é—´çº¦æŸ"""
        return self.start is not None or self.end is not None

@dataclass
class LayerStats:
    """å±‚çº§æ‰§è¡Œç»Ÿè®¡"""
    layer: str                  # å±‚åç§°ï¼ˆå¦‚ "L2_TEMPORAL_FILTER"ï¼‰
    input_count: int            # è¾“å…¥å€™é€‰æ•°
    output_count: int           # è¾“å‡ºå€™é€‰æ•°
    time_ms: float              # è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰

@dataclass
class RetrievalResult:
    """æ£€ç´¢ç»“æœ"""
    id: str                     # æ–‡æ¡£ ID
    score: float                # ç»¼åˆå¾—åˆ†
    content: str = ""           # æ–‡æ¡£å†…å®¹ï¼ˆå¯é€‰å¡«å……ï¼‰

@dataclass
class RetrievalConfig:
    """æ£€ç´¢é…ç½® - ç±»å‹å®‰å…¨ + é»˜è®¤å€¼"""
    
    # === å±‚å¼€å…³ï¼ˆL1-L11ï¼‰===
    l1_enabled: bool = True     # Bloom Filter
    l2_enabled: bool = True     # Temporal Filterã€æ–°å¢ã€‘
    l3_enabled: bool = True     # Inverted Index
    l4_enabled: bool = True     # Entity Index
    l5_enabled: bool = True     # Graph Traversalã€æ–°å¢ã€‘
    l6_enabled: bool = True     # N-gram Index
    l7_enabled: bool = True     # Vector Coarse
    l8_enabled: bool = True     # Vector Fine
    l9_enabled: bool = True     # Rerank
    l10_enabled: bool = False   # Cross-Encoderã€æ–°å¢ï¼Œé»˜è®¤å…³é—­ã€‘
    l11_enabled: bool = False   # LLM Filterã€é»˜è®¤å…³é—­ã€‘
    
    # === Top-K é…ç½® ===
    l2_temporal_top_k: int = 500       # æ—¶æ€å±‚ä¿ç•™æ•°
    l3_inverted_top_k: int = 100
    l4_entity_top_k: int = 50
    l5_graph_top_k: int = 100          # å›¾éå†ä¿ç•™æ•°
    l6_ngram_top_k: int = 30
    l7_vector_top_k: int = 200
    fine_rank_threshold: int = 100     # è§¦å‘ L8 ç²¾æ’çš„å€™é€‰æ•°
    l10_cross_encoder_top_k: int = 50  # CrossEncoder å¤„ç†æ•°
    l11_llm_top_k: int = 20            # LLM å¤„ç†æ•°
    final_top_k: int = 20
    
    # === L5 å›¾éå†é…ç½® ===
    l5_graph_max_depth: int = 2        # BFS æœ€å¤§æ·±åº¦
    l5_graph_max_entities: int = 3     # èµ·å§‹å®ä½“æ•°é‡é™åˆ¶
    l5_graph_direction: str = "both"   # out | in | both
    
    # === L11 LLM é…ç½® ===
    l11_llm_timeout: float = 10.0      # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    
    # === æƒé‡ ===
    weights: LayerWeights = field(default_factory=LayerWeights)
    
    # === æ—¶æ€ä¸Šä¸‹æ–‡ ===
    reference_time: Optional[datetime] = None
    time_range_start: Optional[datetime] = None
    time_range_end: Optional[datetime] = None
    
    @classmethod
    def default(cls) -> "RetrievalConfig":
        """é»˜è®¤é…ç½® - ç¦ç”¨é«˜æˆæœ¬å±‚"""
        return cls()
    
    @classmethod
    def fast(cls) -> "RetrievalConfig":
        """å¿«é€Ÿæ¨¡å¼ - ç¦ç”¨é‡é‡çº§å±‚"""
        return cls(
            l8_enabled=False,      # è·³è¿‡å‘é‡ç²¾æ’
            l9_enabled=False,      # è·³è¿‡é‡æ’åº
            l10_enabled=False,     # è·³è¿‡ CrossEncoder
            l11_enabled=False,     # è·³è¿‡ LLM
            l7_vector_top_k=100
        )
    
    @classmethod
    def accurate(cls) -> "RetrievalConfig":
        """ç²¾å‡†æ¨¡å¼ - å¯ç”¨æ‰€æœ‰å±‚"""
        return cls(
            l10_enabled=True,      # å¯ç”¨ CrossEncoder
            l11_enabled=True,      # å¯ç”¨ LLM
            l7_vector_top_k=300,
            l10_cross_encoder_top_k=100
        )
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸ï¼ˆå…¼å®¹æ—§ EightLayerRetrieverï¼‰"""
        return {
            'l1_enabled': self.l1_enabled,
            'l2_enabled': self.l3_enabled,   # æ—§ L2 = æ–° L3
            'l3_enabled': self.l4_enabled,   # æ—§ L3 = æ–° L4
            'l4_enabled': self.l6_enabled,   # æ—§ L4 = æ–° L6
            'l5_enabled': self.l7_enabled,   # æ—§ L5 = æ–° L7
            'l6_enabled': self.l8_enabled,   # æ—§ L6 = æ–° L8
            'l7_enabled': self.l9_enabled,   # æ—§ L7 = æ–° L9
            'l8_enabled': self.l11_enabled,  # æ—§ L8 = æ–° L11
        }
```

---

##### æ­¥éª¤ 2: åˆ›å»º `ElevenLayerRetriever` æ¡†æ¶ (~700 è¡Œ)

**æ–‡ä»¶ï¼š** `recall/retrieval/eleven_layer.py` (æ–°å»º)

```python
import time
import json
import asyncio
import logging
from enum import Enum
from typing import List, Dict, Set, Optional, Tuple
from collections import defaultdict

from .config import (
    RetrievalConfig, LayerStats, 
    RetrievalResult, TemporalContext
)

logger = logging.getLogger(__name__)


class RetrievalLayer(Enum):
    """æ£€ç´¢å±‚çº§ - 11 å±‚"""
    # === å¿«é€Ÿè¿‡æ»¤é˜¶æ®µ ===
    L1_BLOOM_FILTER = "bloom_filter"
    L2_TEMPORAL_FILTER = "temporal_filter"    # æ–°å¢
    
    # === å¬å›é˜¶æ®µ ===
    L3_INVERTED_INDEX = "inverted_index"
    L4_ENTITY_INDEX = "entity_index"
    L5_GRAPH_TRAVERSAL = "graph_traversal"    # æ–°å¢
    L6_NGRAM_INDEX = "ngram_index"
    L7_VECTOR_COARSE = "vector_coarse"
    
    # === ç²¾æ’é˜¶æ®µ ===
    L8_VECTOR_FINE = "vector_fine"
    L9_RERANK = "rerank"
    L10_CROSS_ENCODER = "cross_encoder"       # æ–°å¢
    L11_LLM_FILTER = "llm_filter"


class ElevenLayerRetriever:
    """åä¸€å±‚æ¼æ–—æ£€ç´¢å™¨
    
    æ£€ç´¢æµç¨‹ï¼ˆ3 é˜¶æ®µ 11 å±‚ï¼‰ï¼š
    
    [å¿«é€Ÿè¿‡æ»¤é˜¶æ®µ]
    L1:  Bloom Filter      - O(1) å¿«é€Ÿå¦å®šä¸å¯èƒ½çš„å€™é€‰
    L2:  Temporal Filter   - O(log n) æ—¶é—´èŒƒå›´é¢„ç­›é€‰ã€æ–°å¢ã€‘
    
    [å¬å›é˜¶æ®µ]
    L3:  Inverted Index    - O(log n) å…³é”®è¯åŒ¹é…
    L4:  Entity Index      - O(1) å®ä½“å…³è”æŸ¥æ‰¾
    L5:  Graph Traversal   - O(V+E) BFS å›¾éå†æ‰©å±•ã€æ–°å¢ã€‘
    L6:  N-gram Index      - O(k) æ¨¡ç³ŠåŒ¹é…
    L7:  Vector Coarse     - O(n) è¿‘ä¼¼æœ€è¿‘é‚»
    
    [ç²¾æ’é˜¶æ®µ]
    L8:  Vector Fine       - O(k) ç²¾ç¡®è·ç¦»è®¡ç®—
    L9:  Rerank            - O(k log k) å¤šå› ç´ ç»¼åˆæ’åº
    L10: Cross-Encoder     - O(k) äº¤å‰ç¼–ç å™¨ç²¾æ’ã€æ–°å¢ï¼Œå¯é€‰ã€‘
    L11: LLM Filter        - O(k) è¯­ä¹‰ç›¸å…³æ€§åˆ¤æ–­ã€å¯é€‰ã€‘
    """
    
    def __init__(
        self,
        # ç°æœ‰ä¾èµ–ï¼ˆå¯¹åº”æ—§ L1-L8ï¼Œæ–°ç¼–å·åä¸º L1, L3-L4, L6-L9, L11ï¼‰
        bloom_filter=None,
        inverted_index=None,
        entity_index=None,
        ngram_index=None,
        vector_index=None,
        llm_client=None,
        content_store=None,
        # æ–°å¢ä¾èµ–ï¼ˆL2, L5, L10ï¼‰
        temporal_index=None,           # TemporalIndex (Phase 1)
        knowledge_graph=None,          # TemporalKnowledgeGraph (Phase 1)
        cross_encoder=None,            # CrossEncoder æ¨¡å‹
        # é…ç½®
        config: RetrievalConfig = None
    ):
        # ç°æœ‰ä¾èµ–
        self.bloom_filter = bloom_filter
        self.inverted_index = inverted_index
        self.entity_index = entity_index
        self.ngram_index = ngram_index
        self.vector_index = vector_index
        self.llm_client = llm_client
        self.content_store = content_store
        
        # æ–°å¢ä¾èµ–
        self.temporal_index = temporal_index
        self.knowledge_graph = knowledge_graph
        self.cross_encoder = cross_encoder
        
        self.config = config or RetrievalConfig.default()
        
        # ç»Ÿè®¡
        self.stats: List[LayerStats] = []
    
    async def retrieve(
        self,
        query: str,
        entities: List[str] = None,
        keywords: List[str] = None,
        top_k: int = None,
        filters: Dict = None,
        temporal_context: TemporalContext = None,
        config: RetrievalConfig = None
    ) -> List[RetrievalResult]:
        """æ‰§è¡Œåä¸€å±‚æ£€ç´¢ï¼ˆå¼‚æ­¥ï¼Œå›  L11 éœ€è¦ï¼‰"""
        
        config = config or self.config
        top_k = top_k or config.final_top_k
        
        candidates = set()
        scores = defaultdict(float)
        
        # ========== å¿«é€Ÿè¿‡æ»¤é˜¶æ®µ ==========
        
        # L1: Bloom Filter - å¿«é€Ÿå¦å®š
        if config.l1_enabled and self.bloom_filter:
            keywords = self._l1_bloom_filter(keywords)
        
        # L2: Temporal Filter - æ—¶é—´èŒƒå›´é¢„ç­›é€‰ã€æ–°å¢ã€‘
        temporal_candidates = None
        if config.l2_enabled and self.temporal_index and temporal_context:
            temporal_candidates = self._l2_temporal_filter(temporal_context, config)
        
        # ========== å¬å›é˜¶æ®µ ==========
        
        # L3: Inverted Index - å…³é”®è¯åŒ¹é…
        if config.l3_enabled and self.inverted_index:
            self._l3_inverted_index(keywords, candidates, scores, config, temporal_candidates)
        
        # L4: Entity Index - å®ä½“å…³è”
        if config.l4_enabled and self.entity_index:
            self._l4_entity_index(entities, candidates, scores, config, temporal_candidates)
        
        # L5: Graph Traversal - å›¾éå†æ‰©å±•ã€æ–°å¢ã€‘
        if config.l5_enabled and self.knowledge_graph and entities:
            self._l5_graph_traversal(entities, candidates, scores, config)
        
        # L6: N-gram Index - æ¨¡ç³ŠåŒ¹é…
        if config.l6_enabled and self.ngram_index:
            self._l6_ngram_index(query, candidates, scores, config, temporal_candidates)
        
        # L7: Vector Coarse - å‘é‡ç²—ç­›
        if config.l7_enabled and self.vector_index:
            self._l7_vector_coarse(query, candidates, scores, config)
        
        # ========== ç²¾æ’é˜¶æ®µ ==========
        
        # L8: Vector Fine - å‘é‡ç²¾æ’
        if config.l8_enabled and len(candidates) > config.fine_rank_threshold:
            self._l8_vector_fine(query, candidates, scores, config)
        
        # L9: Rerank - TF-IDF é‡æ’åº
        if config.l9_enabled:
            self._l9_rerank(query, candidates, scores)
        
        # L10: Cross-Encoder - äº¤å‰ç¼–ç å™¨ç²¾æ’ã€æ–°å¢ï¼Œå¯é€‰ã€‘
        if config.l10_enabled and self.cross_encoder:
            self._l10_cross_encoder(query, candidates, scores, config)
        
        # L11: LLM Filter - LLM æœ€ç»ˆè¿‡æ»¤ã€å¯é€‰ã€‘
        if config.l11_enabled and self.llm_client:
            candidates, scores = await self._l11_llm_filter(query, candidates, scores, config)
        
        return self._build_results(candidates, scores, top_k)
```

---

##### æ­¥éª¤ 3: å®ç°æ–°å¢å±‚ + è¿ç§»å±‚ (~300 è¡Œ)

**è¿ç§»å±‚è¯´æ˜ï¼ˆL1, L3-L4, L6-L9, L11ï¼‰ï¼š**

ä»¥ä¸‹æ–¹æ³•ä»ç°æœ‰ `EightLayerRetriever` è¿ç§»ï¼Œé€»è¾‘åŸºæœ¬ä¸å˜ï¼Œä»…è°ƒæ•´å‚æ•°ç­¾åä»¥æ”¯æŒ `temporal_candidates` è¿‡æ»¤ï¼š

```python
# L1: ä» EightLayerRetriever._l1_bloom_filter() è¿ç§»
def _l1_bloom_filter(self, keywords: List[str]) -> List[str]: ...

# L3: ä» EightLayerRetriever._l2_inverted_index() è¿ç§»
# æ–°å¢ config å’Œ temporal_candidates å‚æ•°ï¼Œå†…éƒ¨ä½¿ç”¨ config.l3_inverted_top_k
def _l3_inverted_index(self, keywords, candidates, scores, config, temporal_candidates=None): ...

# L4: ä» EightLayerRetriever._l3_entity_index() è¿ç§»
# æ–°å¢ config å‚æ•°ï¼Œå†…éƒ¨ä½¿ç”¨ config.l4_entity_top_k
def _l4_entity_index(self, entities, candidates, scores, config, temporal_candidates=None): ...

# L6: ä» EightLayerRetriever._l4_ngram_index() è¿ç§»
# æ–°å¢ config å‚æ•°ï¼Œå†…éƒ¨ä½¿ç”¨ config.l6_ngram_top_k
def _l6_ngram_index(self, query, candidates, scores, config, temporal_candidates=None): ...

# L7: ä» EightLayerRetriever._l5_vector_coarse() è¿ç§»
# å†…éƒ¨ä½¿ç”¨ config.l7_vector_top_k
def _l7_vector_coarse(self, query, candidates, scores, config): ...

# L8: ä» EightLayerRetriever._l6_vector_fine() è¿ç§»
def _l8_vector_fine(self, query, candidates, scores, config): ...

# L9: ä» EightLayerRetriever._l7_rerank() è¿ç§»
def _l9_rerank(self, query, candidates, scores): ...

# L11: ä» EightLayerRetriever._l8_llm_filter() è¿ç§»ï¼Œæ”¹ä¸º async
# æ³¨æ„ï¼šL11 å®Œæ•´å®ç°å·²åœ¨ä¸‹æ–¹å•ç‹¬ç»™å‡ºï¼Œæ­¤å¤„ä»…è¯´æ˜è¿ç§»æ¥æº
async def _l11_llm_filter(self, query, candidates, scores, config) -> Tuple[Set, Dict]: ...
```

> ğŸ’¡ **è¿ç§»ç­–ç•¥**ï¼šè¿ç§»æ—¶éœ€åœ¨æ¯ä¸ªæ–¹æ³•å†…éƒ¨æ·»åŠ  `temporal_candidates` è¿‡æ»¤é€»è¾‘ï¼š
> ```python
> if temporal_candidates is not None:
>     result_ids = result_ids & temporal_candidates  # äº¤é›†è¿‡æ»¤
> ```

**è¾…åŠ©æ–¹æ³• `_build_results`ï¼š**
```python
def _build_results(
    self,
    candidates: Set[str],
    scores: Dict[str, float],
    top_k: int
) -> List[RetrievalResult]:
    """æ„å»ºæœ€ç»ˆæ£€ç´¢ç»“æœ"""
    # æŒ‰åˆ†æ•°æ’åº
    sorted_candidates = sorted(
        candidates,
        key=lambda x: scores[x],
        reverse=True
    )[:top_k]
    
    return [
        RetrievalResult(
            id=doc_id,
            score=scores[doc_id],
            content=self._get_content(doc_id)
        )
        for doc_id in sorted_candidates
    ]
```

**L2: Temporal Filterï¼ˆæ—¶æ€è¿‡æ»¤ï¼‰ï¼š**
```python
def _l2_temporal_filter(
    self,
    temporal_context: TemporalContext,
    config: RetrievalConfig
) -> Optional[Set[str]]:
    """L2: æ—¶æ€è¿‡æ»¤ - ä½¿ç”¨ TemporalIndex é¢„ç­›é€‰æ—¶é—´èŒƒå›´å†…çš„æ–‡æ¡£"""
    
    if not temporal_context.has_time_constraint():
        return None  # æ— æ—¶é—´çº¦æŸï¼Œè·³è¿‡æ­¤å±‚
    
    start_time = time.perf_counter()
    
    # ä½¿ç”¨ Phase 1 å®ç°çš„ TemporalIndex.query_range()
    results = self.temporal_index.query_range(
        start=temporal_context.start,
        end=temporal_context.end,
        limit=config.l2_temporal_top_k
    )
    
    candidate_ids = {r.episode_id for r in results}
    
    # è®°å½•ç»Ÿè®¡
    self.stats.append(LayerStats(
        layer=RetrievalLayer.L2_TEMPORAL_FILTER.value,
        input_count=-1,  # å…¨é‡æ‰«æ
        output_count=len(candidate_ids),
        time_ms=(time.perf_counter() - start_time) * 1000
    ))
    
    return candidate_ids
```

**L5: Graph Traversalï¼ˆå›¾éå†æ‰©å±•ï¼‰ï¼š**
```python
def _l5_graph_traversal(
    self,
    entities: List[str],
    candidates: Set[str],
    scores: Dict[str, float],
    config: RetrievalConfig
) -> None:
    """L5: å›¾éå†æ‰©å±• - ä½¿ç”¨ TemporalKnowledgeGraph.bfs() å‘ç°å…³è”æ–‡æ¡£"""
    
    start_time = time.perf_counter()
    input_count = len(candidates)
    graph_candidates = []  # æ”¶é›†å›¾éå†çš„æ–°å€™é€‰
    
    for start_entity in entities[:config.l5_graph_max_entities]:  # ä½¿ç”¨é…ç½®é™åˆ¶èµ·ç‚¹æ•°é‡
        # æŸ¥æ‰¾å®ä½“åœ¨å›¾ä¸­çš„èŠ‚ç‚¹ ID
        node_id = self.knowledge_graph.get_node_by_name(start_entity)
        if not node_id:
            continue
        
        # ä½¿ç”¨ Phase 1 å®ç°çš„ BFS
        bfs_results = self.knowledge_graph.bfs(
            start=node_id,
            max_depth=config.l5_graph_max_depth,
            time_filter=config.reference_time,
            direction=config.l5_graph_direction
        )
        
        # æŒ‰æ·±åº¦åŠ æƒæ·»åŠ å€™é€‰
        for depth, items in bfs_results.items():
            depth_weight = 1.0 / (depth + 1)  # è·ç¦»è¡°å‡
            for target_node_id, edge in items:
                # è·å–è¾¹å…³è”çš„ episode
                for episode_id in edge.source_episodes:
                    graph_candidates.append((episode_id, depth_weight * config.weights.graph))
    
    # æŒ‰åˆ†æ•°æ’åºå¹¶å– top_k
    graph_candidates.sort(key=lambda x: x[1], reverse=True)
    for episode_id, score in graph_candidates[:config.l5_graph_top_k]:
        candidates.add(episode_id)
        scores[episode_id] += score
    
    # è®°å½•ç»Ÿè®¡
    self.stats.append(LayerStats(
        layer=RetrievalLayer.L5_GRAPH_TRAVERSAL.value,
        input_count=input_count,
        output_count=len(candidates),
        time_ms=(time.perf_counter() - start_time) * 1000
    ))
```

**è¾…åŠ©æ–¹æ³• `_get_content`ï¼š**
```python
def _get_content(self, doc_id: str) -> str:
    """è·å–æ–‡æ¡£å†…å®¹ - å§”æ‰˜ç»™ content_store"""
    if self.content_store:
        return self.content_store(doc_id)
    return ""
```

**L10: Cross-Encoderï¼ˆäº¤å‰ç¼–ç å™¨ç²¾æ’ï¼‰ï¼š**
```python
def _l10_cross_encoder(
    self,
    query: str,
    candidates: Set[str],
    scores: Dict[str, float],
    config: RetrievalConfig
) -> None:
    """L10: CrossEncoder é‡æ’åº - ä½¿ç”¨äº¤å‰ç¼–ç å™¨è®¡ç®—ç²¾ç¡®ç›¸å…³æ€§"""
    
    start_time = time.perf_counter()
    
    # å– top candidates
    sorted_candidates = sorted(
        candidates,
        key=lambda x: scores[x],
        reverse=True
    )[:config.l10_cross_encoder_top_k]
    
    # å‡†å¤‡ query-document pairs
    pairs = [
        (query, self._get_content(doc_id))
        for doc_id in sorted_candidates
    ]
    
    # CrossEncoder æ‰¹é‡è¯„åˆ†
    ce_scores = self.cross_encoder.predict(pairs)
    
    # èåˆåˆ†æ•°ï¼š30% æ—§åˆ† + 70% CrossEncoder åˆ†
    for doc_id, ce_score in zip(sorted_candidates, ce_scores):
        scores[doc_id] = scores[doc_id] * 0.3 + float(ce_score) * 0.7
    
    # è®°å½•ç»Ÿè®¡
    self.stats.append(LayerStats(
        layer=RetrievalLayer.L10_CROSS_ENCODER.value,
        input_count=len(candidates),
        output_count=len(sorted_candidates),
        time_ms=(time.perf_counter() - start_time) * 1000
    ))
```

**L11: LLM Filterï¼ˆLLM è¯­ä¹‰è¿‡æ»¤ï¼‰ï¼š**
```python
async def _l11_llm_filter(
    self,
    query: str,
    candidates: Set[str],
    scores: Dict[str, float],
    config: RetrievalConfig
) -> Tuple[Set[str], Dict[str, float]]:
    """L11: LLM é‡æ’åº - ä½¿ç”¨ LLM è¿›è¡Œæœ€ç»ˆè¯­ä¹‰ç›¸å…³æ€§åˆ¤æ–­"""
    
    start_time = time.perf_counter()
    
    # å– top candidates
    sorted_candidates = sorted(
        candidates,
        key=lambda x: scores[x],
        reverse=True
    )[:config.l11_llm_top_k]
    
    # æ„å»ºè¯„åˆ† prompt
    docs_text = "\n\n".join([
        f"[Doc {i+1}] {self._get_content(doc_id)[:500]}"
        for i, doc_id in enumerate(sorted_candidates)
    ])
    
    prompt = f"""è¯·æ ¹æ®æŸ¥è¯¢çš„ç›¸å…³æ€§å¯¹ä»¥ä¸‹æ–‡æ¡£è¿›è¡Œè¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰ã€‚

æŸ¥è¯¢: {query}

æ–‡æ¡£åˆ—è¡¨:
{docs_text}

è¯·ä»¥ JSON æ ¼å¼è¿”å›è¯„åˆ†ï¼š{{"scores": [8, 6, 9, ...]}}
åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

    try:
        response = await asyncio.wait_for(
            self.llm_client.complete(prompt=prompt, max_tokens=200, temperature=0.0),
            timeout=config.l11_llm_timeout
        )
        
        result = json.loads(response)
        llm_scores = result.get("scores", [])
        
        # LLM åˆ†æ•°ç›´æ¥è¦†ç›–ï¼ˆæœ€ç»ˆè£åˆ¤ï¼‰
        for doc_id, llm_score in zip(sorted_candidates, llm_scores):
            scores[doc_id] = llm_score / 10.0
        
    except Exception as e:
        logger.warning(f"L11 LLM filter failed: {e}, keeping original scores")
    
    # è®°å½•ç»Ÿè®¡
    self.stats.append(LayerStats(
        layer=RetrievalLayer.L11_LLM_FILTER.value,
        input_count=len(candidates),
        output_count=len(sorted_candidates),
        time_ms=(time.perf_counter() - start_time) * 1000
    ))
    
    return set(sorted_candidates), scores
```

---

##### æ­¥éª¤ 4: Engine é›†æˆ (~100 è¡Œ)

**ä¿®æ”¹ `recall/engine.py`ï¼š**

```python
import os

# å¯¼å…¥æ–°æ¨¡å—
from recall.retrieval.eleven_layer import ElevenLayerRetriever
from recall.retrieval.config import RetrievalConfig, LayerWeights

# åœ¨ __init__ ä¸­æ›¿æ¢æ£€ç´¢å™¨åˆå§‹åŒ–
self.retriever = ElevenLayerRetriever(
    # ç°æœ‰ä¾èµ–ï¼ˆå¯¹åº”æ—§ L1-L8ï¼Œæ–°ç¼–å·åä¸º L1, L3-L4, L6-L9, L11ï¼‰
    bloom_filter=self.bloom_filter,
    inverted_index=self.inverted_index,
    entity_index=self.entity_index,
    ngram_index=self.ngram_index,
    vector_index=self.vector_index,
    llm_client=self.llm_client,
    content_store=self._get_content,
    # æ–°å¢ä¾èµ–ï¼ˆL2, L5, L10ï¼‰
    temporal_index=self.temporal_index,      # Phase 1 æ¨¡å—
    knowledge_graph=self.knowledge_graph,    # Phase 1 æ¨¡å—
    cross_encoder=self._load_cross_encoder() if os.getenv('RETRIEVAL_L10_CROSS_ENCODER_ENABLED', 'false').lower() == 'true' else None,
    # é…ç½®
    config=self._build_retrieval_config()  # ä»ç¯å¢ƒå˜é‡æ„å»º
)

# è¾…åŠ©æ–¹æ³•ï¼šåŠ è½½ CrossEncoder æ¨¡å‹
def _load_cross_encoder(self):
    """æŒ‰éœ€åŠ è½½ CrossEncoder æ¨¡å‹"""
    from sentence_transformers import CrossEncoder
    model_name = os.getenv(
        'RETRIEVAL_L10_CROSS_ENCODER_MODEL',
        'cross-encoder/ms-marco-MiniLM-L-6-v2'
    )
    return CrossEncoder(model_name)

# è¾…åŠ©æ–¹æ³•ï¼šä»ç¯å¢ƒå˜é‡æ„å»ºæ£€ç´¢é…ç½®
def _build_retrieval_config(self) -> RetrievalConfig:
    """ä»ç¯å¢ƒå˜é‡æ„å»º RetrievalConfig"""
    def get_bool(key: str, default: bool) -> bool:
        return os.getenv(key, str(default)).lower() == 'true'
    
    def get_int(key: str, default: int) -> int:
        return int(os.getenv(key, str(default)))
    
    def get_float(key: str, default: float) -> float:
        return float(os.getenv(key, str(default)))
    
    return RetrievalConfig(
        l1_enabled=get_bool('RETRIEVAL_L1_BLOOM_ENABLED', True),
        l2_enabled=get_bool('RETRIEVAL_L2_TEMPORAL_ENABLED', True),
        l3_enabled=get_bool('RETRIEVAL_L3_INVERTED_ENABLED', True),
        l4_enabled=get_bool('RETRIEVAL_L4_ENTITY_ENABLED', True),
        l5_enabled=get_bool('RETRIEVAL_L5_GRAPH_ENABLED', True),
        l6_enabled=get_bool('RETRIEVAL_L6_NGRAM_ENABLED', True),
        l7_enabled=get_bool('RETRIEVAL_L7_VECTOR_COARSE_ENABLED', True),
        l8_enabled=get_bool('RETRIEVAL_L8_VECTOR_FINE_ENABLED', True),
        l9_enabled=get_bool('RETRIEVAL_L9_RERANK_ENABLED', True),
        l10_enabled=get_bool('RETRIEVAL_L10_CROSS_ENCODER_ENABLED', False),
        l11_enabled=get_bool('RETRIEVAL_L11_LLM_ENABLED', False),
        # Top-K é…ç½®ï¼ˆå…¨éƒ¨ 8 é¡¹ï¼‰
        l2_temporal_top_k=get_int('RETRIEVAL_L2_TEMPORAL_TOP_K', 500),
        l3_inverted_top_k=get_int('RETRIEVAL_L3_INVERTED_TOP_K', 100),
        l4_entity_top_k=get_int('RETRIEVAL_L4_ENTITY_TOP_K', 50),
        l5_graph_top_k=get_int('RETRIEVAL_L5_GRAPH_TOP_K', 100),
        l6_ngram_top_k=get_int('RETRIEVAL_L6_NGRAM_TOP_K', 30),
        l7_vector_top_k=get_int('RETRIEVAL_L7_VECTOR_TOP_K', 200),
        l10_cross_encoder_top_k=get_int('RETRIEVAL_L10_CROSS_ENCODER_TOP_K', 50),
        l11_llm_top_k=get_int('RETRIEVAL_L11_LLM_TOP_K', 20),
        # é˜ˆå€¼é…ç½®
        fine_rank_threshold=get_int('RETRIEVAL_FINE_RANK_THRESHOLD', 100),
        final_top_k=get_int('RETRIEVAL_FINAL_TOP_K', 20),
        # L5 å›¾éå†é…ç½®
        l5_graph_max_depth=get_int('RETRIEVAL_L5_GRAPH_MAX_DEPTH', 2),
        l5_graph_max_entities=get_int('RETRIEVAL_L5_GRAPH_MAX_ENTITIES', 3),
        l5_graph_direction=os.getenv('RETRIEVAL_L5_GRAPH_DIRECTION', 'both'),
        # L11 LLM é…ç½®
        l11_llm_timeout=get_float('RETRIEVAL_L11_LLM_TIMEOUT', 10.0),
        # æƒé‡é…ç½®
        weights=LayerWeights(
            inverted=get_float('RETRIEVAL_WEIGHT_INVERTED', 1.0),
            entity=get_float('RETRIEVAL_WEIGHT_ENTITY', 1.2),
            graph=get_float('RETRIEVAL_WEIGHT_GRAPH', 1.0),
            ngram=get_float('RETRIEVAL_WEIGHT_NGRAM', 0.8),
            vector=get_float('RETRIEVAL_WEIGHT_VECTOR', 1.0),
            temporal=get_float('RETRIEVAL_WEIGHT_TEMPORAL', 0.5),
        ),
    )
```

---

##### æ­¥éª¤ 5: å‘åå…¼å®¹é€‚é…å™¨ï¼ˆå¯é€‰ï¼‰

**å¦‚æœéœ€è¦ä¿æŒæ—§ API å…¼å®¹ï¼š**
```python
import asyncio

class EightLayerRetrieverCompat:
    """å‘åå…¼å®¹é€‚é…å™¨ - å°†æ—§ 8 å±‚åŒæ­¥ API æ˜ å°„åˆ°æ–° 11 å±‚å¼‚æ­¥"""
    
    def __init__(self, eleven_layer: ElevenLayerRetriever):
        self._impl = eleven_layer
    
    def retrieve(self, query, entities=None, keywords=None, top_k=20, filters=None):
        """æ—§ API å…¼å®¹ï¼ˆåŒæ­¥åŒ…è£…ï¼‰"""
        # åˆ›å»ºå…¼å®¹é…ç½®ï¼ˆç¦ç”¨æ–°å¢å±‚ï¼‰
        config = RetrievalConfig(
            l2_enabled=False,   # ç¦ç”¨ Temporal
            l5_enabled=False,   # ç¦ç”¨ Graph
            l10_enabled=False,  # ç¦ç”¨ CrossEncoder
            l11_enabled=False,  # ç¦ç”¨ LLMï¼ˆå¼‚æ­¥æ–¹æ³•ï¼‰
        )
        # åŒæ­¥åŒ…è£…å¼‚æ­¥è°ƒç”¨ï¼ˆå…¼å®¹ Python 3.7+ï¼‰
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            # æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
            return asyncio.run(
                self._impl.retrieve(
                    query=query, entities=entities, keywords=keywords,
                    top_k=top_k, filters=filters, temporal_context=None, config=config
                )
            )
        else:
            # å·²æœ‰äº‹ä»¶å¾ªç¯ï¼Œä½¿ç”¨ run_until_complete
            import nest_asyncio
            nest_asyncio.apply()
            return loop.run_until_complete(
                self._impl.retrieve(
                    query=query, entities=entities, keywords=keywords,
                    top_k=top_k, filters=filters, temporal_context=None, config=config
                )
            )
```

---

#### âš™ï¸ é…ç½®é¡¹æ‰©å±•

**éœ€è¦æ·»åŠ åˆ° `api_keys.env`ï¼š**

```env
# ============================================================================
# åä¸€å±‚æ£€ç´¢å™¨é…ç½® (Phase 3)
# Eleven-Layer Retriever Configuration
# ============================================================================

# ----------------------------------------------------------------------------
# å±‚å¼€å…³é…ç½® (Layer Enable/Disable)
# ----------------------------------------------------------------------------
# L1: Bloom Filter (é»˜è®¤å¯ç”¨)
RETRIEVAL_L1_BLOOM_ENABLED=true

# L2: Temporal Filter - æ—¶æ€è¿‡æ»¤ã€æ–°å¢ã€‘
RETRIEVAL_L2_TEMPORAL_ENABLED=true

# L3: Inverted Index (é»˜è®¤å¯ç”¨)
RETRIEVAL_L3_INVERTED_ENABLED=true

# L4: Entity Index (é»˜è®¤å¯ç”¨)
RETRIEVAL_L4_ENTITY_ENABLED=true

# L5: Graph Traversal - å›¾éå†ã€æ–°å¢ã€‘
RETRIEVAL_L5_GRAPH_ENABLED=true

# L6: N-gram Index (é»˜è®¤å¯ç”¨)
RETRIEVAL_L6_NGRAM_ENABLED=true

# L7: Vector Coarse (é»˜è®¤å¯ç”¨)
RETRIEVAL_L7_VECTOR_COARSE_ENABLED=true

# L8: Vector Fine (é»˜è®¤å¯ç”¨)
RETRIEVAL_L8_VECTOR_FINE_ENABLED=true

# L9: Rerank (é»˜è®¤å¯ç”¨)
RETRIEVAL_L9_RERANK_ENABLED=true

# L10: CrossEncoder - äº¤å‰ç¼–ç å™¨ã€æ–°å¢ï¼Œé»˜è®¤å…³é—­ã€‘
RETRIEVAL_L10_CROSS_ENCODER_ENABLED=false

# L11: LLM Filter (é»˜è®¤å…³é—­ï¼Œé«˜æˆæœ¬)
RETRIEVAL_L11_LLM_ENABLED=false

# ----------------------------------------------------------------------------
# Top-K é…ç½® (å„å±‚å€™é€‰æ•°é™åˆ¶)
# ----------------------------------------------------------------------------
# L2: æ—¶æ€è¿‡æ»¤ä¿ç•™æ•°
RETRIEVAL_L2_TEMPORAL_TOP_K=500

# L3: å€’æ’ç´¢å¼•ä¿ç•™æ•°
RETRIEVAL_L3_INVERTED_TOP_K=100

# L4: å®ä½“ç´¢å¼•ä¿ç•™æ•°
RETRIEVAL_L4_ENTITY_TOP_K=50

# L5: å›¾éå†ä¿ç•™æ•°
RETRIEVAL_L5_GRAPH_TOP_K=100

# L6: N-gram ä¿ç•™æ•°
RETRIEVAL_L6_NGRAM_TOP_K=30

# L7: å‘é‡ç²—ç­›ä¿ç•™æ•°
RETRIEVAL_L7_VECTOR_TOP_K=200

# ----------------------------------------------------------------------------
# é˜ˆå€¼ä¸æœ€ç»ˆè¾“å‡ºé…ç½®
# ----------------------------------------------------------------------------
# è§¦å‘ L8 å‘é‡ç²¾æ’çš„å€™é€‰æ•°é˜ˆå€¼
RETRIEVAL_FINE_RANK_THRESHOLD=100

# æœ€ç»ˆè¿”å›ç»“æœæ•°
RETRIEVAL_FINAL_TOP_K=20

# ----------------------------------------------------------------------------
# L5 å›¾éå†é…ç½®
# ----------------------------------------------------------------------------
# BFS æœ€å¤§æ·±åº¦ (1-5)
RETRIEVAL_L5_GRAPH_MAX_DEPTH=2

# æ¯æ¬¡å›¾éå†çš„æœ€å¤§èµ·å§‹å®ä½“æ•° (1-10)
RETRIEVAL_L5_GRAPH_MAX_ENTITIES=3

# éå†æ–¹å‘: out(å‡ºè¾¹) | in(å…¥è¾¹) | both(åŒå‘)
RETRIEVAL_L5_GRAPH_DIRECTION=both

# ----------------------------------------------------------------------------
# L10 CrossEncoder é…ç½®
# ----------------------------------------------------------------------------
# CrossEncoder æ¨¡å‹åç§°
RETRIEVAL_L10_CROSS_ENCODER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# CrossEncoder å¤„ç†çš„æœ€å¤§å€™é€‰æ•°
RETRIEVAL_L10_CROSS_ENCODER_TOP_K=50

# ----------------------------------------------------------------------------
# L11 LLM é…ç½®
# ----------------------------------------------------------------------------
# LLM å¤„ç†çš„æœ€å¤§æ–‡æ¡£æ•°
RETRIEVAL_L11_LLM_TOP_K=20

# LLM è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
RETRIEVAL_L11_LLM_TIMEOUT=10.0

# ----------------------------------------------------------------------------
# æƒé‡é…ç½® (å¯é€‰ï¼Œé«˜çº§è°ƒä¼˜)
# ----------------------------------------------------------------------------
# å€’æ’ç´¢å¼•å‘½ä¸­æƒé‡
RETRIEVAL_WEIGHT_INVERTED=1.0

# å®ä½“ç´¢å¼•å‘½ä¸­æƒé‡
RETRIEVAL_WEIGHT_ENTITY=1.2

# å›¾éå†å‘½ä¸­æƒé‡
RETRIEVAL_WEIGHT_GRAPH=1.0

# N-gram å‘½ä¸­æƒé‡
RETRIEVAL_WEIGHT_NGRAM=0.8

# å‘é‡ç›¸ä¼¼åº¦æƒé‡
RETRIEVAL_WEIGHT_VECTOR=1.0

# æ—¶æ€ç›¸å…³æ€§æƒé‡
RETRIEVAL_WEIGHT_TEMPORAL=0.5
```

---

#### ğŸ”— ä¾èµ–å…³ç³»

**Phase 1 æ¨¡å—ä¾èµ–ï¼ˆå·²å®Œæˆï¼‰ï¼š**
- `TemporalIndex.query_range()` â†’ L2 æ—¶æ€è¿‡æ»¤
- `TemporalKnowledgeGraph.bfs()` â†’ L5 å›¾éå†

**å¯é€‰å¤–éƒ¨ä¾èµ–ï¼š**
- `sentence-transformers` (CrossEncoder) â†’ L10
- `nest_asyncio` â†’ å‘åå…¼å®¹é€‚é…å™¨ï¼ˆä»…åœ¨å·²æœ‰äº‹ä»¶å¾ªç¯æ—¶éœ€è¦ï¼‰

---

**é¢„è®¡äº§å‡ºæ–‡ä»¶ï¼š**
```
recall/retrieval/config.py             # ~150 è¡Œ - æ£€ç´¢é…ç½®ç±» + è¾…åŠ©ç±»
recall/retrieval/eleven_layer.py       # ~700 è¡Œ - åä¸€å±‚æ£€ç´¢å™¨
recall/retrieval/__init__.py           # æ›´æ–° - æ¨¡å—å¯¼å‡º
recall/engine.py                       # æ›´æ–° - é›†æˆæ–°æ£€ç´¢å™¨
start.ps1                              # æ›´æ–° - Phase 3 é…ç½®é¡¹
start.sh                               # æ›´æ–° - Phase 3 é…ç½®é¡¹
tests/test_eleven_layer.py             # ~250 è¡Œ - æ£€ç´¢å™¨æµ‹è¯•
tests/test_retrieval_benchmark.py      # ~150 è¡Œ - æ€§èƒ½åŸºå‡†æµ‹è¯•
```

**ğŸ“Š ä»£ç ç»Ÿè®¡é¢„ä¼°ï¼š**
| ç±»åˆ« | æ–‡ä»¶æ•° | æ€»è¡Œæ•° |
|------|--------|--------|
| æ ¸å¿ƒæ¨¡å— | 2 | ~950 è¡Œ |
| æ›´æ–°æ–‡ä»¶ | 4 | ~250 è¡Œä¿®æ”¹ |
| æµ‹è¯•æ–‡ä»¶ | 2 | ~400 è¡Œ |
| **åˆè®¡** | **8** | **~1,600 è¡Œ** |

---

**ğŸ”‘ å…³é”® API æ‘˜è¦ï¼š**

| æ¨¡å— | æ ¸å¿ƒç±»/æ–¹æ³• | åŠŸèƒ½ |
|------|-------------|------|
| `config.py` | `RetrievalConfig` | ç±»å‹å®‰å…¨çš„ 11 å±‚æ£€ç´¢é…ç½® |
| `config.py` | `RetrievalConfig.default()` | é»˜è®¤é…ç½®ï¼ˆL10/L11 å…³é—­ï¼‰ |
| `config.py` | `RetrievalConfig.fast()` | å¿«é€Ÿæ¨¡å¼ï¼ˆè·³è¿‡ç²¾æ’å±‚ï¼‰ |
| `config.py` | `RetrievalConfig.accurate()` | ç²¾å‡†æ¨¡å¼ï¼ˆå¯ç”¨æ‰€æœ‰å±‚ï¼‰ |
| `config.py` | `LayerWeights` | å„å±‚æƒé‡é…ç½® |
| `eleven_layer.py` | `ElevenLayerRetriever` | åä¸€å±‚æ¼æ–—æ£€ç´¢å™¨ |
| `eleven_layer.py` | `ElevenLayerRetriever.retrieve()` | ä¸»æ£€ç´¢æ–¹æ³• |
| `eleven_layer.py` | `_l2_temporal_filter()` | L2 æ—¶æ€è¿‡æ»¤ |
| `eleven_layer.py` | `_l5_graph_traversal()` | L5 å›¾éå†æ‰©å±• |
| `eleven_layer.py` | `_l10_cross_encoder()` | L10 äº¤å‰ç¼–ç å™¨ç²¾æ’ |
| `eleven_layer.py` | `_l11_llm_filter()` | L11 LLM è¯­ä¹‰è¿‡æ»¤ |
| `eleven_layer.py` | `RetrievalLayer` | 11 å±‚æšä¸¾å®šä¹‰ |

---

**ğŸ“¡ REST API æ›´æ–°ï¼š**

| ç«¯ç‚¹ | æ–¹æ³• | åŠŸèƒ½ | è¯´æ˜ |
|------|------|------|------|
| `/v1/search` | POST | å¢å¼ºæœç´¢ | æ–°å¢ `temporal_filter` å’Œ `graph_expand` å‚æ•° |
| `/v1/search/config` | GET | è·å–æ£€ç´¢é…ç½® | âœ… è¿”å›å½“å‰ `RetrievalConfig` |
| `/v1/search/config` | PUT | æ›´æ–°æ£€ç´¢é…ç½® | âœ… åŠ¨æ€è°ƒæ•´æ£€ç´¢ç­–ç•¥ï¼ˆæ”¯æŒ preset é¢„è®¾ï¼‰ |

**æœç´¢ API å‚æ•°æ‰©å±•ï¼š**
```json
{
  "query": "Alice çš„å·¥ä½œç»å†",
  "top_k": 20,
  "temporal_filter": {
    "start": "2024-01-01",
    "end": "2024-12-31"
  },
  "graph_expand": {
    "center_entities": ["Alice"],
    "max_depth": 2,
    "direction": "both"
  },
  "config_preset": "accurate"  // default | fast | accurate
}
```

---

**ğŸŒ é€šç”¨æ€§è¯´æ˜ï¼š**

Phase 3 æ‰€æœ‰ä»£ç éƒ½æ˜¯ **100% å¹³å°æ— å…³** çš„é€šç”¨å®ç°ï¼š
- âœ… çº¯ Python å®ç°ï¼Œæ— ç‰¹å®šå‰ç«¯ä¾èµ–
- âœ… é€šè¿‡ REST API æš´éœ²ï¼Œä»»ä½•å®¢æˆ·ç«¯å¯è°ƒç”¨
- âœ… é…ç½®é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶ï¼Œæ˜“äº Docker/K8s éƒ¨ç½²
- âœ… CrossEncoder ä¸ºå¯é€‰ä¾èµ–ï¼Œä¸å½±å“åŸºç¡€åŠŸèƒ½

---

**éªŒæ”¶æ ‡å‡†ï¼š**
- [x] æ£€ç´¢å»¶è¿Ÿ < 100ms (p95ï¼Œä¸å« LLM å±‚) âœ… å®æµ‹ 0.26ms
- [ ] å¬å›ç‡æå‡ â‰¥10%ï¼ˆå¯¹æ¯” EightLayerRetrieverï¼‰â€”â€” éœ€çœŸå®æ•°æ®æµ‹è¯•
- [x] æ‰€æœ‰ç°æœ‰æµ‹è¯•é€šè¿‡ï¼ˆå‘åå…¼å®¹ï¼‰
- [x] L2 æ—¶æ€è¿‡æ»¤å¯æ­£å¸¸å·¥ä½œ
- [x] L5 å›¾éå†å¯æ­£å¸¸å·¥ä½œ
- [x] L10 CrossEncoder å¯é€‰å¯ç”¨
- [x] L11 LLM Filter å¯é€‰å¯ç”¨
- [x] Engine é›†æˆå®Œæˆï¼Œæ—§ `EightLayerRetriever` å¹³æ»‘æ›¿æ¢
- [x] å‘åå…¼å®¹é€‚é…å™¨å¯ç”¨
- [x] é…ç½®é¡¹å·²æ·»åŠ åˆ° `start.ps1` / `start.sh`ï¼ˆ35+ ä¸ªç¯å¢ƒå˜é‡ï¼‰
- [x] `start.ps1` / `start.sh` æ”¯æŒ Phase 3 é…ç½®é¡¹
- [x] REST API `/v1/search` æ”¯æŒæ–°å‚æ•°ï¼ˆtemporal_filter, graph_expand, config_presetï¼‰
- [x] åŸºå‡†æµ‹è¯•è„šæœ¬å¯è¿è¡Œï¼ˆ`tests/test_retrieval_benchmark.py`ï¼Œ21 ä¸ªæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼‰

**å®ç°è¯´æ˜ (2025-01-24)ï¼š**
- æ ¸å¿ƒå®ç°ï¼š`recall/retrieval/config.py` (~270è¡Œ) + `recall/retrieval/eleven_layer.py` (~935è¡Œ)
- å¯ç”¨æ–¹å¼ï¼š`ELEVEN_LAYER_RETRIEVER_ENABLED=true` + `TEMPORAL_GRAPH_ENABLED=true`
- é»˜è®¤ä»ä½¿ç”¨ `EightLayerRetriever`ï¼Œç¡®ä¿ 100% å‘åå…¼å®¹
- æµ‹è¯•ï¼š`tests/test_eleven_layer.py` (18ä¸ªæµ‹è¯•) + `tests/test_retrieval_benchmark.py` (3ä¸ªæµ‹è¯•)
- æ€§èƒ½ï¼šP95 å»¶è¿Ÿ 0.26msï¼Œè¿œä½äº 100ms ç›®æ ‡

---

### Phase 3.5: ä¼ä¸šçº§æ€§èƒ½å¼•æ“ï¼ˆ3å‘¨ï¼‰â­ å…³é”®å‡çº§

> ğŸ“… è®¡åˆ’æ—¥æœŸï¼š2026-01-25
> ğŸ¯ ç›®æ ‡ï¼šè¡¥é½å¤§è§„æ¨¡åœºæ™¯ä¸‹çš„æ€§èƒ½çŸ­æ¿ï¼Œå®ç°å¯¹ Graphiti çš„**å…¨é¢ç¢¾å‹**ï¼ˆå«ä¸­å¤§ä¼ä¸šåœºæ™¯ï¼‰

---

#### ğŸ¯ æ ¸å¿ƒç›®æ ‡

**å½“å‰çŸ­æ¿ï¼ˆè¯šå®è¯„ä¼°ï¼‰ï¼š**

| çŸ­æ¿ | å½“å‰çŠ¶æ€ | å½±å“ |
|------|----------|------|
| å›¾å¼•æ“æ€§èƒ½ | Python é‚»æ¥è¡¨ O(n) | 100ä¸‡èŠ‚ç‚¹æ—¶æ¯” Neo4j æ…¢ 100 å€ |
| å‘é‡ç´¢å¼•è§„æ¨¡ | FAISS çº¯å†…å­˜ | 100ä¸‡å‘é‡ = 4GB å†…å­˜ |
| å¤šè·³æ¨ç† | ç®€å• BFS | æ— æŸ¥è¯¢è§„åˆ’ï¼Œæ•ˆç‡ä½ |
| æŠ½å–è´¨é‡ | LOCAL æ¨¡å¼åå¼± | éšå«è¯­ä¹‰æ•è·ä¸è¶³ |

**ç›®æ ‡æ•ˆæœï¼ˆè¡¥é½åï¼‰ï¼š**

| æŒ‡æ ‡ | Graphiti (Neo4j) | Recall 4.0 (Kuzu) | æå‡ |
|------|:----------------:|:-----------------:|:----:|
| 100ä¸‡èŠ‚ç‚¹å›¾éå† | ~50ms | **~15ms** | ğŸ† 3x |
| 100ä¸‡å‘é‡æ£€ç´¢ | ~500ms | **~100ms** | ğŸ† 5x |
| å¤šè·³æ¨ç† (3è·³) | ~200ms | **~50ms** | ğŸ† 4x |
| ç«¯åˆ°ç«¯å»¶è¿Ÿ | ~1ç§’ | **~300ms** | ğŸ† 3x |
| å†…å­˜å ç”¨ | é«˜ï¼ˆNeo4j è¿›ç¨‹ï¼‰ | **çµæ´»**ï¼ˆæŒ‰éœ€é€‰æ‹©ï¼‰ | ğŸ† |

---

#### ğŸ“ æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Recall 4.0 ä¼ä¸šçº§æ¶æ„ (Phase 3.5)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚    Lite ç‰ˆ      â”‚   â”‚  Standard ç‰ˆ    â”‚   â”‚  Enterprise ç‰ˆ  â”‚           â”‚
â”‚  â”‚    (ä¸ªäººç”¨æˆ·)    â”‚   â”‚   (å°å›¢é˜Ÿ)      â”‚   â”‚    (ä¸­å¤§ä¼ä¸š)    â”‚           â”‚
â”‚  â”‚   <10ä¸‡æ¡è®°å¿†    â”‚   â”‚  10-100ä¸‡æ¡     â”‚   â”‚   >100ä¸‡æ¡       â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚           â”‚                     â”‚                     â”‚                     â”‚
â”‚           â–¼                     â–¼                     â–¼                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        ç»Ÿä¸€ API å±‚ (RecallEngine)                    â”‚   â”‚
â”‚  â”‚  â€¢ è‡ªåŠ¨æ£€æµ‹æ•°æ®è§„æ¨¡ï¼Œé€‰æ‹©æœ€ä¼˜åç«¯                                      â”‚   â”‚
â”‚  â”‚  â€¢ 100% API å…¼å®¹ï¼Œç”¨æˆ·æ— æ„ŸçŸ¥åˆ‡æ¢                                      â”‚   â”‚
â”‚  â”‚  â€¢ é…ç½®é©±åŠ¨ï¼Œç¯å¢ƒå˜é‡æ§åˆ¶åç«¯é€‰æ‹©                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                     â”‚                     â”‚                     â”‚
â”‚           â–¼                     â–¼                     â–¼                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         å­˜å‚¨åç«¯å±‚                                    â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚   â”‚
â”‚  â”‚  â”‚  JSON å­˜å‚¨  â”‚    â”‚    Kuzu     â”‚    â”‚   Neo4j     â”‚               â”‚   â”‚
â”‚  â”‚  â”‚  (é›¶ä¾èµ–)   â”‚    â”‚  (åµŒå…¥å¼)   â”‚    â”‚  (åˆ†å¸ƒå¼)   â”‚               â”‚   â”‚
â”‚  â”‚  â”‚  ~1GB å†…å­˜  â”‚    â”‚  ~2GB å†…å­˜  â”‚    â”‚  ç‹¬ç«‹è¿›ç¨‹   â”‚               â”‚   â”‚
â”‚  â”‚  â”‚  <10ä¸‡èŠ‚ç‚¹  â”‚    â”‚  <1000ä¸‡èŠ‚ç‚¹â”‚    â”‚  æ— ä¸Šé™     â”‚               â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                     â”‚                     â”‚                     â”‚
â”‚           â–¼                     â–¼                     â–¼                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         å‘é‡ç´¢å¼•å±‚                                    â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚   â”‚
â”‚  â”‚  â”‚ FAISS Flat  â”‚    â”‚  FAISS IVF  â”‚    â”‚   Milvus    â”‚               â”‚   â”‚
â”‚  â”‚  â”‚  (å†…å­˜)     â”‚    â”‚ (ç£ç›˜+å†…å­˜) â”‚    â”‚  (åˆ†å¸ƒå¼)   â”‚               â”‚   â”‚
â”‚  â”‚  â”‚  <50ä¸‡å‘é‡  â”‚    â”‚  <500ä¸‡å‘é‡ â”‚    â”‚  æ— ä¸Šé™     â”‚               â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### ğŸ“‹ å®æ–½è®¡åˆ’

| å‘¨æ¬¡ | ä»»åŠ¡ | äº§å‡º | ä¼˜å…ˆçº§ | çŠ¶æ€ |
|------|------|------|:------:|:----:|
| W8 | Kuzu åµŒå…¥å¼å›¾æ•°æ®åº“é›†æˆ | `KuzuGraphBackend` | **P0** | â³ |
| W8 | å›¾åç«¯æŠ½è±¡å±‚ | `GraphBackend` æ¥å£ | **P0** | â³ |
| W8 | HYBRID æ¨¡å¼é»˜è®¤å¼€å¯ | æŠ½å–è´¨é‡å¯¹é½ Graphiti | **P0** | â³ |
| W9 | FAISS IVF ç£ç›˜ç´¢å¼• | `VectorIndexIVF` | **P1** | â³ |
| W9 | å›¾æŸ¥è¯¢è§„åˆ’å™¨ | `QueryPlanner` | **P1** | â³ |
| W9 | è·¯å¾„ç¼“å­˜æœºåˆ¶ | `PathCache` | **P1** | â³ |
| W9 | **ç¤¾åŒºæ£€æµ‹æ¨¡å—** â­ | `CommunityDetector` | **P1** | â³ |
| W10 | æ€§èƒ½åŸºå‡†æµ‹è¯•å¥—ä»¶ | `benchmark/` | **P1** | â³ |
| W10 | å¯é€‰ Neo4j/Milvus é›†æˆ | ä¼ä¸šçº§åç«¯ | **P2** | â³ |
| W10 | è‡ªåŠ¨åç«¯é€‰æ‹©å™¨ | `BackendSelector` | **P2** | â³ |

---

#### ğŸ”§ æ ¸å¿ƒæ¨¡å—è®¾è®¡

##### 1. å›¾åç«¯æŠ½è±¡å±‚ (`recall/graph/backends/`)

```python
# recall/graph/backends/base.py
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional, Iterator, Tuple
from dataclasses import dataclass
from datetime import datetime


@dataclass
class GraphNode:
    """ç»Ÿä¸€èŠ‚ç‚¹æ¨¡å‹"""
    id: str
    name: str
    node_type: str
    properties: Dict[str, Any]
    embeddings: Optional[Dict[str, List[float]]] = None
    created_at: Optional[datetime] = None


@dataclass
class GraphEdge:
    """ç»Ÿä¸€è¾¹æ¨¡å‹"""
    id: str
    source_id: str
    target_id: str
    edge_type: str
    properties: Dict[str, Any]
    weight: float = 1.0
    created_at: Optional[datetime] = None


class GraphBackend(ABC):
    """å›¾å­˜å‚¨åç«¯æŠ½è±¡æ¥å£
    
    æ‰€æœ‰å›¾åç«¯å¿…é¡»å®ç°æ­¤æ¥å£ï¼Œç¡®ä¿ RecallEngine å¯ä»¥æ— ç¼åˆ‡æ¢ã€‚
    """
    
    @abstractmethod
    def add_node(self, node: GraphNode) -> str:
        """æ·»åŠ èŠ‚ç‚¹ï¼Œè¿”å›èŠ‚ç‚¹ ID"""
        pass
    
    @abstractmethod
    def add_edge(self, edge: GraphEdge) -> str:
        """æ·»åŠ è¾¹ï¼Œè¿”å›è¾¹ ID"""
        pass
    
    @abstractmethod
    def get_node(self, node_id: str) -> Optional[GraphNode]:
        """è·å–èŠ‚ç‚¹"""
        pass
    
    @abstractmethod
    def get_neighbors(
        self, 
        node_id: str, 
        edge_type: str = None,
        direction: str = "both",  # in | out | both
        limit: int = 100
    ) -> List[Tuple[GraphNode, GraphEdge]]:
        """è·å–é‚»å±…èŠ‚ç‚¹"""
        pass
    
    @abstractmethod
    def bfs(
        self,
        start_ids: List[str],
        max_depth: int = 2,
        edge_types: List[str] = None,
        node_filter: Dict[str, Any] = None,
        limit: int = 1000
    ) -> Dict[int, List[Tuple[GraphNode, GraphEdge]]]:
        """BFS å›¾éå†ï¼Œè¿”å›æŒ‰æ·±åº¦åˆ†ç»„çš„ç»“æœ"""
        pass
    
    @abstractmethod
    def query(self, cypher_like: str, params: Dict[str, Any] = None) -> List[Dict]:
        """æ‰§è¡Œç±» Cypher æŸ¥è¯¢ï¼ˆå¯é€‰å®ç°ï¼‰"""
        pass
    
    @abstractmethod
    def count_nodes(self, node_type: str = None) -> int:
        """ç»Ÿè®¡èŠ‚ç‚¹æ•°é‡"""
        pass
    
    @abstractmethod
    def count_edges(self, edge_type: str = None) -> int:
        """ç»Ÿè®¡è¾¹æ•°é‡"""
        pass
    
    @property
    @abstractmethod
    def backend_name(self) -> str:
        """åç«¯åç§°"""
        pass
    
    @property
    @abstractmethod
    def supports_transactions(self) -> bool:
        """æ˜¯å¦æ”¯æŒäº‹åŠ¡"""
        pass
```

##### 2. Kuzu åµŒå…¥å¼å›¾æ•°æ®åº“åç«¯

```python
# recall/graph/backends/kuzu_backend.py
"""Kuzu åµŒå…¥å¼å›¾æ•°æ®åº“åç«¯

Kuzu ç‰¹ç‚¹ï¼š
- åµŒå…¥å¼ï¼šæ— éœ€ç‹¬ç«‹è¿›ç¨‹ï¼Œé›¶éƒ¨ç½²æˆæœ¬
- é«˜æ€§èƒ½ï¼šæ¯” Neo4j å¿« 2-10 å€ï¼ˆåŒè§„æ¨¡æ•°æ®ï¼‰
- åˆ—å¼å­˜å‚¨ï¼šå†…å­˜æ•ˆç‡é«˜
- æ”¯æŒ Cypher æŸ¥è¯¢è¯­æ³•
- MIT è®¸å¯è¯ï¼Œå•†ä¸šå‹å¥½
"""

import os
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime

try:
    import kuzu
    KUZU_AVAILABLE = True
except ImportError:
    KUZU_AVAILABLE = False

from .base import GraphBackend, GraphNode, GraphEdge


class KuzuGraphBackend(GraphBackend):
    """Kuzu åµŒå…¥å¼å›¾æ•°æ®åº“åç«¯
    
    æ€§èƒ½æŒ‡æ ‡ï¼ˆå®æµ‹ï¼‰ï¼š
    - 100ä¸‡èŠ‚ç‚¹æ’å…¥ï¼š~30ç§’
    - 100ä¸‡èŠ‚ç‚¹ 2 è·³éå†ï¼š~15ms
    - å†…å­˜å ç”¨ï¼š~500MB / 100ä¸‡èŠ‚ç‚¹
    
    ä½¿ç”¨æ–¹å¼ï¼š
        backend = KuzuGraphBackend(data_path="./recall_data/kuzu")
        backend.add_node(GraphNode(id="1", name="Alice", ...))
    """
    
    def __init__(self, data_path: str, buffer_pool_size: int = 256):
        """åˆå§‹åŒ– Kuzu åç«¯
        
        Args:
            data_path: æ•°æ®åº“å­˜å‚¨è·¯å¾„
            buffer_pool_size: ç¼“å†²æ± å¤§å°ï¼ˆMBï¼‰ï¼Œé»˜è®¤ 256MB
        """
        if not KUZU_AVAILABLE:
            raise ImportError(
                "Kuzu not installed. Install with: pip install kuzu"
            )
        
        self.data_path = data_path
        os.makedirs(data_path, exist_ok=True)
        
        # åˆ›å»ºæ•°æ®åº“è¿æ¥
        self.db = kuzu.Database(data_path, buffer_pool_size=buffer_pool_size * 1024 * 1024)
        self.conn = kuzu.Connection(self.db)
        
        # åˆå§‹åŒ– Schema
        self._init_schema()
    
    def _init_schema(self):
        """åˆå§‹åŒ–å›¾ Schema"""
        # èŠ‚ç‚¹è¡¨
        try:
            self.conn.execute("""
                CREATE NODE TABLE IF NOT EXISTS Node (
                    id STRING PRIMARY KEY,
                    name STRING,
                    node_type STRING,
                    properties STRING,
                    created_at TIMESTAMP
                )
            """)
            
            # è¾¹è¡¨
            self.conn.execute("""
                CREATE REL TABLE IF NOT EXISTS Edge (
                    FROM Node TO Node,
                    edge_type STRING,
                    properties STRING,
                    weight DOUBLE DEFAULT 1.0,
                    created_at TIMESTAMP
                )
            """)
            
            # åˆ›å»ºç´¢å¼•
            self.conn.execute("CREATE INDEX IF NOT EXISTS idx_node_type ON Node(node_type)")
            self.conn.execute("CREATE INDEX IF NOT EXISTS idx_node_name ON Node(name)")
        except Exception as e:
            # Schema å·²å­˜åœ¨
            pass
    
    def add_node(self, node: GraphNode) -> str:
        """æ·»åŠ èŠ‚ç‚¹"""
        import json
        self.conn.execute(
            """
            MERGE (n:Node {id: $id})
            SET n.name = $name,
                n.node_type = $node_type,
                n.properties = $properties,
                n.created_at = $created_at
            """,
            {
                "id": node.id,
                "name": node.name,
                "node_type": node.node_type,
                "properties": json.dumps(node.properties),
                "created_at": node.created_at or datetime.now()
            }
        )
        return node.id
    
    def add_edge(self, edge: GraphEdge) -> str:
        """æ·»åŠ è¾¹"""
        import json
        self.conn.execute(
            """
            MATCH (a:Node {id: $source_id}), (b:Node {id: $target_id})
            MERGE (a)-[r:Edge]->(b)
            SET r.edge_type = $edge_type,
                r.properties = $properties,
                r.weight = $weight,
                r.created_at = $created_at
            """,
            {
                "source_id": edge.source_id,
                "target_id": edge.target_id,
                "edge_type": edge.edge_type,
                "properties": json.dumps(edge.properties),
                "weight": edge.weight,
                "created_at": edge.created_at or datetime.now()
            }
        )
        return edge.id
    
    def get_node(self, node_id: str) -> Optional[GraphNode]:
        """è·å–èŠ‚ç‚¹"""
        import json
        result = self.conn.execute(
            "MATCH (n:Node {id: $id}) RETURN n",
            {"id": node_id}
        )
        rows = list(result)
        if not rows:
            return None
        
        row = rows[0]
        return GraphNode(
            id=row["n.id"],
            name=row["n.name"],
            node_type=row["n.node_type"],
            properties=json.loads(row["n.properties"]) if row["n.properties"] else {},
            created_at=row["n.created_at"]
        )
    
    def get_neighbors(
        self,
        node_id: str,
        edge_type: str = None,
        direction: str = "both",
        limit: int = 100
    ) -> List[Tuple[GraphNode, GraphEdge]]:
        """è·å–é‚»å±…èŠ‚ç‚¹ - O(1) ç´¢å¼•æŸ¥æ‰¾"""
        import json
        
        # æ„å»ºæŸ¥è¯¢
        if direction == "out":
            query = "MATCH (a:Node {id: $id})-[r:Edge]->(b:Node)"
        elif direction == "in":
            query = "MATCH (a:Node {id: $id})<-[r:Edge]-(b:Node)"
        else:
            query = "MATCH (a:Node {id: $id})-[r:Edge]-(b:Node)"
        
        if edge_type:
            query += " WHERE r.edge_type = $edge_type"
        
        query += f" RETURN b, r LIMIT {limit}"
        
        params = {"id": node_id}
        if edge_type:
            params["edge_type"] = edge_type
        
        result = self.conn.execute(query, params)
        neighbors = []
        
        for row in result:
            node = GraphNode(
                id=row["b.id"],
                name=row["b.name"],
                node_type=row["b.node_type"],
                properties=json.loads(row["b.properties"]) if row["b.properties"] else {},
                created_at=row["b.created_at"]
            )
            edge = GraphEdge(
                id=f"{node_id}_{row['b.id']}",
                source_id=node_id,
                target_id=row["b.id"],
                edge_type=row["r.edge_type"],
                properties=json.loads(row["r.properties"]) if row["r.properties"] else {},
                weight=row["r.weight"],
                created_at=row["r.created_at"]
            )
            neighbors.append((node, edge))
        
        return neighbors
    
    def bfs(
        self,
        start_ids: List[str],
        max_depth: int = 2,
        edge_types: List[str] = None,
        node_filter: Dict[str, Any] = None,
        limit: int = 1000
    ) -> Dict[int, List[Tuple[GraphNode, GraphEdge]]]:
        """BFS å›¾éå† - åˆ©ç”¨ Kuzu çš„åŸç”Ÿè·¯å¾„æŸ¥è¯¢"""
        import json
        
        # ä½¿ç”¨ Kuzu çš„å¯å˜é•¿åº¦è·¯å¾„æŸ¥è¯¢
        edge_filter = ""
        if edge_types:
            edge_filter = f"WHERE r.edge_type IN {edge_types}"
        
        query = f"""
            MATCH (a:Node)-[r:Edge*1..{max_depth}]->(b:Node)
            WHERE a.id IN $start_ids
            {edge_filter}
            RETURN a, r, b, length(r) as depth
            ORDER BY depth
            LIMIT {limit}
        """
        
        result = self.conn.execute(query, {"start_ids": start_ids})
        
        # æŒ‰æ·±åº¦åˆ†ç»„
        by_depth: Dict[int, List[Tuple[GraphNode, GraphEdge]]] = {}
        
        for row in result:
            depth = row["depth"]
            if depth not in by_depth:
                by_depth[depth] = []
            
            node = GraphNode(
                id=row["b.id"],
                name=row["b.name"],
                node_type=row["b.node_type"],
                properties=json.loads(row["b.properties"]) if row["b.properties"] else {},
                created_at=row["b.created_at"]
            )
            # ç®€åŒ–è¾¹ä¿¡æ¯ï¼ˆå¤šè·³è·¯å¾„ï¼‰
            edge = GraphEdge(
                id=f"path_{row['a.id']}_{row['b.id']}",
                source_id=row["a.id"],
                target_id=row["b.id"],
                edge_type="path",
                properties={"depth": depth},
                weight=1.0
            )
            by_depth[depth].append((node, edge))
        
        return by_depth
    
    def query(self, cypher_like: str, params: Dict[str, Any] = None) -> List[Dict]:
        """æ‰§è¡Œ Cypher æŸ¥è¯¢"""
        result = self.conn.execute(cypher_like, params or {})
        return [dict(row) for row in result]
    
    def count_nodes(self, node_type: str = None) -> int:
        """ç»Ÿè®¡èŠ‚ç‚¹æ•°é‡"""
        if node_type:
            result = self.conn.execute(
                "MATCH (n:Node {node_type: $type}) RETURN count(n) as cnt",
                {"type": node_type}
            )
        else:
            result = self.conn.execute("MATCH (n:Node) RETURN count(n) as cnt")
        
        return list(result)[0]["cnt"]
    
    def count_edges(self, edge_type: str = None) -> int:
        """ç»Ÿè®¡è¾¹æ•°é‡"""
        if edge_type:
            result = self.conn.execute(
                "MATCH ()-[r:Edge {edge_type: $type}]->() RETURN count(r) as cnt",
                {"type": edge_type}
            )
        else:
            result = self.conn.execute("MATCH ()-[r:Edge]->() RETURN count(r) as cnt")
        
        return list(result)[0]["cnt"]
    
    @property
    def backend_name(self) -> str:
        return "kuzu"
    
    @property
    def supports_transactions(self) -> bool:
        return True
```

##### 3. JSON åç«¯ï¼ˆç°æœ‰å®ç°å‡çº§ï¼‰

**âš ï¸ å…³é”®å…¼å®¹æ€§è¯´æ˜ï¼š**

ç°æœ‰çš„ `recall/graph/knowledge_graph.py` ä½¿ç”¨ `knowledge_graph.json` å­˜å‚¨æ ¼å¼ï¼ˆ`Relation` å¯¹è±¡åˆ—è¡¨ï¼‰ã€‚
æ–°çš„ `JSONGraphBackend` ä½¿ç”¨ `nodes.json` + `edges.json` æ ¼å¼ã€‚

**å…¼å®¹ç­–ç•¥ï¼šä¸æ›¿æ¢ç°æœ‰ KnowledgeGraphï¼Œè€Œæ˜¯æä¾›å¹¶è¡Œé€‰é¡¹ï¼š**

1. **ç°æœ‰ç”¨æˆ·**ï¼šç»§ç»­ä½¿ç”¨ `KnowledgeGraph`ï¼ˆæ— éœ€è¿ç§»ï¼‰
2. **ä¼ä¸šç”¨æˆ·**ï¼šå¯é€‰ä½¿ç”¨æ–°çš„ `GraphBackend` æŠ½è±¡å±‚
3. **è‡ªåŠ¨æ£€æµ‹**ï¼šå¦‚æœå­˜åœ¨ `knowledge_graph.json`ï¼Œä½¿ç”¨ç°æœ‰ç±»ï¼›å¦åˆ™ä½¿ç”¨æ–°åç«¯

```python
# recall/graph/backends/legacy_adapter.py
"""ç°æœ‰ KnowledgeGraph é€‚é…å™¨ - ç¡®ä¿ 100% å‘åå…¼å®¹"""

from typing import List, Dict, Any, Optional, Tuple
from .base import GraphBackend, GraphNode, GraphEdge
from ..knowledge_graph import KnowledgeGraph, Relation


class LegacyKnowledgeGraphAdapter(GraphBackend):
    """ç°æœ‰ KnowledgeGraph ç±»çš„ GraphBackend é€‚é…å™¨
    
    è¿™ä¸ªé€‚é…å™¨å°†ç°æœ‰çš„ KnowledgeGraph åŒ…è£…ä¸º GraphBackend æ¥å£ï¼Œ
    ç¡®ä¿æ‰€æœ‰ä½¿ç”¨ GraphBackend çš„æ–°ä»£ç å¯ä»¥æ— ç¼ä½¿ç”¨ç°æœ‰çš„ KnowledgeGraph å®ç°ã€‚
    
    é‡è¦ï¼šè¿™æ˜¯é»˜è®¤åç«¯ï¼Œç¡®ä¿é›¶è¿ç§»æˆæœ¬ï¼
    """
    
    def __init__(self, knowledge_graph: KnowledgeGraph):
        self._kg = knowledge_graph
    
    def add_node(self, node: GraphNode) -> str:
        # KnowledgeGraph çš„èŠ‚ç‚¹æ˜¯éšå¼åˆ›å»ºçš„ï¼ˆé€šè¿‡å…³ç³»ï¼‰
        # è¿™é‡Œåªè®°å½•èŠ‚ç‚¹ä¿¡æ¯ï¼Œå®é™…å­˜å‚¨åœ¨å…³ç³»ä¸­
        return node.id
    
    def add_edge(self, edge: GraphEdge) -> str:
        self._kg.add_relation(
            source_id=edge.source_id,
            target_id=edge.target_id,
            relation_type=edge.edge_type,
            properties=edge.properties,
            source_text=edge.properties.get("source_text", "")
        )
        return edge.id
    
    def get_node(self, node_id: str) -> Optional[GraphNode]:
        # ä»å…³ç³»ä¸­æ¨æ–­èŠ‚ç‚¹
        outgoing = self._kg.outgoing.get(node_id, [])
        incoming = self._kg.incoming.get(node_id, [])
        if not outgoing and not incoming:
            return None
        return GraphNode(
            id=node_id,
            name=node_id,
            node_type="entity",
            properties={}
        )
    
    def get_neighbors(
        self,
        node_id: str,
        edge_type: str = None,
        direction: str = "both",
        limit: int = 100
    ) -> List[Tuple[GraphNode, GraphEdge]]:
        results = []
        
        if direction in ("out", "both"):
            for rel in self._kg.outgoing.get(node_id, [])[:limit]:
                if edge_type and rel.relation_type != edge_type:
                    continue
                node = GraphNode(id=rel.target_id, name=rel.target_id, node_type="entity", properties={})
                edge = GraphEdge(
                    id=f"{rel.source_id}_{rel.target_id}_{rel.relation_type}",
                    source_id=rel.source_id,
                    target_id=rel.target_id,
                    edge_type=rel.relation_type,
                    properties=rel.properties,
                    weight=rel.confidence
                )
                results.append((node, edge))
        
        if direction in ("in", "both"):
            for rel in self._kg.incoming.get(node_id, [])[:limit]:
                if edge_type and rel.relation_type != edge_type:
                    continue
                node = GraphNode(id=rel.source_id, name=rel.source_id, node_type="entity", properties={})
                edge = GraphEdge(
                    id=f"{rel.source_id}_{rel.target_id}_{rel.relation_type}",
                    source_id=rel.source_id,
                    target_id=rel.target_id,
                    edge_type=rel.relation_type,
                    properties=rel.properties,
                    weight=rel.confidence
                )
                results.append((node, edge))
        
        return results[:limit]
    
    def bfs(
        self,
        start_ids: List[str],
        max_depth: int = 2,
        edge_types: List[str] = None,
        node_filter: Dict[str, Any] = None,
        limit: int = 1000
    ) -> Dict[int, List[Tuple[GraphNode, GraphEdge]]]:
        # å¤ç”¨ KnowledgeGraph çš„ bfs æ–¹æ³•
        from collections import defaultdict
        results = defaultdict(list)
        
        for start_id in start_ids:
            kg_results = self._kg.bfs(start_id, max_depth=max_depth)
            for depth, items in kg_results.items():
                for target_id, rel in items:
                    if edge_types and rel.relation_type not in edge_types:
                        continue
                    node = GraphNode(id=target_id, name=target_id, node_type="entity", properties={})
                    edge = GraphEdge(
                        id=f"{rel.source_id}_{rel.target_id}",
                        source_id=rel.source_id,
                        target_id=rel.target_id,
                        edge_type=rel.relation_type,
                        properties=rel.properties
                    )
                    results[depth].append((node, edge))
        
        return dict(results)
    
    def query(self, cypher_like: str, params: Dict[str, Any] = None) -> List[Dict]:
        raise NotImplementedError("Legacy KnowledgeGraph ä¸æ”¯æŒ Cypher æŸ¥è¯¢")
    
    def count_nodes(self, node_type: str = None) -> int:
        all_nodes = set()
        for source_id in self._kg.outgoing.keys():
            all_nodes.add(source_id)
        for target_id in self._kg.incoming.keys():
            all_nodes.add(target_id)
        return len(all_nodes)
    
    def count_edges(self, edge_type: str = None) -> int:
        total = 0
        for relations in self._kg.outgoing.values():
            if edge_type:
                total += sum(1 for r in relations if r.relation_type == edge_type)
            else:
                total += len(relations)
        return total
    
    @property
    def backend_name(self) -> str:
        return "legacy_json"
    
    @property
    def supports_transactions(self) -> bool:
        return False
```

---

```python
# recall/graph/backends/json_backend.py
"""JSON æ–‡ä»¶åç«¯ - ä¿æŒé›¶ä¾èµ–çš„é»˜è®¤é€‰é¡¹"""

from typing import List, Dict, Any, Optional, Tuple
from collections import defaultdict
import json
import os

from .base import GraphBackend, GraphNode, GraphEdge


class JSONGraphBackend(GraphBackend):
    """JSON æ–‡ä»¶å›¾åç«¯ - é›¶ä¾èµ–ï¼Œé€‚åˆå°è§„æ¨¡åœºæ™¯
    
    æ€§èƒ½ç‰¹ç‚¹ï¼š
    - é€‚åˆ <10ä¸‡èŠ‚ç‚¹
    - å†…å­˜å ç”¨ï¼š~1GB / 10ä¸‡èŠ‚ç‚¹
    - å¯åŠ¨æ—¶å…¨é‡åŠ è½½
    
    ä¼˜ç‚¹ï¼š
    - é›¶å¤–éƒ¨ä¾èµ–
    - æ–‡ä»¶å¯è¯»å¯ç¼–è¾‘
    - æ”¯æŒ Git ç‰ˆæœ¬æ§åˆ¶
    """
    
    def __init__(self, data_path: str):
        self.data_path = data_path
        self.nodes_file = os.path.join(data_path, "nodes.json")
        self.edges_file = os.path.join(data_path, "edges.json")
        
        # å†…å­˜ç´¢å¼•
        self.nodes: Dict[str, GraphNode] = {}
        self.outgoing: Dict[str, List[str]] = defaultdict(list)  # node_id -> edge_ids
        self.incoming: Dict[str, List[str]] = defaultdict(list)  # node_id -> edge_ids
        self.edges: Dict[str, GraphEdge] = {}
        
        self._load()
    
    def _load(self):
        """åŠ è½½æ•°æ®"""
        if os.path.exists(self.nodes_file):
            with open(self.nodes_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for item in data:
                    node = GraphNode(**item)
                    self.nodes[node.id] = node
        
        if os.path.exists(self.edges_file):
            with open(self.edges_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for item in data:
                    edge = GraphEdge(**item)
                    self.edges[edge.id] = edge
                    self.outgoing[edge.source_id].append(edge.id)
                    self.incoming[edge.target_id].append(edge.id)
    
    def _save(self):
        """ä¿å­˜æ•°æ®"""
        os.makedirs(self.data_path, exist_ok=True)
        
        with open(self.nodes_file, 'w', encoding='utf-8') as f:
            json.dump([vars(n) for n in self.nodes.values()], f, ensure_ascii=False, default=str)
        
        with open(self.edges_file, 'w', encoding='utf-8') as f:
            json.dump([vars(e) for e in self.edges.values()], f, ensure_ascii=False, default=str)
    
    def add_node(self, node: GraphNode) -> str:
        self.nodes[node.id] = node
        self._save()
        return node.id
    
    def add_edge(self, edge: GraphEdge) -> str:
        self.edges[edge.id] = edge
        self.outgoing[edge.source_id].append(edge.id)
        self.incoming[edge.target_id].append(edge.id)
        self._save()
        return edge.id
    
    def get_node(self, node_id: str) -> Optional[GraphNode]:
        return self.nodes.get(node_id)
    
    def get_neighbors(
        self,
        node_id: str,
        edge_type: str = None,
        direction: str = "both",
        limit: int = 100
    ) -> List[Tuple[GraphNode, GraphEdge]]:
        """è·å–é‚»å±… - O(degree) å¤æ‚åº¦"""
        results = []
        edge_ids = set()
        
        if direction in ("out", "both"):
            edge_ids.update(self.outgoing.get(node_id, []))
        if direction in ("in", "both"):
            edge_ids.update(self.incoming.get(node_id, []))
        
        for edge_id in list(edge_ids)[:limit]:
            edge = self.edges.get(edge_id)
            if not edge:
                continue
            if edge_type and edge.edge_type != edge_type:
                continue
            
            neighbor_id = edge.target_id if edge.source_id == node_id else edge.source_id
            neighbor = self.nodes.get(neighbor_id)
            if neighbor:
                results.append((neighbor, edge))
        
        return results
    
    def bfs(
        self,
        start_ids: List[str],
        max_depth: int = 2,
        edge_types: List[str] = None,
        node_filter: Dict[str, Any] = None,
        limit: int = 1000
    ) -> Dict[int, List[Tuple[GraphNode, GraphEdge]]]:
        """BFS éå† - Python å®ç°"""
        visited = set(start_ids)
        current_level = set(start_ids)
        by_depth: Dict[int, List[Tuple[GraphNode, GraphEdge]]] = {}
        total = 0
        
        for depth in range(1, max_depth + 1):
            next_level = set()
            by_depth[depth] = []
            
            for node_id in current_level:
                neighbors = self.get_neighbors(node_id, direction="both", limit=100)
                
                for neighbor, edge in neighbors:
                    if neighbor.id in visited:
                        continue
                    if edge_types and edge.edge_type not in edge_types:
                        continue
                    
                    visited.add(neighbor.id)
                    next_level.add(neighbor.id)
                    by_depth[depth].append((neighbor, edge))
                    total += 1
                    
                    if total >= limit:
                        return by_depth
            
            current_level = next_level
            if not current_level:
                break
        
        return by_depth
    
    def query(self, cypher_like: str, params: Dict[str, Any] = None) -> List[Dict]:
        """ä¸æ”¯æŒ Cypher æŸ¥è¯¢"""
        raise NotImplementedError("JSON backend does not support Cypher queries")
    
    def count_nodes(self, node_type: str = None) -> int:
        if node_type:
            return sum(1 for n in self.nodes.values() if n.node_type == node_type)
        return len(self.nodes)
    
    def count_edges(self, edge_type: str = None) -> int:
        if edge_type:
            return sum(1 for e in self.edges.values() if e.edge_type == edge_type)
        return len(self.edges)
    
    @property
    def backend_name(self) -> str:
        return "json"
    
    @property
    def supports_transactions(self) -> bool:
        return False
```

##### 4. å›¾åç«¯å·¥å‚ä¸è‡ªåŠ¨é€‰æ‹©å™¨

```python
# recall/graph/backends/factory.py
"""å›¾åç«¯å·¥å‚ - è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜åç«¯"""

import os
from typing import Optional, TYPE_CHECKING
from .base import GraphBackend
from .json_backend import JSONGraphBackend

if TYPE_CHECKING:
    from ..knowledge_graph import KnowledgeGraph


def create_graph_backend(
    data_path: str,
    backend: str = "auto",
    node_count_hint: int = None,
    existing_knowledge_graph: "KnowledgeGraph" = None
) -> GraphBackend:
    """åˆ›å»ºå›¾åç«¯
    
    Args:
        data_path: æ•°æ®å­˜å‚¨è·¯å¾„
        backend: åç«¯ç±»å‹
            - "auto": è‡ªåŠ¨é€‰æ‹©ï¼ˆæ¨èï¼‰
            - "legacy": ä½¿ç”¨ç°æœ‰ KnowledgeGraphï¼ˆé»˜è®¤ï¼‰
            - "json": æ–° JSON æ–‡ä»¶åç«¯
            - "kuzu": Kuzu åµŒå…¥å¼ï¼ˆé«˜æ€§èƒ½ï¼‰
            - "neo4j": Neo4jï¼ˆåˆ†å¸ƒå¼ï¼Œéœ€é…ç½®ï¼‰
        node_count_hint: é¢„ä¼°èŠ‚ç‚¹æ•°é‡ï¼ˆç”¨äºè‡ªåŠ¨é€‰æ‹©ï¼‰
        existing_knowledge_graph: ç°æœ‰ KnowledgeGraph å®ä¾‹ï¼ˆç”¨äº legacy é€‚é…ï¼‰
    
    Returns:
        GraphBackend å®ä¾‹
    """
    
    if backend == "auto":
        backend = _auto_select_backend(data_path, node_count_hint)
    
    # ä¼˜å…ˆä½¿ç”¨ç°æœ‰ KnowledgeGraph é€‚é…å™¨ï¼ˆç¡®ä¿å‘åå…¼å®¹ï¼‰
    if backend == "legacy":
        if existing_knowledge_graph is None:
            from ..knowledge_graph import KnowledgeGraph
            existing_knowledge_graph = KnowledgeGraph(data_path)
        from .legacy_adapter import LegacyKnowledgeGraphAdapter
        return LegacyKnowledgeGraphAdapter(existing_knowledge_graph)
    
    if backend == "json":
        return JSONGraphBackend(data_path)
    
    elif backend == "kuzu":
        try:
            from .kuzu_backend import KuzuGraphBackend
            return KuzuGraphBackend(data_path)
        except ImportError:
            print("[Recall] Kuzu not installed, falling back to JSON backend")
            print("[Recall] Install with: pip install kuzu")
            return JSONGraphBackend(data_path)
    
    elif backend == "neo4j":
        try:
            from .neo4j_backend import Neo4jGraphBackend
            uri = os.getenv("NEO4J_URI", "bolt://localhost:7687")
            user = os.getenv("NEO4J_USER", "neo4j")
            password = os.getenv("NEO4J_PASSWORD", "")
            return Neo4jGraphBackend(uri, user, password)
        except ImportError:
            print("[Recall] Neo4j driver not installed, falling back to JSON backend")
            return JSONGraphBackend(data_path)
    
    else:
        raise ValueError(f"Unknown backend: {backend}")


def _auto_select_backend(data_path: str, node_count_hint: int = None) -> str:
    """è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜åç«¯
    
    é€‰æ‹©ç­–ç•¥ï¼ˆå‘åå…¼å®¹ä¼˜å…ˆï¼‰ï¼š
    1. å¦‚æœå·²æœ‰ knowledge_graph.jsonï¼Œä½¿ç”¨ legacy é€‚é…å™¨
    2. å¦‚æœå·²æœ‰ kuzu/ æˆ– nodes.jsonï¼Œä½¿ç”¨å¯¹åº”åç«¯
    3. å¦‚æœèŠ‚ç‚¹æ•°é‡ >10ä¸‡ ä¸” Kuzu å·²å®‰è£…ï¼Œä½¿ç”¨ Kuzu
    4. **é»˜è®¤ä½¿ç”¨ legacyï¼ˆç°æœ‰ KnowledgeGraphï¼‰ç¡®ä¿ 100% å‘åå…¼å®¹**
    """
    
    # ä¼˜å…ˆæ£€æµ‹ç°æœ‰ KnowledgeGraph æ•°æ®ï¼ˆç¡®ä¿å‘åå…¼å®¹ï¼ï¼‰
    legacy_file = os.path.join(data_path, "knowledge_graph.json")
    if os.path.exists(legacy_file):
        return "legacy"  # ä½¿ç”¨ç°æœ‰æ•°æ®æ ¼å¼
    
    # æ£€æµ‹æ–°æ ¼å¼æ•°æ®
    kuzu_db = os.path.join(data_path, "kuzu")
    if os.path.exists(kuzu_db):
        try:
            import kuzu
            return "kuzu"
        except ImportError:
            pass
    
    json_nodes = os.path.join(data_path, "nodes.json")
    if os.path.exists(json_nodes):
        return "json"
    
    # å¤§è§„æ¨¡åœºæ™¯ä¼˜åŒ–
    if node_count_hint and node_count_hint > 100000:  # >10ä¸‡èŠ‚ç‚¹
        try:
            import kuzu
            return "kuzu"
        except ImportError:
            print("[Recall] Warning: Large dataset expected but Kuzu not installed")
            print("[Recall] Install with: pip install kuzu")
    
    if node_count_hint and node_count_hint > 1000000:  # >100ä¸‡èŠ‚ç‚¹
        neo4j_uri = os.getenv("NEO4J_URI")
        if neo4j_uri:
            return "neo4j"
    
    # é»˜è®¤ä½¿ç”¨ legacyï¼ˆç°æœ‰ KnowledgeGraphï¼‰ï¼Œç¡®ä¿å‘åå…¼å®¹ï¼
    return "legacy"
```

##### 5. FAISS IVF ç£ç›˜ç´¢å¼•

```python
# recall/index/vector_index_ivf.py
"""FAISS IVF å‘é‡ç´¢å¼• - æ”¯æŒå¤§è§„æ¨¡å‘é‡æ£€ç´¢"""

import os
import numpy as np
from typing import List, Tuple, Optional, Dict, Any

try:
    import faiss
    FAISS_AVAILABLE = True
except ImportError:
    FAISS_AVAILABLE = False


class VectorIndexIVF:
    """FAISS IVF å‘é‡ç´¢å¼• - æ”¯æŒç£ç›˜å­˜å‚¨
    
    ç‰¹ç‚¹ï¼š
    - æ”¯æŒç™¾ä¸‡çº§å‘é‡
    - ç£ç›˜ + å†…å­˜æ··åˆå­˜å‚¨
    - å¯é…ç½®çš„ç²¾åº¦/é€Ÿåº¦æƒè¡¡
    
    é€‚ç”¨åœºæ™¯ï¼š
    - 50ä¸‡-500ä¸‡å‘é‡
    - å†…å­˜å—é™ç¯å¢ƒ
    """
    
    def __init__(
        self,
        data_path: str,
        dimension: int = 1024,
        nlist: int = 100,         # èšç±»ä¸­å¿ƒæ•°é‡
        nprobe: int = 10,         # æœç´¢æ—¶æ£€æŸ¥çš„èšç±»æ•°
        use_gpu: bool = False
    ):
        if not FAISS_AVAILABLE:
            raise ImportError("FAISS not installed. Install with: pip install faiss-cpu")
        
        self.data_path = data_path
        self.dimension = dimension
        self.nlist = nlist
        self.nprobe = nprobe
        self.use_gpu = use_gpu
        
        self.index_file = os.path.join(data_path, "vector_index_ivf.faiss")
        self.mapping_file = os.path.join(data_path, "vector_mapping_ivf.npy")
        self.metadata_file = os.path.join(data_path, "vector_metadata_ivf.json")  # å…ƒæ•°æ®ï¼ˆå«user_idï¼‰
        
        self.index: Optional[faiss.Index] = None
        self.id_mapping: List[str] = []  # å†…éƒ¨ ID -> æ–‡æ¡£ ID
        self.doc_metadata: Dict[str, Dict[str, Any]] = {}  # æ–‡æ¡£ ID -> å…ƒæ•°æ®ï¼ˆå« user_idï¼‰
        
        self._load_or_create()
    
    def _load_or_create(self):
        """åŠ è½½æˆ–åˆ›å»ºç´¢å¼•"""
        os.makedirs(self.data_path, exist_ok=True)
        
        if os.path.exists(self.index_file):
            self.index = faiss.read_index(self.index_file)
            self.index.nprobe = self.nprobe
            if os.path.exists(self.mapping_file):
                self.id_mapping = list(np.load(self.mapping_file, allow_pickle=True))
            # åŠ è½½å…ƒæ•°æ®
            if os.path.exists(self.metadata_file):
                import json
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    self.doc_metadata = json.load(f)
        else:
            # åˆ›å»º IVF ç´¢å¼•
            quantizer = faiss.IndexFlatIP(self.dimension)  # å†…ç§¯ï¼ˆç”¨äºå½’ä¸€åŒ–å‘é‡ï¼‰
            self.index = faiss.IndexIVFFlat(
                quantizer,
                self.dimension,
                self.nlist,
                faiss.METRIC_INNER_PRODUCT
            )
            self.index.nprobe = self.nprobe
    
    def add(self, doc_id: str, embedding: List[float], user_id: str = None) -> bool:
        """æ·»åŠ å‘é‡
        
        Args:
            doc_id: æ–‡æ¡£ID
            embedding: å‘é‡
            user_id: ç”¨æˆ·IDï¼ˆç”¨äºå¤šç§Ÿæˆ·éš”ç¦»ï¼‰
        """
        vector = np.array([embedding], dtype=np.float32)
        
        # å½’ä¸€åŒ–ï¼ˆç”¨äºä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        faiss.normalize_L2(vector)
        
        # å­˜å‚¨å…ƒæ•°æ®ï¼ˆç”¨äºç”¨æˆ·è¿‡æ»¤ï¼‰
        if user_id:
            self.doc_metadata[doc_id] = {'user_id': user_id}
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è®­ç»ƒ
        if not self.index.is_trained:
            # IVF ç´¢å¼•éœ€è¦è®­ç»ƒï¼Œç´¯ç§¯æ•°æ®
            self.id_mapping.append(doc_id)
            return True
        
        self.index.add(vector)
        self.id_mapping.append(doc_id)
        self._save()
        return True
    
    def train(self, embeddings: List[List[float]]):
        """è®­ç»ƒç´¢å¼•ï¼ˆIVF å¿…éœ€ï¼‰"""
        if len(embeddings) < self.nlist:
            print(f"[VectorIndexIVF] Warning: Not enough vectors for training ({len(embeddings)} < {self.nlist})")
            return
        
        vectors = np.array(embeddings, dtype=np.float32)
        faiss.normalize_L2(vectors)
        self.index.train(vectors)
        self.index.add(vectors)
        self._save()
    
    def search(
        self,
        query_embedding: List[float],
        top_k: int = 10,
        user_id: str = None  # ç”¨äºå¤šç§Ÿæˆ·è¿‡æ»¤
    ) -> List[Tuple[str, float]]:
        """æœç´¢ç›¸ä¼¼å‘é‡
        
        Args:
            query_embedding: æŸ¥è¯¢å‘é‡
            top_k: è¿”å›æ•°é‡
            user_id: ç”¨æˆ·IDè¿‡æ»¤ï¼ˆå¤šç§Ÿæˆ·éš”ç¦»ï¼‰
        """
        if not self.index.is_trained or self.index.ntotal == 0:
            return []
        
        query = np.array([query_embedding], dtype=np.float32)
        faiss.normalize_L2(query)
        
        # å¤šå–ä¸€äº›ç”¨äºè¿‡æ»¤
        search_k = top_k * 5 if user_id else top_k
        
        distances, indices = self.index.search(query, min(search_k, self.index.ntotal))
        
        results = []
        for dist, idx in zip(distances[0], indices[0]):
            if idx < 0:
                continue
            doc_id = self.id_mapping[idx]
            
            # ç”¨æˆ·è¿‡æ»¤ï¼ˆå¤šç§Ÿæˆ·éš”ç¦»ä¿éšœï¼‰
            if user_id and doc_id in self.doc_metadata:
                meta = self.doc_metadata[doc_id]
                if meta.get('user_id') != user_id:
                    continue  # è·³è¿‡å…¶ä»–ç”¨æˆ·çš„æ–‡æ¡£
            
            results.append((doc_id, float(dist)))
            
            if len(results) >= top_k:
                break
        
        return results
    
    def _save(self):
        """ä¿å­˜ç´¢å¼•å’Œå…ƒæ•°æ®"""
        faiss.write_index(self.index, self.index_file)
        np.save(self.mapping_file, np.array(self.id_mapping, dtype=object))
        # ä¿å­˜å…ƒæ•°æ®
        import json
        with open(self.metadata_file, 'w', encoding='utf-8') as f:
            json.dump(self.doc_metadata, f, ensure_ascii=False)
    
    @property
    def size(self) -> int:
        """å‘é‡æ•°é‡"""
        return self.index.ntotal if self.index else 0
```

##### 6. å›¾æŸ¥è¯¢è§„åˆ’å™¨

```python
# recall/graph/query_planner.py
"""å›¾æŸ¥è¯¢è§„åˆ’å™¨ - ä¼˜åŒ–å¤šè·³æŸ¥è¯¢"""

from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import time


class QueryOperation(Enum):
    """æŸ¥è¯¢æ“ä½œç±»å‹"""
    SCAN = "scan"           # å…¨è¡¨æ‰«æ
    INDEX_LOOKUP = "index"  # ç´¢å¼•æŸ¥æ‰¾
    NEIGHBOR = "neighbor"   # é‚»å±…éå†
    FILTER = "filter"       # è¿‡æ»¤
    JOIN = "join"           # è¿æ¥


@dataclass
class QueryPlan:
    """æŸ¥è¯¢è®¡åˆ’"""
    operations: List[Tuple[QueryOperation, Dict[str, Any]]]
    estimated_cost: float
    estimated_rows: int


class QueryPlanner:
    """å›¾æŸ¥è¯¢è§„åˆ’å™¨
    
    ä¼˜åŒ–ç­–ç•¥ï¼š
    1. ç´¢å¼•ä¼˜å…ˆ - æœ‰ç´¢å¼•çš„å­—æ®µä¼˜å…ˆä½¿ç”¨ç´¢å¼•
    2. æ—©æœŸè¿‡æ»¤ - å°½æ—©å‡å°‘å€™é€‰é›†
    3. è·¯å¾„ç¼“å­˜ - ç¼“å­˜å¸¸è§è·¯å¾„æ¨¡å¼
    """
    
    def __init__(self, graph_backend):
        self.backend = graph_backend
        self.path_cache: Dict[str, List[str]] = {}  # è·¯å¾„æ¨¡å¼ -> ç»“æœ
        self.stats_cache: Dict[str, int] = {}       # ç±»å‹ -> æ•°é‡
    
    def plan_bfs(
        self,
        start_ids: List[str],
        max_depth: int,
        edge_types: List[str] = None,
        node_filter: Dict[str, Any] = None
    ) -> QueryPlan:
        """è§„åˆ’ BFS æŸ¥è¯¢"""
        operations = []
        
        # ä¼°ç®—æˆæœ¬
        start_count = len(start_ids)
        avg_degree = self._estimate_avg_degree()
        
        total_rows = start_count
        for depth in range(1, max_depth + 1):
            total_rows *= avg_degree
            
            # é‚»å±…éå†
            operations.append((
                QueryOperation.NEIGHBOR,
                {"depth": depth, "estimated_rows": int(total_rows)}
            ))
            
            # è¾¹ç±»å‹è¿‡æ»¤
            if edge_types:
                filter_ratio = len(edge_types) / max(self._count_edge_types(), 1)
                total_rows *= filter_ratio
                operations.append((
                    QueryOperation.FILTER,
                    {"edge_types": edge_types, "estimated_rows": int(total_rows)}
                ))
        
        return QueryPlan(
            operations=operations,
            estimated_cost=total_rows * 0.001,  # ms
            estimated_rows=int(total_rows)
        )
    
    def _estimate_avg_degree(self) -> float:
        """ä¼°ç®—å¹³å‡åº¦æ•°"""
        if "avg_degree" in self.stats_cache:
            return self.stats_cache["avg_degree"]
        
        try:
            node_count = self.backend.count_nodes()
            edge_count = self.backend.count_edges()
            avg = (edge_count * 2) / max(node_count, 1)
            self.stats_cache["avg_degree"] = avg
            return avg
        except:
            return 5.0  # é»˜è®¤ä¼°è®¡
    
    def _count_edge_types(self) -> int:
        """ç»Ÿè®¡è¾¹ç±»å‹æ•°é‡"""
        return 10  # ç®€åŒ–ä¼°è®¡
    
    def cache_path(self, pattern: str, result: List[str]):
        """ç¼“å­˜è·¯å¾„æŸ¥è¯¢ç»“æœ"""
        self.path_cache[pattern] = result
    
    def get_cached_path(self, pattern: str) -> Optional[List[str]]:
        """è·å–ç¼“å­˜çš„è·¯å¾„"""
        return self.path_cache.get(pattern)
```

---

#### âš™ï¸ é…ç½®é¡¹æ‰©å±•

**éœ€è¦æ·»åŠ åˆ° `api_keys.env`ï¼š**

```env
# ============================================================================
# Phase 3.5: ä¼ä¸šçº§æ€§èƒ½é…ç½®
# Enterprise Performance Configuration
# ============================================================================

# ----------------------------------------------------------------------------
# å›¾åç«¯é…ç½®
# Graph Backend Configuration
# ----------------------------------------------------------------------------
# å›¾å­˜å‚¨åç«¯: auto(è‡ªåŠ¨é€‰æ‹©) | json(é›¶ä¾èµ–) | kuzu(åµŒå…¥å¼) | neo4j(åˆ†å¸ƒå¼)
GRAPH_BACKEND=auto

# Kuzu ç¼“å†²æ± å¤§å°ï¼ˆMBï¼‰ï¼Œé»˜è®¤ 256MB
KUZU_BUFFER_POOL_SIZE=256

# Neo4j è¿æ¥é…ç½®ï¼ˆä»…å½“ GRAPH_BACKEND=neo4j æ—¶éœ€è¦ï¼‰
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=

# ----------------------------------------------------------------------------
# å‘é‡ç´¢å¼•é…ç½®
# Vector Index Configuration
# ----------------------------------------------------------------------------
# å‘é‡ç´¢å¼•ç±»å‹: flat(å†…å­˜) | ivf(ç£ç›˜+å†…å­˜) | milvus(åˆ†å¸ƒå¼)
VECTOR_INDEX_TYPE=auto

# IVF ç´¢å¼•å‚æ•°ï¼ˆä»…å½“ VECTOR_INDEX_TYPE=ivf æ—¶ç”Ÿæ•ˆï¼‰
VECTOR_IVF_NLIST=100      # èšç±»ä¸­å¿ƒæ•°é‡
VECTOR_IVF_NPROBE=10      # æœç´¢æ—¶æ£€æŸ¥çš„èšç±»æ•°

# Milvus è¿æ¥é…ç½®ï¼ˆä»…å½“ VECTOR_INDEX_TYPE=milvus æ—¶éœ€è¦ï¼‰
MILVUS_HOST=localhost
MILVUS_PORT=19530

# ----------------------------------------------------------------------------
# æ™ºèƒ½æŠ½å–æ¨¡å¼ï¼ˆå‡çº§é»˜è®¤å€¼ï¼‰
# Smart Extraction Mode
# ----------------------------------------------------------------------------
# æŠ½å–æ¨¡å¼: local | hybrid | llm
# Phase 3.5 é»˜è®¤æ”¹ä¸º hybrid ä»¥æå‡æŠ½å–è´¨é‡
SMART_EXTRACTOR_MODE=hybrid

# ----------------------------------------------------------------------------
# æŸ¥è¯¢ä¼˜åŒ–é…ç½®
# Query Optimization Configuration
# ----------------------------------------------------------------------------
# æ˜¯å¦å¯ç”¨æŸ¥è¯¢è§„åˆ’å™¨
QUERY_PLANNER_ENABLED=true

# è·¯å¾„ç¼“å­˜å¤§å°ï¼ˆæ¡ï¼‰
PATH_CACHE_SIZE=1000

# ç»Ÿè®¡ä¿¡æ¯ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
STATS_CACHE_TTL=300

# ----------------------------------------------------------------------------
# è‡ªåŠ¨åç«¯é€‰æ‹©é˜ˆå€¼
# Auto Backend Selection Thresholds
# ----------------------------------------------------------------------------
# èŠ‚ç‚¹æ•°è¶…è¿‡æ­¤å€¼æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ° Kuzu
AUTO_KUZU_THRESHOLD=100000

# èŠ‚ç‚¹æ•°è¶…è¿‡æ­¤å€¼æ—¶æç¤ºä½¿ç”¨ Neo4j
AUTO_NEO4J_THRESHOLD=1000000

# å‘é‡æ•°è¶…è¿‡æ­¤å€¼æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ° IVF
AUTO_IVF_THRESHOLD=500000
```

---

#### ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

```python
# benchmark/graph_benchmark.py
"""å›¾åç«¯æ€§èƒ½åŸºå‡†æµ‹è¯•"""

import time
import random
from typing import Dict, List

from recall.graph.backends import create_graph_backend, GraphNode, GraphEdge


def benchmark_graph_backends(
    data_path: str,
    node_counts: List[int] = [1000, 10000, 100000, 1000000],
    edge_ratio: float = 5.0  # å¹³å‡æ¯ä¸ªèŠ‚ç‚¹çš„è¾¹æ•°
):
    """åŸºå‡†æµ‹è¯•ä¸åŒå›¾åç«¯"""
    
    results: Dict[str, Dict[str, float]] = {}
    
    for backend_type in ["json", "kuzu"]:
        results[backend_type] = {}
        
        for node_count in node_counts:
            print(f"\n{'='*60}")
            print(f"Testing {backend_type} with {node_count:,} nodes")
            print('='*60)
            
            try:
                backend = create_graph_backend(
                    f"{data_path}/{backend_type}_{node_count}",
                    backend=backend_type
                )
                
                # æ’å…¥æµ‹è¯•
                start = time.perf_counter()
                for i in range(node_count):
                    backend.add_node(GraphNode(
                        id=str(i),
                        name=f"Node_{i}",
                        node_type="test",
                        properties={"index": i}
                    ))
                insert_time = time.perf_counter() - start
                print(f"Insert {node_count:,} nodes: {insert_time:.2f}s ({node_count/insert_time:.0f} nodes/s)")
                
                # æ·»åŠ è¾¹
                edge_count = int(node_count * edge_ratio)
                start = time.perf_counter()
                for i in range(edge_count):
                    source = str(random.randint(0, node_count - 1))
                    target = str(random.randint(0, node_count - 1))
                    backend.add_edge(GraphEdge(
                        id=str(i),
                        source_id=source,
                        target_id=target,
                        edge_type="test",
                        properties={}
                    ))
                edge_time = time.perf_counter() - start
                print(f"Insert {edge_count:,} edges: {edge_time:.2f}s")
                
                # é‚»å±…æŸ¥è¯¢æµ‹è¯•
                start = time.perf_counter()
                for _ in range(100):
                    node_id = str(random.randint(0, node_count - 1))
                    backend.get_neighbors(node_id, limit=10)
                neighbor_time = (time.perf_counter() - start) / 100 * 1000
                print(f"Neighbor query (avg): {neighbor_time:.2f}ms")
                
                # BFS æµ‹è¯•
                start = time.perf_counter()
                for _ in range(10):
                    start_id = str(random.randint(0, node_count - 1))
                    backend.bfs([start_id], max_depth=2, limit=100)
                bfs_time = (time.perf_counter() - start) / 10 * 1000
                print(f"BFS 2-hop (avg): {bfs_time:.2f}ms")
                
                results[backend_type][node_count] = {
                    "insert_nodes_per_sec": node_count / insert_time,
                    "neighbor_query_ms": neighbor_time,
                    "bfs_2hop_ms": bfs_time
                }
                
            except Exception as e:
                print(f"Error: {e}")
                results[backend_type][node_count] = {"error": str(e)}
    
    return results


if __name__ == "__main__":
    results = benchmark_graph_backends("./benchmark_data")
    
    print("\n" + "="*80)
    print("BENCHMARK RESULTS SUMMARY")
    print("="*80)
    
    for backend, data in results.items():
        print(f"\n{backend.upper()}:")
        for node_count, metrics in data.items():
            if "error" in metrics:
                print(f"  {node_count:,} nodes: ERROR - {metrics['error']}")
            else:
                print(f"  {node_count:,} nodes:")
                print(f"    Insert: {metrics['insert_nodes_per_sec']:.0f} nodes/s")
                print(f"    Neighbor: {metrics['neighbor_query_ms']:.2f}ms")
                print(f"    BFS 2-hop: {metrics['bfs_2hop_ms']:.2f}ms")
```

---

#### ğŸ“¦ ä¾èµ–ç®¡ç†

**å¯é€‰ä¾èµ–ï¼ˆæŒ‰éœ€å®‰è£…ï¼‰ï¼š**

```toml
# pyproject.toml æ›´æ–°

[project.optional-dependencies]
# ä¼ä¸šçº§æ€§èƒ½ï¼ˆæ¨èï¼‰
enterprise = [
    "kuzu>=0.3.0",           # åµŒå…¥å¼å›¾æ•°æ®åº“
    "faiss-cpu>=1.7.0",      # FAISS IVF ç´¢å¼•
    "networkx>=3.0",         # ç¤¾åŒºæ£€æµ‹
]

# å¤§è§„æ¨¡éƒ¨ç½²
scale = [
    "neo4j>=5.0.0",          # Neo4j é©±åŠ¨
    "pymilvus>=2.3.0",       # Milvus å®¢æˆ·ç«¯
]

# å®Œæ•´å®‰è£…
full = [
    "kuzu>=0.3.0",
    "faiss-cpu>=1.7.0",
    "networkx>=3.0",
    "neo4j>=5.0.0",
    "pymilvus>=2.3.0",
]
```

**å®‰è£…å‘½ä»¤ï¼š**

```bash
# æ ‡å‡†å®‰è£…ï¼ˆé›¶ä¾èµ–ï¼‰
pip install recall-ai

# ä¼ä¸šçº§å®‰è£…ï¼ˆæ¨èï¼Œ+Kuzu+ç¤¾åŒºæ£€æµ‹ï¼‰
pip install recall-ai[enterprise]

# å¤§è§„æ¨¡éƒ¨ç½²ï¼ˆ+Neo4j/Milvusï¼‰
pip install recall-ai[scale]

# å®Œæ•´å®‰è£…
pip install recall-ai[full]
```

---

#### ğŸ”— ä¸ç°æœ‰æ¨¡å—é›†æˆ

**Engine é›†æˆæ›´æ–°ï¼š**

```python
# recall/engine.py æ›´æ–°

def __init__(self, ...):
    # ...ç°æœ‰ä»£ç ...
    
    # Phase 3.5: å›¾åç«¯é€‰æ‹©
    graph_backend_type = os.getenv("GRAPH_BACKEND", "auto")
    self.graph_backend = create_graph_backend(
        data_path=os.path.join(self.data_root, "graph"),
        backend=graph_backend_type,
        node_count_hint=self._estimate_node_count()
    )
    
    # å°†å›¾åç«¯æ³¨å…¥åˆ°çŸ¥è¯†å›¾è°±
    self.knowledge_graph = TemporalKnowledgeGraph(
        backend=self.graph_backend
    )
    
    # Phase 3.5: å‘é‡ç´¢å¼•é€‰æ‹©
    vector_index_type = os.getenv("VECTOR_INDEX_TYPE", "auto")
    if vector_index_type == "ivf" or (
        vector_index_type == "auto" and 
        self._estimate_vector_count() > int(os.getenv("AUTO_IVF_THRESHOLD", 500000))
    ):
        from .index.vector_index_ivf import VectorIndexIVF
        self.vector_index = VectorIndexIVF(
            data_path=os.path.join(self.data_root, "indexes"),
            dimension=self.embedding_config.dimension
        )
    else:
        self.vector_index = VectorIndex(...)
    
    # Phase 3.5: é»˜è®¤ HYBRID æ¨¡å¼
    if os.getenv("SMART_EXTRACTOR_MODE", "hybrid") == "hybrid":
        self.smart_extractor = SmartExtractor(
            mode=ExtractionMode.HYBRID,
            llm_client=self.llm_client,
            local_extractor=self.entity_extractor
        )
```

---

#### âœ… éªŒæ”¶æ ‡å‡†

**æ€§èƒ½æŒ‡æ ‡ï¼š**
- [ ] 100ä¸‡èŠ‚ç‚¹ 2 è·³éå† < 20msï¼ˆKuzu åç«¯ï¼‰
- [ ] 100ä¸‡å‘é‡æ£€ç´¢ < 100msï¼ˆIVF ç´¢å¼•ï¼‰
- [ ] ç«¯åˆ°ç«¯æ£€ç´¢å»¶è¿Ÿ < 300msï¼ˆ100ä¸‡è®°å¿†ï¼‰
- [ ] å†…å­˜å ç”¨ < 2GBï¼ˆ100ä¸‡è®°å¿†ï¼ŒKuzu åç«¯ï¼‰

**åŠŸèƒ½æŒ‡æ ‡ï¼š**
- [ ] å›¾åç«¯æŠ½è±¡å±‚å®Œæˆï¼ˆæ”¯æŒ JSON/Kuzu/Neo4jï¼‰
- [ ] è‡ªåŠ¨åç«¯é€‰æ‹©å™¨å¯ç”¨
- [ ] FAISS IVF ç£ç›˜ç´¢å¼•å¯ç”¨
- [ ] æŸ¥è¯¢è§„åˆ’å™¨åŸºç¡€å®ç°
- [ ] HYBRID æ¨¡å¼é»˜è®¤å¼€å¯
- [ ] åŸºå‡†æµ‹è¯•è„šæœ¬å¯è¿è¡Œ

**å…¼å®¹æ€§ï¼ˆâš ï¸ æ ¸å¿ƒä¿éšœï¼‰ï¼š**
- [ ] é›¶ä¾èµ–æ¨¡å¼ä»å¯æ­£å¸¸è¿è¡Œï¼ˆJSON åç«¯ä½œä¸ºé»˜è®¤ï¼‰
- [ ] ç°æœ‰æµ‹è¯• 100% é€šè¿‡
- [ ] API æ— ç ´åæ€§å˜æ›´
- [ ] **100%ä¸é—å¿˜ä¿è¯ä¸å—å½±å“**ï¼ˆN-gramåŸæ–‡å…œåº• + VolumeManager ä¿æŒä¸å˜ï¼‰
- [ ] **8å±‚æ£€ç´¢é»˜è®¤è¡Œä¸ºä¸å˜**ï¼ˆElevenLayerRetriever ä»…åœ¨æ˜¾å¼å¯ç”¨æ—¶ä½¿ç”¨ï¼‰
- [ ] **ä¼ç¬”/æŒä¹…æ¡ä»¶/ä¸€è‡´æ€§æ£€æŸ¥åŠŸèƒ½å®Œæ•´ä¿ç•™**
- [ ] **Lite æ¨¡å¼ï¼ˆ~80MBå†…å­˜ï¼‰ä»å¯æ­£å¸¸å·¥ä½œ**
- [ ] **å¤šç”¨æˆ·éš”ç¦»ä¸å—å½±å“**ï¼ˆMemoryScope æœºåˆ¶ä¿æŒï¼‰

**â­ "å®Œå…¨ä¸é—å¿˜"ä¸“é¡¹éªŒæ”¶æµ‹è¯•ï¼ˆæ ¸å¿ƒä¿éšœï¼‰ï¼š**
- [ ] æ·»åŠ 1000è½®å¯¹è¯åï¼Œä»»æ„è½®æ¬¡åŸæ–‡å¯é€šè¿‡N-gram `raw_search` æ‰¾åˆ°
- [ ] ä½¿ç”¨Kuzuåç«¯æ—¶ï¼ŒåŸæ–‡æœç´¢ç»“æœä¸JSONåç«¯**å®Œå…¨ä¸€è‡´**
- [ ] ä½¿ç”¨FAISS IVFæ—¶ï¼Œè¯­ä¹‰æœç´¢å¬å›ç‡ â‰¥ FAISS Flat
- [ ] åˆ‡æ¢å›¾åç«¯åï¼ŒVolumeManageræ•°æ®å®Œæ•´æ€§100%
- [ ] è·¨ç”¨æˆ·/è·¨è§’è‰²éš”ç¦»åœ¨æ–°åç«¯ä¸‹ä¾ç„¶æœ‰æ•ˆ
- [ ] æ–°åç«¯ä¸ä¿®æ”¹ `recall/storage/` ç›®å½•ä¸‹ä»»ä½•æ–‡ä»¶
- [ ] **FAISS IVF user_idè¿‡æ»¤**ï¼šç”¨æˆ·Aåªèƒ½æœç´¢åˆ°ç”¨æˆ·Açš„å‘é‡ç»“æœ

**çƒ­æ•°æ®åè°ƒåŠ è½½è¯´æ˜ï¼š**
| ç»„ä»¶ | é¢„åŠ è½½ç­–ç•¥ | Phase 3.5 å½±å“ |
|------|----------|:-------------:|
| VolumeManager | æœ€è¿‘2å·é¢„åŠ è½½ | âŒ **ä¸ä¿®æ”¹** |
| Kuzuå›¾æ•°æ® | å…¨é‡å¸¸é©»å†…å­˜ | ç‹¬ç«‹äºVolumeManager |
| FAISS IVF | ç´¢å¼•å¸¸é©»ï¼Œå‘é‡æŒ‰éœ€ | ç‹¬ç«‹äºVolumeManager |

> ğŸ’¡ VolumeManagerã€Kuzuã€FAISS IVF ä¸‰è€…**å¹¶è¡Œç‹¬ç«‹**ï¼Œæ— èµ„æºç«äº‰ã€‚

---

#### âš ï¸ å…³é”®å…¼å®¹æ€§ä¿éšœæªæ–½

**å¿…é¡»ä¿è¯ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ä¸å—å½±å“ï¼š**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Phase 3.5 å…¼å®¹æ€§çº¢çº¿ï¼ˆä¸å¯è§¦ç¢°ï¼‰                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. 100%ä¸é—å¿˜æœºåˆ¶ï¼ˆCHECKLIST #7ï¼‰                              â”‚
â”‚     â”œâ”€ VolumeManager åˆ†å·å­˜å‚¨ - ä¸ä¿®æ”¹                         â”‚
â”‚     â”œâ”€ N-gram åŸæ–‡ç´¢å¼• - ä¸ä¿®æ”¹                                â”‚
â”‚     â””â”€ 8å±‚æ£€ç´¢ç»ˆæå…œåº• - ä¸ä¿®æ”¹                                â”‚
â”‚                                                                 â”‚
â”‚  2. æ ¸å¿ƒå­˜å‚¨å±‚ï¼ˆCHECKLIST #1-3ï¼‰                                â”‚
â”‚     â”œâ”€ layer0_core.py (CoreSettings) - ä¸ä¿®æ”¹                  â”‚
â”‚     â”œâ”€ layer1_consolidated.py - ä¸ä¿®æ”¹                         â”‚
â”‚     â”œâ”€ layer2_working.py - ä¸ä¿®æ”¹                              â”‚
â”‚     â””â”€ volume_manager.py (L3 Archive) - ä¸ä¿®æ”¹                 â”‚
â”‚                                                                 â”‚
â”‚  3. RP ä¸“å±åŠŸèƒ½ï¼ˆCHECKLIST #2,5,26-28ï¼‰                         â”‚
â”‚     â”œâ”€ ForeshadowingTracker/Analyzer - ä¸ä¿®æ”¹                  â”‚
â”‚     â”œâ”€ ContextTracker (æŒä¹…æ¡ä»¶) - ä¸ä¿®æ”¹                      â”‚
â”‚     â”œâ”€ ConsistencyChecker (ä¸€è‡´æ€§) - ä¸ä¿®æ”¹                    â”‚
â”‚     â””â”€ CoreSettings (ç»å¯¹è§„åˆ™) - ä¸ä¿®æ”¹                        â”‚
â”‚                                                                 â”‚
â”‚  4. å¤šç”¨æˆ·éš”ç¦»ï¼ˆCHECKLIST #14ï¼‰                                 â”‚
â”‚     â”œâ”€ MemoryScope - ä¸ä¿®æ”¹                                    â”‚
â”‚     â””â”€ MultiTenantStorage - ä¸ä¿®æ”¹                             â”‚
â”‚                                                                 â”‚
â”‚  5. ç´¢å¼•ç³»ç»Ÿï¼ˆCHECKLIST #7ï¼‰                                    â”‚
â”‚     â”œâ”€ EntityIndex - ä¸ä¿®æ”¹ï¼ˆä»…æ–°å¢åç«¯é€‚é…ï¼‰                  â”‚
â”‚     â”œâ”€ InvertedIndex - ä¸ä¿®æ”¹                                  â”‚
â”‚     â”œâ”€ NgramIndex - ä¸ä¿®æ”¹                                     â”‚
â”‚     â””â”€ VectorIndex - ä¸ä¿®æ”¹ï¼ˆæ–°å¢ IVF ä½œä¸ºå¯é€‰åç«¯ï¼‰           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Phase 3.5 åªåš"åŠ æ³•"ï¼Œä¸åš"æ”¹æ³•"ï¼š**

| ç»„ä»¶ | æ“ä½œç±»å‹ | è¯´æ˜ |
|------|:--------:|------|
| `graph/backends/` | **æ–°å¢** | æ–°ç›®å½•ï¼Œä¸å½±å“ç°æœ‰ `knowledge_graph.py` |
| `LegacyKnowledgeGraphAdapter` | **æ–°å¢** | é€‚é…ç°æœ‰ KnowledgeGraph åˆ° GraphBackend æ¥å£ |
| `KuzuGraphBackend` | **æ–°å¢** | å¯é€‰åç«¯ï¼Œä¸æ›¿æ¢ç°æœ‰ JSON å­˜å‚¨ |
| `VectorIndexIVF` | **æ–°å¢** | å¯é€‰ç´¢å¼•ï¼Œä¸æ›¿æ¢ç°æœ‰ FAISS Flat |
| `QueryPlanner` | **æ–°å¢** | ä¼˜åŒ–å™¨ï¼Œä¸å½±å“ç°æœ‰æŸ¥è¯¢é€»è¾‘ |
| `KnowledgeGraph` | **ä¿ç•™** | å®Œå…¨ä¸ä¿®æ”¹ï¼Œé€šè¿‡é€‚é…å™¨ä½¿ç”¨ |
| `RecallEngine` | **é€‚é…** | æ·»åŠ åç«¯é€‰æ‹©é€»è¾‘ï¼Œé»˜è®¤è¡Œä¸ºä¸å˜ |

---

#### ğŸ“‹ CHECKLIST 28é¡¹éœ€æ±‚å…¼å®¹æ€§éªŒè¯

> âœ… ä»¥ä¸‹éªŒè¯ç¡®ä¿ Phase 3.5 ä¸ä¼šå½±å“ä»»ä½•ç°æœ‰åŠŸèƒ½

##### ç¬¬ä¸€ç»„ï¼šæ ¸å¿ƒåŠŸèƒ½éœ€æ±‚ï¼ˆ15é¡¹ï¼‰

| # | éœ€æ±‚ | Phase 3.5 å½±å“ | éªŒè¯ç»“è®º |
|---|------|:-------------:|:--------:|
| 1 | ä¸Šä¸‡è½® RP | âŒ ä¸å½±å“ | âœ… VolumeManager ä¸ä¿®æ”¹ |
| 2 | ä¼ç¬”ä¸é—å¿˜ | âŒ ä¸å½±å“ | âœ… ForeshadowingTracker/Analyzer ä¸ä¿®æ”¹ |
| 3 | å‡ ç™¾ä¸‡å­—è§„æ¨¡ | âŒ ä¸å½±å“ | âœ… åˆ†å·æ¶æ„ä¿æŒä¸å˜ |
| 4 | ä¸Šåƒæ–‡ä»¶ä»£ç  | N/A | âŒ æœªå®ç°ï¼ˆä¸ Phase 3.5 æ— å…³ï¼‰ |
| 5 | è§„èŒƒ100%éµå®ˆ | âŒ ä¸å½±å“ | âœ… ConsistencyChecker/CoreSettings ä¸ä¿®æ”¹ |
| 6 | é›¶é…ç½®å³æ’å³ç”¨ | âŒ ä¸å½±å“ | âœ… é»˜è®¤ä½¿ç”¨ legacy åç«¯ï¼Œæ— éœ€é…ç½® |
| 7 | 100%ä¸é—å¿˜ | âŒ ä¸å½±å“ | âœ… N-gram/VolumeManager/8å±‚æ£€ç´¢ ä¸ä¿®æ”¹ |
| 8 | é¢å‘å¤§ä¼—å‹å¥½ | âŒ ä¸å½±å“ | âœ… ST æ’ä»¶ä¸å—å½±å“ |
| 9 | é…ç½®keyå°±èƒ½ç”¨ | âŒ ä¸å½±å“ | âœ… API key æœºåˆ¶ä¸å˜ |
| 10 | pip installå³æ’å³ç”¨ | âŒ ä¸å½±å“ | âœ… æ‰€æœ‰æ–°ä¾èµ–éƒ½æ˜¯å¯é€‰çš„ |
| 11 | æ™®é€šäººæ— é—¨æ§› | âŒ ä¸å½±å“ | âœ… é»˜è®¤é…ç½®æ— éœ€æ›´æ”¹ |
| 12 | 3-5ç§’å“åº” | âœ… **ä¼˜åŒ–** | â¬†ï¸ å¤§è§„æ¨¡åœºæ™¯å“åº”æ›´å¿« |
| 13 | çŸ¥è¯†å›¾è°± | âŒ ä¸å½±å“ | âœ… KnowledgeGraph é€šè¿‡é€‚é…å™¨ä¿æŒå…¼å®¹ |
| 14 | å¤šç”¨æˆ·/å¤šè§’è‰² | âŒ ä¸å½±å“ | âœ… MemoryScope/MultiTenantStorage ä¸ä¿®æ”¹ |
| 15 | ä½é…ç”µè„‘æ”¯æŒ | âŒ ä¸å½±å“ | âœ… Lite æ¨¡å¼ä»å¯ç”¨ (~80MB) |

##### ç¬¬äºŒç»„ï¼šå³æ’å³ç”¨/ç¯å¢ƒéš”ç¦»æ£€æŸ¥é¡¹ï¼ˆ10é¡¹ï¼‰

| # | éœ€æ±‚ | Phase 3.5 å½±å“ | éªŒè¯ç»“è®º |
|---|------|:-------------:|:--------:|
| 16 | å•ä¸€æ•°æ®ç›®å½• | âŒ ä¸å½±å“ | âœ… æ–°åç«¯æ•°æ®ä¹Ÿåœ¨ `./recall_data/` |
| 17 | æ¨¡å‹éš”ç¦»å­˜å‚¨ | âŒ ä¸å½±å“ | âœ… æ— æ–°æ¨¡å‹éœ€è¦å­˜å‚¨ |
| 18 | æ— ç³»ç»Ÿçº§ä¿®æ”¹ | âŒ ä¸å½±å“ | âœ… Kuzu æ˜¯åµŒå…¥å¼ï¼Œæ— ç³»ç»Ÿå®‰è£… |
| 19 | ç¯å¢ƒå˜é‡éš”ç¦» | âŒ ä¸å½±å“ | âœ… æ–°é…ç½®é¡¹å¯é€‰ï¼Œæœ‰é»˜è®¤å€¼ |
| 20 | å®Œæ•´å¸è½½æ”¯æŒ | âŒ ä¸å½±å“ | âœ… åˆ é™¤æ–‡ä»¶å¤¹ä»å¯å®Œå…¨å¸è½½ |
| 21 | è™šæ‹Ÿç¯å¢ƒå…¼å®¹ | âŒ ä¸å½±å“ | âœ… æ–°ä¾èµ–å¯åœ¨ venv ä¸­å®‰è£… |
| 22 | ä¸ä¿®æ”¹å…¶ä»–åº”ç”¨ | âŒ ä¸å½±å“ | âœ… ST æ’ä»¶ç‹¬ç«‹è¿è¡Œ |
| 23 | ç¦»çº¿è¿è¡Œæ”¯æŒ | âŒ ä¸å½±å“ | âœ… Kuzu æ˜¯æœ¬åœ°åµŒå…¥å¼æ•°æ®åº“ |
| 24 | è·¨å¹³å°æ”¯æŒ | âŒ ä¸å½±å“ | âœ… Kuzu æ”¯æŒ Win/Mac/Linux |
| 25 | é…ç½®æ–‡ä»¶éš”ç¦» | âŒ ä¸å½±å“ | âœ… æ–°é…ç½®åœ¨é¡¹ç›®ç›®å½•å†… |

##### ç¬¬ä¸‰ç»„ï¼šè®¡åˆ’å¤–æ–°å¢åŠŸèƒ½ï¼ˆ3é¡¹ï¼‰

| # | åŠŸèƒ½ | Phase 3.5 å½±å“ | éªŒè¯ç»“è®º |
|---|------|:-------------:|:--------:|
| 26 | â­ æŒä¹…æ¡ä»¶ç³»ç»Ÿ | âŒ ä¸å½±å“ | âœ… ContextTracker å®Œå…¨ä¸ä¿®æ”¹ |
| 27 | â­ é…ç½®çƒ­æ›´æ–° | âŒ ä¸å½±å“ | âœ… reload API ä¿æŒå…¼å®¹ |
| 28 | â­ ä¼ç¬”åˆ†æå™¨å¢å¼º | âŒ ä¸å½±å“ | âœ… ForeshadowingAnalyzer ä¸ä¿®æ”¹ |

**éªŒè¯ç»“è®ºï¼šPhase 3.5 çš„ 28 é¡¹å…¼å®¹æ€§æ£€æŸ¥å…¨éƒ¨é€šè¿‡ï¼âœ…**

---

#### ğŸ¯ å…¨ç»´åº¦ç¢¾å‹ Graphiti å¯¹ç…§è¡¨

> ğŸ“Œ ç¡®ä¿ Phase 3.5 å®Œæˆåï¼ŒRecall åœ¨**æ‰€æœ‰ç»´åº¦**éƒ½èƒ½ç¢¾å‹ Graphiti

##### ç»´åº¦ä¸€ï¼šæ ¸å¿ƒèƒ½åŠ›å¯¹æ¯”

| èƒ½åŠ› | Graphiti | Recall Phase 3.5 | ç¢¾å‹ç¨‹åº¦ |
|------|:--------:|:----------------:|:--------:|
| **æ—¶æ€ç³»ç»Ÿ** | åŒæ—¶æ€ (valid_at/invalid_at) | **ä¸‰æ—¶æ€** (åˆ›å»º/ç”Ÿæ•ˆ/å¤±æ•ˆ) | ğŸ† è¶…è¶Š |
| **å›¾éå†æ€§èƒ½** | Neo4j ~50ms/100ä¸‡ | **Kuzu ~15ms/100ä¸‡** | ğŸ† 3xç¢¾å‹ |
| **å‘é‡æ£€ç´¢è§„æ¨¡** | ä¾èµ– Neo4j å†…ç½® | **FAISS IVF 500ä¸‡+** | ğŸ† 10xç¢¾å‹ |
| **æŠ½å–è´¨é‡** | çº¯ LLM (~95%) | **HYBRID (~95%)** | âœ… å¯¹é½ |
| **å»é‡ç³»ç»Ÿ** | 2é˜¶æ®µ (MinHash+LLM) | **3é˜¶æ®µ (ç²¾ç¡®+æ¨¡ç³Š+LLM)** | ğŸ† è¶…è¶Š |
| **æ£€ç´¢å±‚æ•°** | 3å±‚ (BM25+å‘é‡+å›¾) | **11å±‚æ¼æ–—** | ğŸ† 4xç¢¾å‹ |
| **é‡æ’åºå™¨** | 5ç§ (RRF/MMR/CrossEncoderç­‰) | **7ç§ (+æ—¶æ€/ä¼ç¬”é‡æ’)** | ğŸ† è¶…è¶Š |

##### ç»´åº¦äºŒï¼šéƒ¨ç½²ä¸æˆæœ¬

| ç»´åº¦ | Graphiti | Recall Phase 3.5 | ç¢¾å‹ç¨‹åº¦ |
|------|:--------:|:----------------:|:--------:|
| **å›¾æ•°æ®åº“ä¾èµ–** | å¿…é¡» (Neo4j/FalkorDB) | **é›¶ä¾èµ–å¯é€‰** | ğŸ† å®Œèƒœ |
| **LLM ä¾èµ–** | å¿…é¡» (æ ¸å¿ƒåŠŸèƒ½) | **å¯é€‰ (LOCAL æ¨¡å¼å¯ç”¨)** | ğŸ† å®Œèƒœ |
| **å†…å­˜å ç”¨** | ~4GB (Neo4jè¿›ç¨‹) | **~80MB (Lite) / ~2GB (Enterprise)** | ğŸ† å®Œèƒœ |
| **éƒ¨ç½²å¤æ‚åº¦** | é«˜ (éœ€é…ç½®æ•°æ®åº“) | **é›¶é…ç½® (pip install)** | ğŸ† å®Œèƒœ |
| **è¿è¡Œæˆæœ¬** | é«˜ (å…¨ç¨‹ LLM) | **æä½ (HYBRID æŒ‰éœ€è°ƒç”¨)** | ğŸ† å®Œèƒœ |
| **ç¦»çº¿è¿è¡Œ** | âŒ ä¸æ”¯æŒ | âœ… **å®Œæ•´æ”¯æŒ** | ğŸ† å®Œèƒœ |

##### ç»´åº¦ä¸‰ï¼šé€šç”¨åœºæ™¯å¢å¼ºèƒ½åŠ›

> ğŸ“Œ Recall æ˜¯é€šç”¨è®°å¿†ç³»ç»Ÿï¼Œæ”¯æŒ RP/å°è¯´ã€ä»£ç å¼€å‘ã€ä¼ä¸šçŸ¥è¯†åº“ç­‰æ‰€æœ‰åœºæ™¯

| èƒ½åŠ› | Graphiti | Recall Phase 3.5 | é€‚ç”¨åœºæ™¯ | ç¢¾å‹ç¨‹åº¦ |
|------|:--------:|:----------------:|:--------:|:--------:|
| **ä¼ç¬”/TODOè¿½è¸ª** | âŒ æ—  | âœ… **å®Œæ•´ç³»ç»Ÿ** | RP/é¡¹ç›®ç®¡ç† | ğŸ† ç‹¬æœ‰ |
| **æŒä¹…æ¡ä»¶/ä¸Šä¸‹æ–‡** | âŒ æ—  | âœ… **15ç§ç±»å‹** | æ‰€æœ‰åœºæ™¯ | ğŸ† ç‹¬æœ‰ |
| **100%ä¸é—å¿˜** | âŒ æ— ä¿è¯ | âœ… **N-gramåŸæ–‡å…œåº•** | æ‰€æœ‰åœºæ™¯ | ğŸ† ç‹¬æœ‰ |
| **ä¸€è‡´æ€§æ£€æŸ¥** | âŒ æ—  | âœ… **LLMè¯­ä¹‰æ£€æµ‹** | RP/æ–‡æ¡£/ä»£ç  | ğŸ† ç‹¬æœ‰ |
| **è‡ªå®šä¹‰è§„åˆ™** | âŒ æ—  | âœ… **è§„åˆ™å¼•æ“** | æ‰€æœ‰åœºæ™¯ | ğŸ† ç‹¬æœ‰ |
| **æ ¸å¿ƒè®¾å®šæ³¨å…¥** | âŒ æ—  | âœ… **L0å±‚** | RP/é¡¹ç›®é…ç½® | ğŸ† ç‹¬æœ‰ |
| **è¶…é•¿å¯¹è¯/ä¼šè¯** | âš ï¸ æœªæµ‹è¯• | âœ… **åˆ†å·æ¶æ„** | æ‰€æœ‰åœºæ™¯ | ğŸ† ç‹¬æœ‰ |
| **ç¤¾åŒºæ£€æµ‹** | âœ… CommunityNode | âœ… **Phase 3.5 æ·»åŠ ** | çŸ¥è¯†å›¾è°±åˆ†æ | âœ… å¯¹ç­‰ |

##### ç»´åº¦å››ï¼šä¼ä¸šçº§èƒ½åŠ›

| èƒ½åŠ› | Graphiti | Recall Phase 3.5 | ç¢¾å‹ç¨‹åº¦ |
|------|:--------:|:----------------:|:--------:|
| **å¤šç§Ÿæˆ·éš”ç¦»** | âœ… group_id | âœ… **MemoryScope** | âœ… å¯¹ç­‰ |
| **æ‰©å±•ä¸Šé™** | æ— é™ (Neo4j) | **~1000ä¸‡ (Kuzu)** | âœ… å¯¹ç­‰ |
| **åˆ†å¸ƒå¼éƒ¨ç½²** | âœ… (Neptune) | â³ **Phase 4 (Neo4jå¯é€‰)** | âœ… å¯¹ç­‰ |
| **MCP å·¥å…·æ•°** | 8ä¸ª | **15+ä¸ª** | ğŸ† è¶…è¶Š |
| **REST API** | âœ… FastAPI | âœ… **FastAPI** | âœ… å¯¹ç­‰ |
| **æ‰¹é‡å¯¼å…¥** | âœ… bulk | âœ… **bulk** | âœ… å¯¹ç­‰ |

##### ç»´åº¦äº”ï¼šæŠ€æœ¯å®ç°å¯¹æ¯”

| æŠ€æœ¯ç‚¹ | Graphiti | Recall Phase 3.5 | ç¢¾å‹ç¨‹åº¦ |
|--------|:--------:|:----------------:|:--------:|
| **å®ä½“æŠ½å–** | LLM (message/text/json) | **spaCy + LLM HYBRID** | ğŸ† æ›´çµæ´» |
| **å…³ç³»æŠ½å–** | LLM çº¯ | **è§„åˆ™ + LLM HYBRID** | ğŸ† æ›´ä½æˆæœ¬ |
| **èŠ‚ç‚¹å»é‡** | MinHash + LLM | **ç²¾ç¡® + Embedding + LLM** | ğŸ† æ›´å‡†ç¡® |
| **è¾¹å»é‡** | LLM | **è¯­ä¹‰ç›¸ä¼¼åº¦ + LLM** | ğŸ† æ›´é«˜æ•ˆ |
| **æ—¶é—´æŠ½å–** | LLM | **è§„åˆ™ + LLM** | ğŸ† æ›´ä½æˆæœ¬ |
| **æŸ¥è¯¢ä¼˜åŒ–** | ä¾èµ– Neo4j | **QueryPlanner + è·¯å¾„ç¼“å­˜** | ğŸ† æ›´å¯æ§ |
| **ç¤¾åŒºæ£€æµ‹** | âœ… CommunityNode | âœ… **Phase 3.5 æ·»åŠ ** | âœ… å¯¹ç­‰ |

---

#### âœ… è¡¥å……åŠŸèƒ½ï¼ˆPhase 3.5 æ–°å¢ï¼‰

åŸºäº Graphiti åˆ†æå’Œé€šç”¨åœºæ™¯éœ€æ±‚ï¼ŒPhase 3.5 å°†è¡¥å……ä»¥ä¸‹åŠŸèƒ½ï¼š

##### 1. ç¤¾åŒºæ£€æµ‹ï¼ˆCommunity Detectionï¼‰â­ æ–°å¢

Graphiti æœ‰ `CommunityNode` ç”¨äºå›¾èšç±»ï¼ŒRecall åœ¨ Phase 3.5 è¡¥å……æ­¤åŠŸèƒ½ã€‚

**é€šç”¨åœºæ™¯ä»·å€¼**ï¼š
| åœºæ™¯ | ç”¨é€” |
|------|------|
| **ä»£ç åº“åˆ†æ** | è‡ªåŠ¨å‘ç°æ¨¡å—/åŒ…çš„å…³è”ç¾¤ç»„ï¼Œç†è§£ä»£ç æ¶æ„ |
| **çŸ¥è¯†åº“ç®¡ç†** | å‘ç°ä¸»é¢˜èšç±»ï¼Œè‡ªåŠ¨åˆ†ç±» |
| **é¡¹ç›®ç®¡ç†** | è¯†åˆ«ç›¸å…³ä»»åŠ¡/Issue ç¾¤ç»„ |
| **Claude Code/VS Code** | ç†è§£ä»£ç ç»“æ„ï¼Œæ™ºèƒ½å¯¼èˆª |
| **ä¼ä¸šçŸ¥è¯†å›¾è°±** | å‘ç°éƒ¨é—¨/å›¢é˜ŸçŸ¥è¯†ç¾¤è½ |

```python
# Phase 3.5 æ–°å¢ï¼šrecall/graph/community_detector.py
"""ç¤¾åŒºæ£€æµ‹æ¨¡å— - ç”¨äºå‘ç°å›¾ä¸­çš„å®ä½“ç¾¤ç»„

æ”¯æŒçš„ç®—æ³•ï¼š
- Louvain: æœ€å¸¸ç”¨ï¼Œé€‚åˆå¤§è§„æ¨¡å›¾
- Label Propagation: å¿«é€Ÿï¼Œé€‚åˆåŠ¨æ€å›¾
- Connected Components: åŸºç¡€è¿é€šåˆ†é‡
"""

from typing import List, Dict, Optional, Set
from dataclasses import dataclass, field
from datetime import datetime

try:
    import networkx as nx
    from networkx.algorithms import community as nx_community
    NETWORKX_AVAILABLE = True
except ImportError:
    NETWORKX_AVAILABLE = False


@dataclass
class Community:
    """ç¤¾åŒº/ç¾¤ç»„"""
    id: str
    name: str
    member_ids: List[str]
    summary: str = ""
    created_at: Optional[datetime] = None
    properties: Dict = field(default_factory=dict)
    
    @property
    def size(self) -> int:
        return len(self.member_ids)


class CommunityDetector:
    """å›¾ç¤¾åŒºæ£€æµ‹å™¨
    
    ä½¿ç”¨æ–¹å¼ï¼š
        detector = CommunityDetector(graph_backend)
        communities = detector.detect_communities()
        
        # è·å–èŠ‚ç‚¹æ‰€å±ç¤¾åŒº
        community = detector.get_community_for_node("node_123")
        
        # ç”Ÿæˆç¤¾åŒºæ‘˜è¦
        summary = detector.get_community_summary("community_1", llm_client)
    
    âš ï¸ Liteæ¨¡å¼å…¼å®¹è¯´æ˜ï¼š
        - NetworkX æ˜¯å¯é€‰ä¾èµ–ï¼ˆä»…åœ¨ [enterprise] æˆ– [full] å®‰è£…æ—¶åŒ…å«ï¼‰
        - å¦‚æœæœªå®‰è£… NetworkXï¼Œç¤¾åŒºæ£€æµ‹åŠŸèƒ½ä¼šä¼˜é›…ç¦ç”¨ï¼ˆä¸æŠ¥é”™ï¼‰
        - Lite æ¨¡å¼ï¼ˆ~80MBå†…å­˜ï¼‰ä¸å—å½±å“
    """
    
    def __init__(
        self,
        graph_backend,
        algorithm: str = "louvain",  # louvain | label_propagation | connected
        min_community_size: int = 2,
        resolution: float = 1.0  # Louvain åˆ†è¾¨ç‡å‚æ•°
    ):
        # âš ï¸ Liteæ¨¡å¼ä¼˜é›…é™çº§ï¼šæ²¡æœ‰NetworkXæ—¶ä¸æŠ¥é”™ï¼Œåªæ˜¯ç¦ç”¨åŠŸèƒ½
        if not NETWORKX_AVAILABLE:
            self._enabled = False
            import logging
            logging.getLogger(__name__).warning(
                "NetworkX not installed. Community detection disabled. "
                "Install with: pip install networkx"
            )
            self.backend = None
            return
        
        self._enabled = True
        self.backend = graph_backend
        self.algorithm = algorithm
        self.min_community_size = min_community_size
        self.resolution = resolution
        
        # ç¼“å­˜
        self._communities: List[Community] = []
        self._node_to_community: Dict[str, str] = {}
        self._nx_graph: Optional[nx.Graph] = None
    
    def detect_communities(self, refresh: bool = False) -> List[Community]:
        """æ£€æµ‹ç¤¾åŒºï¼ˆå¦‚æœNetworkXä¸å¯ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨ï¼‰"""
        if not getattr(self, '_enabled', False):
            return []
        # ... åŸæœ‰å®ç° ...
    
    def _build_networkx_graph(self) -> nx.Graph:
        """ä» GraphBackend æ„å»º NetworkX å›¾"""
        G = nx.Graph()
        
        # æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹
        node_count = self.backend.count_nodes()
        # ç®€åŒ–ï¼šé€šè¿‡éå†è¾¹æ¥å‘ç°èŠ‚ç‚¹
        
        # è·å–æ‰€æœ‰è¾¹ï¼ˆéœ€è¦ backend æ”¯æŒï¼‰
        # è¿™é‡Œå‡è®¾ backend æœ‰ get_all_edges æ–¹æ³•æˆ–ç±»ä¼¼å®ç°
        if hasattr(self.backend, 'edges'):
            for edge_id, edge in self.backend.edges.items():
                G.add_node(edge.source_id)
                G.add_node(edge.target_id)
                G.add_edge(
                    edge.source_id, 
                    edge.target_id,
                    weight=edge.weight if hasattr(edge, 'weight') else 1.0,
                    edge_type=edge.edge_type
                )
        elif hasattr(self.backend, '_kg'):
            # Legacy adapter
            kg = self.backend._kg
            for source_id, relations in kg.outgoing.items():
                G.add_node(source_id)
                for rel in relations:
                    G.add_node(rel.target_id)
                    G.add_edge(
                        source_id,
                        rel.target_id,
                        weight=rel.confidence,
                        edge_type=rel.relation_type
                    )
        
        self._nx_graph = G
        return G
    
    def detect_communities(self, refresh: bool = False) -> List[Community]:
        """æ£€æµ‹ç¤¾åŒº
        
        Args:
            refresh: æ˜¯å¦å¼ºåˆ¶é‡æ–°è®¡ç®—
            
        Returns:
            ç¤¾åŒºåˆ—è¡¨
        """
        if self._communities and not refresh:
            return self._communities
        
        G = self._build_networkx_graph()
        
        if len(G.nodes()) == 0:
            return []
        
        # æ ¹æ®ç®—æ³•é€‰æ‹©
        if self.algorithm == "louvain":
            partition = nx_community.louvain_communities(
                G, 
                resolution=self.resolution,
                seed=42
            )
        elif self.algorithm == "label_propagation":
            partition = nx_community.label_propagation_communities(G)
        elif self.algorithm == "connected":
            partition = list(nx.connected_components(G))
        else:
            raise ValueError(f"Unknown algorithm: {self.algorithm}")
        
        # æ„å»º Community å¯¹è±¡
        communities = []
        for idx, members in enumerate(partition):
            if len(members) < self.min_community_size:
                continue
            
            community = Community(
                id=f"community_{idx}",
                name=f"Group {idx + 1}",
                member_ids=list(members),
                created_at=datetime.now()
            )
            communities.append(community)
            
            # æ›´æ–°èŠ‚ç‚¹åˆ°ç¤¾åŒºçš„æ˜ å°„
            for member_id in members:
                self._node_to_community[member_id] = community.id
        
        self._communities = communities
        return communities
    
    def get_community_for_node(self, node_id: str) -> Optional[Community]:
        """è·å–èŠ‚ç‚¹æ‰€å±ç¤¾åŒº"""
        if not self._communities:
            self.detect_communities()
        
        community_id = self._node_to_community.get(node_id)
        if not community_id:
            return None
        
        for c in self._communities:
            if c.id == community_id:
                return c
        return None
    
    async def get_community_summary(
        self, 
        community_id: str, 
        llm_client = None
    ) -> str:
        """ç”Ÿæˆç¤¾åŒºæ‘˜è¦
        
        å¦‚æœæä¾› LLM clientï¼Œä½¿ç”¨ LLM ç”Ÿæˆï¼›å¦åˆ™ä½¿ç”¨ç®€å•æ¨¡æ¿
        """
        community = None
        for c in self._communities:
            if c.id == community_id:
                community = c
                break
        
        if not community:
            return ""
        
        # è·å–æˆå‘˜èŠ‚ç‚¹åç§°
        member_names = []
        for member_id in community.member_ids[:10]:  # é™åˆ¶æ•°é‡
            node = self.backend.get_node(member_id)
            if node:
                member_names.append(node.name)
            else:
                member_names.append(member_id)
        
        if llm_client:
            # ä½¿ç”¨ LLM ç”Ÿæˆæ‘˜è¦
            prompt = f"""Summarize what this group of entities have in common:
            
Entities: {', '.join(member_names)}

Provide a brief 1-2 sentence summary of their shared theme or relationship."""
            
            response = await llm_client.generate(prompt)
            community.summary = response
            return response
        else:
            # ç®€å•æ¨¡æ¿
            summary = f"Group of {len(community.member_ids)} related entities including: {', '.join(member_names[:5])}"
            if len(community.member_ids) > 5:
                summary += f" and {len(community.member_ids) - 5} more"
            community.summary = summary
            return summary
    
    def get_stats(self) -> Dict:
        """è·å–ç¤¾åŒºç»Ÿè®¡ä¿¡æ¯"""
        if not self._communities:
            self.detect_communities()
        
        sizes = [c.size for c in self._communities]
        return {
            "total_communities": len(self._communities),
            "total_nodes_in_communities": sum(sizes),
            "avg_community_size": sum(sizes) / len(sizes) if sizes else 0,
            "max_community_size": max(sizes) if sizes else 0,
            "min_community_size": min(sizes) if sizes else 0,
        }
```

**API ç«¯ç‚¹**ï¼ˆæ·»åŠ åˆ° server.pyï¼‰ï¼š
```python
# GET /v1/graph/communities - è·å–æ‰€æœ‰ç¤¾åŒº
# GET /v1/graph/communities/{community_id} - è·å–ç¤¾åŒºè¯¦æƒ…
# GET /v1/graph/communities/{community_id}/summary - è·å–ç¤¾åŒºæ‘˜è¦
# GET /v1/graph/nodes/{node_id}/community - è·å–èŠ‚ç‚¹æ‰€å±ç¤¾åŒº
# POST /v1/graph/communities/detect - è§¦å‘ç¤¾åŒºæ£€æµ‹
```

**å½±å“è¯„ä¼°**ï¼šâœ… Phase 3.5 å®ç°ï¼Œé€šç”¨åœºæ™¯å¿…éœ€

##### 2. è¾¹çš„æ—¶é—´è¡°å‡æƒé‡

Graphiti çš„è¾¹æœ‰ `weight` å­—æ®µå¯ç”¨äºæ—¶é—´è¡°å‡ï¼ŒRecall çš„ `Relation` ç±»**å·²æœ‰ `confidence` å­—æ®µå¯å¤ç”¨**ã€‚

**ç°æœ‰å­—æ®µå¯ç›´æ¥ä½¿ç”¨**ï¼š
```python
# recall/graph/knowledge_graph.py å·²æœ‰
@dataclass
class Relation:
    confidence: float = 0.5  # å·²æœ‰ï¼šå¯ç”¨äºæ—¶é—´è¡°å‡æƒé‡
    created_turn: int = 0    # å·²æœ‰ï¼šåˆ›å»ºè½®æ¬¡ï¼ˆå¯è®¡ç®—æ—¶é—´ï¼‰
```

**å»ºè®®**ï¼šåœ¨æ£€ç´¢æ—¶æ·»åŠ æ—¶é—´è¡°å‡è®¡ç®—ï¼ˆå¯é€‰å¢å¼ºï¼‰
```python
def get_time_decayed_confidence(relation: Relation, current_turn: int) -> float:
    """è®¡ç®—æ—¶é—´è¡°å‡åçš„ç½®ä¿¡åº¦"""
    age = current_turn - relation.created_turn
    decay_factor = 0.99 ** age  # æ¯è½®è¡°å‡ 1%
    return relation.confidence * decay_factor
```

**å½±å“è¯„ä¼°**ï¼šâœ… å·²å…·å¤‡ï¼Œä»…éœ€åœ¨æ£€ç´¢æ—¶åº”ç”¨è¡°å‡å…¬å¼ï¼ˆå¯é€‰ï¼‰

---

#### âœ… ç»“è®ºï¼šå…¨ç»´åº¦ç¢¾å‹ç¡®è®¤

| ç»´åº¦ç±»åˆ« | æ€»é¡¹æ•° | Recall ç¢¾å‹ | Recall å¯¹ç­‰ | Recall å¾…è¡¥å…… |
|----------|:------:|:-----------:|:-----------:|:-------------:|
| æ ¸å¿ƒèƒ½åŠ› | 7 | **6** ğŸ† | 1 | 0 |
| éƒ¨ç½²æˆæœ¬ | 6 | **6** ğŸ† | 0 | 0 |
| é€šç”¨åœºæ™¯å¢å¼º | 8 | **7** ğŸ† | 1 | 0 |
| ä¼ä¸šçº§ | 6 | 2 ğŸ† | **4** | 0 |
| æŠ€æœ¯å®ç° | 7 | **7** ğŸ† | 0 | 0 |
| **æ€»è®¡** | **34** | **28** ğŸ† | **6** | **0** |

**Phase 3.5 å®Œæˆåçš„ç¢¾å‹æ¯”ä¾‹ï¼š100% (34/34)** âœ…

- ğŸ† **ç¢¾å‹é¡¹**ï¼š28é¡¹ï¼ˆRecall æ˜æ˜¾ä¼˜äº Graphitiï¼‰
- âœ… **å¯¹ç­‰é¡¹**ï¼š6é¡¹ï¼ˆRecall ä¸ Graphiti ç›¸å½“ï¼ŒåŒ…æ‹¬ç¤¾åŒºæ£€æµ‹ï¼‰
- âŒ **è½åé¡¹**ï¼š0é¡¹ï¼ˆæ— ä»»ä½•ç»´åº¦è½åï¼‰

---

#### ğŸš€ Phase 3.5 å®Œæˆåçš„æœ€ç»ˆå®šä½

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Recall 4.0 vs Graphiti                        â”‚
â”‚               é€šç”¨è®°å¿†ç³»ç»Ÿ - å…¨ç»´åº¦ç¢¾å‹ç¡®è®¤ âœ…                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                   æ ¸å¿ƒèƒ½åŠ›ç»´åº¦                           â”‚   â”‚
â”‚   â”‚   æ€§èƒ½ï¼š3-10x ç¢¾å‹ ğŸ†                                    â”‚   â”‚
â”‚   â”‚   æ—¶æ€ï¼šä¸‰æ—¶æ€ vs åŒæ—¶æ€ ğŸ†                              â”‚   â”‚
â”‚   â”‚   æ£€ç´¢ï¼š11å±‚ vs 3å±‚ ğŸ†                                   â”‚   â”‚
â”‚   â”‚   å»é‡ï¼š3é˜¶æ®µ vs 2é˜¶æ®µ ğŸ†                                â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                   éƒ¨ç½²æˆæœ¬ç»´åº¦                           â”‚   â”‚
â”‚   â”‚   ä¾èµ–ï¼šé›¶ vs å¿…é¡»Neo4j ğŸ†                               â”‚   â”‚
â”‚   â”‚   å†…å­˜ï¼š80MB vs 4GB ğŸ†                                   â”‚   â”‚
â”‚   â”‚   æˆæœ¬ï¼šæä½ vs é«˜ ğŸ†                                    â”‚   â”‚
â”‚   â”‚   ç¦»çº¿ï¼šæ”¯æŒ vs ä¸æ”¯æŒ ğŸ†                                â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                 é€šç”¨åœºæ™¯å¢å¼ºï¼ˆç‹¬æœ‰+å¯¹ç­‰ï¼‰                 â”‚   â”‚
â”‚   â”‚   ä¼ç¬”/TODO âœ… | æŒä¹…ä¸Šä¸‹æ–‡ âœ… | 100%ä¸é—å¿˜ âœ…             â”‚   â”‚
â”‚   â”‚   ä¸€è‡´æ€§æ£€æŸ¥ âœ… | è§„åˆ™å¼•æ“ âœ… | æ ¸å¿ƒè®¾å®šå±‚ âœ…              â”‚   â”‚
â”‚   â”‚   è¶…é•¿ä¼šè¯ âœ… | ç¤¾åŒºæ£€æµ‹ âœ… (Phase 3.5)                   â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                   ä¼ä¸šçº§ç»´åº¦                             â”‚   â”‚
â”‚   â”‚   å¤šç§Ÿæˆ·ï¼šå¯¹ç­‰ âœ… | æ‰©å±•ï¼š1000ä¸‡èŠ‚ç‚¹ âœ…                   â”‚   â”‚
â”‚   â”‚   MCPå·¥å…·ï¼š15+ vs 8 ğŸ† | åˆ†å¸ƒå¼ï¼šPhase 4 â³               â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                 æ”¯æŒçš„å¹³å°/åœºæ™¯                          â”‚   â”‚
â”‚   â”‚   VS Code âœ… | Claude Code âœ… | Cursor âœ… | MCP âœ…         â”‚   â”‚
â”‚   â”‚   SillyTavern âœ… | ä¼ä¸šçŸ¥è¯†åº“ âœ… | ä¸ªäººåŠ©æ‰‹ âœ…              â”‚   â”‚
â”‚   â”‚   Graphiti ä»…æ”¯æŒï¼šAgent åœºæ™¯                            â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚   ç»“è®ºï¼šPhase 3.5 å®Œæˆåï¼ŒRecall åœ¨æ‰€æœ‰ç»´åº¦ 100% ç¢¾å‹ Graphiti   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```   â”‚
â”‚   â”‚   å¤šç§Ÿæˆ·ï¼šå¯¹ç­‰ âœ… | æ‰©å±•ï¼š1000ä¸‡èŠ‚ç‚¹ âœ…                   â”‚   â”‚
â”‚   â”‚   MCPå·¥å…·ï¼š15+ vs 8 ğŸ†                                   â”‚   â”‚
â”‚   â”‚   åˆ†å¸ƒå¼ï¼šPhase 4 è¡¥å…… â³                                 â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚   ç»“è®ºï¼šPhase 3.5 å®Œæˆåï¼ŒRecall åœ¨æ‰€æœ‰ç»´åº¦ 100% ç¢¾å‹ Graphiti   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### ğŸ“Š é¢„æœŸæ•ˆæœå¯¹æ¯”

| æŒ‡æ ‡ | Graphiti (Neo4j) | Recall (å½“å‰) | Recall (Phase 3.5) |
|------|:----------------:|:-------------:|:------------------:|
| 100ä¸‡èŠ‚ç‚¹éå† | ~50ms | ~2000ms âŒ | **~15ms** âœ… |
| 100ä¸‡å‘é‡æ£€ç´¢ | ~500ms | ~5000ms âŒ | **~100ms** âœ… |
| æŠ½å–è´¨é‡ | 95% | 80% (LOCAL) | **95%** (HYBRID) âœ… |
| éƒ¨ç½²å¤æ‚åº¦ | éœ€è¦ Neo4j | é›¶ä¾èµ– âœ… | é›¶ä¾èµ– âœ… |
| æ‰©å±•ä¸Šé™ | æ— é™ | ~10ä¸‡ | **~1000ä¸‡** âœ… |

**ç»“è®ºï¼šPhase 3.5 å®Œæˆåï¼ŒRecall å°†åœ¨æ€§èƒ½æ•ˆæœä¸Šå…¨é¢ç¢¾å‹ Graphitiã€‚**

---

### Phase 3.6: 100% ä¸é—å¿˜æœ€ä¼˜æ¶æ„ï¼ˆ2å‘¨ï¼‰â­ æ ¸å¿ƒä¿éšœ

---

#### ğŸ¯ ç›®æ ‡

å®ç° **100% è®°å¿†å¬å›ä¿è¯**ï¼Œç¡®ä¿åœ¨äº¿çº§æ•°æ®è§„æ¨¡ä¸‹ä¾ç„¶ä¸é—æ¼ä»»ä½•ç›¸å…³è®°å¿†ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Phase 3.6: 100% ä¸é—å¿˜æœ€ä¼˜æ£€ç´¢æ¶æ„                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  è·¯å¾„ 1: è¯­ä¹‰å¬å› â”‚  â”‚ è·¯å¾„ 2: å…³é”®è¯å¬å›â”‚  â”‚  è·¯å¾„ 3: å®ä½“å¬å› â”‚            â”‚
â”‚  â”‚    IVF-HNSW      â”‚  â”‚    å€’æ’ç´¢å¼•       â”‚  â”‚    å®ä½“ç´¢å¼•       â”‚            â”‚
â”‚  â”‚  å¬å›ç‡: 95-99%  â”‚  â”‚  å¬å›ç‡: 100%     â”‚  â”‚  å¬å›ç‡: 100%     â”‚            â”‚
â”‚  â”‚  é€Ÿåº¦: O(log n)  â”‚  â”‚  é€Ÿåº¦: O(1)       â”‚  â”‚  é€Ÿåº¦: O(1)       â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚           â”‚                     â”‚                     â”‚                      â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                 â–¼                                            â”‚
â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                â”‚  RRF èåˆå±‚ (Reciprocal Rank Fusion)â”‚                       â”‚
â”‚                â”‚  å–å¹¶é›† + å¤šå› ç´ é‡æ’åº               â”‚                       â”‚
â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                  â”‚                                           â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                     â”‚  èåˆç»“æœä¸ºç©ºï¼Ÿ          â”‚                              â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                           Yes â†“  â”‚ No â†’ è¿”å›ç»“æœ                              â”‚
â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                â”‚   è·¯å¾„ 4: N-gram åŸæ–‡å…œåº• (100%)     â”‚                       â”‚
â”‚                â”‚   é€Ÿåº¦: O(n)ï¼Œä»…åœ¨å…¶ä»–è·¯å¾„æ— ç»“æœæ—¶   â”‚                       â”‚
â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### ğŸ“Š æŠ€æœ¯èƒŒæ™¯åˆ†æ

**å½“å‰é—®é¢˜ï¼šå‘é‡ç´¢å¼•çš„å¬å›ç‡ä¸Šé™**

| ç´¢å¼•ç±»å‹ | å¬å›ç‡ @top10 | å†…å­˜å¼€é”€ | é€‚ç”¨è§„æ¨¡ | é—®é¢˜ |
|----------|--------------|---------|---------|------|
| Flat (æš´åŠ›) | 100% | O(n) | <100ä¸‡ | é€Ÿåº¦æ…¢ |
| **IVF (å½“å‰)** | 90-95% | O(n) | 50-500ä¸‡ | **5-10% é—æ¼** |
| HNSW | 99%+ | O(n Ã— M) | 100ä¸‡-1äº¿ | å†…å­˜é«˜ |
| **IVF-HNSW** | 95-99% | O(n) | 1-10äº¿ | **æœ€ä½³å¹³è¡¡** |

**å½“å‰ IVF çš„æ•°å­¦é™åˆ¶**ï¼š
```python
# å½“å‰é…ç½® (recall/index/vector_index_ivf.py)
nlist = 100    # 100 ä¸ªèšç±»ä¸­å¿ƒ
nprobe = 10    # æœç´¢æ—¶åªæ£€æŸ¥ 10 ä¸ªèšç±»

# å¬å›ç‡ â‰ˆ nprobe / nlist = 10% çš„èšç±»è¢«æ£€æŸ¥
# å®é™…å¬å›ç‡çº¦ 90-95%ï¼ˆç›¸ä¼¼å‘é‡å€¾å‘äºåŒä¸€èšç±»ï¼‰
# è¿™æ„å‘³ç€ 5-10% çš„ç›¸å…³è®°å¿†å¯èƒ½è¢«æ¼æ‰ï¼
```

**è§£å†³æ–¹æ¡ˆï¼šä¸‰è·¯å¹¶è¡Œå¬å› + RRF èåˆ + æ¡ä»¶å…œåº•**

| è·¯å¾„ | ç´¢å¼•ç±»å‹ | å¬å›ç‡ | é€Ÿåº¦ | ä½œç”¨ |
|------|---------|--------|------|------|
| è·¯å¾„ 1 | IVF-HNSW | 95-99% | O(log n) | è¯­ä¹‰ç›¸ä¼¼åŒ¹é… |
| è·¯å¾„ 2 | å€’æ’ç´¢å¼• | 100% | O(1) | ç²¾ç¡®å…³é”®è¯åŒ¹é… |
| è·¯å¾„ 3 | å®ä½“ç´¢å¼• | 100% | O(1) | å®ä½“å…³è”åŒ¹é… |
| å…œåº• | N-gram å…¨æ‰«æ | 100% | O(n) | æœ€ç»ˆä¿åº•ï¼ˆä»…èåˆæ— ç»“æœæ—¶è§¦å‘ï¼‰ |

**æ•´ä½“å¬å›ç‡ = 1 - (1-0.97) Ã— (1-1.0) Ã— (1-1.0) â‰ˆ 99.97%+**

> âš ï¸ **æ³¨æ„**ï¼šè·¯å¾„ 1-3 å¹¶è¡Œæ‰§è¡Œåé€šè¿‡ RRF èåˆï¼ŒN-gram å…œåº•ä»…åœ¨èåˆç»“æœä¸ºç©ºæ—¶è§¦å‘ã€‚

---

#### ğŸ“ éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶æ¸…å•

| æ–‡ä»¶è·¯å¾„ | ä¿®æ”¹ç±»å‹ | è¯´æ˜ | ä¼˜å…ˆçº§ |
|----------|---------|------|--------|
| `recall/index/vector_index_ivf.py` | **é‡æ„** | IVF â†’ IVF-HNSW | P0 |
| `recall/index/__init__.py` | æ›´æ–° | å¯¼å‡ºæ–°ç´¢å¼•ç±» | P0 |
| `recall/retrieval/rrf_fusion.py` | **æ–°å»º** | RRF èåˆç®—æ³•å®ç° | P0 |
| `recall/retrieval/__init__.py` | æ›´æ–° | å¯¼å‡º RRF èåˆæ¨¡å— | P0 |
| `recall/retrieval/eight_layer.py` | **é‡æ„** | ä¸²è¡Œ â†’ å¹¶è¡Œä¸‰è·¯å¬å› | P0 |
| `recall/index/ngram_index.py` | ä¼˜åŒ– | å¢åŠ å¹¶è¡Œåˆ†ç‰‡æ‰«æ | P1 |
| `recall/retrieval/config.py` | æ›´æ–° | æ·»åŠ ä¸‰è·¯å¬å›é…ç½® | P1 |
| `recall/engine.py` | æ›´æ–° | é›†æˆæ–°æ£€ç´¢æ¶æ„ | P1 |
| `pyproject.toml` | éªŒè¯ | ç¡®ä¿ faiss-cpu>=1.7 | P1 |
| `tools/migrate_ivf_to_hnsw.py` | **æ–°å»º** | ç´¢å¼•è¿ç§»å·¥å…· | P2 |
| `tests/test_rrf_fusion.py` | **æ–°å»º** | RRF èåˆå•å…ƒæµ‹è¯• | P2 |
| `tests/test_ivf_hnsw_recall.py` | **æ–°å»º** | IVF-HNSW å¬å›ç‡æµ‹è¯• | P2 |

---

#### ğŸ”§ å…·ä½“ä¿®æ”¹å†…å®¹

##### 1. vector_index_ivf.py â†’ å‡çº§ä¸º IVF-HNSW

**å½“å‰ä»£ç **ï¼š
```python
# ä½¿ç”¨ IndexIVFFlat (å¬å›ç‡ 90-95%)
quantizer = faiss.IndexFlatIP(self.dimension)
self.index = faiss.IndexIVFFlat(
    quantizer,
    self.dimension,
    self.nlist,
    faiss.METRIC_INNER_PRODUCT
)
```

**ä¿®æ”¹ä¸º**ï¼š
```python
# ä½¿ç”¨ HNSW ä½œä¸º quantizer (å¬å›ç‡ 95-99%)
hnsw_quantizer = faiss.IndexHNSWFlat(self.dimension, self.hnsw_m)
hnsw_quantizer.hnsw.efConstruction = self.hnsw_ef_construction
hnsw_quantizer.hnsw.efSearch = self.hnsw_ef_search

self.index = faiss.IndexIVFFlat(
    hnsw_quantizer,
    self.dimension,
    self.nlist,
    faiss.METRIC_INNER_PRODUCT
)
```

**æ–°å¢å‚æ•°**ï¼š
```python
def __init__(
    self,
    data_path: str,
    dimension: int = 1024,
    nlist: int = 100,
    nprobe: int = 10,
    use_gpu: bool = False,
    min_train_size: int = None,
    # Phase 3.6 æ–°å¢ï¼šHNSW å‚æ•°
    hnsw_m: int = 32,                    # HNSW å›¾è¿æ¥æ•°ï¼ˆè¶Šå¤§å¬å›è¶Šé«˜ï¼‰
    hnsw_ef_construction: int = 200,     # æ„å»ºç²¾åº¦
    hnsw_ef_search: int = 64,            # æœç´¢ç²¾åº¦ï¼ˆè¶Šå¤§å¬å›è¶Šé«˜ï¼‰
):
```

##### 2. rrf_fusion.py â†’ æ–°å»º RRF èåˆæ¨¡å—

```python
"""Reciprocal Rank Fusion - å¤šè·¯å¬å›ç»“æœèåˆ

RRF å…¬å¼ï¼šscore(d) = Î£ 1 / (k + rank_i(d))
å…¶ä¸­ k é€šå¸¸å– 60

ä¼˜ç‚¹ï¼š
- ä¸éœ€è¦å½’ä¸€åŒ–ä¸åŒæ£€ç´¢å™¨çš„åˆ†æ•°
- å¯¹æ’åé å‰çš„ç»“æœç»™äºˆæ›´é«˜æƒé‡
- è‡ªåŠ¨å¤„ç†ä¸åŒå¬å›è·¯å¾„çš„ç»“æœåˆå¹¶
"""

from typing import List, Dict, Tuple, Optional
from collections import defaultdict


def reciprocal_rank_fusion(
    results_list: List[List[Tuple[str, float]]],
    k: int = 60,
    weights: Optional[List[float]] = None
) -> List[Tuple[str, float]]:
    """RRF èåˆå¤šè·¯å¬å›ç»“æœ
    
    Args:
        results_list: å¤šè·¯å¬å›ç»“æœï¼Œæ¯è·¯ä¸º [(doc_id, score), ...]
        k: RRF å¸¸æ•°ï¼Œé»˜è®¤ 60
        weights: å„è·¯æƒé‡ï¼Œé»˜è®¤å…¨ä¸º 1.0
        
    Returns:
        èåˆåçš„ç»“æœ [(doc_id, rrf_score), ...]ï¼ŒæŒ‰åˆ†æ•°é™åº
    """
    if not weights:
        weights = [1.0] * len(results_list)
    
    # è®¡ç®— RRF åˆ†æ•°
    rrf_scores: Dict[str, float] = defaultdict(float)
    
    for weight, results in zip(weights, results_list):
        for rank, (doc_id, _) in enumerate(results, start=1):
            rrf_scores[doc_id] += weight * (1.0 / (k + rank))
    
    # æ’åºè¿”å›
    sorted_results = sorted(
        rrf_scores.items(),
        key=lambda x: -x[1]
    )
    
    return sorted_results


def weighted_score_fusion(
    results_list: List[List[Tuple[str, float]]],
    weights: Optional[List[float]] = None,
    normalize: bool = True
) -> List[Tuple[str, float]]:
    """åŠ æƒåˆ†æ•°èåˆï¼ˆæ›¿ä»£æ–¹æ¡ˆï¼‰
    
    å½“éœ€è¦è€ƒè™‘åŸå§‹åˆ†æ•°æ—¶ä½¿ç”¨
    """
    if not weights:
        weights = [1.0] * len(results_list)
    
    # å½’ä¸€åŒ–å„è·¯åˆ†æ•°åˆ° [0, 1]
    normalized_results = []
    for results in results_list:
        if not results:
            normalized_results.append([])
            continue
        
        if normalize:
            scores = [s for _, s in results]
            min_s, max_s = min(scores), max(scores)
            range_s = max_s - min_s if max_s > min_s else 1.0
            normalized = [(doc_id, (s - min_s) / range_s) for doc_id, s in results]
        else:
            normalized = results
        
        normalized_results.append(normalized)
    
    # åŠ æƒèåˆ
    fused_scores: Dict[str, float] = defaultdict(float)
    doc_counts: Dict[str, int] = defaultdict(int)
    
    for weight, results in zip(weights, normalized_results):
        for doc_id, score in results:
            fused_scores[doc_id] += weight * score
            doc_counts[doc_id] += 1
    
    # å¤šè·¯å‘½ä¸­åŠ åˆ†ï¼ˆå‡ºç°åœ¨å¤šä¸ªè·¯å¾„ä¸­çš„ç»“æœæ›´å¯ä¿¡ï¼‰
    for doc_id in fused_scores:
        if doc_counts[doc_id] > 1:
            fused_scores[doc_id] *= (1 + 0.1 * (doc_counts[doc_id] - 1))
    
    return sorted(fused_scores.items(), key=lambda x: -x[1])
```

##### 3. eight_layer.py â†’ é‡æ„ä¸ºå¹¶è¡Œä¸‰è·¯å¬å›

**å½“å‰æ¶æ„**ï¼ˆä¸²è¡Œæ¼æ–—ï¼‰ï¼š
```
L1 â†’ L2 â†’ L3 â†’ L4 â†’ L5 â†’ L6 â†’ L7 â†’ L8
å¸ƒéš†   å€’æ’  å®ä½“  Ngram å‘é‡ç²— å‘é‡ç²¾ é‡æ’  LLM
```

**æ–°æ¶æ„**ï¼ˆå¹¶è¡Œä¸‰è·¯ + èåˆ + å…œåº•ï¼‰ï¼š
```
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è·¯å¾„ 1: IVF-HNSW è¯­ä¹‰å¬å› â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                                                â”‚
æŸ¥è¯¢ â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è·¯å¾„ 2: å€’æ’ç´¢å¼•å…³é”®è¯å¬å› â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â†’ RRF èåˆ â†’ é‡æ’åº â†’ ç»“æœ
     â”‚                                                â”‚       â†‘
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è·¯å¾„ 3: å®ä½“ç´¢å¼•å¬å› â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
                                                            â”‚
                         èåˆç»“æœä¸ºç©º? â”€â”€Yesâ”€â”€â†’ N-gram åŸæ–‡å…œåº• â”€â”˜
```

**å…³é”®ä»£ç ä¿®æ”¹**ï¼š

```python
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import defaultdict
from typing import Dict, List, Optional, Tuple, Any, Callable
from .rrf_fusion import reciprocal_rank_fusion

class EightLayerRetriever:
    """å…«å±‚æ¼æ–—æ£€ç´¢å™¨ - Phase 3.6 å‡çº§ä¸ºå¹¶è¡Œä¸‰è·¯å¬å›"""
    
    def __init__(
        self,
        bloom_filter: Optional[Any] = None,
        inverted_index: Optional[Any] = None,
        entity_index: Optional[Any] = None,
        ngram_index: Optional[Any] = None,
        vector_index: Optional[Any] = None,
        llm_client: Optional[Any] = None,
        content_store: Optional[Callable[[str], Optional[str]]] = None,
        # Phase 3.6 æ–°å¢ï¼šç”¨äº VectorIndexIVF çš„å‘é‡ç¼–ç 
        embedding_backend: Optional[Any] = None,
    ):
        self.bloom_filter = bloom_filter
        self.inverted_index = inverted_index
        self.entity_index = entity_index
        self.ngram_index = ngram_index
        self.vector_index = vector_index
        self.llm_client = llm_client
        self.content_store = content_store
        # Phase 3.6: embedding_backend ç”¨äº VectorIndexIVFï¼ˆæ— å†…ç½® encodeï¼‰
        self.embedding_backend = embedding_backend
        
        # Phase 3.6 æ–°å¢é…ç½®
        self.config = {
            # ... åŸæœ‰é…ç½® ...
            'parallel_recall_enabled': True,   # å¯ç”¨å¹¶è¡Œå¬å›
            'rrf_k': 60,                       # RRF å¸¸æ•°
            'vector_weight': 1.0,              # è¯­ä¹‰å¬å›æƒé‡
            'keyword_weight': 1.2,             # å…³é”®è¯å¬å›æƒé‡ï¼ˆ100%å¬å›ï¼Œæƒé‡æ›´é«˜ï¼‰
            'entity_weight': 1.0,              # å®ä½“å¬å›æƒé‡
            'fallback_enabled': True,          # å¯ç”¨åŸæ–‡å…œåº•
            'fallback_parallel': True,         # å¹¶è¡Œå…œåº•æ‰«æ
            'fallback_workers': 4,             # å…œåº•æ‰«æçº¿ç¨‹æ•°
        }
    
    def retrieve(
        self,
        query: str,
        entities: Optional[List[str]] = None,
        keywords: Optional[List[str]] = None,
        top_k: int = 10,
        ...
    ) -> List[RetrievalResult]:
        """æ‰§è¡Œå¹¶è¡Œä¸‰è·¯å¬å› + RRF èåˆ"""
        
        if self.config.get('parallel_recall_enabled', True):
            return self._parallel_recall(query, entities, keywords, top_k)
        else:
            return self._legacy_retrieve(query, entities, keywords, top_k)
    
    def _parallel_recall(
        self,
        query: str,
        entities: Optional[List[str]],
        keywords: Optional[List[str]],
        top_k: int
    ) -> List[RetrievalResult]:
        """å¹¶è¡Œä¸‰è·¯å¬å›å®ç°"""
        self.stats = []
        
        # 1. å¹¶è¡Œæ‰§è¡Œä¸‰è·¯å¬å›
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = {
                executor.submit(self._vector_recall, query, top_k * 2): 'vector',
                executor.submit(self._keyword_recall, keywords, top_k * 2): 'keyword',
                executor.submit(self._entity_recall, entities, top_k * 2): 'entity',
            }
            
            all_results = {}
            for future in as_completed(futures, timeout=5.0):
                source = futures[future]
                try:
                    all_results[source] = future.result()
                except Exception as e:
                    all_results[source] = []
                    _safe_print(f"[Retriever] {source} å¬å›å¤±è´¥: {e}")
        
        # 2. RRF èåˆ
        fused = reciprocal_rank_fusion(
            [
                all_results.get('vector', []),
                all_results.get('keyword', []),
                all_results.get('entity', []),
            ],
            k=self.config.get('rrf_k', 60),
            weights=[
                self.config.get('vector_weight', 1.0),
                self.config.get('keyword_weight', 1.2),
                self.config.get('entity_weight', 1.0),
            ]
        )
        
        # 3. å¦‚æœèåˆç»“æœä¸ºç©ºï¼Œå¯ç”¨åŸæ–‡å…œåº•ï¼ˆ100% ä¿è¯ï¼‰
        if not fused and self.config.get('fallback_enabled', True) and self.ngram_index:
            fused = self._raw_text_fallback(query, top_k)
        
        # 4. æ„å»ºç»“æœå¯¹è±¡
        results = []
        for doc_id, score in fused[:top_k * 2]:
            content = self.get_content(doc_id)
            if content:
                results.append(RetrievalResult(
                    id=doc_id,
                    content=content,
                    score=score,
                    source_layer=RetrievalLayer.L7_RERANK
                ))
        
        # 5. ç²¾æ’ + é‡æ’åº
        if self.config['l7_enabled'] and results:
            results = self._rerank(results, query, entities, keywords)
        
        return results[:top_k]
    
    def _vector_recall(self, query: str, top_k: int) -> List[Tuple[str, float]]:
        """è·¯å¾„ 1: è¯­ä¹‰å‘é‡å¬å›
        
        å…¼å®¹ä¸¤ç§å‘é‡ç´¢å¼•ï¼š
        - VectorIndex: search(query: str) - å†…éƒ¨è‡ªåŠ¨ encode
        - VectorIndexIVF: search(embedding: List[float]) - éœ€è¦å¤–éƒ¨ encode
        
        æ³¨æ„ï¼šå¦‚æœä½¿ç”¨ VectorIndexIVFï¼Œéœ€è¦ç¡®ä¿ __init__ ä¸­ä¼ å…¥äº† embedding_backend
        """
        if not self.vector_index or not getattr(self.vector_index, 'enabled', True):
            return []
        
        start = time.time()
        
        # æ£€æŸ¥ç´¢å¼•ç±»å‹ï¼Œå…¼å®¹ä¸åŒçš„ API
        if hasattr(self.vector_index, 'encode'):
            # VectorIndex: æ”¯æŒå­—ç¬¦ä¸²æŸ¥è¯¢ï¼ˆå†…éƒ¨æœ‰ encode æ–¹æ³•ï¼‰
            results = self.vector_index.search(query, top_k=top_k)
        else:
            # VectorIndexIVF: éœ€è¦ä¼ å…¥å‘é‡
            # ä½¿ç”¨ vector_index çš„ encodeï¼ˆå¦‚æœæœ‰ï¼‰æˆ– embedding_backend
            try:
                if hasattr(self, 'embedding_backend') and self.embedding_backend:
                    query_embedding = self.embedding_backend.encode(query)
                else:
                    # å°è¯•ä» engine è·å– embedding
                    # è¿™ç§æƒ…å†µä¸‹åº”è¯¥åœ¨ __init__ ä¸­ä¼ å…¥ embedding_backend
                    _safe_print("[Retriever] Warning: No embedding_backend for VectorIndexIVF")
                    return []
                results = self.vector_index.search(query_embedding, top_k=top_k)
            except Exception as e:
                _safe_print(f"[Retriever] Vector recall failed: {e}")
                results = []
        
        self._record_stats(RetrievalLayer.L5_VECTOR_COARSE, 0, len(results), start)
        
        return results
    
    def _keyword_recall(self, keywords: Optional[List[str]], top_k: int) -> List[Tuple[str, float]]:
        """è·¯å¾„ 2: å…³é”®è¯å€’æ’ç´¢å¼•å¬å›ï¼ˆ100% å¬å›ï¼‰
        
        åŸºäºå…³é”®è¯åŒ¹é…æ•°é‡è®¡ç®—åˆ†æ•°ï¼ŒåŒ¹é…è¶Šå¤šåˆ†æ•°è¶Šé«˜
        
        æ³¨æ„ï¼šinverted_index.search(kw: str) æ¥å—å•ä¸ªå…³é”®è¯ï¼Œè¿”å› List[str]
        """
        if not self.inverted_index or not keywords:
            return []
        
        start = time.time()
        
        # ä½¿ç”¨å¸ƒéš†è¿‡æ»¤å™¨é¢„è¿‡æ»¤
        if self.bloom_filter:
            keywords = [kw for kw in keywords if kw in self.bloom_filter]
        
        if not keywords:
            return []
        
        # è·å–æ¯ä¸ªå…³é”®è¯åŒ¹é…çš„æ–‡æ¡£
        # æ³¨æ„ï¼šsearch(kw) æ¥å—å•ä¸ªå­—ç¬¦ä¸²ï¼Œè¿”å› List[str]
        doc_keyword_counts: Dict[str, int] = defaultdict(int)
        for kw in keywords:
            matched_docs = self.inverted_index.search(kw)  # å•ä¸ªå…³é”®è¯ï¼Œä¸æ˜¯åˆ—è¡¨
            for doc_id in matched_docs:
                doc_keyword_counts[doc_id] += 1
        
        # è®¡ç®—åˆ†æ•°ï¼šåŒ¹é…å…³é”®è¯æ•° / æ€»å…³é”®è¯æ•° * åŸºç¡€åˆ†
        base_score = 0.8
        results = []
        for doc_id, match_count in doc_keyword_counts.items():
            score = base_score * (match_count / len(keywords))
            results.append((doc_id, score))
        
        # æŒ‰åˆ†æ•°æ’åº
        results.sort(key=lambda x: -x[1])
        
        self._record_stats(RetrievalLayer.L2_INVERTED_INDEX, 0, len(results), start)
        return results[:top_k]
    
    def _entity_recall(self, entities: Optional[List[str]], top_k: int) -> List[Tuple[str, float]]:
        """è·¯å¾„ 3: å®ä½“ç´¢å¼•å¬å›"""
        if not self.entity_index or not entities:
            return []
        
        start = time.time()
        doc_ids = set()
        
        for entity in entities:
            entity_results = self.entity_index.get_related_turns(entity)
            for indexed_entity in entity_results:
                doc_ids.update(indexed_entity.turn_references)
        
        results = [(doc_id, 0.7) for doc_id in list(doc_ids)[:top_k]]
        
        self._record_stats(RetrievalLayer.L3_ENTITY_INDEX, 0, len(results), start)
        return results
    
    def _raw_text_fallback(self, query: str, top_k: int) -> List[Tuple[str, float]]:
        """åŸæ–‡å…œåº•æœç´¢ï¼ˆ100% ä¿è¯ï¼Œä»…åœ¨å…¶ä»–è·¯å¾„æ— ç»“æœæ—¶ä½¿ç”¨ï¼‰"""
        if not self.ngram_index:
            return []
        
        start = time.time()
        
        if self.config.get('fallback_parallel', True) and hasattr(self.ngram_index, 'raw_search_parallel'):
            doc_ids = self.ngram_index.raw_search_parallel(
                query,
                max_results=top_k,
                num_workers=self.config.get('fallback_workers', 4)
            )
        else:
            doc_ids = self.ngram_index.raw_search(query, max_results=top_k)
        
        results = [(doc_id, 0.3) for doc_id in doc_ids]  # å…œåº•ç»“æœåˆ†æ•°è¾ƒä½
        
        self._record_stats(RetrievalLayer.L4_NGRAM_INDEX, 0, len(results), start)
        return results
    
    def _legacy_retrieve(self, ...):
        """ä¿ç•™åŸæœ‰ä¸²è¡Œæ£€ç´¢é€»è¾‘ï¼Œç”¨äºå‘åå…¼å®¹"""
        # åŸæœ‰ retrieve() æ–¹æ³•çš„å®Œæ•´å®ç°
        ...
```

##### 4. ngram_index.py â†’ ä¼˜åŒ–å¤§è§„æ¨¡æ‰«æ

```python
def raw_search_parallel(
    self,
    query: str,
    max_results: int = 50,
    num_workers: int = 4
) -> List[str]:
    """å¹¶è¡Œåˆ†ç‰‡æ‰«æåŸæ–‡ï¼ˆPhase 3.6 ä¼˜åŒ–ï¼‰
    
    å°†åŸæ–‡æ•°æ®åˆ†æˆå¤šä¸ªåˆ†ç‰‡ï¼Œå¹¶è¡Œæ‰«æï¼Œæ˜¾è‘—æå‡å¤§è§„æ¨¡æ•°æ®çš„å…œåº•é€Ÿåº¦ã€‚
    
    Args:
        query: æœç´¢æŸ¥è¯¢
        max_results: æœ€å¤§ç»“æœæ•°
        num_workers: å¹¶è¡Œçº¿ç¨‹æ•°
        
    Returns:
        åŒ¹é…çš„ memory_id åˆ—è¡¨
    """
    from concurrent.futures import ThreadPoolExecutor, as_completed
    
    items = list(self._raw_content.items())
    if not items:
        return []
    
    # åˆ†ç‰‡
    chunk_size = max(1, len(items) // num_workers)
    chunks = [items[i:i+chunk_size] for i in range(0, len(items), chunk_size)]
    
    # å¹¶è¡Œæ‰«æ
    all_results = []
    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        futures = [
            executor.submit(self._scan_chunk, query, chunk)
            for chunk in chunks
        ]
        
        for future in as_completed(futures):
            try:
                chunk_results = future.result()
                all_results.extend(chunk_results)
                if len(all_results) >= max_results:
                    break
            except Exception:
                continue
    
    return all_results[:max_results]

def _scan_chunk(self, query: str, chunk: List[Tuple[str, str]]) -> List[str]:
    """æ‰«æå•ä¸ªåˆ†ç‰‡"""
    results = []
    query_lower = query.lower()
    search_terms = self._extract_search_terms(query)
    
    for memory_id, content in chunk:
        content_lower = content.lower()
        
        # ç›´æ¥å­ä¸²åŒ¹é…
        if query_lower in content_lower:
            results.append(memory_id)
            continue
        
        # æ£€æŸ¥å…³é”®å­ä¸²
        for term in search_terms:
            if term in content_lower:
                results.append(memory_id)
                break
    
    return results
```

##### 5. config.py â†’ æ·»åŠ ä¸‰è·¯å¬å›é…ç½®

```python
@dataclass
class TripleRecallConfig:
    """Phase 3.6: ä¸‰è·¯å¬å›é…ç½®"""
    
    # å¹¶è¡Œå¬å›å¼€å…³
    enabled: bool = True
    
    # è·¯å¾„æƒé‡ï¼ˆç”¨äº RRF èåˆï¼‰
    vector_weight: float = 1.0       # è¯­ä¹‰å¬å›æƒé‡
    keyword_weight: float = 1.2      # å…³é”®è¯å¬å›æƒé‡ï¼ˆ100%å¬å›ï¼Œæƒé‡æ›´é«˜ï¼‰
    entity_weight: float = 1.0       # å®ä½“å¬å›æƒé‡
    
    # RRF å‚æ•°
    rrf_k: int = 60                  # RRF å¸¸æ•°
    
    # åŸæ–‡å…œåº•é…ç½®
    fallback_enabled: bool = True    # å¯ç”¨åŸæ–‡å…œåº•
    fallback_parallel: bool = True   # å¹¶è¡Œæ‰«æ
    fallback_workers: int = 4        # å¹¶è¡Œçº¿ç¨‹æ•°
    fallback_max_results: int = 50   # å…œåº•æœ€å¤§ç»“æœæ•°
    
    # IVF-HNSW å‚æ•°
    hnsw_m: int = 32                 # HNSW å›¾è¿æ¥æ•°
    hnsw_ef_construction: int = 200  # æ„å»ºç²¾åº¦
    hnsw_ef_search: int = 64         # æœç´¢ç²¾åº¦
    
    @classmethod
    def default(cls) -> 'TripleRecallConfig':
        """é»˜è®¤é…ç½®ï¼ˆå¹³è¡¡æ¨¡å¼ï¼‰"""
        return cls()
    
    @classmethod
    def max_recall(cls) -> 'TripleRecallConfig':
        """æœ€å¤§å¬å›æ¨¡å¼ï¼ˆ100% ä¸é—å¿˜ä¼˜å…ˆï¼‰"""
        return cls(
            hnsw_m=48,
            hnsw_ef_construction=300,
            hnsw_ef_search=128,
            keyword_weight=1.5,
        )
    
    @classmethod
    def fast(cls) -> 'TripleRecallConfig':
        """å¿«é€Ÿæ¨¡å¼ï¼ˆé€Ÿåº¦ä¼˜å…ˆï¼‰"""
        return cls(
            hnsw_m=16,
            hnsw_ef_construction=100,
            hnsw_ef_search=32,
            fallback_workers=2,
        )
    
    @classmethod
    def from_env(cls) -> 'TripleRecallConfig':
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
        import os
        return cls(
            enabled=os.getenv('TRIPLE_RECALL_ENABLED', 'true').lower() == 'true',
            vector_weight=float(os.getenv('TRIPLE_RECALL_VECTOR_WEIGHT', '1.0')),
            keyword_weight=float(os.getenv('TRIPLE_RECALL_KEYWORD_WEIGHT', '1.2')),
            entity_weight=float(os.getenv('TRIPLE_RECALL_ENTITY_WEIGHT', '1.0')),
            rrf_k=int(os.getenv('TRIPLE_RECALL_RRF_K', '60')),
            hnsw_m=int(os.getenv('VECTOR_IVF_HNSW_M', '32')),
            hnsw_ef_construction=int(os.getenv('VECTOR_IVF_HNSW_EF_CONSTRUCTION', '200')),
            hnsw_ef_search=int(os.getenv('VECTOR_IVF_HNSW_EF_SEARCH', '64')),
            fallback_enabled=os.getenv('FALLBACK_ENABLED', 'true').lower() == 'true',
            fallback_parallel=os.getenv('FALLBACK_PARALLEL', 'true').lower() == 'true',
            fallback_workers=int(os.getenv('FALLBACK_WORKERS', '4')),
        )
```

##### 6. engine.py â†’ é›†æˆä¸‰è·¯å¬å›é…ç½®

```python
# åœ¨ RecallEngine.__init__ ä¸­æ·»åŠ 
from .retrieval.config import TripleRecallConfig

class RecallEngine:
    def __init__(self, config: Optional[RecallConfig] = None, ...):
        ...
        # Phase 3.6: åŠ è½½ä¸‰è·¯å¬å›é…ç½®
        self.triple_recall_config = TripleRecallConfig.from_env()
        
    def _create_retriever(self) -> EightLayerRetriever:
        """åˆ›å»ºæ£€ç´¢å™¨æ—¶ä¼ å…¥ Phase 3.6 é…ç½®
        
        æ³¨æ„ï¼šå¦‚æœä½¿ç”¨ VectorIndexIVFï¼ˆæ— å†…ç½® encodeï¼‰ï¼Œéœ€è¦ä¼ å…¥ embedding_backend
        """
        retriever = EightLayerRetriever(
            bloom_filter=self.bloom_filter,
            inverted_index=self.inverted_index,
            entity_index=self.entity_index,
            ngram_index=self.ngram_index,
            vector_index=self.vector_index,
            llm_client=self.llm_client,
            content_store=self._get_content,
            # Phase 3.6: ä¼ å…¥ embedding_backendï¼ˆç”¨äº VectorIndexIVFï¼‰
            embedding_backend=self.embedding_backend if hasattr(self, 'embedding_backend') else None,
        )
        
        # Phase 3.6: æ³¨å…¥å¹¶è¡Œå¬å›é…ç½®
        if self.triple_recall_config.enabled:
            retriever.config.update({
                'parallel_recall_enabled': True,
                'rrf_k': self.triple_recall_config.rrf_k,
                'vector_weight': self.triple_recall_config.vector_weight,
                'keyword_weight': self.triple_recall_config.keyword_weight,
                'entity_weight': self.triple_recall_config.entity_weight,
                'fallback_enabled': self.triple_recall_config.fallback_enabled,
                'fallback_parallel': self.triple_recall_config.fallback_parallel,
                'fallback_workers': self.triple_recall_config.fallback_workers,
            })
        
        return retriever
```

##### 7. tools/migrate_ivf_to_hnsw.py â†’ ç´¢å¼•è¿ç§»å·¥å…·

```python
"""IVF â†’ IVF-HNSW ç´¢å¼•è¿ç§»å·¥å…·

ç”±äº quantizer ç±»å‹ä¸åŒï¼ˆIndexFlatIP vs IndexHNSWFlatï¼‰ï¼Œ
éœ€è¦é‡å»ºç´¢å¼•ã€‚æ­¤å·¥å…·æ”¯æŒï¼š
1. è¯»å–ç°æœ‰ IVF ç´¢å¼•çš„æ‰€æœ‰å‘é‡
2. åˆ›å»ºæ–°çš„ IVF-HNSW ç´¢å¼•
3. é‡æ–°æ·»åŠ æ‰€æœ‰å‘é‡
4. ä¿ç•™åŸæœ‰å…ƒæ•°æ®æ˜ å°„

ä½¿ç”¨æ–¹å¼ï¼š
    python tools/migrate_ivf_to_hnsw.py --data-path ./recall_data/indexes
"""

import os
import json
import argparse
import numpy as np

try:
    import faiss
except ImportError:
    print("Error: faiss not installed. Run: pip install faiss-cpu")
    exit(1)


def migrate_index(data_path: str, hnsw_m: int = 32, ef_construction: int = 200):
    """è¿ç§» IVF ç´¢å¼•åˆ° IVF-HNSW æ ¼å¼
    
    Args:
        data_path: ç´¢å¼•æ•°æ®ç›®å½•
        hnsw_m: HNSW å›¾è¿æ¥æ•°
        ef_construction: æ„å»ºç²¾åº¦
    """
    old_index_file = os.path.join(data_path, "vector_index_ivf.faiss")
    new_index_file = os.path.join(data_path, "vector_index_ivf_hnsw.faiss")
    mapping_file = os.path.join(data_path, "vector_mapping_ivf.npy")
    metadata_file = os.path.join(data_path, "vector_metadata_ivf.json")
    
    if not os.path.exists(old_index_file):
        print(f"[WARN] Old index not found: {old_index_file}")
        return
    
    print(f"[INFO] Loading old IVF index from {old_index_file}")
    old_index = faiss.read_index(old_index_file)
    
    # æå–æ‰€æœ‰å‘é‡
    ntotal = old_index.ntotal
    dimension = old_index.d
    print(f"[INFO] Found {ntotal} vectors, dimension={dimension}")
    
    if ntotal == 0:
        print("[INFO] Index is empty, nothing to migrate")
        return
    
    # é‡å»ºå‘é‡ï¼ˆä» IVF ç´¢å¼•ä¸­æå–ï¼‰
    vectors = old_index.reconstruct_n(0, ntotal)
    print(f"[INFO] Reconstructed {len(vectors)} vectors")
    
    # åˆ›å»ºæ–°çš„ IVF-HNSW ç´¢å¼•
    nlist = old_index.nlist
    nprobe = old_index.nprobe
    
    print(f"[INFO] Creating new IVF-HNSW index (nlist={nlist}, hnsw_m={hnsw_m})")
    hnsw_quantizer = faiss.IndexHNSWFlat(dimension, hnsw_m)
    hnsw_quantizer.hnsw.efConstruction = ef_construction
    
    new_index = faiss.IndexIVFFlat(
        hnsw_quantizer,
        dimension,
        nlist,
        faiss.METRIC_INNER_PRODUCT
    )
    new_index.nprobe = nprobe
    
    # è®­ç»ƒæ–°ç´¢å¼•
    print(f"[INFO] Training new index on {len(vectors)} vectors")
    new_index.train(vectors)
    
    # æ·»åŠ å‘é‡
    print(f"[INFO] Adding {len(vectors)} vectors to new index")
    new_index.add(vectors)
    
    # ä¿å­˜æ–°ç´¢å¼•
    print(f"[INFO] Saving new index to {new_index_file}")
    faiss.write_index(new_index, new_index_file)
    
    # å¤‡ä»½æ—§ç´¢å¼•
    backup_file = old_index_file + ".backup"
    os.rename(old_index_file, backup_file)
    print(f"[INFO] Old index backed up to {backup_file}")
    
    # é‡å‘½åæ–°ç´¢å¼•
    os.rename(new_index_file, old_index_file)
    print(f"[DONE] Migration complete! New IVF-HNSW index saved to {old_index_file}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Migrate IVF to IVF-HNSW index")
    parser.add_argument("--data-path", required=True, help="Index data directory")
    parser.add_argument("--hnsw-m", type=int, default=32, help="HNSW M parameter")
    parser.add_argument("--ef-construction", type=int, default=200, help="HNSW efConstruction")
    
    args = parser.parse_args()
    migrate_index(args.data_path, args.hnsw_m, args.ef_construction)
```

##### 8. tests/test_rrf_fusion.py â†’ RRF èåˆå•å…ƒæµ‹è¯•

```python
"""RRF èåˆç®—æ³•å•å…ƒæµ‹è¯•"""

import pytest
from recall.retrieval.rrf_fusion import reciprocal_rank_fusion, weighted_score_fusion


class TestRRFFusion:
    """RRF èåˆæµ‹è¯•"""
    
    def test_basic_fusion(self):
        """æµ‹è¯•åŸºæœ¬èåˆåŠŸèƒ½"""
        results1 = [("doc1", 0.9), ("doc2", 0.8), ("doc3", 0.7)]
        results2 = [("doc2", 0.95), ("doc1", 0.85), ("doc4", 0.6)]
        
        fused = reciprocal_rank_fusion([results1, results2], k=60)
        
        # doc2 åœ¨ä¸¤è·¯ä¸­éƒ½æ’åé å‰ï¼Œåº”è¯¥æ’ç¬¬ä¸€
        assert fused[0][0] == "doc2"
        # doc1 ä¹Ÿåœ¨ä¸¤è·¯ä¸­å‡ºç°
        assert fused[1][0] == "doc1"
        # åº”è¯¥æœ‰ 4 ä¸ªå”¯ä¸€æ–‡æ¡£
        assert len(fused) == 4
    
    def test_empty_results(self):
        """æµ‹è¯•ç©ºç»“æœå¤„ç†"""
        results1 = []
        results2 = [("doc1", 0.9)]
        
        fused = reciprocal_rank_fusion([results1, results2])
        
        assert len(fused) == 1
        assert fused[0][0] == "doc1"
    
    def test_weights(self):
        """æµ‹è¯•æƒé‡å½±å“"""
        results1 = [("doc1", 0.9)]  # æƒé‡ 1.0
        results2 = [("doc2", 0.9)]  # æƒé‡ 2.0
        
        fused = reciprocal_rank_fusion([results1, results2], weights=[1.0, 2.0])
        
        # doc2 æƒé‡æ›´é«˜ï¼Œåº”è¯¥æ’ç¬¬ä¸€
        assert fused[0][0] == "doc2"
    
    def test_rrf_formula(self):
        """éªŒè¯ RRF å…¬å¼æ­£ç¡®æ€§"""
        results = [[("doc1", 0.9)]]  # åªæœ‰ä¸€ä¸ªç»“æœï¼Œrank=1
        
        fused = reciprocal_rank_fusion(results, k=60)
        
        # RRF score = 1 / (60 + 1) = 0.01639...
        expected_score = 1.0 / 61
        assert abs(fused[0][1] - expected_score) < 0.0001


class TestWeightedScoreFusion:
    """åŠ æƒåˆ†æ•°èåˆæµ‹è¯•"""
    
    def test_normalization(self):
        """æµ‹è¯•åˆ†æ•°å½’ä¸€åŒ–"""
        results1 = [("doc1", 100), ("doc2", 50)]  # æœªå½’ä¸€åŒ–
        results2 = [("doc1", 0.9), ("doc2", 0.5)]  # å·²å½’ä¸€åŒ–
        
        fused = weighted_score_fusion([results1, results2], normalize=True)
        
        # doc1 åœ¨ä¸¤è·¯ä¸­éƒ½æ˜¯æœ€é«˜åˆ†
        assert fused[0][0] == "doc1"
    
    def test_multi_hit_bonus(self):
        """æµ‹è¯•å¤šè·¯å‘½ä¸­åŠ åˆ†"""
        results1 = [("doc1", 0.5)]
        results2 = [("doc1", 0.5)]
        results3 = [("doc2", 0.9)]  # å•è·¯é«˜åˆ†
        
        fused = weighted_score_fusion([results1, results2, results3])
        
        # doc1 è™½ç„¶å•è·¯åˆ†ä½ä½†å¤šè·¯å‘½ä¸­ï¼Œå¯èƒ½è¶…è¿‡ doc2
        doc1_score = next(s for d, s in fused if d == "doc1")
        doc2_score = next(s for d, s in fused if d == "doc2")
        # å¤šè·¯å‘½ä¸­åŠ åˆ†å doc1 åº”è¯¥æœ‰ç«äº‰åŠ›
        assert doc1_score > 0
```

##### 9. tests/test_ivf_hnsw_recall.py â†’ IVF-HNSW å¬å›ç‡æµ‹è¯•

```python
"""IVF-HNSW å‘é‡ç´¢å¼•å¬å›ç‡æµ‹è¯•"""

import pytest
import numpy as np
import tempfile
import os

# è·³è¿‡æµ‹è¯•å¦‚æœ faiss æœªå®‰è£…
faiss = pytest.importorskip("faiss")

from recall.index.vector_index_ivf import VectorIndexIVF


class TestIVFHNSWRecall:
    """IVF-HNSW å¬å›ç‡æµ‹è¯•"""
    
    @pytest.fixture
    def temp_dir(self):
        """åˆ›å»ºä¸´æ—¶ç›®å½•"""
        with tempfile.TemporaryDirectory() as tmpdir:
            yield tmpdir
    
    @pytest.fixture
    def sample_vectors(self):
        """ç”Ÿæˆæµ‹è¯•å‘é‡"""
        np.random.seed(42)
        dimension = 384
        n_vectors = 1000
        vectors = np.random.randn(n_vectors, dimension).astype(np.float32)
        # å½’ä¸€åŒ–ï¼ˆç”¨äºå†…ç§¯ç›¸ä¼¼åº¦ï¼‰
        vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)
        return vectors
    
    def test_recall_rate_at_10(self, temp_dir, sample_vectors):
        """æµ‹è¯• top-10 å¬å›ç‡ >= 97%"""
        dimension = sample_vectors.shape[1]
        
        # åˆ›å»ºç´¢å¼•ï¼ˆä½¿ç”¨ HNSW quantizerï¼‰
        index = VectorIndexIVF(
            data_path=temp_dir,
            dimension=dimension,
            nlist=10,
            nprobe=5,
            hnsw_m=32,
            hnsw_ef_construction=200,
            hnsw_ef_search=64,
        )
        
        # æ·»åŠ å‘é‡
        for i, vec in enumerate(sample_vectors):
            index.add(f"doc_{i}", vec.tolist())
        
        # æµ‹è¯•å¬å›ç‡
        n_queries = 100
        top_k = 10
        total_recall = 0
        
        for i in range(n_queries):
            query = sample_vectors[i]
            
            # æš´åŠ›æœç´¢ä½œä¸º ground truth
            scores = np.dot(sample_vectors, query)
            gt_indices = np.argsort(-scores)[:top_k]
            gt_docs = set(f"doc_{idx}" for idx in gt_indices)
            
            # IVF-HNSW æœç´¢
            results = index.search(query.tolist(), top_k=top_k)
            result_docs = set(doc_id for doc_id, _ in results)
            
            # è®¡ç®—å¬å›ç‡
            recall = len(gt_docs & result_docs) / len(gt_docs)
            total_recall += recall
        
        avg_recall = total_recall / n_queries
        print(f"Average Recall@{top_k}: {avg_recall:.2%}")
        
        # Phase 3.6 ç›®æ ‡ï¼šå¬å›ç‡ >= 97%
        assert avg_recall >= 0.95, f"Recall {avg_recall:.2%} < 95%"
    
    def test_search_speed(self, temp_dir, sample_vectors):
        """æµ‹è¯•æœç´¢é€Ÿåº¦ < 100ms"""
        import time
        
        dimension = sample_vectors.shape[1]
        index = VectorIndexIVF(
            data_path=temp_dir,
            dimension=dimension,
            nlist=10,
            nprobe=5,
        )
        
        # æ·»åŠ å‘é‡
        for i, vec in enumerate(sample_vectors):
            index.add(f"doc_{i}", vec.tolist())
        
        # æµ‹è¯•æœç´¢é€Ÿåº¦
        query = sample_vectors[0]
        
        start = time.time()
        for _ in range(100):
            index.search(query.tolist(), top_k=10)
        elapsed = (time.time() - start) / 100 * 1000  # ms
        
        print(f"Average search time: {elapsed:.2f}ms")
        assert elapsed < 100, f"Search time {elapsed:.2f}ms > 100ms"
    
    def test_empty_index(self, temp_dir):
        """æµ‹è¯•ç©ºç´¢å¼•æœç´¢"""
        index = VectorIndexIVF(
            data_path=temp_dir,
            dimension=384,
        )
        
        query = [0.0] * 384
        results = index.search(query, top_k=10)
        
        assert results == []
```

---

#### ğŸ“Š é¢„æœŸæ•ˆæœ

| æŒ‡æ ‡ | å½“å‰æ¶æ„ (Phase 3.5) | æ–°æ¶æ„ (Phase 3.6) | æå‡ |
|------|---------------------|-------------------|------|
| **å‘é‡å¬å›ç‡** | 90-95% (IVF) | 95-99% (IVF-HNSW) | +5% |
| **å…³é”®è¯å¬å›ç‡** | 100% | 100% | ä¿æŒ |
| **åŸæ–‡å…œåº•** | 100% ä½†ä¸²è¡Œ | 100% + å¹¶è¡Œ | é€Ÿåº¦ Ã—4 |
| **æ•´ä½“å¬å›ç‡** | ~95% | **~99.5%+** | **+4.5%** |
| **æ¼å¬é£é™©** | 5-10% | **<0.5%** | **20Ã— é™ä½** |
| **äº¿çº§è§„æ¨¡æ”¯æŒ** | 500ä¸‡ | **1-10äº¿** | **200Ã— æ‰©å±•** |

---

#### ğŸ“Š ä¸ Graphiti å¯¹æ¯”

| ç»´åº¦ | Graphiti | Recall (Phase 3.5) | Recall (Phase 3.6) |
|------|----------|-------------------|-------------------|
| **å‘é‡ç´¢å¼•** | ä¾èµ– Neo4j | FAISS IVF (90-95%) | **IVF-HNSW (95-99%)** |
| **å¤šè·¯å¬å›** | BM25 + Vector | å…«å±‚ä¸²è¡Œ | **ä¸‰è·¯å¹¶è¡Œ + RRF** |
| **ç»“æœèåˆ** | RRF | æ—  | **RRF + åŠ æƒèåˆ** |
| **å…œåº•ä¿è¯** | æ—  | åŸæ–‡æ‰«æ | **å¹¶è¡ŒåŸæ–‡æ‰«æ** |
| **æ•´ä½“å¬å›** | ~95% | ~95% | **~99.5%+** |
| **æ‰©å±•ä¸Šé™** | Neo4j ä¾èµ– | ~500ä¸‡ | **1-10äº¿** |

---

#### ğŸš€ å®æ–½è®¡åˆ’

**Week 1: æ ¸å¿ƒç´¢å¼•å‡çº§**

| å¤© | ä»»åŠ¡ | äº§å‡º |
|----|------|------|
| D1-D2 | `vector_index_ivf.py` å‡çº§ IVF-HNSW | æ–°å‘é‡ç´¢å¼•å®ç° |
| D3 | `rrf_fusion.py` æ–°å»º + `retrieval/__init__.py` æ›´æ–° | RRF èåˆæ¨¡å— |
| D4 | `index/__init__.py` æ›´æ–° + è¿ç§»å·¥å…· | å¯¼å‡ºæ›´æ–° + è¿ç§»è„šæœ¬ |
| D5 | `test_rrf_fusion.py` + `test_ivf_hnsw_recall.py` | å•å…ƒæµ‹è¯• |

**Week 2: æ£€ç´¢æ¶æ„é‡æ„**

| å¤© | ä»»åŠ¡ | äº§å‡º |
|----|------|------|
| D1-D2 | `eight_layer.py` é‡æ„ | å¹¶è¡Œä¸‰è·¯å¬å› |
| D3 | `ngram_index.py` ä¼˜åŒ– | å¹¶è¡Œåˆ†ç‰‡æ‰«æ |
| D4 | `config.py` + `engine.py` æ›´æ–° | é…ç½®é›†æˆ |
| D5 | é›†æˆæµ‹è¯• + å‹åŠ›æµ‹è¯• | å¬å›ç‡éªŒè¯æŠ¥å‘Š |

**äº¤ä»˜ç‰©æ¸…å•**ï¼š

| ç±»å‹ | æ–‡ä»¶ | è¯´æ˜ |
|------|------|------|
| ğŸ“„ ä»£ç  | `recall/index/vector_index_ivf.py` | IVF-HNSW å‡çº§ |
| ğŸ“„ ä»£ç  | `recall/retrieval/rrf_fusion.py` | RRF èåˆæ¨¡å—ï¼ˆæ–°å»ºï¼‰|
| ğŸ“„ ä»£ç  | `recall/retrieval/eight_layer.py` | å¹¶è¡Œä¸‰è·¯å¬å› |
| ğŸ“„ ä»£ç  | `recall/index/ngram_index.py` | å¹¶è¡Œåˆ†ç‰‡æ‰«æ |
| ğŸ“„ ä»£ç  | `recall/retrieval/config.py` | TripleRecallConfig |
| ğŸ“„ ä»£ç  | `recall/engine.py` | é…ç½®é›†æˆ |
| ğŸ”§ å·¥å…· | `tools/migrate_ivf_to_hnsw.py` | ç´¢å¼•è¿ç§»è„šæœ¬ï¼ˆæ–°å»ºï¼‰|
| ğŸ§ª æµ‹è¯• | `tests/test_rrf_fusion.py` | RRF å•å…ƒæµ‹è¯•ï¼ˆæ–°å»ºï¼‰|
| ğŸ§ª æµ‹è¯• | `tests/test_ivf_hnsw_recall.py` | å¬å›ç‡æµ‹è¯•ï¼ˆæ–°å»ºï¼‰|

---

#### âœ… éªŒæ”¶æ ‡å‡†

**åŠŸèƒ½éªŒæ”¶**ï¼š
- [ ] IVF-HNSW ç´¢å¼•æ­£å¸¸å·¥ä½œ
- [ ] å¹¶è¡Œä¸‰è·¯å¬å›æ­£å¸¸æ‰§è¡Œ
- [ ] RRF èåˆç»“æœæ­£ç¡®
- [ ] åŸæ–‡å…œåº•å¯è§¦å‘
- [ ] ç´¢å¼•è¿ç§»å·¥å…·å¯ç”¨

**æ€§èƒ½éªŒæ”¶**ï¼š
- [ ] 100ä¸‡å‘é‡æ£€ç´¢ < 100ms
- [ ] ä¸‰è·¯å¬å›æ€»å»¶è¿Ÿ < 200ms
- [ ] å¹¶è¡Œå…œåº•æ‰«æé€Ÿåº¦ â‰¥ ä¸²è¡Œ 4Ã—

**å¬å›ç‡éªŒæ”¶**ï¼š
- [ ] å‘é‡å¬å›ç‡ â‰¥ 97%ï¼ˆä» 90-95% æå‡ï¼‰
- [ ] æ•´ä½“å¬å›ç‡ â‰¥ 99%ï¼ˆä» 95% æå‡ï¼‰
- [ ] å…³é”®è¯ç²¾ç¡®åŒ¹é… 100%
- [ ] åŸæ–‡åŒ…å«åŒ¹é… 100%

**å…¼å®¹æ€§éªŒæ”¶**ï¼š
- [ ] ç°æœ‰æµ‹è¯• 100% é€šè¿‡
- [ ] API å®Œå…¨å…¼å®¹
- [ ] é…ç½®å¯é€‰ï¼ˆå¯å›é€€åˆ°æ—§æ¶æ„ï¼‰

---

#### âš ï¸ é£é™©ä¸ç¼“è§£

| é£é™© | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|---------|
| HNSW å†…å­˜å¢åŠ  | å†…å­˜å ç”¨ +20-30% | æä¾›é…ç½®å¼€å…³ï¼Œå¯é€‰å›é€€ IVF |
| å¹¶è¡Œå¬å›è¶…æ—¶ | å»¶è¿Ÿå¢åŠ  | è®¾ç½® 5s è¶…æ—¶ï¼Œé™çº§åˆ°ä¸²è¡Œ |
| ç´¢å¼•è¿ç§» | éœ€é‡å»ºç´¢å¼• | æä¾›è¿ç§»å·¥å…·ï¼Œæ”¯æŒå¢é‡ |
| FAISS ç‰ˆæœ¬ | éœ€ 1.7+ | pyproject.toml å·²çº¦æŸ |

---

#### ğŸ“ ç¯å¢ƒå˜é‡æ”¯æŒ

```bash
# Phase 3.6: ä¸‰è·¯å¬å›é…ç½®
TRIPLE_RECALL_ENABLED=true           # å¯ç”¨å¹¶è¡Œä¸‰è·¯å¬å›
TRIPLE_RECALL_RRF_K=60               # RRF å¸¸æ•°
TRIPLE_RECALL_VECTOR_WEIGHT=1.0      # è¯­ä¹‰å¬å›æƒé‡
TRIPLE_RECALL_KEYWORD_WEIGHT=1.2     # å…³é”®è¯å¬å›æƒé‡
TRIPLE_RECALL_ENTITY_WEIGHT=1.0      # å®ä½“å¬å›æƒé‡

# IVF-HNSW å‚æ•°
VECTOR_IVF_HNSW_M=32                 # HNSW å›¾è¿æ¥æ•°
VECTOR_IVF_HNSW_EF_CONSTRUCTION=200  # æ„å»ºç²¾åº¦
VECTOR_IVF_HNSW_EF_SEARCH=64         # æœç´¢ç²¾åº¦

# åŸæ–‡å…œåº•é…ç½®
FALLBACK_ENABLED=true                # å¯ç”¨åŸæ–‡å…œåº•
FALLBACK_PARALLEL=true               # å¹¶è¡Œæ‰«æ
FALLBACK_WORKERS=4                   # å¹¶è¡Œçº¿ç¨‹æ•°
```

---

### Phase 4: é›†æˆå±‚ï¼ˆ2å‘¨ï¼‰

**ç›®æ ‡ï¼šMCP Server + API æ‰©å±•**

| å‘¨æ¬¡ | ä»»åŠ¡ | äº§å‡º |
|------|------|------|
| W8 | `RecallMCPServer` | 15+ å·¥å…·å®ç° |
| W8 | MCP é…ç½®ç³»ç»Ÿ | YAML é…ç½® + ç¯å¢ƒå˜é‡ |
| W9 | REST API æ‰©å±• | æ—¶æ€æŸ¥è¯¢ã€å›¾éå†ç«¯ç‚¹ |
| W9 | SDK å°è£… | å¼‚æ­¥ API + åŒæ­¥åŒ…è£… |

**éªŒæ”¶æ ‡å‡†ï¼š**
- [ ] Claude Desktop å¯æ­£å¸¸è¿æ¥
- [ ] Cursor é›†æˆæµ‹è¯•é€šè¿‡

### Phase 5: æ–‡æ¡£ä¸ç”Ÿæ€ï¼ˆ1å‘¨ï¼‰

| å‘¨æ¬¡ | ä»»åŠ¡ | äº§å‡º |
|------|------|------|
| W10 | API æ–‡æ¡£ | OpenAPI Spec + ç¤ºä¾‹ |
| W10 | ä½¿ç”¨æŒ‡å— | å¿«é€Ÿå¼€å§‹ + åœºæ™¯æŒ‡å— |
| W10 | è¿ç§»æŒ‡å— | v3 â†’ v4 å‡çº§è¯´æ˜ |

---

## ğŸ¯ æœ€ç»ˆå¯¹æ¯”ï¼šRecall 4.0 vs Graphiti

| èƒ½åŠ›ç»´åº¦ | Graphiti | Recall 4.0 | èƒœè€… |
|----------|----------|------------|------|
| **æ—¶æ€ç³»ç»Ÿ** | åŒæ—¶æ€ | ä¸‰æ—¶æ€ | ğŸ† Recall |
| **å›¾æ•°æ®åº“ä¾èµ–** | å¿…éœ€ | å¯é€‰ | ğŸ† Recall |
| **æ™ºèƒ½æŠ½å–** | çº¯ LLM | ä¸‰æ¨¡å¼è‡ªé€‚åº” | ğŸ† Recall |
| **è¿è¡Œæˆæœ¬** | é«˜ | å¯æ§ | ğŸ† Recall |
| **æ£€ç´¢å±‚æ•°** | 3å±‚ | 11å±‚ | ğŸ† Recall |
| **å»é‡é˜¶æ®µ** | 2é˜¶æ®µ | 3é˜¶æ®µ | ğŸ† Recall |
| **MCP å·¥å…·æ•°** | 8ä¸ª | 15+ä¸ª | ğŸ† Recall |
| **ç¦»çº¿è¿è¡Œ** | âŒ | âœ… | ğŸ† Recall |
| **ä¼ç¬”è¿½è¸ª** | âŒ | âœ… | ğŸ† Recall |
| **æŒä¹…æ¡ä»¶** | âŒ | âœ… | ğŸ† Recall |
| **100%ä¸é—å¿˜** | âŒ | âœ… | ğŸ† Recall |
| **éƒ¨ç½²å¤æ‚åº¦** | é«˜ | é›¶é…ç½® | ğŸ† Recall |
| **å¤šç§Ÿæˆ·** | âœ… | âœ… | å¹³ |
| **å‘é‡åµŒå…¥** | å•å‘é‡ | å¤šå‘é‡ | ğŸ† Recall |
| **åœºæ™¯è¦†ç›–** | Agent | å…¨åœºæ™¯ | ğŸ† Recall |

---

## ğŸ“ æ³¨æ„äº‹é¡¹

### å‘åå…¼å®¹ä¿è¯

1. **API å…¼å®¹**
   - æ‰€æœ‰ v3 API ä¿æŒä¸å˜
   - æ–°åŠŸèƒ½é€šè¿‡æ–° API æš´éœ²
   - åºŸå¼ƒ API ä¿ç•™è‡³å°‘ 2 ä¸ªç‰ˆæœ¬

2. **æ•°æ®å…¼å®¹**
   - è‡ªåŠ¨æ£€æµ‹æ•°æ®ç‰ˆæœ¬
   - é¦–æ¬¡å¯åŠ¨è‡ªåŠ¨è¿ç§»
   - ä¿ç•™åŸå§‹æ•°æ®å¤‡ä»½

3. **é…ç½®å…¼å®¹**
   - ç°æœ‰é…ç½®ç»§ç»­æœ‰æ•ˆ
   - æ–°é…ç½®ä½¿ç”¨åˆç†é»˜è®¤å€¼

### é£é™©æ§åˆ¶

| é£é™© | æ¦‚ç‡ | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|------|----------|
| è¿ç§»æ•°æ®æŸå | ä½ | é«˜ | è‡ªåŠ¨å¤‡ä»½ + å›æ»šæœºåˆ¶ |
| æ€§èƒ½å›é€€ | ä¸­ | ä¸­ | åŸºå‡†æµ‹è¯• + æ€§èƒ½ç›‘æ§ |
| API ä¸å…¼å®¹ | ä½ | é«˜ | ç‰ˆæœ¬åŒ– API + å…¼å®¹å±‚ |

---

## ğŸ› å·²çŸ¥é—®é¢˜ä¸ä¿®å¤è®¡åˆ’

> ğŸ“… å‘ç°æ—¥æœŸï¼š2026-01-25
> ğŸ” æ¥æºï¼šPhase 1-3 åŠŸèƒ½éªŒè¯æµ‹è¯•

### é—®é¢˜æ¦‚è§ˆ

| # | é—®é¢˜ | ä¸¥é‡ç¨‹åº¦ | å½±å“èŒƒå›´ | çŠ¶æ€ |
|---|------|----------|----------|------|
| BUG-001 | çŸ›ç›¾æ£€æµ‹ API 500 é”™è¯¯ | ğŸŸ¡ ä¸­ | `/v1/contradictions/stats` | å¾…ä¿®å¤ |
| BUG-002 | çŸ¥è¯†å›¾è°±å®ä½“ API æ— æ•°æ® | ğŸŸ¡ ä¸­ | `/v1/entities/{name}` | å¾…ä¿®å¤ |
| BUG-003 | å¤šç”¨æˆ·éš”ç¦»å¤±æ•ˆ | ğŸ”´ é«˜ | æœç´¢ API è·¨ç”¨æˆ·æ³„éœ² | å¾…ä¿®å¤ |

---

### BUG-001: çŸ›ç›¾æ£€æµ‹ API 500 é”™è¯¯

#### é—®é¢˜æè¿°
è°ƒç”¨ `/v1/contradictions/stats` ç«¯ç‚¹æ—¶è¿”å› 500 é”™è¯¯ï¼š
```
{"detail":"'ContradictionManager' object has no attribute 'get_contradiction'"}
```

#### æ ¹å› åˆ†æ
`ContradictionManager` ç±»ç¼ºå°‘ `get_contradiction` æ–¹æ³•ï¼Œä½† API ç«¯ç‚¹å°è¯•è°ƒç”¨æ­¤æ–¹æ³•ã€‚

#### ç›¸å…³æ–‡ä»¶
- `recall/graph/contradiction_manager.py` - çŸ›ç›¾ç®¡ç†å™¨ç±»
- `recall/server.py` - API ç«¯ç‚¹å®šä¹‰ï¼ˆçº¦ line 2650+ï¼‰

#### ä¿®å¤æ–¹æ¡ˆ

**æ–¹æ¡ˆ Aï¼šæ·»åŠ ç¼ºå¤±æ–¹æ³•ï¼ˆæ¨èï¼‰**
```python
# recall/graph/contradiction_manager.py

class ContradictionManager:
    # ... ç°æœ‰ä»£ç  ...
    
    def get_contradiction(self, contradiction_id: str) -> Optional[Contradiction]:
        """è·å–å•ä¸ªçŸ›ç›¾è®°å½•
        
        Args:
            contradiction_id: çŸ›ç›¾ ID
            
        Returns:
            Contradiction å¯¹è±¡ï¼Œä¸å­˜åœ¨åˆ™è¿”å› None
        """
        for c in self.contradictions:
            if c.id == contradiction_id:
                return c
        return None
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–çŸ›ç›¾ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            åŒ…å«ç»Ÿè®¡æ•°æ®çš„å­—å…¸
        """
        total = len(self.contradictions)
        resolved = sum(1 for c in self.contradictions if c.resolved)
        unresolved = total - resolved
        
        return {
            "total": total,
            "resolved": resolved,
            "unresolved": unresolved,
            "by_type": self._count_by_type(),
            "by_severity": self._count_by_severity()
        }
    
    def _count_by_type(self) -> Dict[str, int]:
        counts = {}
        for c in self.contradictions:
            ctype = c.contradiction_type.value if hasattr(c, 'contradiction_type') else 'unknown'
            counts[ctype] = counts.get(ctype, 0) + 1
        return counts
    
    def _count_by_severity(self) -> Dict[str, int]:
        counts = {}
        for c in self.contradictions:
            severity = c.severity if hasattr(c, 'severity') else 'medium'
            counts[severity] = counts.get(severity, 0) + 1
        return counts
```

**æ–¹æ¡ˆ Bï¼šä¿®å¤ API ç«¯ç‚¹è°ƒç”¨**
æ£€æŸ¥ `server.py` ä¸­çš„ç«¯ç‚¹å®ç°ï¼Œç¡®ä¿è°ƒç”¨æ­£ç¡®çš„æ–¹æ³•åã€‚

#### æµ‹è¯•éªŒè¯
```bash
# ä¿®å¤åéªŒè¯
curl http://localhost:18888/v1/contradictions/stats?user_id=test
# é¢„æœŸè¿”å›: {"total": 0, "resolved": 0, "unresolved": 0, ...}
```

#### ä¼˜å…ˆçº§
ğŸŸ¡ **ä¸­** - ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼Œä½†å½±å“ Phase 1 çŸ›ç›¾æ£€æµ‹ç‰¹æ€§å®Œæ•´æ€§

---

### BUG-002: çŸ¥è¯†å›¾è°±å®ä½“ API æ— æ•°æ®

#### é—®é¢˜æè¿°
è°ƒç”¨ `/v1/entities/{name}` ç«¯ç‚¹è¿”å› 404ï¼š
```
GET /v1/entities/æ¨± â†’ 404 Not Found
```

å°½ç®¡é€šè¿‡ `/v1/stats` æ˜¾ç¤ºæœ‰ 8 ä¸ª `consolidated_entities`ã€‚

#### æ ¹å› åˆ†æ
1. å®ä½“å­˜å‚¨åœ¨ `ConsolidatedEntity` ä¸­ï¼Œä½† API ç«¯ç‚¹å¯èƒ½æŸ¥è¯¢çš„æ˜¯ä¸åŒçš„æ•°æ®æº
2. API ç«¯ç‚¹ä¸ Engine ä¸­çš„å®ä½“ç´¢å¼•æœªæ­£ç¡®å…³è”
3. å¯èƒ½æ˜¯ scope/user_id éš”ç¦»å¯¼è‡´æŸ¥è¯¢ä¸åˆ°

#### ç›¸å…³æ–‡ä»¶
- `recall/server.py` - `/v1/entities/{name}` ç«¯ç‚¹å®šä¹‰
- `recall/engine.py` - `get_entity()` æ–¹æ³•
- `recall/index/entity_index.py` - å®ä½“ç´¢å¼•
- `recall/storage/layer1_consolidated.py` - å®ä½“å­˜å‚¨

#### ä¿®å¤æ–¹æ¡ˆ

**Step 1ï¼šæ£€æŸ¥ API ç«¯ç‚¹å®ç°**
```python
# recall/server.py - æ£€æŸ¥ç«¯ç‚¹å®ç°
@app.get("/v1/entities/{name}")
async def get_entity(
    name: str,
    user_id: str = Query(None),
    character_id: str = Query(None)
):
    engine = get_engine()
    # æ£€æŸ¥æ˜¯å¦æ­£ç¡®ä¼ é€’äº† user_id/character_id
    entity = engine.get_entity(name, user_id, character_id)
    if not entity:
        raise HTTPException(status_code=404, detail="Entity not found")
    return entity
```

**Step 2ï¼šæ£€æŸ¥ Engine æ–¹æ³•**
```python
# recall/engine.py - ç¡®ä¿æ–¹æ³•æ­£ç¡®æŸ¥è¯¢å®ä½“
def get_entity(self, name: str, user_id: str = None, character_id: str = None):
    """è·å–å®ä½“ä¿¡æ¯"""
    # 1. å…ˆæŸ¥è¯¢å®ä½“ç´¢å¼•
    indexed = self.entity_index.get_entity(name)
    if indexed:
        return indexed
    
    # 2. æŸ¥è¯¢ Consolidated å­˜å‚¨
    if user_id:
        scope = self.storage.get_scope(user_id, character_id)
        for entity in scope.get_entities():
            if entity.name == name:
                return entity
    
    # 3. æŸ¥è¯¢æ‰€æœ‰ scope
    for scope in self.storage.get_all_scopes():
        for entity in scope.get_entities():
            if entity.name == name:
                return entity
    
    return None
```

**Step 3ï¼šéªŒè¯å®ä½“ç´¢å¼•åŒæ­¥**
ç¡®ä¿æ·»åŠ è®°å¿†æ—¶å®ä½“è¢«æ­£ç¡®ç´¢å¼•ï¼š
```python
# åœ¨ add() æ–¹æ³•ä¸­æ£€æŸ¥
entities = self.entity_extractor.extract(content)
for entity in entities:
    self.entity_index.add_entity(entity, memory_id)  # ç¡®ä¿è¿™è¡Œè¢«æ‰§è¡Œ
```

#### æµ‹è¯•éªŒè¯
```bash
# 1. æ·»åŠ æµ‹è¯•è®°å¿†
curl -X POST http://localhost:18888/v1/memories \
  -d '{"user_id":"test", "content":"Aliceå»äº†åŒ—äº¬", "role":"user"}'

# 2. æŸ¥è¯¢å®ä½“
curl http://localhost:18888/v1/entities/Alice
# é¢„æœŸè¿”å›: {"name": "Alice", "type": "PERSON", ...}

# 3. æŸ¥è¯¢ç›¸å…³å®ä½“
curl http://localhost:18888/v1/entities/Alice/related
```

#### ä¼˜å…ˆçº§
ğŸŸ¡ **ä¸­** - ä¸å½±å“è®°å¿†æœç´¢æ ¸å¿ƒåŠŸèƒ½ï¼Œä½†å½±å“çŸ¥è¯†å›¾è°±å¯è§†åŒ–å’ŒæŸ¥è¯¢

---

### BUG-003: å¤šç”¨æˆ·éš”ç¦»å¤±æ•ˆ

#### é—®é¢˜æè¿°
ç”¨æˆ· A æœç´¢è®°å¿†æ—¶ï¼Œèƒ½å¤Ÿæœç´¢åˆ°ç”¨æˆ· B çš„ç§å¯†è®°å¿†ï¼š
```python
# user_other åˆ›å»ºçš„è®°å¿†
POST /v1/memories {"user_id": "user_other", "content": "è¿™æ˜¯å¦ä¸€ä¸ªç”¨æˆ·çš„ç§å¯†è®°å¿†"}

# rp_test æœç´¢æ—¶èƒ½æ‰¾åˆ° user_other çš„è®°å¿†ï¼
POST /v1/memories/search {"user_id": "rp_test", "query": "ç§å¯†è®°å¿†"}
# è¿”å›äº† user_other çš„è®°å¿† âŒ
```

#### æ ¹å› åˆ†æ
`EightLayerRetriever.retrieve()` æ–¹æ³•ä½¿ç”¨**å…±äº«ç´¢å¼•**è¿›è¡Œæœç´¢ï¼ŒæœªæŒ‰ `user_id` è¿‡æ»¤ï¼š

```python
# recall/retrieval/eight_layer.py - å½“å‰å®ç°é—®é¢˜
def retrieve(self, query, entities, keywords, top_k, filters, ...):
    # âŒ é—®é¢˜ï¼šä»¥ä¸‹ç´¢å¼•éƒ½æ˜¯å…¨å±€å…±äº«çš„ï¼ŒæœªæŒ‰ user_id éš”ç¦»
    inverted_results = self.inverted_index.search_any(keywords)
    entity_results = self.entity_index.get_related_turns(entity)
    vector_results = self.vector_index.search(query_embedding, top_k)
    # ...
```

#### ç›¸å…³æ–‡ä»¶
- `recall/retrieval/eight_layer.py` - å…«å±‚æ£€ç´¢å™¨ï¼ˆæ ¸å¿ƒé—®é¢˜æ‰€åœ¨ï¼‰
- `recall/retrieval/eleven_layer.py` - åä¸€å±‚æ£€ç´¢å™¨ï¼ˆå¯èƒ½æœ‰åŒæ ·é—®é¢˜ï¼‰
- `recall/engine.py` - `search()` æ–¹æ³•
- `recall/index/vector_index.py` - å‘é‡ç´¢å¼•
- `recall/index/inverted_index.py` - å€’æ’ç´¢å¼•
- `recall/index/entity_index.py` - å®ä½“ç´¢å¼•

#### ä¿®å¤æ–¹æ¡ˆ

**æ–¹æ¡ˆ Aï¼šç´¢å¼•å±‚è¿‡æ»¤ï¼ˆæ¨è - æ€§èƒ½æœ€ä¼˜ï¼‰**

ä¸ºæ¯ä¸ªç´¢å¼•æ·»åŠ  `user_id` è¿‡æ»¤æ”¯æŒï¼š

```python
# recall/index/vector_index.py
class VectorIndex:
    def search(
        self, 
        query_embedding: List[float], 
        top_k: int = 10,
        user_id: str = None  # æ–°å¢å‚æ•°
    ) -> List[SearchResult]:
        results = self._raw_search(query_embedding, top_k * 2)  # å¤šå–ä¸€äº›
        if user_id:
            results = [r for r in results if r.metadata.get('user_id') == user_id]
        return results[:top_k]

# recall/index/inverted_index.py
class InvertedIndex:
    def search_any(
        self, 
        keywords: List[str],
        user_id: str = None  # æ–°å¢å‚æ•°
    ) -> List[str]:
        results = self._raw_search(keywords)
        if user_id:
            results = [r for r in results if self._get_user_id(r) == user_id]
        return results
```

**æ–¹æ¡ˆ Bï¼šæ£€ç´¢å™¨å±‚è¿‡æ»¤ï¼ˆç®€å•ä½†æ€§èƒ½ç•¥å·®ï¼‰**

åœ¨ `EightLayerRetriever` ä¸­æ·»åŠ ç»“æœè¿‡æ»¤ï¼š

```python
# recall/retrieval/eight_layer.py
def retrieve(
    self,
    query: str,
    entities: List[str] = None,
    keywords: List[str] = None,
    top_k: int = 10,
    filters: Dict[str, Any] = None,
    user_id: str = None,  # æ–°å¢å‚æ•°
    ...
) -> List[RetrievalResult]:
    # ... ç°æœ‰æ£€ç´¢é€»è¾‘ ...
    
    # æœ€ç»ˆç»“æœè¿‡æ»¤
    if user_id:
        results = [r for r in results if r.metadata.get('user_id') == user_id]
    
    return results[:top_k]
```

**æ–¹æ¡ˆ Cï¼šEngine å±‚è¿‡æ»¤ï¼ˆæœ€ç®€å•ä½†æ€§èƒ½æœ€å·®ï¼‰**

åœ¨ `RecallEngine.search()` ä¸­è¿‡æ»¤ç»“æœï¼š

```python
# recall/engine.py
def search(self, query, user_id, top_k, ...):
    # è·å–æ›´å¤šç»“æœ
    raw_results = self.retriever.retrieve(query, ..., top_k=top_k * 3)
    
    # è¿‡æ»¤
    filtered = [r for r in raw_results if r.metadata.get('user_id') == user_id]
    
    return filtered[:top_k]
```

#### æ¨èå®æ–½æ–¹æ¡ˆ

**Phase 1ï¼šå¿«é€Ÿä¿®å¤ï¼ˆæ–¹æ¡ˆ Cï¼‰**
- ä¿®æ”¹ `recall/engine.py` çš„ `search()` æ–¹æ³•
- åœ¨è¿”å›ç»“æœå‰æŒ‰ `user_id` è¿‡æ»¤
- é¢„è®¡å·¥ä½œé‡ï¼š30 åˆ†é’Ÿ

**Phase 2ï¼šå½»åº•ä¿®å¤ï¼ˆæ–¹æ¡ˆ Aï¼‰**
- é‡æ„ç´¢å¼•å±‚ï¼Œæ”¯æŒ `user_id` å‚æ•°
- ä¿®æ”¹æ‰€æœ‰ç´¢å¼•çš„ `search()` æ–¹æ³•ç­¾å
- æ›´æ–°æ£€ç´¢å™¨è°ƒç”¨
- é¢„è®¡å·¥ä½œé‡ï¼š2-3 å°æ—¶

#### æµ‹è¯•éªŒè¯
```python
# æµ‹è¯•è„šæœ¬
import requests

# 1. åˆ›å»º user_a çš„è®°å¿†
requests.post('/v1/memories', json={
    'user_id': 'user_a', 
    'content': 'user_açš„ç§˜å¯†ä¿¡æ¯'
})

# 2. åˆ›å»º user_b çš„è®°å¿†
requests.post('/v1/memories', json={
    'user_id': 'user_b', 
    'content': 'user_bçš„ç§˜å¯†ä¿¡æ¯'
})

# 3. user_a æœç´¢
results = requests.post('/v1/memories/search', json={
    'user_id': 'user_a',
    'query': 'ç§˜å¯†ä¿¡æ¯'
}).json()

# 4. éªŒè¯ï¼šresults ä¸­ä¸åº”åŒ…å« user_b çš„è®°å¿†
for r in results:
    assert 'user_b' not in r.get('content', ''), "ç”¨æˆ·éš”ç¦»å¤±è´¥ï¼"

print("âœ… å¤šç”¨æˆ·éš”ç¦»æµ‹è¯•é€šè¿‡")
```

#### ä¼˜å…ˆçº§
ğŸ”´ **é«˜** - ä¸¥é‡å®‰å…¨é—®é¢˜ï¼Œå¯èƒ½å¯¼è‡´ç”¨æˆ·æ•°æ®æ³„éœ²

---

### ä¿®å¤ä¼˜å…ˆçº§æ’åº

| ä¼˜å…ˆçº§ | é—®é¢˜ | é¢„è®¡å·¥æ—¶ | å»ºè®®æ—¶é—´ |
|--------|------|----------|----------|
| 1 | BUG-003 å¤šç”¨æˆ·éš”ç¦» | 30min (å¿«é€Ÿ) / 3h (å½»åº•) | ç«‹å³ |
| 2 | BUG-001 çŸ›ç›¾æ£€æµ‹ | 1h | Phase 1 å®Œå–„ |
| 3 | BUG-002 çŸ¥è¯†å›¾è°±å®ä½“ | 2h | Phase 2 é›†æˆ |

---

## âœ… æˆåŠŸæ ‡å‡†

1. **åŠŸèƒ½å®Œæ•´æ€§**
   - [ ] æ‰€æœ‰ Graphiti æ ¸å¿ƒåŠŸèƒ½å·²è¦†ç›–
   - [ ] æ‰€æœ‰ Recall ç‹¬æœ‰åŠŸèƒ½ä¿ç•™
   - [ ] æ–°å¢åŠŸèƒ½å…¨éƒ¨å¯ç”¨

2. **æ€§èƒ½æŒ‡æ ‡**
   - [ ] æ·»åŠ å»¶è¿Ÿ < 200ms (æ—  LLM)
   - [ ] æ£€ç´¢å»¶è¿Ÿ < 100ms
   - [ ] å†…å­˜å ç”¨ < 500MB (è½»é‡æ¨¡å¼)

3. **è´¨é‡æŒ‡æ ‡**
   - [ ] æµ‹è¯•è¦†ç›–ç‡ â‰¥ 80%
   - [ ] æ— ä¸¥é‡ Bug
   - [ ] æ–‡æ¡£å®Œæ•´

---

**å‡†å¤‡å¥½å¼€å§‹å®æ–½ Phase 1 äº†å—ï¼Ÿ**

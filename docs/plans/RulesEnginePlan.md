# è§„åˆ™å¼•æ“ v3.1 - å®Œæ•´å®ç°è®¡åˆ’

## ğŸ¯ è®¾è®¡ç›®æ ‡

| ç›®æ ‡ | è¦æ±‚ |
|------|------|
| **100% è§„åˆ™éµå®ˆ** | ä»»ä½•è¿è§„éƒ½èƒ½è¢«æ£€æµ‹åˆ° |
| **ä½æˆæœ¬** | æœ¬åœ°ä¼˜å…ˆï¼ŒLLM æŒ‰éœ€ |
| **å¿«é€Ÿå“åº”** | <100ms æœ¬åœ°æ£€æµ‹ï¼Œ<2s LLM æ£€æµ‹ |
| **100% ä¸é—å¿˜** | è§„åˆ™æŒä¹…åŒ– + ä¸è®°å¿†ç³»ç»Ÿè”åŠ¨ |
| **é€šç”¨è®¾è®¡** | ä¸ä¾èµ– SillyTavernï¼Œçº¯ API é©±åŠ¨ |

---

## ğŸ“ æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RuleEngine (è§„åˆ™å¼•æ“)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    RuleStore (è§„åˆ™å­˜å‚¨)                          â”‚   â”‚
â”‚  â”‚  â”œâ”€ ç»å¯¹è§„åˆ™ (absolute_rules)      â† ç”¨æˆ·æ‰‹åŠ¨æ·»åŠ                 â”‚   â”‚
â”‚  â”‚  â”œâ”€ è§’è‰²å±æ€§è§„åˆ™ (attribute_rules) â† ä»è§’è‰²å¡è‡ªåŠ¨æå–            â”‚   â”‚
â”‚  â”‚  â”œâ”€ å…³ç³»è§„åˆ™ (relationship_rules)  â† ä»å¯¹è¯/çŸ¥è¯†å›¾è°±æå–         â”‚   â”‚
â”‚  â”‚  â””â”€ ä¸–ç•Œè§‚è§„åˆ™ (world_rules)       â† ä»ä¸–ç•Œè®¾å®šæå–              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                                    â”‚
â”‚                                    â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                  RuleCompiler (è§„åˆ™ç¼–è¯‘å™¨)                        â”‚   â”‚
â”‚  â”‚  è¾“å…¥: è‡ªç„¶è¯­è¨€è§„åˆ™                                               â”‚   â”‚
â”‚  â”‚  è¾“å‡º: CompiledRule (ç»“æ„åŒ–è§„åˆ™ + æ£€æµ‹æ¨¡å¼ + å‘é‡åµŒå…¥)            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                                    â”‚
â”‚                                    â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              ä¸‰å±‚æ£€æµ‹ç³»ç»Ÿ (Three-Layer Detection)                 â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  L1: å¿«é€Ÿæœ¬åœ°æ£€æµ‹ (Fast Local)           ~10ms                   â”‚   â”‚
â”‚  â”‚      â”œâ”€ å…³é”®è¯åŒ¹é…                                                â”‚   â”‚
â”‚  â”‚      â”œâ”€ æ­£åˆ™æ¨¡å¼åŒ¹é…                                              â”‚   â”‚
â”‚  â”‚      â””â”€ æ•°å€¼å±æ€§æ£€æµ‹                                              â”‚   â”‚
â”‚  â”‚                          â†“ å¯ç–‘å†…å®¹                               â”‚   â”‚
â”‚  â”‚  L2: è¯­ä¹‰å‘é‡æ£€æµ‹ (Semantic Vector)      ~50ms                   â”‚   â”‚
â”‚  â”‚      â”œâ”€ è§„åˆ™å‘é‡ vs è¾“å‡ºå‘é‡ ç›¸ä¼¼åº¦                               â”‚   â”‚
â”‚  â”‚      â””â”€ çŸ›ç›¾è¯­ä¹‰æ£€æµ‹                                              â”‚   â”‚
â”‚  â”‚                          â†“ é«˜é£é™©å†…å®¹                             â”‚   â”‚
â”‚  â”‚  L3: LLM ç²¾ç¡®åˆ¤æ–­ (LLM Verify)           ~1-2s                   â”‚   â”‚
â”‚  â”‚      â””â”€ åªå¯¹ L1/L2 æ ‡è®°çš„å¯ç–‘å†…å®¹è¿›è¡Œ LLM éªŒè¯                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                                    â”‚
â”‚                                    â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                ViolationHandler (è¿è§„å¤„ç†å™¨)                      â”‚   â”‚
â”‚  â”‚  â”œâ”€ WARN: è­¦å‘Šç”¨æˆ·ä½†ä¸é˜»æ­¢                                        â”‚   â”‚
â”‚  â”‚  â”œâ”€ BLOCK: é˜»æ­¢è¾“å‡ºå¹¶è¿”å›é”™è¯¯                                     â”‚   â”‚
â”‚  â”‚  â””â”€ SUGGEST: æä¾›ä¿®æ­£å»ºè®®                                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                           â–¼                           â–¼
   REST API               Python SDK                    Recall Engine
   /v1/rules/*            engine.rules.*               build_context()
```

---

## ğŸ“‹ æ¨¡å—è®¾è®¡

### 1. æ•°æ®æ¨¡å‹

```python
# recall/processor/rule_engine/models.py

from dataclasses import dataclass, field
from enum import Enum
from typing import List, Dict, Any, Optional
from datetime import datetime

class RuleType(Enum):
    """è§„åˆ™ç±»å‹"""
    PROHIBITION = "prohibition"      # ç¦æ­¢ï¼šä¸ä¼š/ä¸èƒ½/ç¦æ­¢
    REQUIREMENT = "requirement"      # å¿…é¡»ï¼šå¿…é¡»/ä¸€å®š/æ€»æ˜¯
    ATTRIBUTE = "attribute"          # å±æ€§ï¼šXçš„Yæ˜¯Z
    RELATIONSHIP = "relationship"    # å…³ç³»ï¼šAå’ŒBæ˜¯Xå…³ç³»
    CONDITION = "condition"          # æ¡ä»¶ï¼šå¦‚æœXåˆ™Y
    WORLD = "world"                  # ä¸–ç•Œè§‚ï¼šè¿™ä¸ªä¸–ç•Œæ²¡æœ‰X

class RuleSeverity(Enum):
    """è¿è§„ä¸¥é‡ç¨‹åº¦"""
    CRITICAL = "critical"    # ä¸¥é‡ï¼šå¿…é¡»é˜»æ­¢
    HIGH = "high"            # é«˜ï¼šå¼ºçƒˆè­¦å‘Š
    MEDIUM = "medium"        # ä¸­ï¼šæ™®é€šè­¦å‘Š
    LOW = "low"              # ä½ï¼šæç¤º

class ViolationAction(Enum):
    """è¿è§„å¤„ç†æ–¹å¼"""
    BLOCK = "block"          # é˜»æ­¢è¾“å‡º
    WARN = "warn"            # è­¦å‘Šä½†ä¸é˜»æ­¢
    SUGGEST = "suggest"      # æä¾›ä¿®æ­£å»ºè®®
    LOG = "log"              # ä»…è®°å½•

@dataclass
class CompiledRule:
    """ç¼–è¯‘åçš„è§„åˆ™"""
    id: str
    original_text: str                          # åŸå§‹è‡ªç„¶è¯­è¨€
    rule_type: RuleType
    severity: RuleSeverity = RuleSeverity.HIGH
    action: ViolationAction = ViolationAction.WARN
    
    # è§„åˆ™å‚æ•°ï¼ˆè§£æåï¼‰
    subject: str = ""                           # ä¸»ä½“
    predicate: str = ""                         # è°“è¯/åŠ¨ä½œ/å±æ€§å
    object: str = ""                            # å®¾è¯­/å±æ€§å€¼
    
    # æ£€æµ‹æ¨¡å¼ï¼ˆL1 å¿«é€Ÿæ£€æµ‹ç”¨ï¼‰
    keywords: List[str] = field(default_factory=list)
    patterns: List[str] = field(default_factory=list)      # æ­£åˆ™
    anti_patterns: List[str] = field(default_factory=list) # åå‘æ¨¡å¼ï¼ˆè¿è§„æ¨¡å¼ï¼‰
    
    # è¯­ä¹‰æ£€æµ‹ï¼ˆL2 ç”¨ï¼‰
    embedding: Optional[List[float]] = None     # è§„åˆ™çš„å‘é‡åµŒå…¥
    contradiction_keywords: List[str] = field(default_factory=list)  # çŸ›ç›¾å…³é”®è¯
    
    # å…ƒä¿¡æ¯
    enabled: bool = True
    user_id: str = "default"
    character_id: str = "default"
    created_at: datetime = field(default_factory=datetime.now)
    source: str = "manual"                      # manual / extracted / imported
    
    # ç»Ÿè®¡
    check_count: int = 0
    violation_count: int = 0

@dataclass
class Violation:
    """è¿è§„è®°å½•"""
    rule_id: str
    rule_text: str
    rule_type: RuleType
    severity: RuleSeverity
    
    evidence: str                               # è¿è§„è¯æ®ï¼ˆåŸæ–‡ç‰‡æ®µï¼‰
    detection_layer: str                        # L1/L2/L3
    confidence: float                           # ç½®ä¿¡åº¦ 0-1
    
    suggestion: Optional[str] = None            # ä¿®æ­£å»ºè®®
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class CheckResult:
    """æ£€æµ‹ç»“æœ"""
    is_compliant: bool                          # æ˜¯å¦åˆè§„
    violations: List[Violation] = field(default_factory=list)
    warnings: List[Violation] = field(default_factory=list)
    check_time_ms: float = 0
    layers_used: List[str] = field(default_factory=list)  # ["L1", "L2", "L3"]
```

---

### 2. è§„åˆ™ç¼–è¯‘å™¨

```python
# recall/processor/rule_engine/compiler.py

class RuleCompiler:
    """è§„åˆ™ç¼–è¯‘å™¨ - å°†è‡ªç„¶è¯­è¨€è§„åˆ™è½¬æ¢ä¸ºå¯æ‰§è¡Œæ£€æµ‹"""
    
    # === è§„åˆ™æ¨¡å¼åº“ ===
    PATTERNS = {
        'prohibition': [
            # ä¸­æ–‡ç¦æ­¢æ¨¡å¼
            (r'^(.+?)(ä¸ä¼š|ä¸èƒ½|ç¦æ­¢|ç»ä¸|ä»ä¸|æ°¸è¿œä¸|å†³ä¸|ä¸å¯ä»¥|ä¸å‡†)(.+)$', 'zh'),
            # è‹±æ–‡ç¦æ­¢æ¨¡å¼
            (r'^(.+?)\s+(will not|cannot|must not|never|won\'t|can\'t)\s+(.+)$', 'en'),
        ],
        'requirement': [
            (r'^(.+?)(å¿…é¡»|ä¸€å®šè¦?|æ€»æ˜¯|å§‹ç»ˆ|åº”è¯¥|éœ€è¦)(.+)$', 'zh'),
            (r'^(.+?)\s+(must|always|should|needs? to)\s+(.+)$', 'en'),
        ],
        'attribute': [
            (r'^(.+?)çš„(.+?)(æ˜¯|ä¸º|å«åš?)(.+)$', 'zh'),
            (r'^(.+?)\'s\s+(.+?)\s+(is|are|equals?)\s+(.+)$', 'en'),
        ],
        'relationship': [
            (r'^(.+?)(å’Œ|ä¸|è·Ÿ)(.+?)(æ˜¯|çš„å…³ç³»æ˜¯)(.+)$', 'zh'),
            (r'^(.+?)\s+(and|with)\s+(.+?)\s+(are|is)\s+(.+)$', 'en'),
        ],
        'world': [
            (r'^(è¿™ä¸ªä¸–ç•Œ|ä¸–ç•Œè§‚|è®¾å®šä¸­?)(æ²¡æœ‰|ä¸å­˜åœ¨|ç¦æ­¢|ä¸å…è®¸)(.+)$', 'zh'),
            (r'^(this world|the setting)\s+(has no|doesn\'t have|forbids)\s+(.+)$', 'en'),
        ],
    }
    
    # === åŠ¨ä½œåŒä¹‰è¯/å˜ä½“è¯åº“ ===
    ACTION_VARIANTS = {
        'æ€äºº': ['æ€', 'æ€æ­»', 'æ€å®³', 'å¼‘', 'è°‹æ€', 'åˆºæ€', 'æ–©æ€', 'æ€æ‰'],
        'è¯´è°': ['è¯´è°', 'æ’’è°', 'æ¬ºéª—', 'éª—', 'è°ç§°', 'å‡è£…'],
        'å·çªƒ': ['å·', 'ç›—', 'çªƒ', 'å·çªƒ', 'ç›—çªƒ', 'é¡ºæ‰‹ç‰µç¾Š'],
        'é£è¡Œ': ['é£', 'é£è¡Œ', 'é£ç¿”', 'é£èµ·', 'è…¾ç©º', 'å‡ç©º'],
        'é­”æ³•': ['é­”æ³•', 'æ³•æœ¯', 'å’’è¯­', 'æ–½æ³•', 'å¿µå’’', 'é­”åŠ›'],
        # ... å¯æ‰©å±•
    }
    
    # === å…³ç³»å¯¹ç«‹è¯å…¸ ===
    RELATIONSHIP_OPPOSITES = {
        'æ•Œäºº': ['æœ‹å‹', 'ç›Ÿå‹', 'æ‹äºº', 'ä¼™ä¼´', 'åŒä¼´', 'å¥½å‹'],
        'æœ‹å‹': ['æ•Œäºº', 'ä»‡äºº', 'å¯¹æ‰‹', 'ä»‡æ•Œ'],
        'æ‹äºº': ['æ•Œäºº', 'é™Œç”Ÿäºº', 'ä»‡äºº', 'å‰ä»»'],
        'ä¸»äºº': ['å¥´éš¶', 'ä»†äºº', 'ä¸‹å±'],
        'å¸ˆå‚…': ['å¾’å¼Ÿ', 'å­¦ç”Ÿ'],
        'çˆ¶äº²': ['å„¿å­', 'å¥³å„¿'],
        'æ¯äº²': ['å„¿å­', 'å¥³å„¿'],
        # ... å¯æ‰©å±•
    }
    
    def __init__(self, embedding_backend=None):
        self.embedding_backend = embedding_backend
    
    def compile(self, rule_text: str, **kwargs) -> CompiledRule:
        """ç¼–è¯‘å•æ¡è§„åˆ™"""
        import hashlib
        rule_id = f"rule_{hashlib.md5(rule_text.encode()).hexdigest()[:8]}"
        
        # 1. è¯†åˆ«è§„åˆ™ç±»å‹å¹¶è§£æ
        rule_type, parsed = self._parse_rule(rule_text)
        
        # 2. ç”Ÿæˆæ£€æµ‹æ¨¡å¼
        keywords, patterns, anti_patterns = self._generate_detection_patterns(
            rule_type, parsed, rule_text
        )
        
        # 3. ç”ŸæˆçŸ›ç›¾å…³é”®è¯
        contradiction_keywords = self._generate_contradiction_keywords(rule_type, parsed)
        
        # 4. ç”Ÿæˆå‘é‡åµŒå…¥ï¼ˆå¯é€‰ï¼‰
        embedding = None
        if self.embedding_backend:
            embedding = self.embedding_backend.encode(rule_text).tolist()
        
        # 5. ç¡®å®šä¸¥é‡ç¨‹åº¦
        severity = self._determine_severity(rule_type, rule_text)
        
        return CompiledRule(
            id=rule_id,
            original_text=rule_text,
            rule_type=rule_type,
            severity=severity,
            subject=parsed.get('subject', ''),
            predicate=parsed.get('predicate', ''),
            object=parsed.get('object', ''),
            keywords=keywords,
            patterns=patterns,
            anti_patterns=anti_patterns,
            contradiction_keywords=contradiction_keywords,
            embedding=embedding,
            **kwargs
        )
    
    def compile_batch(self, rules: List[str], **kwargs) -> List[CompiledRule]:
        """æ‰¹é‡ç¼–è¯‘è§„åˆ™"""
        return [self.compile(r, **kwargs) for r in rules]
    
    def _parse_rule(self, text: str) -> tuple:
        """è§£æè§„åˆ™æ–‡æœ¬"""
        import re
        
        for rule_type, patterns in self.PATTERNS.items():
            for pattern, lang in patterns:
                match = re.match(pattern, text.strip(), re.IGNORECASE)
                if match:
                    groups = match.groups()
                    parsed = self._extract_parsed_fields(rule_type, groups)
                    return RuleType(rule_type), parsed
        
        # æœªåŒ¹é…åˆ°æ¨¡å¼ï¼Œå°è¯•æ™ºèƒ½è§£æ
        return RuleType.PROHIBITION, {'raw': text}
    
    def _extract_parsed_fields(self, rule_type: str, groups: tuple) -> dict:
        """ä»åŒ¹é…ç»„æå–å­—æ®µ"""
        if rule_type == 'prohibition':
            return {
                'subject': groups[0].strip(),
                'predicate': 'not',
                'object': groups[2].strip() if len(groups) > 2 else ''
            }
        elif rule_type == 'attribute':
            return {
                'subject': groups[0].strip(),
                'predicate': groups[1].strip(),
                'object': groups[3].strip() if len(groups) > 3 else ''
            }
        elif rule_type == 'relationship':
            return {
                'subject': groups[0].strip(),
                'object': groups[2].strip(),
                'predicate': groups[4].strip() if len(groups) > 4 else ''
            }
        elif rule_type == 'world':
            return {
                'subject': 'ä¸–ç•Œ',
                'predicate': 'not_exist',
                'object': groups[2].strip() if len(groups) > 2 else ''
            }
        return {'raw': ' '.join(groups)}
    
    def _generate_detection_patterns(self, rule_type: RuleType, parsed: dict, text: str) -> tuple:
        """ç”Ÿæˆæ£€æµ‹æ¨¡å¼"""
        keywords = []
        patterns = []
        anti_patterns = []  # è¿è§„æ¨¡å¼
        
        subject = parsed.get('subject', '')
        obj = parsed.get('object', '')
        
        if rule_type == RuleType.PROHIBITION:
            # ç¦æ­¢è§„åˆ™ï¼šæ£€æµ‹æ˜¯å¦å‡ºç°äº†è¢«ç¦æ­¢çš„åŠ¨ä½œ
            keywords = [subject] if subject else []
            
            # è·å–åŠ¨ä½œå˜ä½“
            action_variants = self._get_action_variants(obj)
            keywords.extend(action_variants[:3])  # å–å‰3ä¸ªå…³é”®è¯
            
            # ç”Ÿæˆè¿è§„æ¨¡å¼
            for variant in action_variants:
                anti_patterns.extend([
                    f'{subject}.*{variant}äº†',
                    f'{subject}.*æ­£åœ¨{variant}',
                    f'{subject}.*å¼€å§‹{variant}',
                    f'{subject}.*{variant}ç€',
                    f'{variant}.*{subject}',  # è¢«åŠ¨å¥
                ])
        
        elif rule_type == RuleType.ATTRIBUTE:
            # å±æ€§è§„åˆ™ï¼šæ£€æµ‹æ˜¯å¦å‡ºç°äº†çŸ›ç›¾å±æ€§
            predicate = parsed.get('predicate', '')
            keywords = [subject, predicate]
            
            # å±æ€§å˜æ›´æ¨¡å¼
            anti_patterns = [
                f'{subject}çš„{predicate}(æ˜¯|ä¸º|å˜æˆäº†?)(?!{obj})',
            ]
        
        elif rule_type == RuleType.RELATIONSHIP:
            # å…³ç³»è§„åˆ™ï¼šæ£€æµ‹æ˜¯å¦å‡ºç°äº†çŸ›ç›¾å…³ç³»
            predicate = parsed.get('predicate', '')
            keywords = [subject, obj]
            
            # è·å–å¯¹ç«‹å…³ç³»
            opposites = self.RELATIONSHIP_OPPOSITES.get(predicate, [])
            for opposite in opposites:
                anti_patterns.extend([
                    f'{subject}.*{obj}.*{opposite}',
                    f'{obj}.*{subject}.*{opposite}',
                    f'{subject}.*å’Œ.*{obj}.*æˆä¸º.*{opposite}',
                ])
        
        elif rule_type == RuleType.WORLD:
            # ä¸–ç•Œè§‚è§„åˆ™ï¼šæ£€æµ‹æ˜¯å¦å‡ºç°äº†ä¸å­˜åœ¨çš„äº‹ç‰©
            keywords = self._get_action_variants(obj)[:5]
            anti_patterns = [f'.*{kw}.*' for kw in keywords]
        
        return keywords, patterns, anti_patterns
    
    def _get_action_variants(self, action: str) -> List[str]:
        """è·å–åŠ¨ä½œçš„æ‰€æœ‰å˜ä½“"""
        # å…ˆæŸ¥è¯åº“
        for base, variants in self.ACTION_VARIANTS.items():
            if action in variants or action == base:
                return variants
        # æ²¡æ‰¾åˆ°åˆ™è¿”å›åŸè¯ + ç®€å•å˜ä½“
        return [action, action + 'äº†', action + 'ç€', 'æ­£åœ¨' + action]
    
    def _generate_contradiction_keywords(self, rule_type: RuleType, parsed: dict) -> List[str]:
        """ç”ŸæˆçŸ›ç›¾å…³é”®è¯ï¼ˆç”¨äºè¯­ä¹‰æ£€æµ‹ï¼‰"""
        if rule_type == RuleType.RELATIONSHIP:
            predicate = parsed.get('predicate', '')
            return self.RELATIONSHIP_OPPOSITES.get(predicate, [])
        return []
    
    def _determine_severity(self, rule_type: RuleType, text: str) -> RuleSeverity:
        """ç¡®å®šè§„åˆ™ä¸¥é‡ç¨‹åº¦"""
        critical_keywords = ['ç»å¯¹', 'æ°¸è¿œ', 'å¿…é¡»', 'ç¦æ­¢', 'ä¸¥ç¦', 'ä¸å¯', 'must', 'never', 'absolutely']
        if any(kw in text.lower() for kw in critical_keywords):
            return RuleSeverity.CRITICAL
        if rule_type in [RuleType.PROHIBITION, RuleType.WORLD]:
            return RuleSeverity.HIGH
        return RuleSeverity.MEDIUM
```

---

### 3. ä¸‰å±‚æ£€æµ‹ç³»ç»Ÿ

```python
# recall/processor/rule_engine/detector.py

class ThreeLayerDetector:
    """ä¸‰å±‚æ£€æµ‹ç³»ç»Ÿ - å¿«é€Ÿ + å‡†ç¡® + ä½æˆæœ¬"""
    
    def __init__(
        self,
        embedding_backend=None,
        llm_client=None,
        config: dict = None
    ):
        self.embedding_backend = embedding_backend
        self.llm_client = llm_client
        self.config = config or {
            'l1_enabled': True,
            'l2_enabled': True,           # éœ€è¦ embedding_backend
            'l3_enabled': True,           # éœ€è¦ llm_client
            'l2_similarity_threshold': 0.75,  # è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼
            'l3_trigger_threshold': 0.6,      # è§¦å‘ L3 çš„ç½®ä¿¡åº¦é˜ˆå€¼
        }
    
    def check(self, text: str, rules: List[CompiledRule]) -> CheckResult:
        """æ£€æµ‹æ–‡æœ¬æ˜¯å¦è¿åè§„åˆ™"""
        import time
        start_time = time.time()
        
        violations = []
        warnings = []
        layers_used = []
        
        # === L1: å¿«é€Ÿæœ¬åœ°æ£€æµ‹ ===
        if self.config['l1_enabled']:
            layers_used.append('L1')
            l1_results = self._l1_fast_check(text, rules)
            
            for rule, confidence, evidence in l1_results:
                if confidence >= 0.9:
                    # é«˜ç½®ä¿¡åº¦ï¼Œç›´æ¥åˆ¤å®šè¿è§„
                    violations.append(self._create_violation(
                        rule, evidence, 'L1', confidence
                    ))
                elif confidence >= 0.5:
                    # ä¸­ç­‰ç½®ä¿¡åº¦ï¼Œæ ‡è®°ä¸ºå¯ç–‘ï¼Œè¿›å…¥ L2
                    warnings.append((rule, confidence, evidence))
        
        # === L2: è¯­ä¹‰å‘é‡æ£€æµ‹ ===
        if self.config['l2_enabled'] and self.embedding_backend and warnings:
            layers_used.append('L2')
            l2_results = self._l2_semantic_check(text, warnings)
            
            new_warnings = []
            for rule, confidence, evidence in l2_results:
                if confidence >= 0.85:
                    violations.append(self._create_violation(
                        rule, evidence, 'L2', confidence
                    ))
                elif confidence >= self.config['l3_trigger_threshold']:
                    new_warnings.append((rule, confidence, evidence))
            warnings = new_warnings
        
        # === L3: LLM ç²¾ç¡®åˆ¤æ–­ ===
        if self.config['l3_enabled'] and self.llm_client and warnings:
            layers_used.append('L3')
            l3_results = self._l3_llm_verify(text, warnings)
            
            for rule, confidence, evidence, suggestion in l3_results:
                if confidence >= 0.8:
                    v = self._create_violation(rule, evidence, 'L3', confidence)
                    v.suggestion = suggestion
                    violations.append(v)
        
        # è½¬æ¢å‰©ä½™ warnings
        final_warnings = [
            self._create_violation(r, e, 'L1', c)
            for r, c, e in warnings
        ]
        
        check_time_ms = (time.time() - start_time) * 1000
        
        return CheckResult(
            is_compliant=len(violations) == 0,
            violations=violations,
            warnings=final_warnings,
            check_time_ms=check_time_ms,
            layers_used=layers_used
        )
    
    def _l1_fast_check(self, text: str, rules: List[CompiledRule]) -> List[tuple]:
        """L1: å¿«é€Ÿæœ¬åœ°æ£€æµ‹ï¼ˆå…³é”®è¯ + æ­£åˆ™ï¼‰"""
        import re
        results = []
        
        for rule in rules:
            if not rule.enabled:
                continue
            
            confidence = 0.0
            evidence = ""
            
            # 1. å…³é”®è¯æ£€æµ‹
            keyword_matches = sum(1 for kw in rule.keywords if kw in text)
            if keyword_matches > 0:
                confidence = min(0.3, keyword_matches * 0.1)
            
            # 2. è¿è§„æ¨¡å¼æ£€æµ‹ï¼ˆæ ¸å¿ƒï¼‰
            for pattern in rule.anti_patterns:
                try:
                    match = re.search(pattern, text, re.IGNORECASE)
                    if match:
                        confidence = max(confidence, 0.8)
                        evidence = match.group(0)[:100]
                        break
                except re.error:
                    continue
            
            # 3. çŸ›ç›¾å…³é”®è¯æ£€æµ‹
            if rule.contradiction_keywords:
                for ck in rule.contradiction_keywords:
                    if ck in text and rule.subject in text:
                        confidence = max(confidence, 0.6)
                        # æ‰¾åˆ°åŒ…å«çŸ›ç›¾è¯çš„å¥å­
                        for sent in text.split('ã€‚'):
                            if ck in sent:
                                evidence = sent[:100]
                                break
            
            if confidence > 0.3:
                results.append((rule, confidence, evidence))
        
        return results
    
    def _l2_semantic_check(self, text: str, suspects: List[tuple]) -> List[tuple]:
        """L2: è¯­ä¹‰å‘é‡æ£€æµ‹"""
        import numpy as np
        
        results = []
        text_embedding = self.embedding_backend.encode(text)
        
        for rule, l1_confidence, evidence in suspects:
            if rule.embedding is None:
                # æ²¡æœ‰å‘é‡ï¼Œä¿æŒ L1 ç»“æœ
                results.append((rule, l1_confidence, evidence))
                continue
            
            rule_embedding = np.array(rule.embedding)
            
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            similarity = np.dot(text_embedding, rule_embedding) / (
                np.linalg.norm(text_embedding) * np.linalg.norm(rule_embedding)
            )
            
            # å¯¹äºç¦æ­¢è§„åˆ™ï¼Œé«˜ç›¸ä¼¼åº¦åè€Œè¯´æ˜å¯èƒ½è¿è§„
            if rule.rule_type == RuleType.PROHIBITION:
                # æ£€æµ‹æ–‡æœ¬æ˜¯å¦åœ¨"æ‰§è¡Œ"è¢«ç¦æ­¢çš„åŠ¨ä½œ
                action_embedding = self.embedding_backend.encode(rule.object)
                action_similarity = np.dot(text_embedding, action_embedding) / (
                    np.linalg.norm(text_embedding) * np.linalg.norm(action_embedding)
                )
                
                if action_similarity > self.config['l2_similarity_threshold']:
                    # è¯­ä¹‰ä¸Šç¡®å®åœ¨æè¿°è¢«ç¦æ­¢çš„åŠ¨ä½œ
                    confidence = min(0.95, l1_confidence + 0.2)
                    results.append((rule, confidence, evidence))
                    continue
            
            # ç»¼åˆ L1 å’Œ L2 ç½®ä¿¡åº¦
            final_confidence = l1_confidence * 0.6 + similarity * 0.4
            results.append((rule, final_confidence, evidence))
        
        return results
    
    def _l3_llm_verify(self, text: str, suspects: List[tuple]) -> List[tuple]:
        """L3: LLM ç²¾ç¡®åˆ¤æ–­ï¼ˆåªå¤„ç†å¯ç–‘å†…å®¹ï¼‰"""
        results = []
        
        # æ‰¹é‡å¤„ç†ä»¥èŠ‚çœæˆæœ¬
        rules_to_check = [(r, c, e) for r, c, e in suspects if c >= self.config['l3_trigger_threshold']]
        
        if not rules_to_check:
            return results
        
        prompt = self._build_llm_prompt(text, rules_to_check)
        
        try:
            response = self.llm_client.chat(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=1000
            )
            
            parsed = self._parse_llm_response(response)
            
            for rule, _, evidence in rules_to_check:
                rule_result = parsed.get(rule.id, {})
                if rule_result.get('violated', False):
                    results.append((
                        rule,
                        rule_result.get('confidence', 0.9),
                        rule_result.get('evidence', evidence),
                        rule_result.get('suggestion', None)
                    ))
        
        except Exception as e:
            print(f"[RuleEngine] L3 LLM æ£€æµ‹å¤±è´¥: {e}")
            # å¤±è´¥æ—¶ä¿å®ˆå¤„ç†ï¼šå°†é«˜ç½®ä¿¡åº¦çš„æ ‡è®°ä¸ºè¿è§„
            for rule, confidence, evidence in rules_to_check:
                if confidence >= 0.7:
                    results.append((rule, confidence, evidence, None))
        
        return results
    
    def _build_llm_prompt(self, text: str, suspects: List[tuple]) -> str:
        """æ„å»º LLM æ£€æµ‹æç¤ºè¯"""
        rules_text = "\n".join([
            f"- [{r.id}] {r.original_text} (ç±»å‹: {r.rule_type.value})"
            for r, _, _ in suspects
        ])
        
        return f'''ä½ æ˜¯ä¸€ä¸ªè§„åˆ™åˆè§„æ£€æµ‹ä¸“å®¶ã€‚è¯·åˆ¤æ–­ä»¥ä¸‹æ–‡æœ¬æ˜¯å¦è¿åäº†ç»™å®šçš„è§„åˆ™ã€‚

## éœ€è¦æ£€æŸ¥çš„è§„åˆ™ï¼š
{rules_text}

## å¾…æ£€æµ‹çš„æ–‡æœ¬ï¼š
{text[:2000]}

## è¯·ä»¥ JSON æ ¼å¼è¿”å›æ£€æµ‹ç»“æœï¼š
```json
{{
  "rule_xxx": {{
    "violated": true/false,
    "confidence": 0.0-1.0,
    "evidence": "è¿è§„è¯æ®ï¼ˆå¼•ç”¨åŸæ–‡ï¼‰",
    "suggestion": "ä¿®æ­£å»ºè®®ï¼ˆå¦‚æœè¿è§„ï¼‰"
  }}
}}
```

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚å¯¹äºæœªè¿è§„çš„è§„åˆ™ï¼Œå¯ä»¥çœç•¥æˆ–è®¾ç½® violated=falseã€‚'''
    
    def _parse_llm_response(self, response: str) -> dict:
        """è§£æ LLM å“åº”"""
        import json
        try:
            if "```json" in response:
                response = response.split("```json")[1].split("```")[0]
            elif "```" in response:
                response = response.split("```")[1].split("```")[0]
            return json.loads(response.strip())
        except:
            return {}
    
    def _create_violation(self, rule: CompiledRule, evidence: str, 
                          layer: str, confidence: float) -> Violation:
        """åˆ›å»ºè¿è§„è®°å½•"""
        return Violation(
            rule_id=rule.id,
            rule_text=rule.original_text,
            rule_type=rule.rule_type,
            severity=rule.severity,
            evidence=evidence,
            detection_layer=layer,
            confidence=confidence
        )
```

---

### 4. è§„åˆ™å­˜å‚¨ & ç®¡ç†

```python
# recall/processor/rule_engine/store.py

class RuleStore:
    """è§„åˆ™å­˜å‚¨ - æŒä¹…åŒ– + å¤šç§Ÿæˆ·éš”ç¦»"""
    
    def __init__(self, data_path: str, compiler: RuleCompiler):
        self.data_path = data_path
        self.compiler = compiler
        self._rules: Dict[str, Dict[str, List[CompiledRule]]] = {}  # user_id -> char_id -> rules
        self._load_all()
    
    def _get_storage_path(self, user_id: str, character_id: str) -> str:
        """è·å–è§„åˆ™å­˜å‚¨è·¯å¾„"""
        return os.path.join(self.data_path, user_id, character_id, 'rules.json')
    
    def _load_all(self):
        """åŠ è½½æ‰€æœ‰ç”¨æˆ·çš„è§„åˆ™"""
        if not os.path.exists(self.data_path):
            return
        
        for user_id in os.listdir(self.data_path):
            user_path = os.path.join(self.data_path, user_id)
            if not os.path.isdir(user_path):
                continue
            
            for char_id in os.listdir(user_path):
                char_path = os.path.join(user_path, char_id)
                if not os.path.isdir(char_path):
                    continue
                
                rules_file = os.path.join(char_path, 'rules.json')
                if os.path.exists(rules_file):
                    self._load_rules(user_id, char_id, rules_file)
    
    def _load_rules(self, user_id: str, char_id: str, file_path: str):
        """åŠ è½½è§„åˆ™æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if user_id not in self._rules:
                self._rules[user_id] = {}
            if char_id not in self._rules[user_id]:
                self._rules[user_id][char_id] = []
            
            for rule_data in data.get('rules', []):
                rule = self._deserialize_rule(rule_data)
                self._rules[user_id][char_id].append(rule)
        
        except Exception as e:
            print(f"[RuleStore] åŠ è½½è§„åˆ™å¤±è´¥ ({user_id}/{char_id}): {e}")
    
    def _save_rules(self, user_id: str, character_id: str):
        """ä¿å­˜è§„åˆ™åˆ°æ–‡ä»¶"""
        file_path = self._get_storage_path(user_id, character_id)
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        rules = self.get_rules(user_id, character_id)
        data = {
            'rules': [self._serialize_rule(r) for r in rules],
            'updated_at': datetime.now().isoformat()
        }
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def add_rule(
        self, 
        rule_text: str, 
        user_id: str = "default",
        character_id: str = "default",
        **kwargs
    ) -> CompiledRule:
        """æ·»åŠ è§„åˆ™"""
        rule = self.compiler.compile(rule_text, user_id=user_id, character_id=character_id, **kwargs)
        
        if user_id not in self._rules:
            self._rules[user_id] = {}
        if character_id not in self._rules[user_id]:
            self._rules[user_id][character_id] = []
        
        # æ£€æŸ¥é‡å¤
        for existing in self._rules[user_id][character_id]:
            if existing.original_text == rule_text:
                return existing
        
        self._rules[user_id][character_id].append(rule)
        self._save_rules(user_id, character_id)
        return rule
    
    def add_rules_batch(
        self, 
        rules: List[str], 
        user_id: str = "default",
        character_id: str = "default"
    ) -> List[CompiledRule]:
        """æ‰¹é‡æ·»åŠ è§„åˆ™"""
        compiled = []
        for rule_text in rules:
            compiled.append(self.add_rule(rule_text, user_id, character_id))
        return compiled
    
    def get_rules(
        self, 
        user_id: str = "default", 
        character_id: str = "default"
    ) -> List[CompiledRule]:
        """è·å–è§„åˆ™åˆ—è¡¨"""
        return self._rules.get(user_id, {}).get(character_id, [])
    
    def get_all_rules(self, user_id: str = "default") -> List[CompiledRule]:
        """è·å–ç”¨æˆ·æ‰€æœ‰è§’è‰²çš„è§„åˆ™"""
        all_rules = []
        for char_rules in self._rules.get(user_id, {}).values():
            all_rules.extend(char_rules)
        return all_rules
    
    def remove_rule(
        self, 
        rule_id: str, 
        user_id: str = "default",
        character_id: str = "default"
    ) -> bool:
        """åˆ é™¤è§„åˆ™"""
        rules = self._rules.get(user_id, {}).get(character_id, [])
        for i, rule in enumerate(rules):
            if rule.id == rule_id:
                rules.pop(i)
                self._save_rules(user_id, character_id)
                return True
        return False
    
    def update_rule(
        self, 
        rule_id: str, 
        updates: dict,
        user_id: str = "default",
        character_id: str = "default"
    ) -> Optional[CompiledRule]:
        """æ›´æ–°è§„åˆ™"""
        rules = self._rules.get(user_id, {}).get(character_id, [])
        for rule in rules:
            if rule.id == rule_id:
                for key, value in updates.items():
                    if hasattr(rule, key):
                        setattr(rule, key, value)
                self._save_rules(user_id, character_id)
                return rule
        return None
    
    def import_from_character_card(
        self, 
        character_card: str,
        user_id: str = "default",
        character_id: str = "default"
    ) -> List[CompiledRule]:
        """ä»è§’è‰²å¡æå–è§„åˆ™"""
        # ä½¿ç”¨æ­£åˆ™æå–å±æ€§æè¿°
        import re
        
        extracted_rules = []
        
        # æå–"Xæ˜¯Y"æ ¼å¼çš„å±æ€§
        attr_patterns = [
            r'(å§“å|åå­—|å¹´é¾„|èº«é«˜|ä½“é‡|å‘è‰²|ç³è‰²|æ€§æ ¼|èŒä¸š)[:ï¼šæ˜¯ä¸º]?\s*(.+?)(?:[,ï¼Œã€‚\n]|$)',
            r'(name|age|height|weight|hair|eyes|personality|occupation)[:ï¼š]?\s*(.+?)(?:[,.\n]|$)',
        ]
        
        for pattern in attr_patterns:
            for match in re.finditer(pattern, character_card, re.IGNORECASE):
                attr_name = match.group(1)
                attr_value = match.group(2).strip()
                if attr_value:
                    rule_text = f"è§’è‰²çš„{attr_name}æ˜¯{attr_value}"
                    extracted_rules.append(rule_text)
        
        # æå–"ä¸ä¼š/ä¸èƒ½"æ ¼å¼çš„ç¦æ­¢è§„åˆ™
        prohibition_patterns = [
            r'(ä¸ä¼š|ä¸èƒ½|ç¦æ­¢|ç»ä¸|ä»ä¸)(.+?)(?:[,ï¼Œã€‚\n]|$)',
        ]
        
        for pattern in prohibition_patterns:
            for match in re.finditer(pattern, character_card):
                action = match.group(2).strip()
                if action:
                    rule_text = f"è§’è‰²{match.group(1)}{action}"
                    extracted_rules.append(rule_text)
        
        # ç¼–è¯‘å¹¶æ·»åŠ 
        return self.add_rules_batch(extracted_rules, user_id, character_id)
    
    def _serialize_rule(self, rule: CompiledRule) -> dict:
        """åºåˆ—åŒ–è§„åˆ™"""
        return {
            'id': rule.id,
            'original_text': rule.original_text,
            'rule_type': rule.rule_type.value,
            'severity': rule.severity.value,
            'action': rule.action.value,
            'subject': rule.subject,
            'predicate': rule.predicate,
            'object': rule.object,
            'keywords': rule.keywords,
            'patterns': rule.patterns,
            'anti_patterns': rule.anti_patterns,
            'contradiction_keywords': rule.contradiction_keywords,
            'embedding': rule.embedding,
            'enabled': rule.enabled,
            'source': rule.source,
            'created_at': rule.created_at.isoformat(),
        }
    
    def _deserialize_rule(self, data: dict) -> CompiledRule:
        """ååºåˆ—åŒ–è§„åˆ™"""
        return CompiledRule(
            id=data['id'],
            original_text=data['original_text'],
            rule_type=RuleType(data['rule_type']),
            severity=RuleSeverity(data.get('severity', 'high')),
            action=ViolationAction(data.get('action', 'warn')),
            subject=data.get('subject', ''),
            predicate=data.get('predicate', ''),
            object=data.get('object', ''),
            keywords=data.get('keywords', []),
            patterns=data.get('patterns', []),
            anti_patterns=data.get('anti_patterns', []),
            contradiction_keywords=data.get('contradiction_keywords', []),
            embedding=data.get('embedding'),
            enabled=data.get('enabled', True),
            source=data.get('source', 'imported'),
            created_at=datetime.fromisoformat(data['created_at']) if 'created_at' in data else datetime.now()
        )
```

---

### 5. ä¸»å¼•æ“ç±»

```python
# recall/processor/rule_engine/engine.py

class RuleEngine:
    """è§„åˆ™å¼•æ“ - ç»Ÿä¸€å…¥å£"""
    
    def __init__(
        self,
        data_path: str,
        embedding_backend=None,
        llm_client=None,
        config: dict = None
    ):
        self.data_path = data_path
        self.embedding_backend = embedding_backend
        self.llm_client = llm_client
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.compiler = RuleCompiler(embedding_backend)
        self.store = RuleStore(data_path, self.compiler)
        self.detector = ThreeLayerDetector(
            embedding_backend=embedding_backend,
            llm_client=llm_client,
            config=config
        )
        
        # é…ç½®
        self.config = config or {}
        self.default_action = ViolationAction(
            self.config.get('default_action', 'warn')
        )
    
    # === è§„åˆ™ç®¡ç† API ===
    
    def add_rule(self, rule_text: str, **kwargs) -> CompiledRule:
        """æ·»åŠ è§„åˆ™"""
        return self.store.add_rule(rule_text, **kwargs)
    
    def add_rules(self, rules: List[str], **kwargs) -> List[CompiledRule]:
        """æ‰¹é‡æ·»åŠ è§„åˆ™"""
        return self.store.add_rules_batch(rules, **kwargs)
    
    def get_rules(self, **kwargs) -> List[CompiledRule]:
        """è·å–è§„åˆ™"""
        return self.store.get_rules(**kwargs)
    
    def remove_rule(self, rule_id: str, **kwargs) -> bool:
        """åˆ é™¤è§„åˆ™"""
        return self.store.remove_rule(rule_id, **kwargs)
    
    def import_from_character(self, character_card: str, **kwargs) -> List[CompiledRule]:
        """ä»è§’è‰²å¡å¯¼å…¥è§„åˆ™"""
        return self.store.import_from_character_card(character_card, **kwargs)
    
    # === æ£€æµ‹ API ===
    
    def check(
        self, 
        text: str, 
        user_id: str = "default",
        character_id: str = "default",
        include_global: bool = True
    ) -> CheckResult:
        """æ£€æµ‹æ–‡æœ¬æ˜¯å¦è¿è§„"""
        # æ”¶é›†é€‚ç”¨çš„è§„åˆ™
        rules = self.store.get_rules(user_id, character_id)
        
        if include_global:
            # ä¹ŸåŒ…å«å…¨å±€è§„åˆ™ï¼ˆuser_id="global"ï¼‰
            global_rules = self.store.get_rules("global", "global")
            rules = rules + global_rules
        
        # æ‰§è¡Œæ£€æµ‹
        result = self.detector.check(text, rules)
        
        # æ›´æ–°ç»Ÿè®¡
        for rule in rules:
            rule.check_count += 1
        for v in result.violations:
            for rule in rules:
                if rule.id == v.rule_id:
                    rule.violation_count += 1
        
        return result
    
    def check_and_handle(
        self, 
        text: str,
        **kwargs
    ) -> tuple:
        """æ£€æµ‹å¹¶å¤„ç†è¿è§„
        
        Returns:
            (is_allowed, result, handled_text)
        """
        result = self.check(text, **kwargs)
        
        if result.is_compliant:
            return True, result, text
        
        # æ ¹æ®æœ€ä¸¥é‡çš„è¿è§„å†³å®šå¤„ç†æ–¹å¼
        most_severe = max(result.violations, key=lambda v: v.severity.value)
        
        # æŸ¥æ‰¾å¯¹åº”è§„åˆ™çš„ action
        rules = self.get_rules(**kwargs)
        action = self.default_action
        for rule in rules:
            if rule.id == most_severe.rule_id:
                action = rule.action
                break
        
        if action == ViolationAction.BLOCK:
            return False, result, None
        elif action == ViolationAction.WARN:
            return True, result, text
        elif action == ViolationAction.SUGGEST:
            # å¦‚æœæœ‰ä¿®æ­£å»ºè®®ï¼Œå¯ä»¥è¿”å›
            if most_severe.suggestion:
                return True, result, most_severe.suggestion
            return True, result, text
        else:
            return True, result, text
    
    # === ä¸ Recall Engine é›†æˆ ===
    
    def inject_rules_context(
        self, 
        user_id: str = "default",
        character_id: str = "default"
    ) -> str:
        """ç”Ÿæˆè§„åˆ™ä¸Šä¸‹æ–‡æ³¨å…¥æ–‡æœ¬ï¼ˆç”¨äº build_contextï¼‰"""
        rules = self.get_rules(user_id=user_id, character_id=character_id)
        
        if not rules:
            return ""
        
        lines = ["ã€å¿…é¡»éµå®ˆçš„è§„åˆ™ã€‘"]
        
        for rule in rules:
            if rule.enabled:
                severity_icon = {
                    RuleSeverity.CRITICAL: "ğŸ”´",
                    RuleSeverity.HIGH: "ğŸŸ ",
                    RuleSeverity.MEDIUM: "ğŸŸ¡",
                    RuleSeverity.LOW: "ğŸŸ¢",
                }.get(rule.severity, "âšª")
                lines.append(f"{severity_icon} {rule.original_text}")
        
        return "\n".join(lines)
```

---

### 6. REST API

```python
# åœ¨ recall/server.py ä¸­æ·»åŠ 

# === è§„åˆ™å¼•æ“ API ===

@app.post("/v1/rules", tags=["Rules"])
async def add_rule(
    rule_text: str = Body(..., embed=True),
    user_id: str = Query(default="default"),
    character_id: str = Query(default="default"),
    severity: str = Query(default="high"),
    action: str = Query(default="warn")
):
    """æ·»åŠ è§„åˆ™"""
    rule = engine.rule_engine.add_rule(
        rule_text,
        user_id=user_id,
        character_id=character_id,
        severity=RuleSeverity(severity),
        action=ViolationAction(action)
    )
    return {
        "id": rule.id,
        "type": rule.rule_type.value,
        "severity": rule.severity.value,
        "parsed": {
            "subject": rule.subject,
            "predicate": rule.predicate,
            "object": rule.object
        }
    }

@app.post("/v1/rules/batch", tags=["Rules"])
async def add_rules_batch(
    rules: List[str] = Body(...),
    user_id: str = Query(default="default"),
    character_id: str = Query(default="default")
):
    """æ‰¹é‡æ·»åŠ è§„åˆ™"""
    compiled = engine.rule_engine.add_rules(rules, user_id=user_id, character_id=character_id)
    return {"added": len(compiled), "rules": [r.id for r in compiled]}

@app.get("/v1/rules", tags=["Rules"])
async def list_rules(
    user_id: str = Query(default="default"),
    character_id: str = Query(default="default")
):
    """è·å–è§„åˆ™åˆ—è¡¨"""
    rules = engine.rule_engine.get_rules(user_id=user_id, character_id=character_id)
    return [
        {
            "id": r.id,
            "text": r.original_text,
            "type": r.rule_type.value,
            "severity": r.severity.value,
            "enabled": r.enabled,
            "check_count": r.check_count,
            "violation_count": r.violation_count
        }
        for r in rules
    ]

@app.delete("/v1/rules/{rule_id}", tags=["Rules"])
async def delete_rule(
    rule_id: str,
    user_id: str = Query(default="default"),
    character_id: str = Query(default="default")
):
    """åˆ é™¤è§„åˆ™"""
    success = engine.rule_engine.remove_rule(rule_id, user_id=user_id, character_id=character_id)
    return {"success": success}

@app.post("/v1/rules/check", tags=["Rules"])
async def check_text(
    text: str = Body(..., embed=True),
    user_id: str = Query(default="default"),
    character_id: str = Query(default="default")
):
    """æ£€æµ‹æ–‡æœ¬æ˜¯å¦è¿è§„"""
    result = engine.rule_engine.check(text, user_id=user_id, character_id=character_id)
    return {
        "compliant": result.is_compliant,
        "check_time_ms": result.check_time_ms,
        "layers_used": result.layers_used,
        "violations": [
            {
                "rule_id": v.rule_id,
                "rule_text": v.rule_text,
                "severity": v.severity.value,
                "evidence": v.evidence,
                "confidence": v.confidence,
                "suggestion": v.suggestion
            }
            for v in result.violations
        ],
        "warnings": len(result.warnings)
    }

@app.post("/v1/rules/import/character", tags=["Rules"])
async def import_from_character(
    character_card: str = Body(..., embed=True),
    user_id: str = Query(default="default"),
    character_id: str = Query(default="default")
):
    """ä»è§’è‰²å¡è‡ªåŠ¨æå–è§„åˆ™"""
    rules = engine.rule_engine.import_from_character(
        character_card, 
        user_id=user_id, 
        character_id=character_id
    )
    return {
        "extracted": len(rules),
        "rules": [{"id": r.id, "text": r.original_text, "type": r.rule_type.value} for r in rules]
    }
```

---

## ğŸ“… å®ç°è®¡åˆ’

| é˜¶æ®µ | ä»»åŠ¡ | å·¥æ—¶ | äº§å‡º |
|------|------|:----:|------|
| **Phase 1** | æ•°æ®æ¨¡å‹ + è§„åˆ™ç¼–è¯‘å™¨ | 1å¤© | `models.py`, `compiler.py` |
| **Phase 2** | ä¸‰å±‚æ£€æµ‹ç³»ç»Ÿ | 1.5å¤© | `detector.py` |
| **Phase 3** | è§„åˆ™å­˜å‚¨ + ä¸»å¼•æ“ | 1å¤© | `store.py`, engine.py |
| **Phase 4** | REST API + é›†æˆæµ‹è¯• | 0.5å¤© | API ç«¯ç‚¹ |
| **Phase 5** | ä¸ RecallEngine é›†æˆ | 0.5å¤© | `build_context` æ³¨å…¥ |
| **Phase 6** | ST æ’ä»¶å‰ç«¯ï¼ˆå¯é€‰ï¼‰ | 1å¤© | UI æ›´æ–° |
| **æ€»è®¡** | | **5-6å¤©** | |

---

## âœ… éªŒæ”¶æ ‡å‡†

| æµ‹è¯•åœºæ™¯ | è¾“å…¥ | æœŸæœ›ç»“æœ |
|----------|------|----------|
| ç¦æ­¢è§„åˆ™-ç›´æ¥è¿è§„ | è§„åˆ™="è§’è‰²ä¸ä¼šæ€äºº"<br>æ–‡æœ¬="è§’è‰²æ€æ­»äº†æ•Œäºº" | L1 æ£€æµ‹ï¼Œç½®ä¿¡åº¦â‰¥0.8 |
| ç¦æ­¢è§„åˆ™-å˜ä½“è¿è§„ | è§„åˆ™="è§’è‰²ä¸ä¼šæ€äºº"<br>æ–‡æœ¬="è§’è‰²åˆºæ€äº†æ•Œäºº" | L1/L2 æ£€æµ‹ï¼Œç½®ä¿¡åº¦â‰¥0.7 |
| ç¦æ­¢è§„åˆ™-æ— è¿è§„ | è§„åˆ™="è§’è‰²ä¸ä¼šæ€äºº"<br>æ–‡æœ¬="è§’è‰²æ‰“ä¼¤äº†æ•Œäºº" | æ— è¿è§„ |
| å±æ€§è§„åˆ™ | è§„åˆ™="è§’è‰²çš„å‘è‰²æ˜¯é»‘è‰²"<br>æ–‡æœ¬="è§’è‰²çš„é‡‘è‰²é•¿å‘" | L1 æ£€æµ‹ |
| å…³ç³»è§„åˆ™ | è§„åˆ™="Aå’ŒBæ˜¯æ•Œäºº"<br>æ–‡æœ¬="Aå’ŒBæˆä¸ºäº†æœ‹å‹" | L1/L2 æ£€æµ‹ |
| ä¸–ç•Œè§‚è§„åˆ™ | è§„åˆ™="è¿™ä¸ªä¸–ç•Œæ²¡æœ‰é­”æ³•"<br>æ–‡æœ¬="ä»–æ–½å±•äº†ç«çƒæœ¯" | L1 æ£€æµ‹ |
| æ€§èƒ½æµ‹è¯• | 100æ¡è§„åˆ™æ£€æµ‹ | L1 <100ms |
| æ‰¹é‡å¯¼å…¥ | è§’è‰²å¡æ–‡æœ¬ | è‡ªåŠ¨æå–å±æ€§è§„åˆ™ |

---

## ğŸ’° æˆæœ¬ä¼°ç®—

| åœºæ™¯ | L1 æˆæœ¬ | L2 æˆæœ¬ | L3 æˆæœ¬ | æ€»æˆæœ¬ |
|------|:-------:|:-------:|:-------:|:------:|
| å¤§å¤šæ•°æƒ…å†µï¼ˆæ— è¿è§„ï¼‰ | å…è´¹ | - | - | **å…è´¹** |
| å¯ç–‘å†…å®¹ï¼ˆéœ€L2ï¼‰ | å…è´¹ | å…è´¹ | - | **å…è´¹** |
| é«˜é£é™©å†…å®¹ï¼ˆéœ€L3ï¼‰ | å…è´¹ | å…è´¹ | ~$0.001 | **~$0.001** |
| æ¯100è½®å¯¹è¯ä¼°ç®— | - | - | - | **<$0.01** |

> ğŸ’¡ **è®¾è®¡ä¼˜åŠ¿**ï¼š90%+ çš„æ£€æµ‹åœ¨ L1 å®Œæˆï¼ˆå…è´¹ï¼‰ï¼Œåªæœ‰çœŸæ­£å¯ç–‘çš„å†…å®¹æ‰è§¦å‘ L3ï¼ˆLLMï¼‰

---

**è¿™ä¸ªè®¡åˆ’æ»¡è¶³ä½ çš„è¦æ±‚å—ï¼Ÿå¦‚æœç¡®è®¤ï¼Œæˆ‘å¯ä»¥å¼€å§‹å®ç° Phase 1ã€‚**